[{"categories":["Generative"],"contents":" Survey of Diffusion, Flow Models Keyword: Bayesian, VAE, Diffusion Models, Score Models, Schrodinger Bridge, Normalizing Flows, Rectified Flows, Neural ODE, Consistency Models Abstract\n2013년 VAE[Kingma \u0026amp; Welling, 2013.], 2014년 GAN[Goodfellow et al., 2014.]을 지나 2020년의 DDPM[Ho et al., 2020.]과 2022년의 Flow Matching[Lipman et al., 2022.]까지, 생성 모델은 다양한 형태로 발전해 왔다. 기존까지의 생성 모델을 짚어보고, 앞으로의 방향성에 관하여 고민해 보고자 한다.\nIntroduction\nSupervised Learning에서는 흔히 입력 데이터 $x\\in X$와 출력 데이터 $y\\in Y$를 가정한다. 이때 데이터셋 $D = \\{(x, y)\\}$의 분포 $\\Pi(X, Y)$를 X와 Y의 Coupling이라 정의하자(i.e. $(x, y)\\sim\\Pi(X, Y)$). 단순히는 dirac delta $\\delta$에 대해 $\\Pi(X, Y)$의 pdf를 $p_{X, Y}(x, y) = \\delta_{(x, y)\\in D}; (x, y)\\in (X, Y)$로 가정해볼 수 있다.\n많은 경우에 Supervised Learning은 parametrized function $f_\\theta: X \\to Y$를 통해 $x\\mapsto y$의 대응을 학습하고, 조건부 분포의 likelihood를 maximizing 하는 방식으로 이뤄진다.\n$$\\hat\\theta = \\arg\\max_\\theta \\sum_{(x, y)\\sim\\Pi(X, Y)} \\log p_{Y|X}(f_\\theta(x)|x)$$\n만약 조건부 분포를 정규 분포로 가정한다면, 이는 흔히 알려진 Mean Squared Error의 형태로 정리된다.\n$$\\log p_{Y|X}(f_\\theta(x)|x) \\propto -||f_\\theta(x) - y||^2 + C \\implies \\hat\\theta = \\arg\\min_\\theta \\sum_{(x, y)\\sim\\Pi(X, Y)}||f_\\theta(x) - y||^2$$\n생성 모델(Generative Model)은 주어진 데이터의 확률 분포 학습을 목표로 한다. 이는 데이터로부터 probability density function을 추정하거나(혹은 probability mass function), Generator의 학습을 통해 데이터 분포의 표본을 생성하고자 한다.\ni.e. 데이터 $X$의 분포를 $\\pi_X$라 할 때, $\\pi_X$의 pdf $p_X(x)$를 construct 하거나, known distribution(e.g. $\\mathcal N(0, I)$)의 표본 $z\\sim Z$를 데이터 분포의 한 점 $x\u0026rsquo;\\sim\\pi_X$으로 대응하는 Generator $G: Z \\to X$를 학습한다.\n이 경우 대부분 사전 분포와 데이터 분포의 Coupling은 독립으로 가정하며(i.e. $\\Pi(Z, X) = \\pi_Z\\times \\pi_X$), parameterized generator $G_\\theta$에 대해 log-likelihood(i.e. $\\log p_X(x)$)를 maximizing 하거나, 분포 간 거리를 측정할 수 있는 differentiable objective $D$를 최적화하기도 한다(i.e. $\\min_\\theta \\sum_{(x, z)\\sim\\Pi(Z, X)} D(G_\\theta(z), x)$).\nGenerator가 $z\\sim Z$의 조건부 분포를 표현하는 것은 자명하다(i.e. $G_\\theta(z)\\sim p_{\\theta, X|Z}(\\cdot|z)$). 전자의 상황에서 우리는 $p_X$의 형태를 모를 때(혹은 가정하지 않을 때), 조건부 분포를 $Z$에 대해 marginalize 하여(i.e. $p_{\\theta, X}$) 데이터셋 $X$에 대해 maximize 하는 선택을 할 수 있다. $\\max_\\theta \\sum_{x\\sim\\pi_X}\\log p_{\\theta, X}(x)$\n(후자는 GAN에 관한 논의로 이어지므로, 현재의 글에서는 다루지 않는다.)\n조건부 분포를 marginalize 하기 위해서는 $p_{\\theta,X}(x) = \\int_Z p_Z(z)p_{\\theta,X|Z}(x|z)dz$의 적분 과정이 필요한데, neural network로 표현된 $G_\\theta$의 조건부 분포 $p_{\\theta,X}$를 적분하는 것은 사실상 불가능하다(intractable).\n만약 이를 $\\Pi(X, Y)$에 대해 충분히 Random sampling 하여 Emperical average를 취하는 방식으로 근사한다면(i.e. Monte Carlo Estimation), 대형 데이터셋을 취급하는 현대의 문제 상황에서는 Resource Exhaustive 할 것이다. 특히나 Independent Coupling을 가정하고 있기에, Emperical Estimation의 분산이 커 학습에 어려움을 겪을 가능성이 높다. 분산을 줄이기 위해 표본을 늘린다면 컴퓨팅 리소스는 더욱더 많이 필요할 것이다.\n현대의 생성 모델은 이러한 문제점을 다양한 관점에서 풀어 나간다. Invertible Generator를 두어 변수 치환(change-of-variables)의 형태로 적분 문제를 우회하기도 하고, 적분 없이 likelihood의 하한을 구해 maximizing lower bound의 형태로 근사하는 경우도 있다.\n아래의 글에서는 2013년 VAE[Kingma \u0026amp; Welling, 2013.]부터 차례대로 각각의 생성 모델이 어떤 문제를 해결하고자 하였는지, 어떤 방식으로 해결하고자 하였는지 살펴보고자 한다. VAE[Kingma \u0026amp; Welling, 2013., NVAE; Vahdat \u0026amp; Kautz, 2020.]를 시작으로, Normalizing Flows[RealNVP; Dinh et al., 2016., Glow; Kingma \u0026amp; Dhariwal, 2018.], Neural ODE[NODE; Chen et al., 2018], Score Models[NCSN; Song \u0026amp; Ermon, 2019., Song et al., 2020.], Diffusion Models[DDPM; Ho et al., 2020., DDIM; Song et al., 2020.], Flow Matching[Liu et al., 2022., Lipman et al., 2022.], Consistency Models[Song et al., 2023., Lu \u0026amp; Song, 2024.], Schrodinger Bridge[DSBM; Shi et al., 2023.]에 관해 이야기 나눠본다.\nVAE: Variational Autoencoder\nVAE: Auto-Encoding Variational Bayes, Kingma \u0026amp; Welling, 2013. [arXiv:1312.6114] 2013년 Kingma와 Welling은 VAE를 발표한다. VAE의 시작점은 위의 Introduction과 같다. Marginalize 과정은 intractable하고, Monte Carlo Estimation을 하기에는 컴퓨팅 자원이 과요구된다.\n이에 VAE는 $z$의 intractable posterior $p_{Z|X}(z|x) = p_{Z, X}(z, x)/p_X(x)$를 approximate posterior $E_\\phi(x)\\sim p_{\\phi,Z|X}(\\cdot|x)$ 로 대치하는 방식을 택한다. (아래는 편의를 위해 $q_\\phi(z|x) = p_{\\phi,Z|X}(z|x)$로 표기한다.)\n$$\\begin{align*} \\log p_{\\theta, X}(x) \u0026amp;= \\mathbb E_{z\\sim q_\\phi(\\cdot|x)} \\log p_{\\theta, X}(x) \\\\ \u0026amp;= \\mathbb E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log p_{\\theta, X}(x) + \\log\\frac{p_{\\theta,Z,X}(z, x)q_\\phi(z|x)}{p_{\\theta,Z,X}(z, x)q_\\phi(z|x)}\\right] \\\\ \u0026amp;= \\mathbb E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\frac{p_Z(z)p_{\\theta,X|Z}(x|z)\\cdot q_\\phi(z|x)}{p_{\\theta,Z|X}(z|x)\\cdot q_\\phi(z|x)} \\right] \\\\ \u0026amp;= \\mathbb E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\frac{q_\\phi(z|x)}{p_{\\theta,Z|X}(z|x)} - \\log\\frac{q_\\phi(z|x)}{p_Z(z)} + \\log p_{\\theta,X|Z}(x|z)\\right] \\\\ \u0026amp;= D_{KL}(q_\\phi(z|x)||p_{\\theta,Z|X}(z|x)) - D_{KL}(q_\\phi(z|x)||p_Z(z)) + \\mathbb E_{z\\sim q_\\phi(\\cdot|x)}\\log p_{\\theta,X|Z}(x|z) \\end{align*}$$\n$q_\\phi(z|x)$의 도입과 함께 $\\log p_{\\theta, X}(x)$는 위와 같이 정리된다. 순서대로 $D_{KL}(q_\\phi(z|x)||p_{\\theta,Z|X}(z|x))$은 approximate posterior와 true posterior의 KL-Divergence, $D_{KL}(q_\\phi(z|x)||p_{Z}(z))$는 사전 분포 $p_Z(z)$와의 divergence, $\\mathbb E_{z\\sim q_\\phi(\\cdot|x)}\\log p_{\\theta, X|Z}(x|z)$는 reconstruction을 다루게 된다.\n여기서 계산이 불가능한 true posterior $p_{\\theta, Z|X}(z|x)$를 포함한 항을 제외하면, 다음의 하한을 얻을 수 있으며 이를 Evidence Lower Bound라 한다(이하 ELBO). VAE는 ELBO $\\mathcal L_{\\theta, \\phi}$를 Maximize 하는 방식으로 확률 분포를 학습한다.\n$$\\log p_{\\theta, X}(x)\\ge \\mathbb E_{z\\sim q_\\phi(\\cdot|x)}\\log p_{\\theta, X|Z}(x|z)- D_{KL}(q_\\phi(z|x)||p_Z(z)) = \\mathcal L_{\\theta, \\phi}(x)\\ \\ (\\because D_{KL} \\ge 0)$$\nELBO를 maximize하는 과정은 approximate posterior가 사전 분포와의 관계성을 유지하면서도, 데이터를 충분히 결정지을 수 있길 바라는 것이다.\n이 과정은 Expectation 내에 $z\\sim q_\\phi(\\cdot|x)$의 Sampling을 상정하고 있지만, Sampling 자체는 미분을 지원하지 않아 Gradient 기반의 업데이트를 수행할 수 없다. VAE는 이를 우회하고자, approximate posterior의 분포를 $z\\sim \\mathcal N(\\mu_\\phi(x), \\sigma_\\phi^2(x)I)$의 Gaussian으로 가정하고, $z = \\mu_\\phi(x) + \\sigma_\\phi(x)\\zeta;\\ \\zeta\\sim \\mathcal N(0, I)$로 표본 추출을 대치하여 $E_\\phi = (\\mu_\\phi, \\sigma_\\phi)$ 역시 학습할 수 있도록 두었다(i.e. reparametrization trick).\n이때 $z_i\\sim\\mathcal N(\\mu_\\phi(x), \\sigma^2_\\phi(x)I)$를 몇 번 샘플링하여 평균을 구할 것인지 실험하였을 때(i.e. $1/N\\cdot \\sum_i^N\\log p(x|z_i)$), 학습의 Batch size가 커지면(논문에서는 100개) 각 1개 표본만을 활용해도(N=1) 성능상 큰 차이가 없었다고 한다.\nmu, sigma = E_phi(x) # reparametrization z = mu + sigma * torch.randn(...) # ELBO loss = ( # log p(x|z) (x - G_theta(z)).square().mean() # log p(z) + z.square().mean() # - log q(z|x) - ((z - mu) / sigma).square().mean() ) VAE는 Approximate posterior를 도입하여 Intractable likelihood를 근사하는 방향으로 접근하였고, Posterior 기반 Coupling을 통해 분산을 줄여 Monte Carlo Estimation의 시행 수를 줄일 수 있었다.\n하지만 VAE 역시 여러 한계를 보였다.\n$D_{KL}(q_\\phi(z|x)||p_Z(z))$의 수렴 속도가 다른 항에 비해 상대적으로 빨라 posterior가 reconstruction에 필요한 정보를 충분히 담지 못하였고, 이는 Generator의 성능에 영향을 미쳤다. 이에 KL-Annealing/Warmup 등의 다양한 엔지니어링 기법이 소개되기도 한다.\n또한, 뒤에 소개될 Normalizing Flows, Diffusion Models, GAN에 비해 Sample이 다소 Blurry 하는 등 품질이 높지 않았다. 이에는 Reconstruction loss가 MSE의 형태이기에 Blurry 해진다는 이야기, Latent variable의 dimension이 작아 그렇다는 이야기, 구조적으로 Diffusion에 비해 NLL이 높을 수밖에 없다는 논의 등 다양한 이야기가 뒤따랐다.\n이에 VAE의 성능 개선을 위해 노력했던 연구 중, NVIDIA의 NVAE 연구를 소개하고자 한다.\nNVAE: A Deep Hierarchical Variational Autoencoder, Vahdat \u0026amp; Kautz, NeurIPS 2020. [arXiv:2007.03898] NVAE(Nouveau VAE)는 프랑스어 Nouveau: 새로운의 뜻을 담아 make VAEs great again을 목표로 한다.\n당시 VAE는 네트워크를 더 깊게 가져가고, Latent variable $z$를 단일 벡터가 아닌 여럿 두는 등(e.g. $z = \\{z_1, \u0026hellip;, z_N\\}$) Architectural Scaling에 초점을 맞추고 있었다(e.g. VDVAE; Child, 2020.). 특히나 StyleGAN[Karras et al., 2018., Karras et al., 2019.], DDPM[Ho et al., 2020.] 등의 생성 모델이 Latent variable의 크기를 키우며 성능을 확보해 나가는 당대 분위기상 VAE에서도 유사한 시도가 여럿 보였다[blog:Essay: VAE as a 1-step Diffusion Model].\nFigure 2: The neural networks implementing an encoder and generative model. (Vahdat \u0026amp; Kautz, 2020)\nNVAE는 latent groups $z = \\{z_1, z_2, \u0026hellip; z_L\\}$에 대해 $q(z|x) = \\Pi_l q(z_l|z_{\u0026lt;1}, x)$의 hierarchical approximate posterior를 활용한다. ELBO는 다음과 같다.\n$$\\mathcal L_{VAE}(x) = \\mathbb E_{q(z|x)}[\\log p(x|z)] - D_{KL}(q(z_1|x)||p(z_1)) - \\sum^L_{l=2}\\mathbb E_{q(z_{\u0026lt;l}|x)}[D_{KL}(q(z_l|x, z_{\u0026lt;l})||p(z_l))]$$\nEncoder가 이미지로부터 feature map r를 생성(i.e. hierarchical approximate posterior, $q(z_l|x, z_{\u0026lt;l})$), Decoder가 trainable basis h로부터 Encoder feature map을 역순으로 더해가며 이미지를 생성하는 U-Net 구조를 상상하자. Generation 단계에서는 Encoder feature map r이 주어지지 않기에, feature map의 prior distribution $p(z_l)$의 샘플로 대체한다. 이는 어찌 보면 Spatial noise를 더해가는 StyleGAN[Karras et al., 2018.]과도 형태가 유사하다.\n다만 이 경우, $D_{KL}$의 조기 수렴에 따라 posterior collapse가 발생할 가능성이 높기에, 여러 engineering trick이 함께 제안되었다. Decoder에는 Depthwise-seperable convolution을 활용하지만 Encoder에서는 사용하지 않고, SE Block[Hu et al., 2017.]과 Spectral regularization, KL Warmup 도입, Batch normalization의 momentum parameter 조정 등이 있다.\n이를 통해 실제로 당시 Normalizing Flows와 VAE 계열 모델 중에서는 좋은 성능을 보였다. 하지만 논문에서는 NLL(bit/dim)에 관한 지표만 보일 뿐, FID나 Precision/Recall 등 지표는 보이지 않아 다른 모델과의 비교는 쉽지 않았다.\n정성적으로 보았을 때는 NVAE는 여전히 다소 Blurry 한 이미지를 보이거나, 인체의 형태가 종종 왜곡되는 등의 Degenerate Mode가 관찰되며 아쉬운 모습을 보이기도 했다.\nNormalizing Flows\nRealNVP: Density estimation using Real NVP, Dinh et al., 2016. [arXiv:1605.08803] VAE가 연구되는 동시에 approximate posterior 도입 없이 marginal $\\log p_{\\theta,X}(x)$를 구하려는 시도가 있었다.\n만약 parametrized generator $G_\\theta: Z \\to X$가 가역함수(혹은 전단사함수, Bijective)이면 marginal pdf는 변수 치환 법칙에 따라 $p_{\\theta,X}(x) = p_Z(f^{-1}(x))\\left|\\frac{\\partial f^{-1}(x)}{\\partial x}\\right|$를 만족한다.\n적분 없이도 determinant of jacobian을 구함으로 marginal을 구할 수 있게 되었고, 이 과정이 differentiable 하다면 gradient 기반의 학습도 가능하다. 문제는 뉴럴 네트워크 가정에서 jacobian을 구한 후, 이미지 pixel-dimension에서 $O(n^3)$의 determinant 연산을 수행해야 한다는 것이다(e.g. 256x256 이미지의 경우 281조, 281 Trillion).\nRealNVP는 현실적인 시간 내에 이를 수행하기 위해 Coupling layer를 제안한다.\n$$\\begin{align*} y_{1:d} \u0026amp;= x_{1:d} \\\\ y_{d+1:D} \u0026amp;= x_{d+1:D} \\odot \\exp(s_\\theta(x_{1:d})) + t_\\theta(x_{1:d}) \\end{align*}$$\nAffine coupling layer는 hidden state를 반으로 나눠 한 쪽을 유지한 채, 나머지 반에 다른 반을 기반으로 affine transform을 가한다. 이는 가역 연산으로, 절반의 원본을 통해 다른 절반의 역연산이 가능하며, 연산 복잡도 역시 순연산과 동일하다.\n$$\\begin{align*} x\u0026rsquo;_{1:d} \u0026amp;= y _{1:d} \\\\ x\u0026rsquo; _{d+1:D} \u0026amp;= (y _{d+1:D} - t _\\theta(y _{1:d})) \\odot \\exp(-s _\\theta(y _{1:d})) \\end{align*}$$\nAffine coupling layer의 Jacobian matrix는 $y_{1:d}$와 $x_{1:d}$가 identity mapping이기에 identity matrix를 형성, $y_{1:d}$는 $x_{d+1:D}$에 dependent 하지 않기 때문에 zeroing out 되고, $y_{d+1:D}$와 $x_{d+1:D}$는 element-wise linear 관계로 diagonal matrix가 되어, 최종 low triangular block matrix의 형태로 구성된다. 이 경우 determinant는 별도의 matrix transform을 거치지 않고 대각 원소의 곱으로 곧장 연산해 낼 수 있다.\n$$\\begin{align*} \\frac{\\partial y}{\\partial x} \u0026amp;= \\left[\\begin{matrix} \\mathbb I_d \u0026amp; 0 \\\\ \\frac{\\partial y_{d+1:D}}{\\partial x_{1:d}} \u0026amp; \\mathrm{diag}[\\exp(s(x_{1:d}))] \\end{matrix}\\right] \\\\ \\det\\frac{\\partial y}{\\partial x} \u0026amp;= \\prod_{i=d+1}^D \\exp(s_i(x_{1:d})) = \\exp\\left(\\sum^D_{i=d+1}s_i(x_{1:d})\\right) \\end{align*} $$\nAffine coupling layer를 여러 개 쌓아 $f_2(f_1(z))$의 형태로 표현한다면, 역함수는 $f_1^{-1}(f_2^{-1}(x))$로 네트워크를 출력부부터 역순으로 연산해 나가면 되고, determinant 역시 각각 계산하여 구할 수 있다.\n$$\\det\\frac{\\partial f_2}{\\partial z} = \\det\\frac{\\partial f_2}{\\partial f_1}\\frac{\\partial f_1}{\\partial z} = \\left(\\det \\frac{\\partial f_2}{\\partial f_1}\\right)\\left(\\det\\frac{\\partial f_1}{\\partial z}\\right)$$\n다만 이 경우 한쪽에만 연산이 가해지는 형태이기에, Coupling layer 이후 shuffling $[y_{1:d}, y_{d+1:D}] = [x_{d+1:D}, x_{1:d}]$를 수행하여 각각의 청크가 모두 transform 될 수 있도록 구성한다.\n$$\\begin{align*} \\max_\\theta \\log p_{\\theta, X}(x) \u0026amp;= \\max_\\theta \\left[\\log p_Z(f_\\theta^{-1}(x)) + \\log\\left|\\det\\frac{\\partial f_\\theta^{-1}(x)}{\\partial x}\\right|\\right] \\\\ \u0026amp;= \\max_\\theta \\left[\\log p_Z(f_\\theta^{-1}(z)) - \\exp\\left(\\sum^L_{l=1}\\sum^D_{i=d+1}s^l_{\\theta,i}(x^l_{1:d})\\right)\\right] \\end{align*}$$\nL개 affine coupling layer w/shuffling으로 구성된 네트워크 $f_\\theta$의 최종 objective는 위와 같다.\nNormalzing Flow는 Network의 형태를 제약함으로 Generation과 함께 exact likelihood를 구할 수 있게 되었고, 별도의 Encoder 없이 posterior를 구할 수 있다는 장점이 있다.\n하지만 반대로, 네트워크의 형태에 제약을 가하기에 발생하는 approximation의 한계가 발생할 수 있다. 자세한 내용은 뒤에서 논의한다.\nGlow: Generative Flow and Invertible 1x1 Convolutions, Kingma \u0026amp; Dhariwal, 2018. [arXiv:1807.03039] Glow는 이에서 더 나아가, 256x256 크기의 이미지까지 연구를 확장하여 그 실용성을 보였다.\n기본적으로 가역 함수와 치환 법칙을 기저로 하며, RealNVP에서 몇 가지 네트워크 구조를 수정하였다.\n가장 먼저 Batch Normalization을 Activation Normalization으로 교체한다. 당시 GPU VRAM은 10GB (1080TI, 2080TI) 정도로, 이미지의 크기가 조금만 커져도 배치의 크기를 1~2까지로 줄여나가야 했다. 이러한 상황에서 BN의 Moving statistics는 noisy 했고, 성능 하락을 감안해야 했다.\n이에 Glow는 최초 Forward pass에서 normalization 직전 레이어의 평균과 표준편차를 연산하여 저장해두고, 이를 토대로 normalization을 수행한다. 한 번 초기화된 파라미터는 이후 별도의 이동 평균 처리나 통계치 재연산을 수행하지 않고, 일반적인 trainable constant로 여긴다. 이를 data-dependent initalization이라 하고, 위 정규화 레이어를 activation normalization이라 한다.\n# PSEUDO CODE OF DATA-DEPENDENT INITIALIZATION def __init__(self): super().__init__() self.mean, self.logstd = None, None def forward(self, x: Tensor) -\u0026gt; tuple[Tensor, Tensor]: # x: [B, C, H, W] if self.mean is None: with no_grad(): self.register_parameter( \u0026#34;mean\u0026#34;, nn.Parameter(x.mean(dim=[0, 2, 3], keepdim=True)), ) self.register_parameter( \u0026#34;logstd\u0026#34;, nn.Parameter(x.std(dim=[0, 2, 3], keepdim=True).log()), ) norm = (x - self.mean) * (-self.logstd).exp() logdet = -self.logstd return norm, logdet def inverse(self, y: Tensor) -\u0026gt; Tensor: assert self.mean is not None return y * self.logstd.exp() + self.mean ActNorm은 첫 배치에서 zero-mean, unit-variance의 feature map을 반환하여 학습을 안정화하고, 이후는 학습에 따라 자연스레 값을 바꿔나간다.\nFYI. DDI는 Weight normalization[Salimans \u0026amp; Kingma, 2016.]에서 효과가 확인된 바 있다.\n다음은 Invertible 1x1 convolution이다. RealNVP가 Shuffling을 통해 절반의 feature map에 연산이 가해지지 않던 문제를 해결했다면, Glow는 가역 행렬을 channel-axis에 곱함으로(1x1 conv), 채널 축의 정보 공유를 학습 가능하도록 두었다(generalized permutation).\n우선 초기화 단계에서 QR 분해를 통해 1x1 Convolution의 Random weight matrix W가 invertible 하게 두었고, 이후에는 $\\log|\\det W|$를 직접 연산하여 objective에 활용(torch.linalg.slogdet), inference에는 weight의 역행렬을 구하여 활용한다(torch.linalg.inv).\n다만 이 경우 channel-axis의 크기가 커질 경우 연산량에 부담이 생길 수 있으므로, 다음과 같이 LU Decomposition을 활용하여 연산량을 줄여볼 수도 있다.\ndef __init__(self, channels: int): super().__init__() weight, _ = torch.linalg.qr(torch.randn(channels, channels)) p, l, u = torch.linalg.lu(weight) self.p = nn.Parameter(p) self.l = nn.Parameter(l) self.u = nn.Parameter(u) self.s = nn.Parameter(torch.diagonal(u)) self.register_buffer(\u0026#34;i\u0026#34;, torch.eye(channels), persistent=False) @property def weight(self): return self.p @ (self.l.tril(-1) + self.i) @ (self.u.triu(1) + self.s) def forward(self, x: torch.Tensor) -\u0026gt; tuple[torch.Tensor, torch.Tensor]: b, c, h, w = x.shape shuffled = F.conv2d(x, self.weight[..., None, None]) logdet = self.s.abs().log().sum() * h * w return shuffled, logdet def inverse(self, y: torch.Tensor) -\u0026gt; torch.Tensor: return F.conv2d(x, torch.linalg.inv(self.weight)[..., None, None]) 마지막으로 affine coupling layer의 두 개 네트워크 $t_\\theta, s_\\theta$의 마지막 convolution 레이어를 zero-initialize하여 학습의 첫 forward pass에서는 identity mapping이 되도록 구성하였다. 이는 LayerScale[Touvron et al., 2021.]처럼 레이어가 많은 네트워크를 운용할 때 학습을 안정화한다고 알려져 있다.\n이러한 트릭을 활용하여 Glow는 256x256 이미지에서도 좋은 합성 결과를 보였고, 아직도 likelihood 기반의 새로운 학습 방법론이 소개될 때마다 베이스라인으로 인용되고 있다.\nCIF: Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows, Cornish et al., 2019. [arXiv:1909.13833] 앞서 이야기한 Bijective의 제약에 의해 발생하는 Approximation의 한계에 관하여 이야기해 보고자 한다.\nExact Support Matching\nNormalizing flows는 대표적인 pushforward measure이다.\ni.e. measurable space $(Z, \\Sigma_Z, \\mu_Z)$, $(X, \\Sigma_X)$와 measurable mapping $f: Z \\to X$에 대해 $f_\\# p_Z = p_Z(f^{-1}(B)); B \\in \\Sigma_X$를 Pushforward measure라 한다. (w/sigma algebra $\\Sigma_Z, \\Sigma_X$ of $Z, X$)\nNormalizing flows는 특히 generator $f$를 전단사함수로 가정하기 때문에, $\\mathrm{supp}\\ p_X$와 $\\overline{f(\\mathrm{supp}\\ p_Z)}$가 같아야 한다. i.e. support of $p_X$, $\\mathrm{supp}\\ p_X = \\{x \\in X : \\forall \\mathrm{open}\\ U \\ni x,\\ p_X(U) \\ge 0 \\}$, closure of $S$, $\\overline S$\nFYI. 직관적으로 support는 사건의 발생 확률이 0보다 큰 원소의 집합이다. 확률이 존재하는 공간을 전단사 함수로 대응하였을 때, 대응된 원소 역시 발생 가능성이 0보다 커야 함을 의미한다.\nRealNVP, Glow 등의 Normlizing flows는 대부분 연속 함수이다(tanh, relu, sigmoid 등의 연속 활성함수를 사용하는 네트워크 기반의 affine coupling을 가정). 동시에 전단사 함수이기 때문에 역함수 역시 연속 함수이고, 이 경우 $f$는 topological property를 보존하는 homeomorphism이다(위상 동형 사상).\n위상 동형인 $Z$와 $X$는 hole의 수, connected component의 수 등이 같아야 한다. 흔히 가정하는 정규 분포의 support는 hole을 가지지 않고, 1개의 connected components를 가진다. 만약 데이터의 분포가 두 Truncate Normal 분포의 mixture로 표현되어 그의 support가 2개의 connected components를 가진다면, 두 분포를 대응하는 연속 함수 형태의 normalizing flows를 construction 하는 데에 한계가 발생한다.\nLipschitz Constraints\n경우에 따라 Invertible ResNet[Behrmann et al., 2018.], Residual Flow[Chen et al., 2019.]는 invertibility를 위해 network의 lipschitz constant를 제약한다.\n$$\\mathrm{Lip}(f) = \\sup_{x\\ne y}\\frac{|f(x) - f(y)|}{|x - y|} \\implies |f(x) - f(y)| \\le \\mathrm{Lip}(f)|x - y|\\ \\forall x, y$$\nInjective $f$에 대해 bi-Lipschitz constant $\\mathrm{BiLip}\\ f = \\max\\left(\\sup_{z\\in Z}|J_{f(z)}|, \\sup_{x\\in f(Z)}|J_{f^{-1}(x)}|\\right)$를 정의하자(w/norm of jacobian $|J_\\cdot|$). homeomorphic하지 않은 두 topological space $Z$와 $X$는 $\\lim_{n\\to\\infty}\\mathrm{BiLip}\\ f_n = \\infty$일 때에만 $f_{n}\\#p_Z \\stackrel{D}{\\to}p_X$의 weak convergence를 보장한다(under statistical divergence $D$, i.e. $D(f_n\\#p_Z, p_X)\\to 0$ as $n\\to\\infty$).\nResidual Flow의 각 레이어가 Lipschitz Constant $K$를 갖는다면, N개 레이어로 구성된 네트워크 전체의 Lipschitz Constant는 최대 $K^N$이다. Homeomorphic하지 않은 임의의 pushforward measure $f_n\\#p_Z$를 $p_X$로 근사하기 위해서는 $K^N\\to\\infty$의 조건이 만족해야 하고, 그에 따라 무수히 많은 레이어를 요구할 수도 있다.\nNormalizing flows는 네트워크의 제약상 고질적으로 Exact support matching 문제와 Lipschitz-constrained network의 표현력 문제를 겪게 된다. Continuously Indexed Flow, CIF는 이를 해결하고자 augmentation을 제안한다.\nCIF는 bijective generator $G_\\theta$를 indexed family $\\{F_{\\theta, u}(\\cdot): Z \\to X\\}_{u\\in\\mathrm{supp}\\ U}$ 로 확장한다. $x = F _\\theta(z, u)$의 2 변수 함수를 생각한다면, u가 고정되어 있을 때, $z = F _\\theta^{-1}(x; u)$의 가역함수를 고려할 수 있다. $z$와 $x$는 여전히 change-of-variables의 관계인 반면, $u\\sim U$는 데이터의 차원과 무관한 잠재 변수이기에 variational inference의 대상이 된다.\nprior $p_U(u)$와 approximate posterior $q_\\phi(u|x)$를 가정하자. 우리의 목표는 $p_{\\theta, X}(x)$이고, graphical model을 가정할 때 joint는 $p_{\\theta, X,U}(x, u) = p_U(u)p_Z(F^{-1}_\\theta(x; u))\\left|\\frac{\\partial F^{-1} _\\theta(x)}{\\partial x}\\right|$이다. variational lowerbound는 다음과 같이 정리된다.\n$$\\mathrm E _{u\\sim q _\\phi(u|x)}\\log\\frac{p _{\\theta, X,U}(x, u)}{q _\\phi(u|x)} = \\mathbb E _{u\\sim q _\\phi(u|x)}\\left[\\log p _U(u) + \\log\\frac{p_Z(F^{-1} _\\theta(x; u))}{q _\\phi(u|x)}\\right] + \\log\\left|\\det\\frac{\\partial F^{-1} _\\theta(x)}{\\partial x}\\right|$$\nCIF는 여기서 더 발전시켜, prior $p_U(u)$를 $z$ 조건부 분포 $p_{\\theta, U|Z}(u|z) = \\mathcal N(\\mu_\\theta(z), \\Sigma_\\theta(z))$로 두어 학습의 대상으로 삼는다(i.e. $p_{\\theta, X, U}(F_\\theta(z; u), u) = p_{\\theta, U|Z}(u|z)p_Z(z)|J_{F^{-1}_\\theta}|$).\n이를 통해 저자는 homeomorphic하지 않은 두 공간에 대해서도 $F_\\theta$가 $Z$에서 $U$에 대해 항상 Surjective이면, CIF가 Exact support matching을 가능케 함을 보인다. lipschitz constraints가 존재하는 네트워크에서도 동일하다.\n$$\\forall z\\in\\mathrm{supp}\\ Z,\\ F_\\theta(z; \\cdot): U\\to X\\ \\mathrm{is\\ surjective} \\iff p_{\\theta, X} = p_X$$\nSurjective라는 어렵지 않은 조건 내에서 exact match가 가능한 해가 존재함을 보였고, 이의 학습 가능성은 emperical하게 NLL이 낮아짐을 통해 보인다.\n이렇게 Normalizing flows에서 데이터의 차원을 넘어 새로운 latent variable을 추가하는 형태를 agumentation이라 하고, ANF[Huang et al., 2020.], VFLow[Chen et al., 2020.]의 Concurrent work가 존재한다.\n이 두 논문 모두 augmented normalizing flow에 관한 emperical study를 보이며, VFlow의 경우 CIF와 유사히 augmented normalizing flow가 vanilla보다 NLL이 더 낮을 수 있음을 보인다.\nFFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models, Grathwohl et al., 2018. [arXiv:1810.01367] TBD\nReferences\nVAE: Auto-Encoding Variational Bayes, Kingma \u0026amp; Welling, 2013. [arXiv:1312.6114] GAN: Generative Adversarial Networks, Goodfellow et al., 2014. [arXiv:1406.2661] DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [arXiv:2006.11239] Flow Matching for Generative Modeling, Lipman et al., 2022. [arXiv:2210.02747] NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat \u0026amp; Kautz, 2020. [arXiv:2007.03898] RealNVP: Density estimation using Real NVP, Dinh et al., 2016. [arXiv:1605.08803] Glow: Generative Flow and Invertible 1x1 Convolutions, Kingma \u0026amp; Dhariwal, 2018. [arXiv:1807.03039] NODE: Neural Ordinary Differential Equations, Chen et al., 2018. [arXiv:1806.07366] NCSN: Generative Modeling by Estimating Gradients of the Data Distribution, Song \u0026amp; Ermon, 2019. [arXiv:1907.05600] Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., 2020. [arXiv:2011.13456] DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [arXiv:2006.11239] DDIM: Denoising Diffusion Implicit Models, Song et al., 2020. [arXiv:2010.02502] Rectified Flow: Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow, Liu et al., 2022. [arXiv:2209.03003] Flow Matching for Generative Modeling, Lipman et al., 2022. [arXiv:2210.02747] Consistency Models, Song et al., 2023. [arXiv:2303.01469] Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models, Lu \u0026amp; Song, 2024. [arXiv:2410.11081] DSBM: Diffusion Schrodinger Bridge Matching, Shi et al., 2023. [arXiv:2303.16852] VDVAE: Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images, Child, 2020. [arXiv:2011.10650] StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Karras et al., 2018. [arXiv:1812.04948] StyleGAN2: Analyzing and Improving the Image Quality of StyleGAN, Karras et al., 2019. [arXiv:1912.04958] Squeeze-and-Excitation Networks, Hu et al., 2017. [arXiv:1709.01507] CIF: Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows, Cornish et al., 2019. [arXiv:1909.13833] FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models, Grathwohl et al., 2018. [arXiv:1810.01367] Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks, Salimans \u0026amp; Kingma, 2016. [arXiv:1602.07868] LayerScale: Going deeper with Image Transformers, Touvron et al., 2021. [arXiv:2103.17239] Invertible Residual Networks, Behrmann et al., 2018. [arXiv:1811.00995] Residual Flows for Invertible Generative Modeling, Chen et al., 2019. [arXiv:1906.02735] Augmented Normalizing Flows: Bridging the Gap Between Generative Flows and Latent Variable Models, Huang et al., 2020. [arXiv:2002.07101] VFlow: More Expressive Generative Flows with Variational Data Augmentation, Chen et al., 2020. [arXiv:2002.09741] TODO Preliminaries Oksendal SDE\nBrownian Motion Model Ito process Ito Diffusion, Markovian Property Neural ODE\nNeural Ordinary Differential Equations, Chen et al., 2018. https://arxiv.org/abs/1806.07366 Score model Generative Modeling by Estimating Gradients of the Data Distribution, Song \u0026amp; Ermon, https://arxiv.org/abs/1907.05600 Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., https://arxiv.org/abs/2011.13456 DDPM Denoising Diffusion Probabilistic Models, Ho et al., 2020. https://arxiv.org/abs/2006.11239, https://revsic.github.io/blog/diffusion/ Diffusion Models Beat GANs on Image Synthesis, Dhariwal \u0026amp; Nichol, 2021. https://arxiv.org/abs/2105.05233 Variational Diffusion Models, Kingma et al., 2021. https://arxiv.org/abs/2107.00630, https://revsic.github.io/blog/vdm/ Denoising Diffusion Implicit Models, Song et al., 2020. https://arxiv.org/abs/2010.02502 Classifier-Free Diffusion Guidance, Ho \u0026amp; Salimans, 2022. https://arxiv.org/abs/2207.12598 [Blog] Essay: VAE as a 1-step Diffusion Model , https://revsic.github.io/blog/1-step-diffusion/ SDE \u0026amp; PF ODE Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., 2020. https://arxiv.org/abs/2011.13456 Rectified Flow \u0026amp; Flow Matching Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow, Liu et al., 2022. https://arxiv.org/abs/2209.03003 Flow Matching for Generative Modeling, Lipman et al., 2022. https://arxiv.org/abs/2210.02747 Simple ReFlow: Improved Techniques for Fast Flow Models, Kim et al., 2024. https://arxiv.org/abs/2410.07815s Improving the Training of Rectified Flows, Lee et al., 2024. https://arxiv.org/abs/2405.20320 Consistency Models Consistency Models, Song et al., 2023. https://arxiv.org/abs/2303.01469, https://revsic.github.io/blog/cm/ Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples, Vouitsis et al., 2024. https://arxiv.org/abs/2411.08954 Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models, Lu \u0026amp; Song, 2024. https://arxiv.org/abs/2410.11081 Bridge Diffusion Schrodinger Bridge Matching, Shi et al., 2023. https://arxiv.org/abs/2303.16852 Furthers Unified view SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows, Nielsen et al., 2020. https://arxiv.org/abs/2007.02731, https://revsic.github.io/blog/survaeflow/ Simulation-Free Training of Neural ODEs on Paired Data, Kim et al., 2024. https://arxiv.org/abs/2410.22918 Simulation-Free Differential Dynamics through Neural Conservation Laws, Hua et al., ICLR 2025. https://openreview.net/forum?id=jIOBhZO1ax Fewer-step approaches\nProgressive Distillation for Fast Sampling of Diffusion Models, Salimans \u0026amp; Ho, 2022. https://arxiv.org/abs/2202.00512 Tackling the Generative Learning Trilemma with Denoising Diffusion GANs, Xiao et al., 2021. InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation, Liu et al., 2023. https://arxiv.org/abs/2309.06380 One Step Diffusion via Shortcut Models, Frans et al,. 2024. https://arxiv.org/abs/2410.12557 Velocity consistency\nRectified Diffusion: Straightness Is Not Your Need in Rectified Flow, Want et al., 2024. https://arxiv.org/abs/2410.07303\nConsistency Flow Matching: Defining Straight Flows with Velocity Consistency, Yang et al., 2024. https://arxiv.org/abs/2407.02398\n[Blog] Essay: Generative models, Mode coverage, https://revsic.github.io/blog/coverage/\n","permalink":"https://revsic.github.io/blog/diffusion-survey/","tags":["Machine Learning","Deep Learning","Generative","Bayesian","DDPM","Denoising Diffusion","Diffusion","Consistency model","Normalizing flow","Stochastic Process","VAE","Likelihood","Oksendal","SDE"],"title":"[WIP] Diffusion, Flow Survey"},{"categories":["Writing"],"contents":"재미 삼아 24년 초 친구와 신점을 보러 갔다. 나한테 25년에는 하는 일이 바뀔 거란다.\n3월 복학\n23년 산업기능요원 복무가 종료된 후, 24년도 4학년으로 복학하였다. 퇴사하지 않고, 학업과 파트타임 업무를 병행하였다.\n이미 학업과 일의 병행은 경험한 적이 있다. 코로나 바이러스의 영향으로 모든 수업이 비대면이었던 20년 당시에도 회사 일과 3학년 수업을 병행하였다.\n당시에는 40시간 풀타임 근무였기에 특히나 고생이 많았다. 수업 시간에 맞춰 강의를 켜 출석만 챙기고, 퇴근 후에서야 강의를 제대로 다시 들으며 과제를 하였다. 이번에는 3일 출근-24시간 근무였기에 이전보다는 쉽겠다며 덥석 기회를 잡았다.\n처음 3주 정도는 굉장히 좋았다. 어찌 되었든 이틀은 출근하지 않아도 되었고, 다시 학교에 들어서서 수업을 들으러 가는 길이 좋았다. 아침 지하철역 빵집에서 소금빵 하나와 아이스 아메리카노를 사 들고 학교 정문에 들어서면 세상 그렇게 설렐 일이 없었다.\n24.04.02.혼자 찍고 있었는데, 가려니까 다른 사람들도 벚꽃 찍고 있었음\n수업은 수학과 과목이 특히 많았다. 4학년이어서 그런지, 졸업 학점 중 교양과 전공과목은 이미 거의 다 채워져 있었다. 부족한 부전공 과목 학점 위주로 채우다 보니 특히 그러했다. 듣고 싶던 수업 위주로 채워, 무엇 하나 부족함 없던 복학이라 생각했다.\n3주간 행복학 복학 생활을 즐긴 뒤 하나둘 현실감이 생겨갔다.\n우선 학교 자연대학이 너무 높다. 학교에서도 산 끝에 있어서 고도도 높고, 올라가는 길도 험하다. 전국 경사도 높은 대학에 있는 학교인데, 심지어는 학교에서도 제일 높이에 있다. 분명 전철역에서 산 빵인데, 건물에 도착하면 다 먹다 못해 소화도 다 한 기분이었다.\n반면 컴퓨터 공학 대학은 학교 후문에 있다. 연강인 날에는 그저 후문에서 정문 앞의 산 끝까지 달려야 한다. 지금 체력은 올해 1학기에 다 만든 것 같다.\n둘째는 수학 과목이 공부할 게 너무 많았다. 비록 이틀은 출근하지 않아 수업 끝나고 공부할 시간이 있었지만, 결국은 출근한 3일도 퇴근한 후에 카페로 출근해야 했다.\n6시 퇴근 - 저녁 식사 - 7시 카페 출근 - 3시간 공부 - 10시 퇴근의 굴레에 빠졌다. 3일 출근하면 일이 줄어들 것이라 누가 그러던가 업무량도 줄이지 못해 그저 3학년 병행의 후회를 되풀이 한 사람이 된 것 같았다.\n별 수 없었다. 내가 잡은 기회였고, 그냥 열심히 해야지 하면서 지냈다.\n수학과\n2학년 때 수학과 부전공을 신청하여 3학년 때부터 수학 전공을 듣게 되었다. 원래는 1학년 때 다전공을 신청하였지만, 미적 성적이 좋지 못해 거절되었다.\n4학년이 되고 졸업 기준을 보니 부전공으로 이수한 것은 신의 한 수였다. 다전공은 들어야 할 학점도 많고, 졸업 논문도 써야 한다고 들었다. 그에 비해 부전공은 학점도 적고, 졸업 논문 없이 수업 학점만 채우면 되니 좋아하는 공부를 가볍게 하기 좋았다.\n물론 그렇다고 내용이 가볍지는 않았다. 3학년 때 선형대수, 해석학까지만 해도 할 만하다고 생각했다.\n문제는 3년 회사 일만 하다가 학교에 돌아와 들은 수업이 복소해석, 위상, 현대대수였다. 한동안 손 놓고 있다가 돌아와서 주전공자들과 동일하게 학점 경쟁을 해야 하니 골머리가 아플 수밖에 없었다.\n그나마 위상수학은 할만했다. 오히려 컴퓨터를 하는 듯한 감각을 많이 받았다. 기존까지의 수적 구조를 위상 구조로 추상화하고 또 다른 방식으로 구체화하는 과정이 코드를 추상화하여 Trait을 만들고 implement 하는 과정과 상당히 흡사했다. 그리고 그를 통해 보장받는 어떠한 불변성 역시 개발을 하는 과정과 상당히 비슷하다 느꼈다.\n24.06.01.복소 과제 중\n복병은 복소수였다. 나름 음성 합성 공부를 하면서 신호 처리나 복소 공간에 대해 익숙하다 생각했는데, 이는 큰 오산이었다.\n안 그래도 아는 사람 없는 아싸 복학생인데, 수업 시간은 또 아침 9시다. 늦잠이라도 자면 못 들은 부분은 독학의 영역이다.\n안 그래도 영어로 수업해 더 난해한데, 복소 공간에서의 쌍곡 함수 표현, 미분 가능성에 다다르니 이제는 도를 닦는 기분이었다. 내 앞의 종교인이 심오한 인생의 철학을 연설하는데, 이를 알아듣지도 못하면서 고개를 끄덕이는 신도가 된 듯했다.\n할 수 있는 건 그저 퇴근하고 카페에 출근해 공부하는 것뿐이었다. 매주 나오는 과제를 풀고, 머리를 싸매는 것 말고는 할 수 있는 게 없었다.\n그럼에도 이런 시간이 아깝지 않았고, 마냥 좋았다. 물론 이 과제 언제 끝내지, 이거 끝내고 일도 마저 해야 하는데, 이런저런 고민에 골은 아파졌지만 하나의 문제를 오래 고민하지 못했던 사무실 공간에서 벗어나 문제 하나를 위해 고민하는 시간을 낼 수 있다는 것이 좋았다.\n그렇게 중간고사, 기말고사를 보았다. 예상대로 위상수학은 잘 보았고, 복소해석과 현대대수는 딱 평균만큼 보았다.\n시험 당일, 당연하게도 수학과 학생들은 삼삼오오 모여 본인들의 풀이에 관하여 이야기했다. 그 중 비상해 보이는 한 친구는 자신의 증명을 설명하고 있었다.\n실제로는 아닐 수도 있지만, 공부를 많이 하지 않았다고도 한다. 그때 또 그런 감정을 느꼈다.\n고등학생 당시 컴퓨터 보안 분야를 잘하는 친구가 있었다. 하루에 30분만 자고 1년을 살아도, 도저히 그 친구를 이기지 못할 것 같았다. 넘을 수 없는 벽을 보았고, 끝내 인공지능 분야로 넘어와 활동하게 되었다.\n수학과에서 그런 사람이었다. 원래는 수학과 대학원 진학도 고려하였지만, 그 사람을 보고 깔끔히 포기했다.\n인공지능 분야에서도 그런 사람을 만나면 어떻게 할지 고민했다. 꽤 태평했다.\n5년을 인공지능 개발자로 일하였고, 일하면서 정말 그런 사람이 없었냐면 그건 아닌 것 같다. 그럼에도 이 일을 계속하고 있다면, 난 앞으로 그냥 계속 이 일을 할 사람인가 보다 했다.\n졸업 프로젝트\n우리 과는 졸업 프로젝트를 진행해야 졸업이 가능하다. 지도 교수가 정해져야 하고, 2인 이상 팀으로 참여해야 한다.\n아직 졸업하지 않은 동기가 하나 있어 팀 선정이 어렵지는 않았다. 보안 분야로 취업하길 희망하는 친구였다 보니, 주제는 자연스럽게 보안으로 기울었다.\n졸업 프로젝트 주제는 교수가 사전에 제안을 하기도 하고, 경우에 따라 학생이 교수를 찾아가 주제를 제안하기도 한다.\n사전에 공지된 주제 중 보안 프로젝트는 많지 않았고, 여러 교수님을 컨택하던 중 LLM을 기반으로 Fuzzer를 개선하는 프로젝트로 결정하였다.\n처음 만난 교수님은 주에 2회 이상 연구실에 출근하라 하셨지만, 당시 나는 재직 중이었기에 현실적으로 어려운 일정이었다.\n두 번째 교수님은 주 1회 대면으로 진행 상항 보고만 하라 하셨다. 이 정도면 할만하다 싶어 결정하였는데, 막상 해보니 주 1회도 쉽지는 않았다. (동기들에게 들어보니, 학기에 2번만 뵌 교수님도 계셨다고 한다.)\n교수님에 따라 진행 방식에 편차가 있었다. 우리 프로젝트는 온보딩 기간과 연구 개발 기간으로 나뉘었고, 3월부터 7월까지는 Fuzzing 기술에 관한 온보딩, 8월부터는 실제 연구 개발을 수행하였다.\n3월 컨택이 마무리된 후, 교수님은 온보딩의 일환으로 매주 과제를 내주셨다. git+antonio-morales/Fuzzing101의 실습을 매주 1개씩 푸는 것이다. 보안 회사에 있었지만, 실제 Fuzzing을 해보는 것은 처음이었다.\n연구 개발 경과가 좋다면, 회사에서도 써볼 법한 기술이었기에 더 욕심이 생겨 열심히 했다.\nFuzzer도 돌리고, Crash가 나오면 코드 보면서 Root cause도 정리하여 보고서로 작성했다.\n하지만 현실적으로 직장 생활 - 수학과 과제 - 졸업 프로젝트를 모두 병행하는 것이 쉽지만은 않았다. 주로 수요일에 연구실로 찾아뵙고 준비된 자료를 발표하였다 보니, 보고가 끝나자마자 다음 실습 환경을 준비하여 Fuzzer를 돌려놓고, 주말에 하루는 크래시를 모아 분석, 하루는 수학과 과제를 하며 보냈다.\n생각보다 재밌었다. 당시 회사에서는 CVE 설명문을 토대로 PoC를 생성하는 시스템을 개발하고 있었는데, Fuzzer를 공부하다 보니, 이를 활용하여 특정 지점에서 Crash를 발생시키는 PoC를 생성해 볼 수 있지 않을까 싶었다.\n온보딩 기간은 무난하게 흘러갔다. 동기와 분석도 같이 하고, 발표 자료도 함께 정리하는 등 협업에 큰 무리가 없었다. 문제는 동기가 취업한 이후였다.\n동기는 졸업 전 마지막 학기에 취업에 성공하였다. 1학년 때부터 함께했던 친구였기에 진심으로 축하했다.\n하지만 동기는 입사 첫 주부터 야근을 달리게 되었다. 8시 출근, 새벽 1시에 퇴근하는 친구는 집에 도착하면 바로 잠에 들었다. 당연하게도 함께 졸업 프로젝트를 이어 가기는 쉽지 않았다.\n나는 퇴근 시간 조정이 가능했기에, 1학기 병행 때에도, 2학기 취업계를 내고도 퇴근 후 3~4시간은 졸프에 투자가 가능했다.\n결국 온보딩이 끝난 8월 넘어서는 홀로 졸프를 이어 나가게 되었다. 나무랄 수도 없었다. 누구보다 피곤해할 친구였기에, 홀로 진행한다 생각하고 미련 없이 그러려니 했다.\n프로젝트는 PromptFuzz[arXiv:2312.17677]를 개선하는 방향으로 이뤄졌다. 테스트가 부족한 영역에 LLM으로 Harness를 생성하여, 커버리지를 보강하는 방법론이다.\n저자가 공개한 코드가 있었기에; git+PromptFuzz/PromptFuzz 8월부터 실제로 벤치마크 데이터를 돌려보며 경향을 살폈다.\n벤치마크 프로젝트의 경향을 토대로 Taxonomy도 제안하고, 문제점도 정리하였다. 버그도 몇 가지 찾아 포크 레포에 정리해 두었다. git+revsic/PromptFuzz\n개선 방향성은 LLM Agent로 잡았다. PromptFuzz는 생성한 하네스를 평가하여, 부적절하다 판단된 하네스를 과감히 버리는데 이러다 보니 버려지는 하네스가 너무 많았고, 몇몇 API는 하네스에 반영조차 되지 못했다.\n평가에 통과하지 못한 사유를 LLM에게 전달하고, LLM이 하네스를 수정하여 재평가받을 수 있도록 파이프라인을 설계하였다. 이렇게 되면 하네스의 재사용성도 증가하고, 대부분의 API가 하네스에 포함될 수 있을 것이라 판단하였다.\nPromptFuzz를 파이썬으로 재구현하고, git+revsic/agent-fuzz 본격적으로 개선에 착수했다.\n역시나 개선은 마음처럼 되지 않았다. 코드를 주고받다 보니 Context-length는 늘어나 갔고, LLM의 코드 수정 성능은 하락, API 코스트는 증가했다.\nContext-length를 줄이는 트릭을 도입하고, 몇몇 엔지니어링을 추가 진행하였다. 결과적으로 대부분의 프로젝트에서 10~20%의 개선을 확인했다. 아쉽게도 2개 벤치마크 프로젝트에서는 오히려 성능 하락이 관찰되어 논문으로 정리하지는 않기로 하였다. 아마 조금 더 깎으면 되지 않을까 싶기도 하다.\n프로젝트가 종료되었고, 논문 대신 블로그 글을 하나 정리하고 있다. blog/agentfuzz\n아쉬움이 없지는 않았다. 회사에 재직 중이지 않았다면 더 깎아서 논문까지 정리해 볼 수 있지 않았을까 싶기도 하다.\n얻은 것도 많았다. 회사에서 DARPA AIxCC 대회에 참가 중인데, 여기서 경험한 것들을 토대로 개발 속도를 내고 있다. Context-length 길이 관리에 사용했던 트릭이나, Fuzzer 도입 등 여러 아이디어를 적용해 내고 있다. 이번 대회는 풀타임으로 참여하고 있기에 더 좋은 결과가 있기를 기대한다.\n5월 마지막 축제\n올해도 학교 축제에 다녀왔다. 졸업 전의 마지막으로 다녀올 축제였다.\n수업을 듣고 재학생 인증을 받으러 갔다. 학생증 인증을 하면 입장권을 주는데, 입장권이 있어야 중앙의 재학생 자리에 앉을 수 있다.\n생각보다 재학생 인증 줄이 길지는 않았지만, 공연장에 입장하는 줄이 정말 너무 길었다. 입장 2시간 전부터 서 있던 줄은, 노천극장에서 중앙도서관까지 산길을 따라 이어져 있었다. 선착순으로 입장하기 때문에, 재학생 자리에 들어가는 것은 포기했다.\n24.05.24.마지막 축제\n결국 극장 사진만 찍고, 컴퓨터 공학관으로 돌아왔다.\n학교에서는 학과마다 주점을 하나씩 내주고, 각 학과는 학생들에게 주점 자리를 예약받기도 한다.\n내가 활동했던 AI 동아리는 미리 자리를 잡아두었었고, 오랜만에 후배들도 볼 수 있었다. 오히려 아는 후배는 몇 없었고, 거의 새로 보는 얼굴들이었다.\n이미 이전에 갔던 엠티에서 90년대생이 나 혼자였기에, 이제는 졸업할 때가 되었나 보다 했는데 주점을 둘러보고는 진짜 졸업해야겠다는 생각을 많이 했다.\n졸업이 그다지 멀지도 않다는 생각에 싱숭생숭했다.\n10월 대학원 입시\n뒤에서 할 이야기이지만, 7월에 건강이 다시 안 좋아짐을 느끼고, 끝내 10월 팀장을 위임하고, 연구원으로 내려와 건강 회복에 집중했다.\n일을 덜어내고 어느 정도 상황과 건강이 안정되고 나니, 대학원이 눈에 들기 시작했다.\n이전부터 학위에 대한 생각은 가지고 있었다.\n첫 회사에서 처음 팀장을 하던 당시, 박사 학위를 막 취득하고 입사한 신입 사원은 나에게 당신을 인정할 수 없다며 자만하지 말라 했다.\n새로운 사람이 합류할 때마다 챌린지를 받아왔다. 막상 시간이 지나고 나면 업무 수행 능력도 인정받고, 신뢰도 쌓아 팀장 업무에 큰 무리는 없었다. 다만, 초기에 신뢰를 얻는 비용이 남들보다 많이 드는 것 같았다.\n나이가 어려서 그런가, 연차가 적어서 그런가, 학력이 짧아서 그런가 이런저런 고민을 많이 하였다.\n나이와 연차는 시간이 해결해 줄 수 있지만, 학력은 움직여야 했다. 그러다 보니 특히 대학원에 대해서는 기회가 될 때 가야겠다 생각하고 있었다.\n대학원에 가서는 연구에 집중하고 싶었다. 팀장으로 근무하다 보면, 이런저런 행정 작업이 많이 요구되는 시기가 있다. 채용, 성과 평가, 연봉 협상 등 인력 관리 / OKR, 투자자 보고 등 성과 관리 / 사업 기획, 영업 미팅 등 사업 관리\n연구에 집중하고 싶어도, 실질적으로 분기 말-반기 말-연말에는 행정 작업에 치여 연구를 하기 어렵다. 연구에 집중하더라도 성과가 사업적으로 이어질 수 없거나, 더 강한 사업적 기회가 발견되면 중단되는 경우도 잦았다.\n7월에서 9월은 특히 그러한 행정 업무의 강도가 강했다. 아예 직무를 사업 개발로 옮겨야 할 수준이었다.\n연구에 집중할 수 있는 환경을 만들고 싶었고, 팀장을 내려놓고 나니 대학원 생각이 나는 것은 당연한 수순이었다.\n대학원을 알아보기 시작했다. 대부분의 연구실이 학부 연구생으로 활동한 학생을 우선 선발하고 있었다.\n나는 재직 중이었기에 출퇴근이 필요한 학부 연구생 활동이 불가능하였고, 관심 있는 교수님께 메일을 보내 학부 연구생 활동 없이도 선발이 가능할지 의향을 물어보는 것이 최선이었다.\n그럼에도 긍정적인 반응을 전달주신 교수님이 계셨고, 합격증부터 가져오라 하셨다.\n퇴근 후 졸업 프로젝트도 하고, 이제는 입시 준비도 해야 한다. 이력서를 쓰고, 포트폴리오를 정리했다.\n근무 경력을 쓰기 위해서는 재직 증명서도 떼야 했는데, 현재 직장의 재직 증명서만 발송했다가, 전 직장은 경력으로 인정을 못 받기도 하였다.\n다른 동기들에게 물어보니 주로 졸업 프로젝트에서 작성한 논문을 많이들 낸다고 한다. 나는 당시 졸프를 진행하던 시기였고, 아직 논문이 없었기에 포트폴리오로 낼 것이 많지 않았다. 결국 경력 기술서 정도만 첨부하여 발송했다.\n운이 좋게 두 개 대학 서류 전형에 합격하였다. 다음은 면접이었다.\n한 학교는 면접 때 나올 수 있는 기술 질문을 정리하여 학과 홈페이지 공지 게시판에 올려두었다. 3년을 휴학하고 나니 이제는 질문을 봐도 답이 가물가물했다. 프림 알고리즘, 크루스칼 알고리즘, 데이터 해저드, 하나씩 다시 공부하며 답을 정리하였다.\n실제로 면접 당시 최소 신장 트리에 관한 질문이 나왔지만, 답을 썩 잘 하지는 않았던 것 같다.\n해당 학교는 하루에 두 번의 면접을 봐야 했는데, 운이 좋게도 두 면접 모두에 보안을 하던 교수님이 계셔서, 현재의 직장 경력을 긍정적으로 봐주신 듯하다.\n거의 2시간에 가까운 면접을 보았고, 할 수 있는 모든 것을 이야기하고 왔다.\n두 번째 학교는 따로 준비할 것이 제시되지는 않았다. 면접 10분 전에 질문지를 주고, 면접에서 문제의 풀이를 하는 방식이었다.\n면접은 15분 정도로 아주 짧게 이뤄졌고, 심지어는 문제도 다 못 풀었다 보니 아쉬움이 많이 남았다. 심지어는 60명 중 60번으로 면접을 보아, 이건 당연히 떨어졌다 했다.\n결과는 둘 모두 합격하였다. 한 분은 강화학습을 하는 교수님이셨고, 한 분은 비전을 하는 교수님이셨다.\n전 직장에서는 비전 합성을, 현 직장에서는 LLM 기반 보안 자동화를 하고 있었기에 어느 랩실을 선정하여도 큰 무리는 없었다.\n어떤 랩실을 가야 할지 고민하던 중, 비전 랩실을 결정하게 되었다.\n건강이 안 좋아지고 다시 병원에 통원 치료를 하고 있었는데, 당시 의료계 상황도 좋지 않다 보니, 병원을 옮기는 것에 부담을 느끼고 있었다.\n강화학습 랩실은 대전에 있었다 보니, 통원 치료가 더 부담이었다. 가까운 대학원으로 최종 선정하고, 교수님께도 상황을 설명하고 입학 포기 의사를 전달하였다.\n대학원 진학이 확실시된 후 회사에 퇴사 의사를 밝혔다.\n가장 많이 들은 반응은 왜 비전 연구실인지였다. 새로운 프로젝트의 시장 반응도 좋은데 지금 꼭 가야 하냐, 회사에서 LLM하고 보안 잘하고 있었는데 갑자기 비전 연구실이냐\n설명을 많이 드렸다. 전 직장에서 비전을 해왔고, 학위에 대한 결핍도 있었고, 연구 환경도 만들고 싶었다. 2년 정도 연구에 집중해 보고 싶다고 이야기했다.\n1월 마지막 주로 퇴사 일정을 조율하였다.\n2월에 학교 근처로 이사도 가고, 중순부터 연구실에 나가기로 했다. 그전까지 24년도에 쓰려고 했던 글들도 정리하고, 연구도 정리하려 한다.\n12월 계엄\n12월 3일 저녁 11시, 자려고 누웠는데 유튜브에 MBC 속보가 올라왔다. 비상계엄에 관한 대국민 담화였다. 전쟁인가 싶어 급하게 담화 전문을 살폈다.\n당황을 금치 못했다. 이 계엄이 정말 합헌적인지, 정말 저 사유로 계엄이 발생한 것인지 믿을 수 없어 두어번 더 읽었다.\n당연히도 그날 잠은 포기했다. 국회의 의결 후에도 계엄 해제 선포가 올라오지 않아 몇시간은 더 자지 못했다.\n걱정의 연속이었다. 안 그래도 정리해고의 소식이 잦았던 한 해였다. 환율은 급속도로 올랐고, 해외 투자자들은 빠져나갈 것이다.\n당장 해외 투자를 계획 중이었던 대부분의 회사는 굉장한 비보였을 것이다. 이제 더 이상 이런 기사는 남의 일이 아니었다. 이렇게 한 달, 두 달이 이어졌다간 내가 혹은 친구들이 다시 취직 시장으로 풀려나올 것이다.\n빠른 상황의 해결이 필요했다. 할 수 있는걸 하자 싶어 8일 집회에 향했다.\n엄청나게 많은 인파가 결집해 있었다. 또 너무 가까이 서 있을 때 사고가 날 수 있다며, 간격을 지키기 위한 노력도 돋보였다.\n24.12.14.여의도 공원\n14일 한 번 더 집회에 참여했다. 이번엔 가결되길 바라며 자리를 잡았다.\n사람들은 서로 가진 간식을 나눠주고, 방석을 빌려주기도 했다. 유독 추웠던 하루, 모두가 간절하게 국회를 향해 구호를 외치고 있었다.\n당일 표결, 모두가 현장의 스크린을 통해 중계를 바라보고 있었다. 가결 발표 후 현장의 모두는 환호성을 질렀다. 사람들은 그제서 하나둘 자리를 털고 일어났다.\n하지만 글을 쓰는 지금까지도 모든 것이 해결되지는 않았다. 조속히 재판이 마무리되고, 상황이 나아지길 바랄 뿐이다.\n여행\n올해도 종종 여행을 다녀왔다.\n팀장 위임이 결정되고 리프레시 겸 해운대에 다녀왔다. 항상 가던 호텔에 가고, 항상 가던 식당에 다녀왔다.\n매번 같은 곳에 가도 갈 때마다 좋다.\n24.09.19.부산\n코타키나발루로 가족 여행도 다녀왔다. 거의 4년 만의 해외여행이었다.\n관광지라 그런지, 점원 절반 이상이 한국어를 굉장히 잘했다. 심지어는 망고 시장에 존맛탱구리라 적혀 있어 크게 웃었다.\n확실히 휴양지였다. 시내 관광, 야시장, 스노클링까지 무엇하나 빠짐없이 재밌었다.\n특히 음식이 입에 잘 맞았다. 카야 토스트도 맛있었고, 쌀국수 역시 거슬리는 것 하나 없이 좋았다.\n말레이시아에서만 파는 맥주가 있었는데, 이 역시 챙겨 먹었다.\n귀국 전날 거의 3시간가량 해변에서 일몰을 보았는데, 지금까지 본 일몰 중에 가장 인상 깊었다.\n이래서 해외 여행 다니나 보다 했다.\n24.12.25.코타키나발루\n바로 다음 주에 대학 동기들과 삿포로에 다녀왔다.\n크리스마스 연휴에 붙여 목금 연차, 이듬 주 설 연휴에 붙여 목금 연차로 2주 정도 푹 쉬고 왔다.\n8명이라는 꽤 많은 인원이 같이 여행을 떠났다. 시내도 다니고, 맛집도 찾아다니며 즐거운 시간을 보냈다.\n특히 3일 내내 술을 마시는데, 하루 더 있었으면 술병이 날 뻔했다.\n요리를 잘하는 친구가 있어 안주도 많이 먹고, 공포 영화도 보고, 인생 상담도 하고, 연애 상담도 하고 나중에 또 가도 재밌을 것 같다.\n정말 오랜만에 뇌 빼고 잘 놀다 온 것 같다.\n25.01.01.삿포로\n맥주\n올해도 맥주 많이 마셨다. 올해는 98번까지 23캔 정도가 추가 되었다.\n이제 슬슬 편의점에서 새로운 맥주를 찾기 힘들다. 오히려 해외여행 두 번에서 새로 보는 맥주를 많이 마셨다. 이제는 원정을 떠나야 하나 싶다.\n올해는 제로 맥주도 많이 시도 했었는데, 끝까지 마신 맥주는 없었다. 알코올을 빼면서 사라진 향내와 그걸 메꾸기 위해 추가한 인공 감미료가 오히려 거북한 경우가 많았다.\n그나마 괜찮았던 것은 홉스플래시 IPA와 빅웨이브 골든 에일 정도였다. 원래는 캔에 들어있는 IPA는 쇳내가 많이 나 선호하지 않는데, 홉스플래시 IPA는 쇳내도 많지 않고, 홉 향의 쓴 내가 산미를 잘 잡아줘서 맛있게 마셨다. 빅웨이브 골든 에일은 에일 특유의 산미에 라거스러운 홉 향이 겹쳐 최근에 마신 에일 중에 가장 맘에 들었다.\n내년엔 100번은 무난히 채울 것 같고, 그다음에는 다른 주종에 대해서 도전해 볼까도 고민 중이다.\n76번부터 98번 맥주\nTheori\n1월 On-premise LLM 구축\n23년 12월 드디어 회사에 A100 서버가 한 대 들어왔다.\n서버 구매를 설득한 이유는 몇 가지 있었다. 우선 AWS가 너무 비싸다. 다른 GPU 클라우드 업체를 조사해도 12개월 이상 A100 GPU의 풀타임 임대가 이뤄지면 대여비가 구매비를 넘는다.\n아무래도 LLM을 기반으로 한 보안 기술 연구를 목표로 했기에, GPU 활용은 필연적이었다. 또, 고객사에서 보안상 이유로 외부 클라우드 배제를 희망하는 경우도 있어, 앞으로의 자동화 사업에 있어 사내 GPU 서버 구매는 꼭 필요한 상황이었다.\n서버가 들어오고 이제 실제로 On-premise LLM 서버를 구성하였다.\n당시에는 Llama-2-70B-chat이나 Mixtral 8x7B 정도가 후보에 있었고, 이를 어떻게 실시간에 가깝게 운영할지 고민하고 있었다.\n처음에는 내부 연구원이나 컨설턴트들이 사용할 수 있는 사내 서비스를 만드는 게 목표였는데, 아무래도 다들 ChatGPT나 Claude에 익숙하다 보니, 응답에 지연이 생기면 피드백이 썩 좋지 않았다.\nQuantization, Pruning 등 경량화 시도도 있었고, 전용 쿠다 커널도 찾아보며 이런저런 퍼포먼스 실험을 많이 하였다.\n문제는 대부분이 라마에 맞춰 개발된 프로젝트가 많았다 보니, MoE 기반의 Mixtral은 작동하지 않는 경우가 많았다.\n하루 이틀씩 투자해서 Mixtral에 맞게 코드 작업하고, 오픈소스에 기여하는 등 시간을 많이 가졌다. 그렇게 1k context-length 미만에서 30tok/sec, 12k 미만 20tok/sec까지 열심히 깎았다.\n그럼에도 GPT3.5나 당시에 막 출시한 GPT4보다는 오픈소스 모델 성능이 썩 좋지 않았기에, 범용 목적보다는 특정 작업에 맞게 파인튜닝된 모델이나 특수 파이프라인을 지원하는 방향으로 선회하였다.\n또 다른 문제는 GPU가 1대이다 보니, LLM 서빙이 이뤄지고 나면 학습 등 연구 목적으로는 사용이 불가능했다.\n당장 GPU를 추가 구매할 수는 없던 상황이다 보니, 결국 GPU 클라우드를 사용해야만 했다.\n프라이빗 클라우드까지 나가도 되는 정보와 사내에만 있어야 하는 정보를 나누고, API가 취급하는 정보에 따라 클라우드와 사내 서버로 로드를 나눴다.\n그럼에도 클라우드를 풀타임 운영하는 것에는 비용상 부담이 있었기에, 오토 스케일러도 함께 알아보았다. AWS는 스케일러를 지원하였지만, GPU 클라우드 중에서도 가장 비싼 편이었기에 후보에서 배제되었다.\n알아본 업체 중 보안도 잘 챙기고, 가격도 저렴한 업체로는 Runpod이 있었다. 다만 스케일러를 지원하지는 않았고, Runpod의 클라우드 인스턴스를 동적으로 올리고 내릴 수 있는 API를 지원했다.\n사내 서비스에서 주기적으로 사용량을 관찰하다, 일정 시간 동안 요청이 없을 때는 Runpod API로 인스턴스를 내리고, 요청이 발생하면 인스턴스를 띄우게 해두었다.\n마찬가지로 사내 서버에서도 vLLM 서비스를 띄워두었다가, 요청이 없을 때는 서비스를 내리고, 요청이 발생하면 vLLM 서버를 다시 띄우도록 해두었다.\n비용은 월 30만원까지 줄일 수 있었고, 서비스 운영과 연구 병행에도 큰 차질을 주지 않았다.\n2월 위협 시나리오 생성\nGPU 환경이 생기고 가장 먼저 연구한 주제는 위협 시나리오 생성이다. 소스 코드를 분석하여 자동으로 위협을 발굴할 수 있는가이다.\n사내에는 모의 해킹 교육용으로 만들어진 웹 서비스가 하나 있었는데, 가장 먼저는 해당 서비스에 심어져 있는 취약점을 찾는 시스템을 만드는 것이 목표였다.\n여러 가지 문제를 직면했다. 몇십만줄의 코드를 LLM에 모두 넣을 수도 없었고, 함수 단위로 넣으면 함수 내부의 위협은 발췌해도, 호출 관계나 비즈니스 로직 수준에서의 위협은 발굴할 수 없었다.\n상용 위협 시나리오 툴을 리서치하니, 대부분은 구성 컴퍼넌트와 데이터 플로우에 초점을 맞추고 있었다. 다만 RDB가 있다면 SQLi를 조심하라, 웹 서버가 있다면 XSS를 조심하라 등 다소 나이브하다 느껴졌다. 또한 시스템 내에 어떤 컴퍼넌트가 있고 어떤 데이터 플로우가 있는지를 사용자가 직접 입력해야 했다.\n이를 구체화하기 위해 우리는 어떤 데이터 플로우 다이어그램을 만들어야 실질적 위협을 검출할 수 있을지 의논했다. 특히 모의 해킹 교육용 서비스의 취약점이 발굴되기 위해서는 어떤 요소가 기입되어야 할지 케이스 스터디에 집중했다.\n서비스 컴퍼넌트를 어느 단위에 맞춰 노드로 정의할지, 각 노드는 어떤 속성을 지녀야 하는지, 데이터 플로우에는 어떤 정보가 들어가야 하고, 데이터의 제약 조건은 어떻게 전파할지, 다이어그램만으로 위협 발굴이 가능할지, 소스 코드까지 필요할지 다양한 논의가 이어졌다.\n여러 형태의 다이어그램을 LLM에 입력해 보며 LLM이 이해하기 위한 다이어그램의 형태에 관하여도 논의했다. 일차적인 다이어그램 명세가 정리되고, 원하는 위협이 모두 LLM에 의해 생성될 수 있음을 확인했다.\n이후 소스 코드로부터 다이어그램을 만들기 위한 시도가 이어졌다.\n다이어그램 생성 자체에서도 여러 난관이 있었다. 코드가 길어 함수 하나조차 LLM에 넣지 못할 때는 코드를 분할, LLM을 통해 노드의 속성을 추출하고 병합했다.\n단번에 다이어그램 전체를 만들 수는 없었기에, 몇 가지 단계로 나눠 순차적으로 다이어그램을 완성해 갔고, 노드의 크기와 단위에 따라 다이어그램도 추상화 단계에 맞춰 여럿 만들어 두었다.\nEnd-to-End 파이프라인을 완성하고, 실제 테스트 베드에서 위협이 생성됨을 확인했다.\n이제는 On-premise LLM에서도 작동하게 만들어야 한다. 특히 소스 코드는 고객사 자산 중에서도 특히 보안이 중요하기에, 대부분 클라우드로 나가는 것조차 꺼리는 편이다. OpenAI GPT를 기반으로 만들었기에, On-premise LLM에서의 작동 여부는 따로 확인해야 했다.\n오픈 소스 LLM 중 다이어그램 생산에 적합한 모델을 찾기 위해 케이스 스터디 당시에 만들어두었던 GT 페어를 토대로 평가용 데이터셋을 만들었다. 생성된 그래프를 데이터셋과 매칭하는 방식으로 자동화된 정량 평가를 수행했다.\n그렇게 여러 오픈 소스 LLM을 평가하여 하나를 골랐고, 프롬프트를 더 깎아 GPT 보다 나은 성능의 시스템을 만드는데 성공했다.\n이후에는 실사례에서 성공하는 경우를 보이기로 했다. Curl 같은 오픈소스 라이브러리에 있던 1-day 취약점을 동일 버전에서 위협으로 발굴할 수 있는가 보았다.\n몇몇은 실제로 찾아내기도 했고, 몇몇은 찾지 못했다. 문제는 생성한 몇천개의 위협 중에 실존하는 위협이 얼마나 있는지 분간이 어렵다는 것이다.\n모든 위협을 대상으로 PoC를 만들거나 검증하려 든다면 너무나도 많은 리소스가 들 것이다. 이를 자동으로 검증하거나 트리아제할 수 있는 새로운 시스템에 관한 니즈가 발생했다.\n이는 당장 개발을 고려하지는 않았고, 잠시 미루기로 하였다.\n7월 재발\n이직을 하고 1년, 몸이 다시 안 좋아짐을 느꼈다.\n분명 23년 퇴사 후 1개월간 대부분의 증상이 완화되었고, 이직 후에도 경과가 좋아 24년 초만 해도 의사 선생님과 이야기를 나눠 약을 잠시나마 끊기도 하였다.\n여기서는 서로를 존중하고 신뢰하는 분위기 속에서 큰 무리 없이 지내고 있다고 느꼈다.\n그렇기에 다시 몸이 안 좋아짐에 당황스럽기도 했다. 무엇 때문에 또 출근이 힘들어지는지, 회의와 대외 활동이 스트레스로 다가오는지 고민뿐이었다.\n아무래도 이전 회사에서 연구 경과가 사업적 성과로 이어지지 못했었다 보니, 이번 회사에서는 특히 연구 결과를 사업적 성과로 잇기 위한 노력을 많이 했다.\n하지만 이미 각자의 사업과 로드맵이 있는 부서에, AI를 활용한 새로운 기능을 제안하는 것은 쉽지 않았다. 또한 기술적 성취가 충분하고 이에 자부심을 느끼는 기업 분위기 속에서, LLM이 만든 \u0026ldquo;그럴듯한 무언가\u0026quot;는 그들의 엄밀함과 기준을 만족시키지 못하는 경우가 많았다.\n이러한 상황에서 팀 빌딩 후 1년이 되어가다 보니 알게 모를 초조함에 스트레스를 많이 받았나 보다.\n주변에서는 걱정 말고 더 연구해 봐라, 안 된다면 다른 방향을 탐구해도 좋다고 이야기하지만, 막상 또 내 성격이 여유를 가지지는 못하나 보다.\n업무 자체가 가중되기도 했다. 내 연구 주제도 있었고, 그 외적으로 인력 관리, 성과 관리, 목표 관리, 예산 지출 관리 등 매니징 업무도 적지 않았다.\n자리에 앉아 있는 시간보다 미팅을 가는 시간이 더 많았고, 팀 사이의 역학 관계 속에서 신설 팀의 목소리를 내고, 우리의 성과를 만들고 이행하는 것도 쉽지 않았다.\n결국 다시 통원 치료를 받기 시작했고, 약도 다시 챙겨 먹기 시작했다.\n9월 출장\n9월은 유독 출장이 많았다.\n금융보안원에서 8월 망 분리 규제 완화에 관한 보도 자료를 공개했다. 금융권에서 클라우드 서비스나 AI를 순차적으로 도입할 수 있게 하되, 관련 보안 감사를 조건으로 내건 것이다.\n회사는 이에 발맞춰 AI 서비스에 관한 보안 감사 서비스를 새로 기획하게 되었다.\n당시에는 사내 비즈니스 개발 조직이 별도로 없었기 때문에, 사내 관련 인원을 모아 TF 조직을 급하게 구성하였다. 팀의 사업적 성과에 목말라 있던 나는 초기 분석과 사업 기획의 틀을 만드는데 나섰다.\n금융보안원의 자료와 관련 금융권 기술 트렌드를 분석하고, AI 도입 시 발생 가능한 위협 시나리오와 관련 사례를 수집하기 시작했다.\n금융권 망 분리 완화 대응 프레임워크를 개발하고, 관련 사업에 관한 브로슈어 초안을 만들었다. 큰 틀은 사내 컨설팅팀의 확장판으로 가되, AI에 관련된 항목은 AI팀에서 처리하는 협업의 방향이었다.\n미팅에 나가서는 회사의 기본 컨설팅 서비스와 AI 보안 감사에 관한 서비스를 소개했다.\n대부분의 고객사는 AI 도입을 희망하기는 하나, 이를 통해 무엇을 할 수 있을지가 명확하지는 않아 보였고, 그러다 보니 어떤 부분에서 위협이 발생할 수 있는지 구체화하지 못하고 있었다.\n우리 또한 사업을 완전히 구체화한 상황은 아니었다 보니, 하나둘 조율해야 하는 상황이었다. 당연하게도 첫술에 배부를 수는 없었지만, 한편으로는 많이 아쉽기도 했다.\n팀의 공감대를 끌어내는 것도 쉽지 않았다. 기술적 구체화가 이뤄지지 않은 상황에서 사업 제안을 먼저 꺼내는 것이 맞는지, 이 사업을 했을 때 우리 팀의 성과는 얼마나 인정되는지, 우리 팀이 이를 수행할 역량이 있는지 등 팀 내에서의 챌린지를 대응하는 데에도 시간이 들었다.\n그럼에도 당장 시작해야 할 사업이라 느꼈다. 지금 당장 사업 제안과 기술 개발이 병행되지 않는다면 24년 말 25년 초에는 다른 이들이 자리를 선점할 것이다. 조금 부족하더라도 우리 회사에 이러한 사업이 있음을 알리고, 첫 레퍼런스를 따내는 것이 중요하다 느꼈다. 첫 사업을 성공적으로 끝낸다면, 근 몇 년은 매출에 관한 여유를 갖고 다른 사업이나 연구에 집중할 수 있을 것이다.\n반면에 내가 이 사업을 발전시킬 수 있을까에 대해서는 걱정도 많았다. 사업적 방향성과 기술 지원에 관해서는 이런저런 경험이 있었지만, 실제 사업을 구체화하고 영업을 한 경험은 없었다. 그렇기에 이에 대한 부담이 없었다면 거짓말일 것이다.\n이런저런 부담과 스트레스에 재발했을 수도 있겠다. 전반적으로 스트레스의 내구성이 낮나 보다.\n매주 나가는 대외 미팅은 점점 힘들어져 갔고, 나는 결국 리타이어 했다. 더 이상 팀장 업무 수행은 어려울 것 같다 느꼈고, 본격적으로 팀장 위임에 관하여 인사팀에 이야기를 꺼냈다.\n운이 좋게도 당시 회사는 비즈니스 조직을 다시 강화해 나가고 있었고, 나는 사업 기획은 비즈니스 조직으로, 기술 개발은 다음 팀장분께 위임하고 하나둘 일을 덜어갔다.\n10월 선임 연구원\n인사팀에 솔직히 이야기를 꺼내기 전, 팀의 시니어 연구원에게 먼저 이야기를 꺼냈다. 사실 근래 몸이 좋아지지 않았음을, 업무 수행에 지장이 있음을 토로했다. 혹여 팀장을 위임한다면 맡아줄 수 있을지 의향을 물었다.\n그분이라면 다른 팀원들이 잘 따라줄 것 같았다. 사업적 욕심도 있었기에, 내가 아니더라도 진행되던 사업을 더 잘 키워주실 것 같았다.\n다행히 긍정적인 답변을 받았다. 정말 크게 한숨 놓인 기분이었다.\n만약 받아주지 않는다면 어떡하지, 난 이 일을 계속할 자신이 없는데, 다른 대안이 있어야 하나, 다 포기하고 퇴사할까 등 다양한 고민이 있었지만, 한순간 사라졌다.\n인사팀을 찾아갔다. 마찬가지로 근래 몸이 안 좋아짐을, 업무 수행에 지장이 있음을 밝혔다. 그리고 팀장의 위임을 희망함을, 대상자와 이야기 나눴음을 전달했다.\n긍정적 호응을 받았다. 직무 변경은 꽤 잦은 일이고, 대상자와도 협의가 되었다면 큰 무리가 없다는 것이다.\n어떻게 보면 이전의 회사와 지금의 회사는 정말 다양한 부분에서 반응이 달랐다. 이전 회사에서도 위임을 이야기했지만, 당시에는 다 그렇다며 버티라는 반응이 전부였다면, 지금은 건강이 최우선이라며 바로 전환 계획을 구체화하기 시작했다.\n인사팀, 대표님과도 한 달여간 이야기를 나누며 전환에 관한 계획을 구체화했고, 대상자와의 인수인계도 시작했다.\n그렇게 계획이 확정된 후 팀원들에게도 현황을 알렸고, 다행히 큰 무리 없이 수긍하는 모습을 보였다.\n한 달여간의 순차적 인수인계 후 10월, 인사 공지가 올라오며 전환이 마무리되었다.\n이후 팀은 파트 체제를 공식화하였다. Security for AI, AI 시스템의 보안 감사를 맡는 파트와 AI for Security, 보안 기술을 자동화하는 파트로 나뉘었다.\n나는 2월부터 수행한 위협 시나리오 생성 및 검증 연구를 이어가기를 희망했고, AI for Security 파트의 파트장으로 업무를 보게 되었다.\n위임 후 처음 한 달은 체감이 잘 안되었다. 하지만 12월이 된 후, 24년 지출 결산, 25년 예산 계획, 인력 운용 및 채용 계획, 팀 기술 연구 목표 및 사업 매출 기획 등 밀려 들어오는 행정 업무를 처리하는 팀장님을 보고 나서야 체감이 되었다.\n현재는 대학원 진학 및 퇴사를 결정짓고, 파트장 역시 위임하여 선임 연구원으로 기술 개발에 집중하고 있다.\n사실 이렇게 일을 줄이고 나면 바로 건강이 회복될 것이라 기대했지만, 막상 또 23년 퇴사 당시처럼 극적으로 좋아지지는 않았다. 24년 7월보다는 확실히 나아지고 있기에, 또 몇 달이면 괜찮아지지 않을까 싶기도 하다.\n11월 AIxCC\nAI for Security 파트는 위협 시나리오 생성 연구의 연장선으로 미국팀과 협업 아래 AIxCC 대회 본선을 준비하기 시작했다.\n원래에는 미국팀과 별개로 자체적인 연구 개발에 집중하고 있었지만, 미국팀이 한국에 방문하여 이런저런 이야기를 나누다 아예 협업으로 방향성을 잡게 되었다.\n졸업 프로젝트가 AI 기반 Fuzzing 기술 개선이었고, 미국팀이 그리는 시스템 또한 너무나도 매력적이었기에 이는 놓쳐선 안 될 기회였다.\n이후 곧장 한국팀에서 기여할 수 있는 기술과 관련된 개발 로드맵을 만들어 공유했다. 계획에 없던 협업임에도 미국팀은 흔쾌히 이를 수용하였고, 우리는 곧장 연구 개발에 착수했다.\n근래에는 매주 미국팀과 비디오 콜을 하고 있다. 개발 내용에 관한 공유와 의견 교류를 목적으로 하고 있다.\n항상 잔뜩 써가고, 의견을 듣고 나면 하고 싶은 말도 많지만, 말이 목까지 올라왔다 뱉어지지 못하고 항상 들어간다. 결국 하고 싶었던 말은 미팅이 끝난 후에 슬랙에 글로 남기는 편이다.\n팀 내에 영어를 정말 잘하는 팀원이 있는데, 브리핑은 이분이 거의 전담해 주시고 있다. 확실히 영어는 필수구나 하는 생각이 들었지만, 막상 공부는 시작하지 않고 있다.\n자세한 기술적 내용은 대회가 끝나난 후에 풀어 보겠다.\n1월 퇴사\n대학원 진학이 확정된 후, 팀장님과 인사팀에 퇴사 의사를 밝혔다.\n적지 않게 당황해하는 분위기였다. 대학원에 갈 것 같기는 했지만, 그게 지금 시점일지는 몰랐다는 것이다. 왜 비전 연구실로 가는지도 많이들 물어왔다.\n당연하게도 내막을 모르는 인원은 사실 팀장 위임이 퇴사를 위한 큰 그림이었냐고도 물었다. 이런 런 질문에 열심히 해명을 담아 왔다.\n아직 회사에 말을 돌리지는 않았다. 가능한 조용히 나가고 싶기도 했고, 혹여나 있을 오해는 없었으면 하기도 헀다.\n퇴사 소식을 접한 인원들은 아쉽다는 인사를 전해왔다. 이런저런 이야기를 들으며 그래도 회사 생활 열심히 했나보다 생각이 들었다.\n이번 회사에서도 정말 여러 경험을 해왔다. 예산이나 매출 관리도 해보고, 사업 기획 및 영업도 나가보았다. 처음으로 내 위에 대표님 외의 사람도 모시고, 처음으로 정리해고가 아닌 자발적 퇴사도 해보았다.\n돌아오고 싶은 회사다. 정말 좋은 경험 많이 했고, 비전도 있는 회사이다. 엑싯까지 보고 가는 것도 좋았겠지만, 지금은 대학원에 대한 기대도 크다.\n퇴사 일자가 정해졌고, 지금은 인수인계 중이다. 퇴사 후에는 쓰고 싶던 블로그 글이나 왕창 쓰며 쉬다가 연구실로 출근할 계획이다.\n올해에도 새로운 것들 많이 해보며 즐겁게 지내길 바란다.\n25.01.24.퇴사\n","permalink":"https://revsic.github.io/blog/on2024/","tags":["Writing","2024th"],"title":"On 2024"},{"categories":["Software Testing"],"contents":"아래 글은 2024년 3월부터 11월까지 수행한 학부 졸업 프로젝트에 관한 수기이다.\nResearch about the Automatic Fuzzing Harness Generation Keyword: Software Testing, Fuzzing, Harness Generation, Large Language Model, LLM Basis: How to increate Branch Coverage in fuzzing. Problem: Low TP Rate in Harness Generation with PromptFuzz. Solution: Agentic Harness Generation. Benefits: Improved Branch Coverage of the three projects; libxml2, libpcap, and libaom. Contribution: Suggest an LLM Agent for the Harness Generation. Weakness or Future work: - Introduction\n소프트웨어 테스팅에서 Fuzzing은 소프트웨어에 무작위 입력을 대입하여 결함의 발생 여부를 관찰하는 방법론을 일컫는다. 무작위 입력을 생성하여 소프트웨어에 대입하고, 결함의 관찰을 대행하는 도구를 Fuzzer라 지칭한다. 경우에 따라 완전히 무작위한 값을 생성하기도 하고, 사용자에 의해 주어진 입력을 활용하기도 한다.\n일반적으로 무작위 값을 단순히 소프트웨어에 입력할 경우, 대다수는 인터페이스에 해당하는 영역에서 입력값 검증 등 조건 분기를 통과하지 못하고 조기에 종료된다. 이에 내부 구현에 해당하는 영역은 대개 실행되지 않고, 테스트의 범위는 좁아지게 된다. 테스트의 범위를 효과적으로 확장하기 위해서는 다양한 조건 분기를 관측 및 선택하여, 각 경로를 exhaustive하게 탐색하는 것이 유리하다.\n분기의 탐색을 효과적으로 수행하기 위해 Fuzzer는 Coverage를 활용하기도 한다.\n소프트웨어 테스팅에서는 소프트웨어의 동작 과정에서 어떤 코드 블럭/분기/함수 등이 몇 번 실행되었는지 기록하여, 이를 \u0026ldquo;Coverage\u0026quot;라는 이름으로 관리한다. 기존까지는 실행되지 않았던 새로운 코드 블럭/분기/함수가 실행된 경우, 우리는 Coverage가 증가하였다고 표현한다.\n몇몇 Fuzzer는 Coverage를 증가시킨 입력에 높은 우선순위를 두고, 우선순위에 따라 과거의 입력을 선택하여 무작위로 변조-소프트웨어에 대입하는 일련의 작업을 반복한다. 이 경우 전략 없이 단순 무작위 입력값을 생성하는 Fuzzer에 비해 높은 확률로 Coverage가 증가하는 방향의 입력이 성생되길 기대할 수 있다.\n이렇게 무작위로 값을 변조하는 과정을 Mutation이라 하고, 과거의 입력을 Seed Corpora(복수형 Seed corpus)라 하자. 또한 Coverage 기반의 Mutation 전략을 가지는 Fuzzer를 아래 수기에서는 Greybox Fuzzer라 표현하겠다.\nGreybox Fuzzer 역시 한계를 가진다. Coverage 기반의 Mutation 전략을 통해 상대적으로 테스트 범위를 확장할 수 있었지만, 충분히 복잡한 소프트웨어의 분기 구조 속에서 무작위 입력만으로 도달할 수 있는 코드에는 한계가 있다. 또한, 그래픽 인터페이스를 내세운 소프트웨어의 경우, 생성된 입력을 적절한 인터페이스에 전달할 별도의 장치도 필요하다.\n이러한 상황 속 더욱 효과적인 테스트를 위해 등장한 것이 Fuzzer Harness이다. Harness는 무작위 입력을 테스트 대상에 전달하는 별도의 소프트웨어로, 무작위 값을 인자로 특정 함수를 호출하거나, 네트워크 혹은 GUI 이벤트를 모방하여 무작위 입력을 인터페이스에 연결한다. Fuzzer는 Harness를 실행하고, Harness는 Fuzzer가 생성한 무작위 입력을 소프트웨어에 전달한다.\n이를 통해 인터페이스의 제약에서 벗어나 테스트 대상의 특정 구현체를 직접 Fuzzing 할 수 있다.\n다만, 이러한 Harness를 작성하기 위해서는 테스트 대상에 관한 이해가 선행되어야 하며, 테스트 대상에 새 기능이 추가 되거나 수정될 경우 Harness 역시 수정되어야 할 수 있다.\nOSS-Fuzz-Gen, PromptFuzz 등 프로젝트는 이에 대응하기 위해 LLM을 활용하여 Harness를 생성, Fuzzing을 수행한다. Harness 작성 시간을 단축하고, Fuzzing의 진행 경과에 따라 동적으로 테스트가 부족한 영역에 Harness를 보강하여 전반적인 테스트 커버리지를 높여간다.\n이번 졸업 프로젝트는 이러한 맥락 속에서 OSS-Fuzz-Gen과 PromptFuzz의 문제점을 정의하고, 그 개선점으로 AgentFuzz; Agentic fuzz harness generation을 제안한다.\nRelative Works: OSS-Fuzz-Gen\nOSS-Fuzz[google/oss-fuzz]는 구글에서 운영하는 오픈소스 Fuzzing 프로젝트이다. 오픈소스 제공자가 빌드 스크립트와 Fuzzer를 제공하면 구글이 ClusterFuzz[google/cluster-fuzz]를 통해 Google Cloud Platform(이하 GCP) 위에서 분산 Fuzzing을 구동-결과를 통고해 주는 방식으로 작동한다.\nFigure 1. google/oss-fuzz#Overview\n일부 오픈소스 프로젝트에 대해 OSS-Fuzz는 LLM 기반으로 Harness를 생성-테스트하는 일련의 파이프라인을 제공한다; OSS-Fuzz-Gen[google/oss-fuzz-gen].\nOSS-Fuzz는 Fuzz-introspector[ossf/fuzz-introspector]를 통해 ClusterFuzz의 실행 결과로부터 어떤 함수가 얼마나 호출되었고, 어떤 분기에 의해 후속 함수의 호출이 불발되었는지 분석-전달한다(i.e. fuzz-blocker, Figure 2.). OSS-Fuzz-Gen은 테스트가 미진한(호출되지 않았거나, 테스트 범위에 포함되지 않은) 함수를 fuzz-introspector의 보고서로부터 발췌하여 LLM에게 해당 함수의 Harness 생성을 요청한다.\nFigure 2. Reachability tree with coverage overlay (ref:git+ossf/fuzz-introspector)\ne.g. Prompt (from:oss-fuzz-llm-targets-public):\nYou are a security testing engineer who wants to write a C++ program to execute all lines in a given function by defining and initialising its parameters in a suitable way before fuzzing the function through `LLVMFuzzerTestOneInput`. Carefully study the function signature and its parameters, then follow the example problems and solutions to answer the final problem. YOU MUST call the function to fuzz in the solution. Try as many variations of these inputs as possible. Do not use a random number generator such as `rand()`. All variables used MUST be declared and initialized. Carefully make sure that the variable and argument types in your code match and compiles successfully. Add type casts to make types match. You MUST call `CJSON_PUBLIC(cJSON_bool) cJSON_Compare(const cJSON *const a, const cJSON *const b, const cJSON_bool case_sensitive)` in your solution! *SKIPPED* Problem: `` CJSON_PUBLIC(cJSON_bool) cJSON_Compare(const cJSON *const a, const cJSON *const b, const cJSON_bool case_sensitive) `` Generated:\n#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;string.h\u0026gt; #ifdef __cplusplus extern \u0026#34;C\u0026#34; { #endif #include \u0026#34;../cJSON.h\u0026#34; int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size); /* required by C89 */ int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) { cJSON *a = cJSON_Parse((const char*)data); cJSON *b = cJSON_Parse((const char*)data); if(a == NULL || b == NULL) return 0; cJSON_Compare(a, b, 0); cJSON_Compare(a, b, 1); cJSON_Delete(a); cJSON_Delete(b); return 0; } #ifdef __cplusplus } #endif LLM은 함수의 Spec을 입력으로 Harness를 작성한다(주로 OpenAI GPT, Google Gemini). 단번에 Syntax Error가 없는 Harness를 생성하기는 어려우므로, OSS-Fuzz-Gen은 컴파일 에러 메시지를 LLM에게 전달하여 오류 수정을 요구한다.\nGiven the following C program and its build error message, fix the code without affecting its functionality. First explain the reason, then output the whole fixed code. If a function is missing, fix it by including the related libraries. Code: `` CJSON_PUBLIC(cJSON_bool) cJSON_Compare(const cJSON *const a, const cJSON *const b, const cJSON_bool case_sensitive) `` Solution: `` #include \u0026lt;stdlib.h\u0026gt; /* *SKIPPED* */ `` Build error message: /src/cjson/fuzzing/cjson_read_fuzzer.c:1:1: error: unknown type name \u0026#39;CJSON_PUBLIC\u0026#39; CJSON_PUBLIC(cJSON_bool) cJSON_Compare(const cJSON *const a, const cJSON *const b, const cJSON_bool case_sensitive) ^ /src/cjson/fuzzing/cjson_read_fuzzer.c:1:25: error: expected \u0026#39;;\u0026#39; after top level declarator CJSON_PUBLIC(cJSON_bool) cJSON_Compare(const cJSON *const a, const cJSON *const b, const cJSON_bool case_sensitive) ^ ; Fixed code: 최대 3~5회까지 수정을 반복하여 Syntax Error를 수정하고, 컴파일에 성공한 경우 최초 시동을 통해 Harness가 Fuzzing과 무관히 Crash를 내는지 확인한다. Fuzzing 전부터 Crash가 발생한다면, 생성된 Harness를 활용하여 Fuzzing을 수행하는 것이 무의미할 것이다.\nFYI. 끝내 Syntax Error 해결에 실패한 경우 해당 Harness는 폐기하고, LLM에게 새 Harness 합성을 요구한다.\n정상 작동한 Harness는 ClusterFuzz로 전달되고, GCP 위에서 Fuzzer를 구동한다.\nOSS-Fuzz-Gen은 LLM을 활용하여 tinyxml2 등 프로젝트에서 Test Coverage를 30%까지 추가 획득하였다고 이야기한다[googleblog].\nRelative Works: PromptFuzz\nOSS-Fuzz-Gen은 LLM을 기반으로 가용한 Harness를 생성할 수 있다는 점을 보였다. 하지만, 대개 함수 개개에 대한 Harness를 작성하기에, API 간의 유기 관계를 테스트하는 것에는 한계가 있다. 특히나 Internal State를 공유하고, 이에 따라 조건 분기를 취하는 라이브러리의 경우, 어떻게 API를 조합하느냐에 따라 trigging할 수 있는 코드 블럭의 부류가 달라질 수 있다.\nPromptFuzz[arXiv:2312.17677, git+PromptFuzz/PromptFuzz]는 이에 대응하고자 여러 API를 하나의 Harness에서 동시에 호출하는 방식을 취하고, 어떤 API를 선택하는 것이 테스트에 유리할지 전략을 제시한다.\nFigure 3. PromptFuzz/PromptFuzz#workflow\nPromptFuzz는 라이브러리의 헤더 파일로부터 AST 파서를 활용해 함수(API) 및 타입의 선언을 발췌, Gadget이라는 이름으로 관리한다. PromptFuzz는 매 Round마다 이 중 일부를 선택하여 LLM에 Harness 생성을 요구한다.\nPromptFuzz는 생성된 Harness의 유효성, Correctness를 검증하기 위한 몇 가지 방법론을 제안하며, 이를 모두 통과한 Harness에 대해서만 Fuzzing을 수행한다.\nPromptFuzz: Harness Mutation\n가장 먼저 고민한 문제는 어떤 API Gadget을 골라 Harness를 만드는가이다. PromptFuzz가 API의 유기 관계를 모델링하기 위해 선택한 방식은 상용 Fuzzer가 Seed Corpus를 Mutation 하는 정책과 동일 선상에 있다.\n상용 Fuzzer는 유전 알고리즘을 통해 Coverage가 높은 Seed Corpora를 선택하고, 이를 무작위로 조작하여(random mutation을 가하여) 새로운 입력을 생성한다. Coverage를 측정하여 상위부터 Mutation을 수행하는 일련의 과정을 반복하며, Coverage를 높일 입력을 찾아나가는 것이다.\nPromptFuzz는 API Gadget의 순열(이하 API Sequence)을 잘 선택하여 Harness를 구성, 테스트 범위를 확장하길 바란다. 그렇기에 API Sequence를 평가할 지표를 두어 서로 다른 API Sequence 사이에 순서를 정하고, 상위 API Sequence부터 Random Mutation을 수행하여 LLM에게 Harness 생성을 요청한다.\n## PSEUDO CODE OF PROMPTFUZZ type APISequence = list[APIGadget] def round(seed_harnesses: list[Harness]): # selection selected: Harness = weighted_sample( seed_harnesses, weight_fn=quality_measure, ) # mutation new_api_sequence: APISequence = mutation(selected) # generate to harness harness: Harness = LLM( SYSTEM_PROMPT, f\u0026#34;Generate a fuzzer harness containing the given APIs: {new_api_sequence}\u0026#34;, ) # validation if not is_valid(harness): return ValidationFailureError() # run the fuzzer result = run_fuzzer(harness) # append to seeds seed_harnesses.append(harness) return result seed_harnesses, quiet = [], 0 # given max_round: int max_budget: float max_quiet: int # run the PromptFuzz for _ in range(max_round): result = round(seed_harnesses) # terminal condition#1: API Budget if litellm._current_cost \u0026gt; max_budget: break # terminal condition#2: Quiet round if not isinstance(result, ValidationFailureError): quiet = 0 elif quiet \u0026gt; max_quiet: break else: quiet += 1 PromptFuzz는 Harness 역시 Mutation의 대상으로 바라보아 전략적으로 테스트 범위 확장을 의도한다.\nGreybox Fuzzer가 Coverage를 Seed Corpus 평가의 지표로 두었다면, PromptFuzz는 API Sequence에 대해 Quality라는 지표를 제안한다.\nMeasure\nQuality는 Density와 #Unique Branches의 곱으로 표현된다. Harness Mutation의 목표는 Coverage 확보이다. Mutated Harness를 통해 Coverage(혹은 #Unique Branches)가 얼마나 확보되었는지 파악하는 것은 자명한 일이다. 여기서 중요한 것은 Density의 역할이다.\nFYI. #Unique Branches는 Harness를 단위 시간 동안 Fuzzing 하였을 때, Harness에 의해 실행된 대상 프로젝트 내 분기의 수이다. 대상 프로젝트의 Coverage는 #Unique Branches를 프로젝트 내 전체 분기의 수로 나눈 것과 같다.\n$$\\mathrm{Quality}(g) = \\mathrm{Density}(g) \\times (1 + \\mathrm{UniqueBranches}(g))$$\nPromptFuzz는 Harness 내 API의 유기 관계를 적극 활용하여 Coverage를 높이고자 한다. API의 유기 관계에 대한 평가 지표가 제안되어야 하고, 해당 지표가 Coverage 확보에 기여함을 보인다면 명쾌할 것이다.\nPromptFuzz가 이를 위해 제안한 지표가 Density이다. API의 유기 관계는 앞선 API의 호출이 후속 API의 실행 흐름에 얼마나 영향을 미치는지로 표현된다. 한 API의 호출이 다른 API의 실행 흐름에 영향을 주기 위해서는 (1) 앞선 호출이 프로젝트의 State를 변화시켜, 후속 실행 흐름에 간접적 영향을 주거나 (2) 앞선 호출의 결과값이 후속 API의 인자로 전달되어 직접적 영향을 주는 2가지 경우로 나뉠 것이다.\nDensity는 이중 후자의 경우에 집중한다. Harness 내에 존재하는 API를 Node로 표현하고, Taint Analysis를 통해 Harness의 실행 흐름 중 한 API의 반환값이 다른 API의 인자로 전달되는 경우를 Directed Edge로 하여 API Call Depedency Graph를 그린다.\n만약 아래의 Harness가 있다면, 다음의 CDG를 예상해 볼 수 있다.\nvpx_codec_dec_cfg_t dec_cfg = {0}; ... // Initialize the decoder vpx_codec_ctx_t decoder; vpx_codec_iface_t *decoder_iface = vpx_codec_vp8_dx(); vpx_codec_err_t decoder_init_res = vpx_codec_dec_init_ver( \u0026amp;decoder, decoder_iface, \u0026amp;dec_cfg, 0, VPX_DECODER_ABI_VERSION); if (decoder_init_res != VPX_CODEC_OK) { return 0; } // Process the input data vpx_codec_err_t decode_res = vpx_codec_decode(\u0026amp;decoder, data, size, NULL, 0); if (decode_res != VPX_CODEC_OK) { vpx_codec_destroy(\u0026amp;decoder); return 0; } // Get the decoded frame vpx_image_t *img = NULL; vpx_codec_iter_t iter = NULL; while ((img = vpx_codec_get_frame(\u0026amp;decoder, \u0026amp;iter)) != NULL) { // Process the frame vpx_img_flip(img); ... } // Cleanup vpx_codec_destroy(\u0026amp;decoder); return 0; Figure 4. Call Dependency Graph\nFYI. 위는 예시이며, 실제 구현과는 다를 수 있다.\nGraph는 SCC로 분해가능하고, 각 Component의 Cardinality(집합 내 원소의 수) 중 가장 큰 값을 Density라 명명한다.\nFYI. SCC(Strongly Connected Component): 노드의 집합, (1) 집합 내 어떤 임의의 두 노드를 선택하여도 이를 잇는 경로가 존재하고-Strongly Connected, (2) Graph 내 어떤 두 노드가 Strongly Connected이면 둘은 같은 SCC에 속함-Component. (Strongly Connected Nodes의 집합 중 가장 크기가 큰 집합.)\nFYI. Graph는 SCC로 Partition 가능하다. (i.e. Graph는 SCC의 집합으로 표현 가능하고, Graph 내 모든 SCC는 mutually disjoint이다.)\n위 CDG는 기재된 모든 함수 사이에 서로를 잇는 Edge가 존재하므로 Graph 전체가 하나의 SCC이며, Density는 SCC 내 노드의 개수인 6이다.\nDensity는 Harness 내 직접적 영향을 주고 받는 API의 군집 중 가장 큰 군집의 크기를 의미한다. Density가 크다는 것은 Harness 내의 API 유기 관계에 부피감이 있음을 의미한다. (1) 이는 너비를 의미할 수도 있고-여러 API의 독립적 실행 결과가 하나의 API에 영향을 가함, (2) 깊이를 의미할 수도 있으며-API의 호출이 순차적으로 영향을 가함, (3) 이 둘 모두를 의미할 수도 있다.\nDensity는 Taint Analysis의 범위에 따라 간접 영향에 관하여는 모델링하지 못할 수도 있고, 그 부피감이 어떤 형태의 Call Dependency를 가지는지 묘사하지 못하기도 한다.\n결국 Quality는 (1) Coverage가 높을수록 (2) API의 유기 관계에 부피감이 있을수록 좋은 Harness라 정의하고 있다.\nMutation\nQuality에 따라 Harness가 선택되고 나면 PromptFuzz는 Mutation을 수행한다. Byte string을 직접 조작하는 Corpus Mutation과 달리, Harness Mutation은 API Sequence 수준에서 Mutation을 가하고, LLM을 통해 Mutated API Sequence를 새로운 Harness로 생성하는 과정을 거친다.\n$$\\mathrm{Harness} \\mapsto \\mathrm{API\\ Sequence} \\mapsto \\mathrm{Mutated} \\mapsto \\mathrm{New\\ Harness}$$\nLLM이 Mutated API Sequence를 토대로 Harness를 만들어도, 제시된 API가 모두 Harness에 포함되어 있지는 않다(LLM의 한계). 따라서 Harness에서 사용한 API를 모두 발췌하여 실행 순서에 따라 Topological Sort를 수행, 생성된 Harness의 API Sequence로 정의한다.\nAPI Sequence에는 (1) API Insert, (2) API Remove, (3) Crossover 3가지 방식의 Mutation 중 하나를 무작위 선택하여 가하게 된다.\nAPI Insert와 Remove는 주어진 API Sequence의 임의 지점에 새로운 API Gadget을 삽입하거나, 임의 지점의 API Gadget을 제거하는 방식으로 작동한다. Crossover는 또 다른 API Sequence와 임의 지점에서 Sequence 전-후반을 접합하는 방식으로 작동한다.\n## PSEUDO CODE OF MUTATION def insert(harness: Harness, gadgets: list[APIGadget]): seq: APISequence = extract_apis(harness) while True: api: APIGadget = weighted_sample( gadgets, weight_fn=energy_measure, ) if api not in seq: break seq.insert(random.randint(0, len(seq)), api) return seq def remove(harness: Harness): seq: APISequence = extract_apis(hanress) # inverse energy order api: APIGadget = weighted_sample( seq, weight_fn=lambda x: 1 / energy_measure(x), ) seq.remove(api) return seq def crossover(harness: Harness, seed_harnesses: list[Harness]): seq: APISequence = extract_apis(harness) other: Harness = weighted_sample( seed_harnesses, weight_fn=quality_measure, ) other_seq: APISequence = extract_apis(other) i = random.randint(1, len(seq) - 1) j = random.randint(1, len(other_seq) - 1) return seq[:i] + other_seq[j:] new_api_sequence: APISequence match random.randint(0, 2): case 0: new_api_sequence = insert(harness, gadgets) case 1: new_api_sequence = remove(harness) case 2: new_api_sequence = crossover(harness, seed_harnesses) return new_api_sequence Crossover는 역시 Quality에 따라 Harness를 추가 선발하여 활용한다. 동일 논리라면, Insert와 Remove 역시 추가 혹은 제거 대상으로 삼을 API의 기준이 필요할 것이다.\n프로젝트에 따라 PromptFuzz에서 발췌된 API Gadget은 만여개 단위까지 늘어난다. 이 중에는 실제로도 자주 쓰이는 API로, LLM 역시 단번에 활용처를 이해하고 컴파일까지 성공하는 API가 있는반면, 자주 쓰이지 않아 LLM 역시 컴파일에 실패하거나 빈번히 오사용하는 API도 있다.\nPromptFuzz는 이러한 상황에서 이미 충분히 테스트 되었다 판단된 API의 사용을 줄이고, 테스트 되지 않은 API의 사용 시도를 늘리기 위해 Insert와 Remove의 대상에 Energy라는 기준을 제시한다.\n$$\\mathrm{Energy}(a) = \\frac{1 - \\mathrm{Coverage}(a)}{(1 + \\mathrm{Seed}(a))^E \\times (1 + \\mathrm{Prompt}(a))^E}$$\nEnergy는 각 API에 대한 평가 지표로, Energy가 높을수록 Mutation 후 Harness에 해당 API가 잔존할 확률을 높이고, Energy가 낮을수록 잔존 확률을 낮춘다.\nFYI. Coverage(a)는 API $a$ 내부의 분기 중 실행된 분기의 비율. Prompt(a)는 mutated api sequence에 API $a$가 포함된 횟수(LLM에게 전달된 횟수). Seed(a)는 실제 API $a$를 포함하고 있는 Seed Harnesses의 수(API가 LLM에게 합성 요청되어도 실제 Harness에 포함되지 않을 수 있고, 포함되더라도 Validation 단계를 통과하지 못해 Seed Harnesses에 포함되지 않을 수 있음.)\nFYI. E는 하이퍼파라미터, git+PromptFuzz/PromptFuzz는 1로 가정.\nAPI가 충분히 테스트 되었다 판단될수록(i.e. Coverage가 100%에 가까워질수록) API는 Mutated Harness에 포함될 가능성이 줄어든다. 이는 자명하다.\n어떤 API는 LLM에게 많이 합성 요청되었지만, 컴파일 오류나 오사용으로 인해 Fuzzing 대상이 되지 못할 수 있다. 이 경우는 LLM의 성능상 한계라 이해하고, Energy를 통해 해당 API 역시 Mutated Harness에 포함될 가능성을 낮춘다.\n결국 PromptFuzz는 Quality와 Energy를 통해 API가 고루 테스트 될 수 있도록 하고, 지표 기반 Mutation으로 좋은 Harness를 찾아나간다.\nPromptFuzz: Harness Validation\n생성된 Harness는 유효성, Correctness를 검증받게 된다. Syntax Error를 포함하여 컴파일이 불가능하거나, API의 오사용으로 인해 새로이 탐색 가능한 분기가 없다면 굳이 이를 구동할 이유가 없을 것이다. PromptFuzz는 효과적인 Fuzzing을 위해 몇 가지 검증 기준을 제안한다.\n가장 간단히는 컴파일이 가능해야 한다. LLM의 응답으로부터 ```의 코드 블록이 존재한다면, 블록 내에서 코드를 발췌-컴파일을 시도한다. Syntax Error가 발생할 경우 LLM에게 오류 수정을 요구하는 OSS-Fuzz-Gen과 달리 PromptFuzz는 곧장 생성된 Harness를 폐기하고, 새로 생성을 시도한다.\n컴파일에 성공했다면, 최대 10분간 Fuzzer를 구동한다. 1분 단위로 현재 Fuzzer의 Coverage를 측정하여, Coverage가 증가할 경우 지속-유지될 경우 구동을 중지한다. 이후 기존까지 실행되었던 Seed Harnesses의 Fuzzing 결과와 비교하여 새로운 분기가 발견되었는지 검사한다. 만약 분기가 발견되지 않았다면, 현재 검토 중인 Harness는 Coverage 확보에 기여하기 어렵다 판단하여 폐기한다.\n만약 컴파일에도 성공하고, 새로운 분기도 확인하였다면 Critical Path 검증으로 마무리 한다.\nCritical Path\nCritical Path는 Harness 내 여러 Control Flow 중 가장 많은 API를 호출할 수 있는 흐름을 의미한다. 예를 들면, Figure 4.의 예시에서 Critical Path는 다음 6개 API를 포함하고 있다.\nvpx_codec_vp8_dx \u0026gt; vpx_codec_dec_init_ver \u0026gt; vpx_codec_decode \u0026gt; vpx_codec_get_frame \u0026gt; vpx_img_flip \u0026gt; vpx_codec_destroy\nPromtpFuzz는 최대 10분간의 Harness 구동 중 Critical Path 내의 모든 API가 Hit 되었는지 검사한다.\n만약 생성된 Harness가 API를 오사용하였다면 테스트는 비정상 종료될 것이고, Harness에 포함된 API 중 일부는 실행되지 않을 것이다. 반대로 모든 API가 사용되었는지를 테스트한다면, 주류 흐름 외의 에러 핸들링에 사용되는 API까지 강제되는 등 통과가 불가능하거나 비효율적인 평가가 이뤄질 수 있다.\n이에 PromptFuzz는 주류 API 흐름의 실행을 보장하고자 Critical Path를 정의하고, 주류 흐름 내의 모든 API가 실행되었는지를 검토한다.\nPromptFuzz: Benchmarks\nPromptFuzz는 총 14개 프로젝트에 대해 벤치마크 테스트를 수행한다.\nTable 1. Overall results for PromptFuzz-generated fuzz drivers\nAgentFuzz의 개발 전, git+PromptFuzz/PromptFuzz를 토대로 벤치마크 테스트를 재현하였다. 논문에서 Harness 생성에 사용한 gpt-3.5-turbo-0613 모델은 현재 Deprecate 되어 사용이 불가능하다. 아래는 gpt-4o-mini-2024-07-18을 운용하였을 때의 결과를 첨부한다.\nFigure 5. Evaluation results of the benchmark projects.\n프로젝트의 Branch Coverage는 대개 프로젝트의 전체 Branch 수(i.e. # Total Branch, log-scale)와, 전체 API Gadget 중 실행된 API의 비율(i.e. api/executed, %)에 상관관계를 갖는다. 이 둘은 직관 상 자명한 지표이다.\n(1) 일정 깊이 이상의 경로를 Random mutation만으로 접근하게 될 가능성은 깊이에 따라 기하급수적으로 감소한다. Branch가 많아지면 Nested Branch의 존재 가능성이 커지고, 자연스레 Mutation의 한계로 Branch Coverage가 감소하는 것이다.\n(2) AgentFuzz는 거의 모든 API를 LLM에게 1회 이상 전달한다. 하지만 LLM의 성능상 한계로 인해, 생성된 Harness가 요청된 API 중 일부를 포함하지 않거나, 포함하더라도 평가를 통과하지 못해 결국 테스트 되지 않는 API가 발생한다. 해당 API에 포함된 Branch는 실행 기회를 얻지 못하고, Branch Coverage에는 상한선이 발생한다.\nproj#revision Branch Cov Total Branch Executed API Exposed API Coverage(R/UB) cjson#424ce4c 82.08% 1038 100% 67.85% 82.08% zlib#545f194 70.09% 2906 92.04% 57.89% 83.12% c-ares#3b8058 59.96% 8076 12.59% 17.44% 76.67% sqlite3#27095f 62.44% 39926 77.66% 10.66% 91.93% libpng#d3cf9b 44.58% 7750 93.08% 47.49% 52.31% libmagic#cf6bf1 48.31% 7470 61.11% 5.84% 163.51% libpcap(1.11.0) 36.76% 7808 90.47% 15.30% 36.90% lcms#5c54a6 42.70% 9220 75.94% 24.31% 63.10% libtiff#7a3fb2 29.29% 14576 38.26% 21.77% 155.42% libvpx#b15d2a 17.70% 35050 97.29% 0.88% 20.35% libaom#47f42d 15.79% 60100 97.87% 0.48% 15.87% libxml2(2.9.4) 1.31% 71378 9.41% 54.32% 7.06% 이를 기반으로 성능 분석과 개선점 확보를 위해 다음과 같이 분류해 보았다.\nExecuted API 비율 70% 미만: c-ares(59.96%), libmagic(48.31%), libtiff(29.29%), libxml2(1.31%) 상한 대비 Coverage 70% 미만 API 노출 비율 10% 미만: libvpx(17.70%), libaom(15.79%) 원인 불명: libpng(52.31%), libpcap(36.90%) lcms(42.70%): 다소 못 미치지만, 다른 프로젝트에 비해 비교적 양호한 Coverage를 확보 Executed API 비율 70% 이상, 상한 대비 Coverage 70% 이상: cjson(82.08%), zlib(70.09%), sqlite3(62.44%) FYI. Executed API: 전체 API Gadget 중 실행이 확인된 API의 비율 (i.e. api/executed, %)\nFYI. 상한 대비 Coverage(R/UB; Relative coverage to upper bound): 실행된 API의 전체 Branch 모수 대비 실행된 Branch의 비율(실행되지 않은 API의 Branch는 모수에서 제외).\nExecuted API의 비율이 70% 미만인 네 개 프로젝트(c-ares 12.59%, libmagic 61.11%, libtiff 38.26%, libxml2 9.41%)는 Branch Coverage가 60% 미만이다. 이는 생성된 Harness가 API를 충분히 포함하지 않아, Coverage 확보에 불리한 조건을 가지고 시작하는 사례이다.\nCoverage(R/UB)의 관찰 목적은 LLM이 만든 Harness가 API Gadget을 충분히 포함한다면, 이후 Branch Coverage 확보에 문제가 없는지 확인하기 위함이다. Nested Branch가 유독 많거나, Branch의 조건이 tight 한 경우에는 많은 API가 테스트 되어도 Random Mutation 등의 한계로 여전히 Branch Coverage 확보가 어려울 수 있다.\n실제로 상한 대비 Coverage가 70% 미만인 프로젝트는 총 6건이 관찰되었다. 이중 libvpx와 libaom은 비디오 코덱 라이브러리로, 입력에 따라 어떤 코덱 모듈이 실행될지 결정된다. Public corpus에 특정 코덱이 주어지지 않거나, 운이 좋게 변조된 입력이 다른 코덱으로 인식되어도, 후속 파싱 과정에서 sanity check failure로 조기 종료될 가능성이 높다.\n이러한 사례들은 라이브러리에 존재하는 전체 함수의 수 대비 API로 공개된 함수의 수가 10% 미만이다(이하 Exposed API, %).\n원인 불명의 두 개 라이브러리 libpng와 libpcap을 제외하면 나머지는 Executed API의 비율 70% 이상, 상한 대비 Coverage(R/UB) 역시 70% 이상으로 양호한 경향을 보인다.\nTP Rate and Executed API\n다음은 12개 프로젝트, 40회의 실험에 대한 Pearson Correlation Matrix이다.\nFigure 6. Matrix of Pearson Correlation\n항목 설명 api/prompted(%): 전체 API Gadget 중 Harness 생성 프롬프트에 기재된 API Gadget의 비율 api/executed(%): 전체 API Gadget 중 TP Harness에 포함되어 1회 이상 테스트 된 API Gadget의 비율 api/energies(mean): Harness 생성 시도가 종료된 후 최종 API별 Energy 값의 평균 api/coverages(mean): Harness 생성 시도가 종료된 후 최종 API별 Branch Coverage의 평균 api/#apis(log): 전체 API Gadget의 수 (log-scale) branch/#branches(log): 프로젝트 내 전체 Branch의 수 (log-scale) branch/coverage(%): Fuzzing 종료 후 최종 Branch Coverage llm/quota($): Harness 생성에 사용한 LLM API 비용 llm/#call: Harness 생성 중 총 LLM을 호출한 횟수 llm/tp-rate(%): 생성된 Harness 중 검증 과정을 전부 통과한 Harness의 수 이번 AgentFuzz 프로젝트는 Branch Coverage 확보를 대전제로 잡는다.\nBranch Coverage(i.e. branch/coverage, %)와 다른 지표의 상관관계를 살피면, 다음의 순서대로 계수가 높은 것을 확인할 수 있다.\n(절댓값 기준) api/coverages(mean) 0.88 \u0026gt; api/energies(mean) 0.76 \u0026gt; branch/#branches(log) 0.75 \u0026gt; llm/tp-rate(%) 0.73 \u0026gt; api/#apis(log) 0.71 \u0026gt; api/executed(%) 0.70 이중 api/coverages(mean)과 api/energies(mean)은 직접적으로 Branch Coverage와 포함 관계를 가지는 지표이기에 제외, branch/#branches(log)와 api/#apis(log)는 프로젝트와 함께 주어지는 수치이므로 제외한다.\n현재 관찰된 지표 내에서 0.70 이상의 계수를 가지며, 개선의 대상으로 삼을 수 있는 지표는 TP Rate와 Executed API의 비율이다.\n앞서 확인하였듯, Executed API는 직접적으로 Branch Coverage와 인과 관계를 가지는 지표이며, 12개의 프로젝트 중 4개의 프로젝트는 70% 미만의 Executed API를 가진다. 이는 특히 libxml2에서 그 문제가 두드러진다(Executed API 9.41%).\nExecuted API를 개선할 수 있다면, 확보 가능한 Branch Coverage의 상한을 높이는 일이 될 것이다.\nQ. 정말 대부분의 API가 LLM에게 전달되었는가\nExecuted API를 살피기 전, 정말 대부분의 API가 LLM에 전달되었는지 확인해야 한다. 만약 LLM에 API가 전달되지 않았다면, Execution은 당연히 기대할 수 없다.\nproj#revision Total API Prompted API Executed API Executed/Prompted (%) cjson#424ce4c 76 76(100%) 76(100%) 100% zlib#545f194 88 87(98.86%) 81(92.04%) 93.10% c-ares#3b8058 135 135(100%) 17(12.59%) 12.59% sqlite3#27095f 291 290(99.65%) 226(77.66%) 77.93% libpng#d3cf9b 246 246(100%) 229(93.08%) 93.08% libmagic#cf6bf1 18 18(100%) 11(61.11%) 61.11% libpcap(1.11.0) 84 83(98.80%) 76(90.47%) 91.56% lcms#5c54a6 291 287(98.62%) 221(75.94%) 77.00% libtiff#7a3fb2 196 193(98.46%) 75(38.26%) 38.86% libvpx#b15d2a 37 37(100%) 36(97.29%) 97.29% libaom#47f42d 47 45(95.74%) 46(97.87%) 97.82% libxml2(2.9.4) 1594 1109(69.57%) 150(9.41%) 13.52% 확인 결과 libxml2를 제외한 11개 프로젝트는 모두 95% 이상의 API가 LLM에게 전달되었다. libxml2 역시 70%에 가까운 API가 LLM에게 전달되었으나, 전달된 API 중 13.52%만이 실제 TP Harness에 1회 이상 포함되었다.\n앞서 Executed API의 비중이 70%를 넘지 않았던 c-ares, libmagic, libtiff, libxml2는 Prompted API 대비 Executed API의 비율이 역시 70%를 넘지 않았다.\n이는 반대로 API Gadget이 1천여개를 넘지 않는다면, gpt-4o-mini 기준 5$의 budget 내에서 현재의 Harness Mutation이 만드는 조합이 전체 API를 1회 이상 테스트하는데 충분함을 의미한다.\nFigure 7. API Mutations (좌: libpcap 1.11.0, 우: libxml2 2.9.4)\n위는 각 Round에서 몇 개의 API가 Mutator에 의해 제거되었고(removed), 유지되었으며(keep), 새로 추가되었는지를 보인다(inserted). API Mutator는 평균 80% 이상의 API를 매번 교체한다(libpcap 82%, libxml2 98%).\nPrompted API에 포함되지 않은 API는 Budget 등 조건에 의해 Harness 생성이 조기 종료되지 않는다면, 시간이 지남에 따라 충분히 포함될 여지를 가진다.\nFYI. 1회 이상의 테스트를 통해 Quality와 Density 지표를 기반으로 API의 조합에 따른 경향을 살피고 싶다면, 5$ 이상의 Budget을 요구할 수 있다. 이는 이번 프로젝트에서는 다루지 않는다.\nProblems; TP Rate\n아래는 각 벤치마크를 5$ 내에서 구동하며 LLM이 생성한 Harness의 수(Generated Harnesses)와 모든 검증 과정을 통과한 Harness의 수(TP Harnesses)이다.\nproj#revision Generated Harnesses TP Harnesses TP Rate cjson#424ce4c 1050 170 16.19% zlib#545f194 1660 155 9.33% c-ares#3b8058 8880 92 1.03% sqlite3#27095f 4300 797 18.53% libpng#d3cf9b 5450 327 6.00% libmagic#cf6bf1 10000 8 0.08% libpcap(1.11.0) 8950 187 2.89% lcms#5c54a6 8620 267 3.09% libtiff#7a3fb2 11660 2 0.017% libvpx#b15d2a 8180 194 2.37% libaom#47f42d 2500 145 5.80% libxml2(2.9.4) 8770 15 0.17% 도표에서 확인할 수 있듯, 대개 TP Rate는 10%를 넘지 않는다.\nlibxml2의 사례를 살폈을 때, 각 검증 단계의 실패 비율은 다음과 같다(모수 8770개 Harness).\nSyntax Error Link Error Execution Failure Coverage Ungrowth Critical Path Unhit Hang 76% 0.98% 17.9% 0.18% 4.5% 0.1% 사실상 대부분의 Harness가 단번의 컴파일에 성공하지 못하는 상황이다. OSS-Fuzz-Gen과 달리 PromptFuzz는 재시도를 수행하지 않기에, LLM이 자체적으로 고칠 수 있는 컴파일 에러 역시 묵과하고 모두 실패 처리한다.\n이 중 일부는 Instruction Prompt에 기재된 API Gadget의 시그니처만으로 인자를 정상 기입하지 못해 발생한다. 인자의 타입이 aliased type인지, 구조체라면 어떤 타입의 멤버를 가지는지 등 정보를 충분히 확보하지 못했다면, LLM은 인자에 기입할 데이터의 타입을 적절히 선정하지 못하고, 이는 syntax error로 이어진다.\n이러한 API를 포함한 Harness는 지속적으로 검증에 실패하고, 해당 API는 테스트 되지 못한 채 $\\mathrm{Prompt(\\cdot)}$ 항에 의해 Energy의 감소를 겪어, 끝내 TP Harness에 단 한 번도 포함되지 않는다. 앞서 Executed API의 비율이 특히 낮았던 libxml2에서 자주 관측되는 사례이다.\n결국 Executed API의 비중을 높여, 실행 가능한 Branch의 상한을 추가 확보하기 위해서는 Syntax Error를 통과할 수 있는 환경을 구성해야 한다.\n그러고 나면 Exposed API의 비중이 낮은 2개 사례를 제외하고, Executed API의 비중이 낮은 4개 프로젝트, 상한 대비 Coverage가 70% 미만인 원인 불명의 2개 프로젝트에서 개선을 관측할 수 있길 기대한다.\nPre-trials\n다음은 AgentFuzz 개발 이전의 개선 시도이다. 실험의 대상은 가장 경과가 좋지 않았던 libxml2이다.\nTrial#1: Fix Syntax Error\n가장 먼저 시도한 것은 OSS-Fuzz-Gen과 같은 Syntax Error 개선 시도이다.\nPromptFuzz는 컴파일에 실패한 모든 Harness를 폐기한다. 생성된 Harness 중 76%가 Syntax Error 단계에서 폐기된다. OSS-Fuzz-Gen은 최대 5회까지 컴파일 에러를 LLM에게 전달하여 Syntax Error 수정을 요구한다. 이를 참고하여 동일한 instruction으로 PromptFuzz에서도 Harness의 수정을 시도하였다. (ref:git+revsic/PromptFuzz/commit/7438a0dc86cfb3604618bc33f470b9e3cd60990c)\nGiven the above C fuzz harness and its build error message, fix the code to make it build for fuzzing. If there is undeclared identifier or unknown type name error, fix it by finding and including the related libraries. MUST RETURN THE FULL CODE, INCLUDING UNCHANGED PARTS. Below is the error to fix: The code has the following build issues: `` {} `` Fix code: 1. Consider possible solutions for the issues listed above. 2. Choose a solution that can maximize fuzzing result, which is utilizing the function under test and feeding it not null input. 3. Apply the solutions to the original code. It\u0026#39;s important to show the complete code, not only the fixed line. proj#revision TP Rate Branch Cov Executed API libpcap(1.11.0) 187/8950(2.89%) 39.76% 76/83/84(90.47%) libpcap(1.11.0) syntax-error fix 68/4255(1.598%) 35.30% 76/83/84(90.47%) libxml2(2.9.4) 15/8770(0.17%) 1.31% 150/1109/1594(9.41%) libxml2(2.9.4) syntax-error fix 20/2138(0.935%) 1.38% 153/476/1594(9.59%) 기본적으로 Syntax Error를 수정하는 과정에서 LLM API 비용이 추가 발생하므로, 동일 Budget 내에서 생성된 Harness의 모수는 줄어들었다(8950 \u0026gt; 4255, 8770 \u0026gt; 2138). libpcap에서는 TP Rate가 줄어들었으나, 실행된 API의 비율은 동일하게 유지되었다. 동일 Harness 생성 모수 187개까지 비용을 더 투자하였다면, 선형 추정 시 TP Harness는 143개였을 것이기에 Branch Cov 역시 유사한 수준까지 오를 것이라 기대할 수 있다.\nlibxml2에서도 극적인 개선을 보이지는 않았다. 마찬가지로 Harness 생성 시도가 줄었지만, TP Rate는 5배가량 개선되었다. 그에 따라 Executed API와 Branch Coverage도 미세하게 증가하였다. Prompted API 대비 Executed API의 비중은 13.52%(150/1109)에서 32.14%(153/476)로 증가한 만큼, Saturation의 속도는 감소할 것으로 기대한다.\n실제로 Syntax Error에 의한 검증 실패는 6천여건에서 1천여건 이상 감소하였지만(~16% 감소), 후속 Coverage Growth와 Critical Path Hit 단계의 오류는 증가하였다.\n이를 두고 동일 Budget 내에서 Tp Rate이 개선되었다고 보기는 어렵다.\nTrial#2: Extend gadget length\n다음은 Gadget length를 늘려보았다.\nPromptFuzz는 API Sequence의 길이를 10으로 두어, LLM에게 최대 10개의 API를 포함하는 Harness 생성을 요구한다. 이 시도는 libxml2만을 위한 시도로, API의 수가 많아 Prompted API가 유독 낮은 프로젝트에 대해 API Sequence의 길이를 20까지 증가시켜 Prompted API의 비율을 높일 수 있는지 보았다.\nproj#revision TP Rate Branch Cov Executed API libxml2(2.9.4) 15/8770(0.17%) 1.31% 150/1109/1594(9.41%) + gadget length=20 11/8640(0.127%) 1.06% 63/1585/1594(3.95%) 실제로 Prompted API는 99.43%에 가깝게 증가하였지만, 오히려 TP Rate와 Coverage는 감소하였다. 이는 Gadget의 수가 증가하면서 인자의 타입 추정 실패로 인한 Syntax Error가 더 자주 발생하여 TP Rate를 낮춘 것이 원인일 것으로 추정된다.\nGadget length Syntax Error Link Error Execution Failure Coverage Ungrowth Critical Path Unhit Hang 5~10 76%(6669) 0.98%(86) 17.9%(1573) 0.18%(16) 4.5%(401) 0.1%(10) 10~20 81%(7105) 1.1%(96%) 14.5%(1255) 0.092%(8) 2.8%(247) 0.92%(8) Q. Generate Harness until all APIs are executed ?\nAPI Sequence의 길이를 늘리는 것이 부수 효과를 발생시켜 오히려 TP Rate를 낮추는 현상을 확인했다. 그렇다면 Budget 등 종료 조건이 없는 상황에서 시간과 자원을 투자한다면 70% 이상의 Executed API를 확보할 수 있을까.\n우선 libxml2에 대해 10$ API Budget을 모두 소모할 때까지 돌려보았다. 총 218시간(=9일 2시간) 동안 구동하였지만, TP Rate 0.601%, Branch Coverage 2.43%이다. 선형 추정하였을 때도 Branch Coverage 100%를 위해서는 500달러(25.01.27.기준 71만원)의 Budget과 10,900시간(454일)의 시간이 필요하다.\nproj#revision TP Rate Cost(4o-mini) Coverage Expectation lcms#5c54a6 3.09% 78H, 5.0$ 42.70% 182H(7D), 11.70$ libaom#47f42d 5.80% 176H, 10$ 15.79% 1,114H(46D), 63.33$ libxml2(2.9.4) 0.601% 218H, 10$ 2.43% 10,900H(454D), 500$ sqlite3#27095f 18.53% 266H, 10$ 62.44% 426H(17D), 16.01$ 이는 선형 추정이므로, Saturation을 고려하였을 때는 이보다 많은 시간과 비용이 필요할 것이다. TP Rate는 단순 Executed API 확보뿐 아니라, 현실적 시간 내에 유의미한 Harness를 얼마나 만들 수 있는가의 또 다른 논의를 만든다.\nAgentFuzz\nAgentFuzz는 단위 시간 내 TP Rate 개선을 목표로 하였다.\ngit+revsic/agent-fuzz Syntax Error에 관한 피드백은 해당 단계의 오류를 1천여건 이상 감소시켰지만, 그만큼의 오류가 후속 검증 단계로 옮겨갔다. 전반적인 검증 단계에서의 오류 수정 시도가 필요하다.\n그를 위해서는 LLM이 \u0026ldquo;Project에 대한 이해\u0026quot;를 가져야 한다고 판단한다. 여기서 \u0026ldquo;이해\u0026quot;는 \u0026ldquo;특정 브랜치를 Hit 하도록 Harness를 조작하기 위해 필요한 지식\u0026quot;으로 정의한다. 함수의 정의, 함수 간 참조 관계 등의 정보가 필요할 것으로 보인다.\n이러한 이해를 LLM에게 전달하기 위해서는, 사전에 정보를 모두 전달하거나 필요할 때마다 Tool Call을 통해 획득할 수 있게 두어야 한다. 사전에 모든 정보를 전달하기에 C 프로젝트의 함수는 하나하나의 길이가 길어, 전문을 첨부할 경우 Context length에 의한 추론 성능 하락이 발생할 수 있다[ref:RULER, Hsieh et al., 2024. arXiv:2404.06654]. 이에 필요에 따라 정보를 획득하도록 설계하였고, LLM Agent의 형태로 구현하여 \u0026ldquo;agent-fuzz\u0026rdquo; 프로젝트로 명명했다.\nRe-implement PromptFuzz with Python\n가장 먼저 PromptFuzz를 Python으로 재현하였다. PromptFuzz는 Rust로 구현되어 있었고, 그다지 친숙하지는 않은 개발 환경이었기에 가장 활발히 사용한 언어로 재현하며 구현 상세를 이해하고자 하였다.\n재현하는 과정에서 PromptFuzz를 구동하며 겪은 불편함도 몇 가지 해결하였다.\nPromptFuzz는 CDG를 구성하고 Critical Path를 발췌하는 과정에서 직접 AST를 순회한다. 문제는 이 과정에서 Visitor가 구현되지 않은 AST Node가 발견되면 panic을 내며 Harness 생성을 종료한다. 직접 AST Visitor를 구현한다면 재현체에서도 동일하게 발생할 문제이기에, LLVM의 opt를 활용하여 CFG를 생성하는 방식으로 대체하였다.\nFigure 8. A dot-CFG Sample\nopt는 LLVM Optimizer 겸 Analyzer로, IR을 입력으로 CFG를 생성하는 옵션을 제공한다. 생성된 CFG를 기반으로 가장 긴 API Call Sequence를 파싱한다면 구현되지 않은 AST Visitor를 고민할 필요가 사라진다.\n그 외에도 C/C++이 아닌 언어에서도 사용할 수 있도록 추상화하는 작업과 프롬프트 템플릿 분리 등 몇몇 리팩토링을 병행하였다.\nTool Call Design\nAgentFuzz는 검증을 통과하지 못한 Harness를 재사용하여 TP-Rate를 높이는 것이 목표이다. 이는 현실적인 시간 내에 가용한 Harness를 많이 확보하기 위함이고, 이를 통해 Executed API의 비중을 높여 프로젝트의 전반적인 Coverage를 상향 평준화하기 위함이다.\n이를 위해 AgentFuzz는 두 가지 기능상 요구사항을 가진다.\n생성된 Harness가 검증에 실패할 경우, 실패 원인을 피드백하여 LLM에 개선을 요구할 수 있어야 한다. Harness 개선에 필요한 정보를 제공할 수 있어야 한다. 요구사항을 LLM Agent에 녹여내기 위해 (1) 생성한 Harness를 평가하고 피드백하는 Tool과 (2) 프로젝트의 정보를 제공하는 Tool을 구현하였다.\n프로젝트의 정보 검색 Tool은 Harness에 포함하라 전달된 API의 정의를 검색할 수 있는 기능과 소스 코드의 일부를 읽고 반환하는 기능 두 가지로 단순히 구성하였다.\nValidation Feedback\nHarness Validation에 관한 Tool로는 validate 함수를 구현하였다.\nLLM은 Harness를 반환하기 이전, 생성한 Harness를 validate Tool을 통해 검증할 것을 요구받는다. OpenAI의 Tool Calling API를 통해 validate Tool의 명세를 전달하면, LLM은 Harness를 입력으로 validate Tool을 호출한다.\ndef validate(self, harness: str) -\u0026gt; dict: \u0026#34;\u0026#34;\u0026#34;Validate the given harness. Validation consists of seven steps. 1. Parse the code segment from the requested harness. The process only uses the code segment enclosed within ``` ```. 2. Compile the code segment into a runnable fuzzer. 3. Run the fuzzer. 4. Check whether the coverage has increased more than the global coverage. 5. Check whether all APIs have been hit. If all steps pass, you will see a \u0026#34;success\u0026#34; flag in the response. However, if something is wrong, you will see an error flag and the steps where the error occurs. Then you should fix the harness to ensure the steps pass and retry the validation. Parameters ---------- harness : str The requested harness, for example, ```cpp #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; extern \u0026#34;C\u0026#34; int LLVMFuzzerTestOneInput(const uint8_t data, size_t size) { // your harness here } ``` \u0026#34;\u0026#34;\u0026#34; Validator는 Harness를 각 단계에 맞게 검증하고, 실패할 경우 사전에 정의된 피드백을 전달한다.\nFigure 9. Tool Call: Harness Validation (Compile failure)\nFigure 9은 그 중 컴파일에 실패했을 때의 피드백이다. 단순히 컴파일 에러를 첨부하는 것만으로도 LLM이 Syntax Error가 수정된 Harness를 생산할 수 있음을 확인하였다.\nFigure 10. Tool Call: Harness Validation (Coverage Ungrowth)\n다음은 Coverage Ungrowth이다. 현재까지의 Harness Generation 과정에서 발견하지 못했던 Branch가 존재하는지를 피드백한다. 우선은 단순히 Coverage가 낮음을 지적한다.\nFYI. Ideation: Fuzz blocker나 Hit되지 않은 새로운 Branch를 명시적으로 제안하는 것도 하나의 피드백이 될 수 있어 보인다.\nFigure 11. Tool Call: Harness Validation (Critical Path Unhit)\n마지막은 Critical Path Unhit이다. Critical Path에 포함된 API 중 일부가 호출되지 않은 경우에, Local Coverage를 토대로 호출된 함수와 호출되지 않은 함수를 구분하여 전달한다.\nFYI. Local Coverage: 현행 Validation 단계에서 10분간 Fuzzing을 수행하면서 획득한 Coverage로 정의. 이전까지의 Seed Harnesses에서 획득한 모든 Coverage는 별도로 병합하여 Global Coverage로 정의-관리.\nInitial Run\n이렇게 두 가지 툴이 주어졌을 때, 최대 30회의 Tool Call 내에 Harness 생성을 지시했다. gpt-4o-mini-2024-07-18은 대개 다음 순서에 따라 Harness 생성을 시도한다.\nAPI Sequence에 포함된 API 각각의 정의를 검색 정의 검색 결과를 토대로 정의에 해당하는 코드 영역을 리뷰 Harness 생성, 평가 함수 호출 반복 최초에는 미리 함수의 정의를 전달하는 것이 비효율적일 것이라 판단하였으나, 실제 LLM의 경향상 정의를 사전에 전달하여도 무관했을 것으로 보인다.\nAgentFuzz의 최초 Testbed는 cJSON으로 삼았다. API의 수가 적고 PromptFuzz에서도 Coverage가 높았던 프로젝트이기에 상대적으로 쉬운 대상으로 여겼다.\ncJSON 프로젝트 기준, Agent는 최초 시동에서 39회의 Harness 생성 시도 중 회당 평균 13.84회의 Tool Call을 수행하였다. 이 중 4회는 LLM을 30회 이상 호출하여 강제 중지되었으며, 21개의 Harness가 정상 생성되었다.\nTP Rate는 53.84%(21/39)이며, 회당 평균 13.84회의 LLM 호출이 있었으므로 PromptFuzz와 비교한다면 3.88%(21/540)로 볼 수 있다. 기존 16.19%(170/1050)와 비교한다면 23% 정도로 많이 감소한 수치이지만, Branch Coverage는 77.53%로(기존 82.08%) 감소 폭이 상대적으로 적은 편이다.\n다음은 LLM Agent를 통해 Harness 생성을 시도하면서 1493회의 Tool Call, 그중 1261회의 Validation Failure를 통계화한 도표이다.\nParse Error Compile Error Execution Failure Coverage Ungrowth Critical Path Unhit 0.40% 3.82% 0% 62.76% 1.94% Harness 평가에 관한 피드백 이후 Compile Error는 3.82% 수준이다. 하지만 cJSON은 libxml2과 대비하여 Compile Error의 비율이 낮았던 프로젝트이기에, 기존의 컴파일 에러 76%와 직접 비교할 수는 없다.\n그 외에 Coverage Ungrowth에서 상당히 많은 오류가 발생함을 확인할 수 있었다.\nproj#revision TP Rate Branch Cov Executed API cjson#424ce4c 170/1050(16.19%) 852/1038(82.08%) 76/76/76(100%) - AgentFuzz Baseline 42/135(31.11%) 809/1038(77.93%) 70/72/76(92.10%) libpcap(1.11.0) 187/8950(2.89%) 3129/7870(39.76%) 76/83/84(90.47%) - AgentFuzz Baseline 48/167(28.74%) 2684/6476(41.44%) 134/302/317(44.86%) libxml2(2.9.4) 15/8770(0.17%) 935/71378(1.31%) 150/1109/1594(9.41%) - AgentFuzz Baseline 77/142(54.22%) 4925/40018(12.30%) 213/755/1683(12.65%) 최초 시동 이후 3개 프로젝트에 관하여 10$ Budget 내에서 구동을 시도하였다. 실제로 TP Rate는 높게 나왔으나, 시도 횟수는 Tool Call 빈도에 비례하여 줄어들었다. 또한 구현상의 차이로 집계된 API의 수와 Branch의 수가 다소 차이가 나기도 한다. 이에 표에는 모수를 병기한다.\ncJSON은 모수가 온전히 동일함에도 4% 정도의 Branch Coverage 하락을 보였다. libpcap 또한 Cover 된 Branch의 수가 줄었으나, libxml2에서는 확연한 개선을 보였다. Executed API와 Branch Cov 모두 월등히 증가하였다.\n최초 목표와 같이 상향 평준화의 논의에서 유의하다.\nFigure 12. Saturation of Executed API (cJSON, libpcap, libxml2)\n예상과 다른 부분도 존재한다. Prompted API가 선형 증가하는 것에 반하여 Executed API와 Branch Coverage는 앞서 포화 상태(이하 Saturation)에 이른 것으로 보인다. 이는 API가 특정 이유로 TP Harness에 편입되지 못함을 의미한다.\nTP Rate와 Executed API 개선을 위해 Validation Feedback이 적절히 이뤄지는지 확인이 필요했고, 각 피드백에 대한 LLM의 반응을 살폈다.\nReactions\n다음은 피드백이 주어진 횟수와 피드백 후 해당 단계를 통과한 사례의 수이다. (Execution Failure는 발생하지 않아 표에서는 배제하였다.)\nParse Error Compile Error Coverage Ungrowth Critical Path Unhit Pass Rate 5/6(83.33%) 51/57(89.47%) 143/937(15.26%) 17/29(58.26%) Coverage Ungrowth에서 압도적인 횟수로 검증 실패가 발생했고, 피드백이 발생하였을 때 개선 역시 낮은 비율로 발생하였다. 이에 각 사례에 대해 실제 케이스를 정성적으로 살피며, 주요 문제점이라 인지된 부분을 정리해 보았다.\nFigure 13. Reaction of Compile failure\n컴파일에 실패한 경우는 대개 include를 하지 않았거나, API Signature를 맞추지 않은 경우였다. 곧장 수정하거나 API의 정의를 검색하는 정도의 반응을 통해 대개 많은 경우에서 정상 수정되었다.\nFigure 14. Reaction of Coverage Ungrowth\nCoverage가 증가하지 않았을 때 LLM에게 기대한 반응은 API의 실행 순서, 조합, 상황 가정 등을 바꿔가며 시도하길 바랐다. 하지만, LLM은 단순히 API의 종류를 늘리거나, 입력을 생성하는 파이프라인을 직접 만들려 시도하였다. 이를 통해 실제 Coverage를 높일 수도 있겠으나, API의 종류를 늘리려는 시도 또한 다양하지 못하다 보니 크게 유의미하지 않다.\nFigure 14. Reaction of Critical Path Unhit\nCritical Path를 모두 실행하지 못한 경우는 대개 항상 거짓인 조건문에 의해 주요 블록이 실행되지 않은 것이 원인이었다. 예로, 아래의 코드는 실제 생성된 Harness의 일부이다. \u0026quot;exampleKey\u0026quot; 키의 존재 여부를 파악한 후 조건문을 이어간다. 당연하게도, 많은 케이스에서 해당 키값은 주어지지 않을 것이고 대부분의 경우에서 다음 조건문은 거짓이다.\n이러한 경우에 LLM은 단순히 \u0026quot;exampleKey\u0026quot;를 json_object에 추가하거나, API의 호출 자체를 지워버리는 등의 시도를 보인다.\n// THE REAL SAMPLE OF THE GENERATED HARNESS // Parse the JSON data cJSON *json_object = cJSON_Parse(json_string); free(json_string); // Free the string after parsing if (!json_object) { // Handle parse error return 0; } // Get an item from the object (case-sensitive) cJSON *item = cJSON_GetObjectItemCaseSensitive(json_object, \u0026#34;exampleKey\u0026#34;); if (item) { ... } Coverage Ungrowth, Critical Path Unhit의 주요 문제는 생성된 Harness가 Mutated Input Byte Stream이 아닌 상수 입력을 사용하는 사례가 잦다는 것이다. 이는 PromptFuzz에서도 동일하게 발생한다.\n위에서는 언급하지 않았지만, PromptFuzz는 생성된 Harness에 대해 상수 Literal을 AST 수준에서 발췌하여 Fuzzed Data Provider(이하 FDP)로 대치한다. 이후 상수는 Corpus 뒤에 덧붙여져 FDP에 의해 전달되며, 마찬가지로 Mutation의 대상으로 삼아진다.\n결국 PromptFuzz 또한 이러한 문제를 인지하고 있었으며, 그의 대책으로 FDP를 도입한 것으로 보인다.\nAgentFuzz에서는 아직 FDP 대치 모듈을 구현하지 않았기에, 관련된 논의는 Future Works로 남긴다.\nPrompt Engineering\nLLM의 Reaction이 의도와 다름을 확인하였다. 이에 의도에 맞는 Reaction을 보이도록 가이드라인을 주고자, Zero-shot CoT Prompting을 시도하였다.\n가장 크게 Coverage Ungrowth의 피드백으로는 이 단계가 숫자 싸움이 아닌 Unique Branch를 탐색하는 과정임을 밝히고, 단순 API를 추가하기보다는 다양한 방면에서 Harness를 검토하길 권고했다. 예로, Mutated Input Byte Stream을 사용하도록 권고하고, 상수 키를 통한 gathering보다는 iteration을 통해 데이터를 획득하는 방향을 제안하였다.\nThis validation step (coverage-growth) is designed to check whether a new unique branch was covered, rather than simply measuring coverage growth in a naive way We do not recommend using additional APIs. Instead of increasing the number of APIs, we suggest thoroughly reviewing and modifying the harness. Here are some possible review questions: 1. Are you making sufficient use of the input byte stream from LLVMFuzzerTestOneInput: `const uint8_t *data`, or are you relying on hardcoded data or your own data generation stream? We recommend utilizing the input byte stream rather than generating your own input or using hardcoded test cases. 2. Are the APIs in the harness organically connected? For example, in Python, if you create a dictionary `a = dict(**data)`, you could then test the `del` operation with `for k in a: del a[k]`. This would be a well-organized case. However, if you simply test `del a[\u0026#34;exampleKey\u0026#34;]` without checking if exampleKey exists in a, the test case may not be properly covered. Additionally, this approach only covers the specific case of `exampleKey` and does not fully utilize the input stream data. Based on these types of questions, list the areas you want to review in the harness, conduct the review, and then rewrite the harness to achieve more unique branch coverage 마찬가지로 Critical Path Unhit 역시 Harness의 검토를 권고하고, 예로 조건 분기 흐름이 항상 거짓인지 검토할 것을 제안하였다.\nThis validation step (api-hit) is designed to check whether the APIs are correctly invoked during the fuzzing of the harness. We recommend thoroughly reviewing the harness and modifying it to ensure that all APIs from the harness are invoked. Here is a possible review question: Q. Does the control flow of your harness sufficiently cover the API calls? For example, in Python, if you create a dictionary `a = dict(**data)`, you might construct a control flow like `if \u0026#34;exampleKey\u0026#34; in a: delete_item(a, \u0026#34;exampleKey\u0026#34;)` to test the `delete_item` API. However, since the input byte stream `data` is provided by the fuzzer, in most cases, `exampleKey` will not be a member of `a`. As a result, this control flow will rarely invoke `delete_item`. A better approach would be to modify it to `for key in a: delete_item(a, key)` to ensure the `delete_item` API is tested. This will invoke the `delete_item` API, allowing the `api-hit` round to be passed. Based on these types of questions, list the areas you want to review in the harness, conduct the review, and then rewrite the harness to ensure that all APIs are invoked. 이는 git+revsic/agent-fuzz의 experiment/feedback에서 확인 가능하다.\n경과가 만족스럽지는 않았다. 일차적으로 성능상 개선이 미비하다.\nproj#revision TP Rate Branch Cov Executed API cjson#424ce4c 170/1050(16.19%) 852/1038(82.08%) 76/76/76(100%) - AgentFuzz Baseline 42/135(31.11%) 809/1038(77.93%) 70/72/76(92.10%) + Zero-shot CoT 35/182(19.23%) 734/1038(70.71%) 67/70/76(88.15%) libxml2(2.9.4) 15/8770(0.17%) 935/71378(1.31%) 150/1109/1594(9.41%) - AgentFuzz Baseline 77/142(54.22%) 4925/40018(12.30%) 213/755/1683(12.65%) + Zero-shot CoT 101/189(53.43%) 4760/40018(11.89%) 261/826/1683(15.50%) 피드백의 발생 빈도 역시 제자리에 가깝다. Coverage Ungrowth와 Critical Path Unhit 모두 1% 내외의 차이를 보인다.\nParse Error Compile Error Coverage Ungrowth Critical Path Unhit Baseline 6/1493(0.40%) 57(3.82%) 937(62.76%) 29(1.94%) Zero-shot CoT 46/2448(1.87%) 85(3.47%) 1554(63.48%) 30(1.25%) 정성 평가에서 리뷰를 수행하는 시도를 확인하였고, Coverage Ungrowth에서 실제로 의도에 맞게 개선된 사례도 관찰하였다. 하지만 이로는 부족해 보이기도 한다.\nFigure 15. Feedback before and after (Critical Path Unhit)\nRepetition Problem\n여기까지 진행한 시점에서 졸업 프로젝트의 종료 시점은 다가와 갔고, 더 Prompt Engineering에 집중하기보다는 남은 문제를 정리한 후에 종료하는 방향으로 논의가 이뤄졌다.\n남은 문제는 두 개이다. 하나는 Agent의 반복 현상이고, 남은 하나는 허수 API의 존재이다.\n실행 로그를 살피던 중, 다음의 이상 로그를 관찰하였다.\nPrompted API를 활용하여 Harness를 작성, Compile Failure 발생 헤더 파일을 포함하지 않았거나, static 함수를 포함하여 linker 에러 발생 에러를 수정하기 위해 문제의 API를 제거 Coverage Ungrowth 발생 문제의 API를 다시 Harness에 추가, Compile Failure 발생 문제의 API 제거, Coverage Ungrowth 발생 문제의 API를 Harness에 추가, \u0026hellip; 반복 이러한 반복 현상은 30회 이상의 Tool Call이 이뤄진 대부분의 사례에서 관측되었으며, 전체 Harness 생성 시도의 10% 정도에 해당한다.\nLLM이 History에 대조하여 새로운 행위를 탐색하는 것이 아닌, 이를 토대로 실패했던 행위를 반복한다 판단하여 Conversation History를 축약하는 방향을 고려하였다. 특히, 당시에는 RULER, Hsieh et al., 2024. arXiv:2404.06654 등으로 Context length에 관한 논의가 활발하던 시기이기에, Context length를 줄여 성능 향상을 도모할 수 있을 것이란 직관을 가지고 있었다.\n실제로 논문에서는 GPT-4의 경우 128k 컨텍스트를 지원하지만, 64k 이후로 성능이 하락함을 보였다. 현재의 AgentFuzz는 코드를 주고받는 과정에서 64k를 넘는 경우가 자주 발생하였기에, 이미 해결된 Feedback을 History에서 Truncate하는 방향으로 구성, 마지막 2~4개의 대화 기록만을 유지하게 두었다. 실제로 24~32k 수준의 Context-length로 유지할 수 있었고, 결과는 긍정적이었다.\nproj#revision TP Rate Branch Cov Executed API cjson#424ce4c 170/1050(16.19%) 852/1038(82.08%) 76/76/76(100%) - AgentFuzz Baseline 42/135(31.11%) 809/1038(77.93%) 70/72/76(92.10%) + Truncate 46/142(32.39%) 841/1038(81.02%) 72/75/76(94.73%) libpcap(1.11.0) 187/8950(2.89%) 3129/7870(39.76%) 76/83/84(90.47%) - AgentFuzz Baseline 48/167(28.74%) 2684/6476(41.44%) 134/302/317(44.86%) + Truncate 84/194(43.29%) 2230/6476(34.44%) 161/302/317(50.78%) libxml2(2.9.4) 15/8770(0.17%) 935/71378(1.31%) 150/1109/1594(9.41%) - AgentFuzz Baseline 77/142(54.22%) 4925/40018(12.30%) 213/755/1683(12.65%) + Truncate 112/203(55.17%) 5826/40018(14.55%) 247/856/1683(14.67%) Context length가 줄어드니 동일 Budget 내에서 더 많은 Harness 생성 시도가 가능할 뿐 아니라, Executed API와 Branch Coverage 역시 대개 상승한 것을 확인할 수 있었다.\nTODO; 실제로 반복 현상이 줄어들었는지는 아직 확인하지 않았다.\nAdditional Tricks\n마지막은 허수 API 문제이다. libxml2에서 발굴된 API Gadget 중에는 컴파일이 불가능한 경우가 존재한다. 예로, #ifdef 블록 안에서 함수가 정의된 경우, 현행 정적 분석기에서는 Gadget으로 획득 가능하나, Macro에 의해 해당 조건부 전처리자가 실행되지 않는다면 함수는 정의되어 있지 않다.\n이를 위해 모든 API에 대해 간단히 다음의 코드를 컴파일 시도하여 사전 검수 과정을 갖는다.\n#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026#34;{api._meta[\u0026#34;__source__\u0026#34;]}\u0026#34; extern \u0026#34;C\u0026#34; int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) { (void){api.name}; } Conclusion\n다음은 Truncation과 API 사전 검수를 포함한 최종 벤치마크 결과이다.\nproj#revision TP Rate Branch Cov Executed API cjson#424ce4c 170/1050(16.19%) 852/1038(82.08%) 76/76/76(100%) - AgentFuzz 47/206(22.81%) 834/1038(80.34%) 71/73/76 (93.42%) libpcap(1.11.0) 187/8950(2.89%) 3129/7870(39.76%) 76/83/84(90.47%) - AgentFuzz 84/194(43.29%) 2697/6476(41.64%) 161/302/317(50.78%) libxml2(2.9.4) 15/8770(0.17%) 935/71378(1.31%) 150/1109/1594(9.41%) - AgentFuzz 112/203(55.17%) 5826/40018(14.55%) 250/830/1683(14.85%) lcms#5c54a6 267/8620(3.09%) 3937/9220(42.70%) 221/287/291(75.94%) - AgentFuzz 7/195(3.58%) 1634/9190(17.78%) 154/1419/1464(10.51%) c-ares#3b8058 92/8880(1.03%) 4843/8076(59.96%) 17/135/135(12.59%) - AgentFuzz 61/190 (32.10%) 3431/9072(37.81%) 462/874/904(51.10%) zlib#545f194 155/1660(9.33%) 2037/2906(70.09%) 81/87/88(92.04%) - AgentFuzz 139/296(46.95%) 1694/2898(58.45%) 117/147/152(76.97%) libtiff#7a3fb2 2/11660(0.017%) 4270/14576(29.29%) 75/193/195(38.26%) - AgentFuzz 38/160(23.75%) 1718/13176(13.03%) 158/702/757(20.87%) libaom#47f42d 145/2500(5.80%) 9494/60100(15.79%) 46/45/47(97.87%) - AgentFuzz 62/173(35.83%) 21326/72562(29.39%) 26/414/447(5.81%) libpcap, libxml2, libaom에서는 성능 향상을 확인, lcms, c-ares, zlib, libtiff에서는 큰 하락을 보였다.\nFuture works\n여전히 실험해 보고 점검해 보아야 할 영역이 많다. Q. Context length를 줄인 것이 실질적으로 반복 현상 완화에 도움이 되었는가 Q. Quality 지표는 생성에 영향을 미치는가, API가 1회만 테스트 될 경우 조합에 관한 시도는 없는 것 아닌가 Q. Prompt Engineering을 통해 더 개선할 수 있는가 Q. Coverage Ungrowth에는 어떤 피드백이 유효한가\n그 외에도 lcms, c-ares, zlib, libtiff에서는 왜 성능 하락이 발생했는지도 확인이 필요하고, FDP 도입 및 스케쥴러의 구현도 필요하다.\n급하게 졸업 프로젝트를 마무리 짓다 보니 아쉬운게 많다. 시간이 된다면, 더 투자하여 개선을 시도해보고자 한다.\n","permalink":"https://revsic.github.io/blog/agentfuzz/","tags":["Software Testing","Fuzzing","LibFuzzer","Large Language Model","LLM","Harness"],"title":"Research: AgentFuzz, Agentic Fuzzing Harness Generation with LLM"},{"categories":["Bayesian"],"contents":" Consistency Models, Song et al., 2023. [arXiv:2303.01469] Keyword: Consistency Models, Probability Flow ODE Problem: Slow generation of Diffuison Models. Solution: Map the sample points on a trajectory to a single datum point. Benefits: Few-step generation (1 or 2 steps), accelerate the generation speed. Contribution: Introduce a new generative model, called Consistency Models. Introduction\nDiffusion Model은 높은 합성 품질을 보이지만, 50~1,000번의 forward pass를 요구하는 등 합성 속도에 한계를 가진다. Diffusion Model은 데이터의 분포에서 사전 분포까지의 forward process를 다회 진행하여, 한 번의 process에서 취급하는 transform의 변량을 작게 유지한다. 이를 통해 inverse process에 필요한 score을 unimodal gaussian으로 근사할 수 있게 되었다.\n반대로 forward process의 수가 극도로 줄어, 한 번의 process에서 취급하는 transform의 변량이 커지면, inverse process를 unimodal gaussian으로 근사하는데 한계가 생긴다. 실제로 Diffusion model을 2-steps, 5-steps로 모델링할 경우 학습의 안전성과 샘플의 품질이 떨어진다.\n이를 Mitigate 하기 위한 여러 시도가 있었다. Denoising Diffusion GANs[Xiao et al., arXiv:2112.07804]에서는 Score을 implicit model(e.g. GAN)을 통해 모델링하여 분포 형태와 무관히 학습을 수행하고자 하였고, Progressive Distillation[Salimans \u0026amp; Ho, arXiv:2202.00512]에서는 더 많은 스텝에서 학습된 Diffusion Model로부터 Distillation을 수행하기도 한다.\nNCSN[Song \u0026amp; Ermon, arXiv:1907.05600]의 저자인 Yang Song은 이에 새로운 모델군인 Consistency Model을 제안한다.\nFigure2: We learn to map any point on the ODE trajectory to its origin. (Song et al., 2023)\nScore 모델은 사전 분포의 샘플을 데이터 분포로 변환하는 과정에서 궤적(이하 trajectory)을 남긴다. 이때 Langevin-like sampler는 generation 과정에도 소량의 noise를 더해가기에, trajectory의 중간에서 어떤 데이터가 생성될지 추정할 수 없다. 일정 수준 이상의 SNR이 확보된 후에야 샘플의 형태를 어렴풋이 확인하는 정도이다.\nDDIM[Song et al., arXiv:2010.02502] 혹은 Probability Flow ODE[Song et al., arXiv:2011.13456]를 가정하여 deterministic trajectory를 구성하더라도, 5~10회 이상의 샘플링을 요구한다.\n만약 deterministic trajectory 위의 점이 주어졌을 때 trajectory의 시점을 추정할 수 있다면, 궤적을 따라 샘플링을 수행할 필요 없이 1-step으로 이미지를 생성할 수 있게 된다.\nConsistency Model(이하 CM)의 목적은 trajectory 위의 모든 점을 trajectory의 시점으로 매핑시키는 것이다. Trajectory의 종점에 존재하는 tractable noise distribution에서 시작하여 few-step 내에 data distribution sample을 획득하는 것이 목표이다.\nDiffusion Models\nCM은 continuous diffusion에서 영감을 받았다.\n$$\\mathrm{d}x_t = \\mu(x_t, t)\\mathrm{d}t + \\sigma(t)\\mathrm{d}w_t\\ \\mathrm{where}\\ t\\in [0, T],\\ T \u0026gt; 0$$\nstandard brownian motion $w_t$, drift $\\mu(x, t) = 0$, diffusion $\\sigma(t) = \\sqrt{2t}$을 가정하여, $p_t(x) = p_\\mathrm{data}(x) \\otimes \\mathcal N(0, t^2I)$의 variance exploding diffusion을 상정한다. (i.e. tractable prior $\\mathcal N(0, T^2I)$)\n위 SDE는 Reverse process에 대한 ODE의 존재성을 보장한다. 이를 [Song et al., arXiv:2011.13456]에서는 Probability Flow ODE라 표현한다.\n$$\\mathrm{d}x_t = \\left[\\mu(x_t, t) - \\frac{1}{2}\\sigma(t)^2\\nabla\\log p_t(x_t)\\right]$$\nProbability Flow ODE에 앞서 가정한 drift, diffusion term을 대입하면 $\\mathrm{d}x_t /\\mathrm{d}t = -ts_\\phi(x_t, t)$로 정리할 수 있다(이하 Emperical PF ODE). 이에 $\\hat x_T \\sim \\pi = \\mathcal N(0, T^2I)$로 ODE를 초기화하면, numerical ode solver를 통해 데이텀 포인트를 획득할 수 있게 된다.\nNumerical stability를 위해 $t = \\epsilon$에서 정지한다. ($\\because \\hat x_0 \\sim \\mathcal N(0, 0)$) (image를 [-1, 1]의 pixel value로 rescale, T=80, $\\epsilon$=0.002로 가정)\nConsistency Models\nCM은 가장 먼저 $\\{x_t\\}_ {t\\in [\\epsilon, T]}$의 Solution trajectory에 대해 Consistency function $f: (x_t, t)\\mapsto x_\\epsilon$을 정의한다. 이는 trajectory의 두 시점 $t, t\u0026rsquo;\\in[\\epsilon, T]$에 대해 $f(x_t, t) = f(x_{t\u0026rsquo;}, t\u0026rsquo;)$의 consistency를 보장하고, 종점(사전 분포)을 포함한 trajectory 위 어디서든 데이텀 포인트를 획득할 수 있게 지원한다.\nGeneration trajectory (Figure 2, Song et al., 2023)\n데이터 분포의 시점을 보장하기 위해 $f(x_\\epsilon, \\epsilon) = x_\\epsilon$의 identity function을 가정한다(boundary condition). Free-form Network $F_\\theta(x, t)$위에서 boundary condition을 만족하는 함수 $f_\\theta(x, t)$는 다음과 같이 표현할 수 있다.\n$$f_\\theta(x, t) = \\left\\{\\begin{matrix}x \u0026amp; t=\\epsilon \\\\ F_\\theta(x, t) \u0026amp; t\\in(\\epsilon, T]\\end{matrix}\\right.$$\n혹은 다음과 같이도 표현할 수 있다.\n$$f_\\theta(x, t) = c_\\mathrm{skip}(t)x + c_\\mathrm{out}(t)F_\\theta(x, t)$$\n이때 $c_\\mathrm{skip}(t)$와 $c_\\mathrm{out}(t)$는 $c_\\mathrm{skip}(\\epsilon) = 1,\\ c_\\mathrm{out}(\\epsilon) = 0$을 만족하는 미분 가능한 함수이다. 디퓨전 모델에서는 후자와 같은 Formulation을 많이 활용해 왔기에, CM은 후자를 가정한다.\n이후 사전 분포 샘플 $\\hat x_T \\sim \\mathcal N(0, T^2I)$에 대해 $\\hat x_\\epsilon = f_\\theta(\\hat x_T, T)$로 데이텀 샘플을 획득할 수 있게 된다(single-step). 만약 multistep으로 운용할 경우 $\\hat x_{\\tau_n} \\leftarrow x + \\sqrt{\\tau^2_n - \\epsilon^2}z,\\ x \\leftarrow f_\\theta(\\hat x_{\\tau_n}, \\tau_n)$로 $\\{\\tau_1, \u0026hellip;, \\tau_{N - 1}\\}$에 대해 N회 샘플링을 수행한다.\nTraining\n가장 먼저 제안할 학습 방법은 Score model로부터 Distillation을 받아오는 것이다.\n$$t_i = (\\epsilon^{1/\\rho} + \\frac{i-1}{N-1}(T^{1/\\rho} - \\epsilon^{1/\\rho}))^\\rho,\\ \\mathrm{where}\\ \\rho=7$$\nPretrained score model $s_\\phi(x, t)$이 있을 때, range $[\\epsilon, T]$를 $N - 1$개 지점으로 양자화한다(discretizing horizon, distillation 과정 중 N의 수를 scheduling 하기 위해).\nODE solver의 update function을 First-order Euler method로 가정 시 (i.e. $\\Phi(x, t; \\phi) = -ts_\\phi(x, t)$), Emperical PF ODE의 Trajectory 위 인접 샘플 포인트는 다음과 같다.\n$$\\hat x^\\phi_{t_n} = x_{t_{n+1}} - (t_n - t_{n+1})t_{n+1}s_\\phi(x_{t_{n+1}}, t_{n+1})$$\n$x \\sim p_{data}, x_{t_{n+1}}\\sim\\mathcal N(x, t^2_{n+1}I)$의 샘플링 후, adjacent data point pairs $(\\hat x^\\phi_{t_n}, x_{t_{n+1}})$에 대한 Consistency Distillation(이하 CD) objective는 다음과 같다.\n$$\\mathcal L^N_{CD}(\\theta, \\theta^-; \\phi) := \\mathbb E_{x\\sim p_{data}, n\\sim \\mathcal U(1, N-1)}[\\lambda d(f_\\theta(x_{t_{n+1}}, t_{n+1}), f_{\\theta^-}(\\hat x^\\phi_{t_n}, t_n))]$$\n이때 $\\lambda\\in\\mathbb R^+$, $\\theta^-$는 $\\theta$의 running average, $d(\\cdot, \\cdot)$은 metric function이다.\nMetric으로는 L2, L1, LPIPS를 후보로, $\\lambda = 1$, $\\theta^-$는 EMA로 가정한다. i.e. $\\theta^- \\leftarrow \\mathrm{stopgrad}(\\mu\\theta^- + (1 - \\mu)\\theta)$\nAnalysis를 통해 $f_\\theta$가 lipschitz constant를 가질 때 다음을 만족함을 확인할 수 있다. $$\\mathcal L^N_{CD}(\\theta, \\theta; \\phi) = 0 \\rightarrow \\sup_{n, x}||f_\\theta(x, t_n) - f(x, t_n; \\phi)||^2 = O((\\Delta t)^p)\\ \\mathrm{with}\\ p \\ge 1$$\n$\\theta^-$가 EMA이므로, 수렴 상황에서 $\\theta = \\theta^-$를 가정할 수 있고, T가 충분히 클 때 CM의 성능이 arbitarily accurate 해질 수 있음을 방증한다. 또한 $f_\\theta(x, \\epsilon) = x$의 identity boundary condition으로 인해 $f_\\theta(x, t) = 0$이 되는 trivial solution은 고려하지 않아도 된다.\n경우에 따라 극한을 취해 $N\\to\\infty$ Continuous-time CM을 가정할 수 있지만, jacobian vector product에 대한 미분이 필요하여 현대 딥러닝 프레임워크에서는 연산상 비효율이 존재하고, 관련된 효율적 구현은 appendix에서 논의한다.\nDistillation을 하지 않는 Consistency Training(이하 CT)는 unbiased score estimation으로 pretrained score model을 대체한다.\n$$\\nabla\\log p_t(x_t) = -\\mathbb E_{x\\sim p_{data}, x_t\\sim \\mathcal (x; t^2I)}\\left[\\frac{x_t - x}{t^2}|x_t\\right]$$\n이의 수렴성을 보이기 위해서는, $f_{\\theta^-}$가 twice continuously differentiable with bounded second derivatives여야 하고, $\\lambda$와 $\\mathbb E[||\\nabla\\log p_{t_n}(x_{t_n})]||^2_2$가 bounded, $\\forall t\\in[\\epsilon, T]: s_\\phi(x, t) = \\nabla\\log p_t(x)$인 경우에 한하여 다음을 만족한다.\n$$\\mathcal L^N_{CD}(\\theta, \\theta^-; \\phi) = \\mathcal L^N_{CT}(\\theta, \\theta^-) + o(\\Delta t)$$ $$\\inf_N\\mathcal L^N_{CD}(\\theta, \\theta^-; \\phi) \u0026gt; 0 \\to \\mathcal L^N_{CT}(\\theta, \\theta^-)\\ge O(\\Delta t)$$\ndistillation에 비해 objective가 $o(\\Delta t)$만큼 크기에, distillation에 비해 느리게 학습될 것임을 방증한다. (사견: 이는 score estimator의 variance에 영향을 받을 것으로 추정된다.)\nN에 따라 실험을 수행하였을 때, N이 작은 경우 training loss가 조기 수렴하는 경향성을 보였고, N이 클 수록 수렴은 느리지만 샘플 품질이 오르는 것을 확인하였다.\n빠른 학습과 샘플 품질의 Trade-off를 위해 N은 학습이 진행됨에 따라 점차 늘리는 방향으로 scheduling하고, 그에 따라 $\\mu$는 감소하도록 설계한다.\n$$N(k) = \\left\\lceil\\sqrt{\\frac{k}{K}((s_1 + 1)^2 - s^2_0) + s_0^2} - 1\\right\\rceil + 1 \\\\ \\mu(k) = \\exp\\left(\\frac{s_0\\log \\mu_0}{N(k)}\\right)$$\nContinuous-time이 되면 schedule function이 필요하지 않지만, 여전히 jacobian vector product에 대한 효율적인 구현이 필요하다.\nExperiments\nFigure3: Various factors that affect CD and CT / Figure4: Multistep generation. (Song et al., 2023)\nMetric function의 경우 LPIPS에서 가장 좋은 성능을 보였다. LPIPS는 Progressive Distillation에서도 유의미한 개선을 보이기도 했다. Consistency Distillation은 Progressive Distillation에 비해 uniform 하게 좋은 성능을 보였고, 샘플링 스텝이 늘어남에 따라 실제로 성능 향상을 보인다.\n아쉬운 점은 데이터셋의 이미지가 대개 작다(e.g. cifar-10 32x32, imagenet 64x64, lsun 256x256). FFHQ와 같이 mega pixel image에 대해서도 점검이 되었다면 좋지 않았을까 싶다.\nThoughts\n왜 PD 보다 CD의 성능이 나은가 PD는 여전히 Score modeling을 가정하기에, distillation을 수행하여도 posterior를 unimodal gaussian으로 근사하는데 한계를 가질 것이다(step 수가 줄어들수록 forward process의 transform 변량이 커지고, 이에 inverse process가 더 복잡한 분포의 형태를 보이므로).\n반면 Consistency model은 Score을 모델링하는 것이 아니다. Score model의 trajectory 위에서 주어진 샘플의 시점을 추정한다. 그렇기에 unimodal distribution을 가정할 필요도 없고, 분포 간 괴리를 고려할 이유도 없다. 이러한 점에서 PD에 비해 relaxed condition에서 더 좋은 성능을 보일 수 있던 것 아닌가 싶다.\n왜 Multistep generation에서 성능이 더 좋은가 잘 학습된 CM 입장에서는 trajectory의 종점에서 샘플 포인트를 추정하는 것 보다, 상대적으로 SNR이 높은 중간 지점에서 샘플 포인트를 추정하기 더 쉬울 것이다(e.g. 원본과의 PSNR이 더 높은 등).\n그렇기에 trajectory 위에서 최초 샘플링을 거쳐 이미지의 개형(e.g. low-frequency signal)을 만들고 나면, 이후 noising(on the same trajectory) 후 다시 샘플링을 수행함으로써 더 쉽게 추정된 높은 품질의 이미지를 획득할 수 있던 것 아닐까 싶다.\nWrap up\n고민해 보아야 할 부분이 더 있다.\nQ. adjacent points를 넘어 더 먼 지점의 샘플을 토대로 학습하면 어떻게 되는가\nQ. diffusion model과의 variance 차이는 어떨 것인가 (i.e. langevin-like sampler는 trajectory에 perturbation을 가하는데, DDIM, PF ODE, CM과 같은 모델은 deterministic trajectory를 가정)\nQ. Trajectory가 datum point에 대해 유일할 필요는 없는가 (i.e. 현재는 데이터와 사전 분포에서 독립적으로 표본을 획득하고, 이를 토대로 trajectory를 구축하는데, 두 분포를 독립적이라 가정해도 무방한가. 이 trajectory는 generation time에 발생 가능한 true trajectory인가)\n관련하여서는 더 고민한 후에 글로 정리할 예정이다.\nReferences\nConsistency Models, Song et al., 2023. [arXiv:2303.01469] Progressive Distillation for Fast Sampling of Diffusion Models, Salimans \u0026amp; Ho, 2022. [arXiv:2202.00512] Denoising Diffusion GANs: Tackling the Generative Learning Trilemma with Denoising Diffusion GANs, Xiao et al., 2021. [arXiv:2112.07804] Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., 2020. [arXiv:2011.13456] DDIM: Denoising Diffusion Implicit Models, Song et al., 2020. [arXiv:2010.02502] DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [arXiv:2006.11239] NCSN: Generative Modeling by Estimating Gradients of the Data Distribution, Song \u0026amp; Ermon, 2019. [arXiv:1907.05600] ","permalink":"https://revsic.github.io/blog/cm/","tags":["Machine Learning","Deep Learning","Generative","Bayesian","Consistency Model"],"title":"Consistency Models"},{"categories":["Bayesian"],"contents":"아래 글은 비공식적인 개인의 사견임을 밝힌다.\nEssay on VAE and its relationship to diffusion model Keyword: VAE, Diffusion Model, VDM, VLB Introduction\nDDPM[arXiv:2006.11239] 이후 Diffusion Model은 그 합성 품질에 힘입어 빠른 속도로 발전해 왔다.\nDDPM과 VAE[arXiv:1312.6114]는 동일하게 Variational Lowerbounds(이하 VLB)를 통해 학습되지만, DDPM에서 더 High-fidelity의 이미지를 생성한다.\nDDPM은 어떻게 VAE 보다 더 실제같은 이미지를 생성할 수 있었는가, 그에 대해 논의한다.\nVAE DDPM Objective VLB VLB Size of latent variable Smaller than data dimension Same with data dimension Generation Single forward pass Multiple forward passe (T-steps) Architecture Autoencoder w/Bottleneck U-Net w/Time-embedding Revisit: Variational Lowerbounds\nVAE는 몇 가지 문제 상황을 가정한다.\n어떤 데이터셋 $X = \\{x_i\\}^N_{i=1}$는 Random variable $x$에서 i.i.d.로 샘플링되었다. 우리는 이 데이터가 관측되지 않은 random variable $z$에 어떤 random process를 취해 생성되었다 가정할 것이다.\n$z$는 prior distribution $p(z)$에서 샘플링되고, $x$는 조건부 분포 $p(x|z;\\theta)$에 의해 생성된다. (그리고 각 분포는 $z$와 $\\theta$에 대해 미분가능하다 가정한다)\n우리는 $p(z)$가 어떻게 생긴 분포인지 모르기 때문에, $p(x; \\theta) = \\int p(z)p(x|z; \\theta)dz$의 marginalize가 불가능하다. (그렇기에 true posterior $p(z|x) = p(x|z)p(z)/(x)$ 역시 연산 불가능하다)\n이에 대응하고자 VAE에서는 approximate posterior $q(z|x; \\phi)$를 도입하여 $\\phi$와 $\\theta$를 동시에 업데이트할 수 있는 objective function $\\mathcal L$을 제안하였다.\n$$\\log p(x;\\theta) = \\mathcal L(x; \\theta, \\phi) + D_{KL}(q(z|x;\\phi) || p(z|x;\\theta))$$ $$\\mathcal L(x; \\theta, \\phi) = \\mathbb E_{q(z|x; \\phi)}\\left[\\log p(x|z; \\theta)\\right] - D_{KL}(q(z|x; \\phi)||p(z))$$\n$D_{KL}$은 0 이상 값을 가지므로 $\\mathcal L(\\theta, \\phi; x)$는 log-likelihood의 하한이 되고, 이를 optimizing 하면 log-likelihood를 ascent 하는 것과 같은 효과를 볼 수 있다는 것이다.\nDDPM 역시 Markov chain에 대한 variational lowerbound를 ascent 하는 방식으로 학습을 수행한다.\n$x = x_0,\\ z = x_T \\sim \\mathcal N(0, I)$의 T-step Diffusion Model을 가정할 때, variance schedule $\\beta_1, \u0026hellip;\\beta_T$에 대해 forward process(noising) $q(x_t|x_{t-1})$와 reverse process(denoising) $p(x_{t-1}|x_t; \\theta)$를 가정한다.\n$$q(x_t|x_{t-1}) = \\mathcal N(\\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t I), \\ p(x_{t-1}|x_t; \\theta) = \\mathcal N(\\mu_\\theta(x_t; t), \\Sigma_\\theta(x_t, t))$$\n이때 VLB는 동일하게 적용된다.\n$$\\log p(x; \\theta) \\ge \\mathbb E_{q(x_0|x)}[\\log p(x|x_0)] + \\mathcal L_{T}(x; \\theta) - D_{KL}(q(x_T|x)||p(z))$$ $$\\mathcal L_{T}(x; \\theta) = -\\sum^T_{i=1}\\mathbb E_{q(x_i|x)} D_{KL}\\left[q(x_{i-1}|x_i, x)||p(x_{i-1}|x_i; \\theta)\\right]$$\n학습 목적 함수는 사실상 같다고 봐야 한다.\nSize of latent variables\nVAE와 Diffusion Model의 차이로 떠오르는 것은 Bottleneck Architecture이다.\nVAE는 latent variable의 dimension은 대개 데이터보다 작다. Diffusion은 markov chain 내의 state를 모두 latent variable로 바라보고, 각각의 latent variable은 데이터의 dimension과 크기가 같다.\n작은 latent variable은 초기 GAN[arXiv:1406.2661] 기반의 모델에서도 공통으로 나타나는 특징이다.\n이후 VAE와 GAN 모두, 데이터 차원과 같은 크기의 잠재 변수를 도입하여 성능 향상을 본 모델이 나온다. StyleGAN[arXiv:1812.04948]은 이미지의 stochastic detail을 생성하기 위해 $\\mathbb R^{\\mathrm{H\\times W\\times 1}}$의 single-channel noise를 더하였고, NVAE[arXiv:2007.03898]는 U-Net-like architecture를 도입하면서 residual signal을 latent variable로 모델링한다.\nLeft: Figure 1, Karras et al.(StyleGAN), 2018 / Right: Figure 2, Vahdat \u0026amp; Kautz(NVAE), 2020.\n다만 둘 모두 이론적 근거를 제시하기보단 Ablation study를 통해 정량적, 정성적 개선 정도를 보인다.\n이미지의 대략적인 형상과 배치 등 lower frequency의 정보는 작은 잠재 변수 공간에서 capture 할 수 있지만, Higher frequency의 정보를 capture 하기 위해서는 spatial information에 correlate 된 latent variable이 있어야 하지 않을까 싶은 정도이다.\nVAE와 Diffusion의 합성 품질 차이는 latent variable의 크기에서 일부 기인했을 것으로 보인다.\nVAE as a 1-step Diffusion Model\nVAE가 이미지와 같은 크기의 잠재 변수를 취급하고, $z \\mapsto x$의 매핑을 U-Net으로 모델링한다 가정하자. 동일하게 VLB를 통해 학습되고, 잠재 변수의 크기도 이미지의 차원과 같으며, U-Net을 디코더 백본으로 사용한다.\n주어진 가정 아래 VAE는 $\\beta_1 = 1$의 variance schedule을 가지는 T=1의 Single-step diffusion model로 볼 수 있다. T=1 이므로 timestep embedding을 배제하고 학습하여도 무방하며, timestep embdding을 포함하여 DDPM과 완전히 동일한 백본을 가정할 수도 있다.\n$$q(x_1|x_0) = \\mathcal N(\\sqrt{1 - \\beta_1}x_0, \\beta_1 I) = \\mathcal N(0, I) \\Leftrightarrow p(z)$$ $$p(x_0|x_1) = \\mathcal N(\\mu_\\theta(x_1), \\Sigma_\\theta(x_1)) \\Leftrightarrow p(x|z; \\theta)$$\n1-step Diffusion model은 $x_0 = x, z = x_1 \\sim \\mathcal N(0, I)$을 상정하므로, 단순 이름 바꾸기를 통해 $p(x|z; \\theta) = p(x_0|x_1; \\theta)$를 얻을 수 있고, 이는 VAE의 generation process와 같다.\n이 경우 Encoder의 위치에 관하여 고민해 볼 필요가 있다. VAE는 Encoder를 통해 posterior를 근사하지만, DDPM은 variance schedule을 통해 chain의 끝이 prior distribution에 충분히 가깝도록 설계한다.\n$$\\bar\\alpha_t = \\prod^t_{i=1}(1 - \\beta_i) \\Rightarrow q(x_t|x_0) = \\mathcal N(\\sqrt{\\bar\\alpha_t}x_0, (1 - \\bar\\alpha_t)I)$$\n일반화를 위해 기존의 $q(x_t|x)$를 $q(x_t|x; \\psi)$로 parametrize하고, $D_{KL}(q(x_T|x; \\psi)||p(z))$ 역시 학습의 대상으로 삼자. 이 경우 $x_t = \\sqrt{\\bar\\alpha_t}x + \\sqrt{1 - \\bar\\alpha_t}\\epsilon_\\psi\\ \\mathrm{where}\\ \\epsilon_\\psi \\sim \\mathcal N(\\mu_\\psi(x), \\sigma^2_\\psi(x))$로 모델링하여 VAE와 같이 $D_{KL}(\\mathcal N(\\mu_\\psi(x), \\Sigma_\\psi(x))||p(z))$가 학습되도록 한다. ($\\because x_T = 0\\cdot x + 1\\cdot\\epsilon_\\psi = \\epsilon_\\psi$)\n$\\mathcal L_T$의 $D_{KL}(q(x_{i-1}|x_i, x; \\psi)||p(x_{i-1}|x_i; \\theta))$는 $||x - x_\\theta(\\sqrt{\\bar\\alpha_t}x + \\sqrt{1 - \\bar\\alpha_t}\\epsilon_\\psi; t)||^2_2$의 noise estimation loss 형태로 표현해 볼 수 있다. (w/reparametrization $\\epsilon_\\psi = \\mu_\\psi(x) + \\sigma_\\psi(x)\\epsilon,\\ \\epsilon \\sim \\mathcal N(0, I)$)\n이제 둘의 마지막 차이는 step의 수뿐이다.\nMore step is better\nVDM[arXiv:2107.00630]에서는 step의 수가 많을수록 더 tight 한 VLB의 하한을 얻을 수 있다고 이야기한다.\nvariance preserving diffusion model에서의 SNR(signal-to-noise ratio)을 $\\gamma^2_t = \\frac{\\bar\\alpha_t}{1 - \\bar\\alpha_t}$로 표현하면, variance schedule $\\beta_1, \u0026hellip;\\beta_{2T}$에 대해 목적함수 $\\mathcal L_{2T}$는 다음으로 정리할 수 있다.\n$$\\mathcal L_{2T}(x; \\theta) = -\\frac{1}{2}\\mathbb E_{\\epsilon \\sim \\mathcal N(0, I)}\\left[\\sum^{2T}_ {t=1}(\\gamma^2_{t-1} - \\gamma^2_t)||x - x_\\theta(x_t; t)||^2_2\\right]$$\nvariance schedule을 유지한 채 step을 절반으로 줄이면 다음과 같이 표현할 수 있다.\n$$\\mathcal L_T(x; \\theta) = -\\frac{1}{2}\\mathbb E_{\\epsilon \\sim\\mathcal N(0, I)}\\left[\\sum^T_{t=1}(\\gamma^2_{2(t-1)} - \\gamma^2_{2t})||x - x_\\theta(x_{2t}; 2t)||^2_2\\right]$$\n우리가 보이고 싶은 것은 $\\mathcal L_{2T} - \\mathcal L_T \u0026gt; 0$가 성립하여 $\\mathcal L_{2T}$가 $\\log p(x; \\theta)$에 더 가까운 하한이라는 것이다.\n$$\\mathcal L_T(x; \\theta) = -\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, I)}\\left[\\sum^T_{t=1}(\\gamma^2_{2(t-1)} - \\gamma^2_{2t - 1} + \\gamma^2_{2t - 1} - \\gamma^2_{2t})||x - x_\\theta(x_{2t}; 2t)||^2_2\\right]$$ $$\\begin{align*}\\mathcal L_{2T}(x; \\theta) = -\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, I)}\u0026amp;\\left[\\sum^T_{t=1}(\\gamma^2_{2t - 1} - \\gamma^2_{2t})||x - x_\\theta(x_{2t}; 2t)||^2_2\\right. \\\\\u0026amp;+ \\left.\\sum^T_{t=1}(\\gamma^2_{2(t-1)} - \\gamma^2_{2t-1})||x - x_\\theta(x_{2t-1}; 2t-1)||^2_2 \\right]\\end{align*}$$ $$\\mathcal L_{2T}(x; \\theta) - \\mathcal L_{T}(x; \\theta) = -\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, I)}\\left[\\sum^T_{t=1} (\\gamma^2_{2(t-1)} - \\gamma^2_{2t-1})(||x - x_\\theta(x_{2t-1}; 2t-1)||^2_2 - ||x - x_\\theta(x_{2t}; 2t)||^2_2) \\right]$$\nvariance schedule에서 $\\gamma_t$는 대개 감소함수로 설정되므로, $\\gamma^2_{2(t-1)} - \\gamma^2_{2t-1}$은 양수이다.\n$||x - x_\\theta(x_{2t-1}; 2t-1)||^2_2 - ||x - x_\\theta(x_{2t}; 2t)||^2_2$는 2t-1번째 스텝에서 추정한 데이터와 2t번째 스텝에서 추정한 데이터 각각의 MSE를 다룬다. 잘 학습된 네트워크 입장에서는 상대적으로 SNR이 높은 2t-1번째 스텝에서 데이터를 추정하기 더 쉬울 것이고, 그렇기에 MSE 값은 상대적으로 낮게 측정될 것이다. 결국 MSE의 차는 음수로 떨어진다.\n가장 앞단의 부호를 포함하면 $\\mathcal L_{2T} - \\mathcal L_T$는 양수가 되고, $\\mathcal L_{2T}$가 tighter lower bound가 된다.\nVAE를 1-step Diffusion model로 볼 경우, 1천 스텝 정도를 다루는 Diffusion model에 대비하여 NLL(Negative log-likelihood)이 높게 측정될 가능성이 높다. 물론 NLL이 낮다고 visual quality가 좋은 것은 아니나, 그 가능성 측면에서는 유의미하게 해석할 수 있는 지표일 것이다.\nHow about a 1,000-step VAE ?\n반대로 VAE를 Diffusion model처럼 1천번 forward pass 하여 성능 개선이 가능할지도 고민해 볼 법하다. 네트워크로부터 데이터 포인트를 생성하고, forward process(noising)을 거쳐 다시 네트워크에 통과시키는 것을 가정하자.\n$$\\tilde x_t = \\mathrm{Decoder}(x_t; \\theta),\\ x_{t-1} = \\sqrt{\\bar\\alpha_{t-1}}\\tilde x_t + \\sqrt{1 - \\bar\\alpha_{t-1}}\\epsilon\\ \\mathrm{where}\\ \\epsilon \\sim \\mathcal N(0, I),\\ t=1000,\u0026hellip;,0$$\nDiffusion model은 $D_{KL}(q(x_{i-1}|x_i, x)||p(x_{i-1}|x_i; \\theta))$을 통해 하나의 데이터를 두고, noised sample에서 noise를 줄여가는 방향으로 학습한다. 충분히 작은 noise를 데이터에 더하여 t=1의 네트워크에 통과시킬 경우, 네트워크의 출력물로 원본 데이터가 나올 것이라 기대할 수 있다.\nGeneration trajectory (Figure 1, Song et al., 2023)\n반면 VAE는 $0.99999\\times x + 0.00001\\times\\epsilon$을 입력으로 하여도 $x$가 나올 것이라 기대할 수 없다. VAE는 학습 중에 posterior를 prior에 가까워지게 할 뿐이다. 보수적으로는 noised sample 역시 prior에서 샘플링하였다 가정해야 하고, 1천번의 수행 과정에서 1천개의 서로 다른 이미지가 나올 수도 있다.\n이를 대응하기 위해서는 noised sample에 대해 원본 샘플이 나오도록 학습해야 하고, Consistency model[arXiv:2303.01469]과도 관련이 있어 보인다.\n$$\\mathcal L(\\theta, \\theta^-) \\leftarrow \\lambda(t_n)d(f_\\theta(x + t_{n+1}z, t_{n+1}), f_{\\theta^-}(x + t_nz, t_n))$$\nWrap up\nDiffusion의 합성 품질은 latent variable의 크기와 sampling step의 수에 기인했을 것으로 보인다. 또한 VAE를 1-step Diffusion으로 해석할 수도 있으나, 1000-step VAE로는 성능 향상을 기대할 수 없다는 것도 확인하였다.\n근래에는 datum point를 prior distribution으로 transport 하는 trajectory에 관하여도 연구가 많은 듯 보인다. 이에 관하여도 연관하여 고민하면 좋을 듯하다.\nReferences\nConsistency Models, Song et al., 2023. [arXiv:2303.01469] VDM: Variational Diffusion Models, Kingma et al., 2021. [arXiv:2107.00630] NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat \u0026amp; Kautz, 2020. [arXiv:2007.03898] DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [arXiv:2006.11239] StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Karras et al., 2018. [arXiv:1812.04948] GAN: Generative Adversarial Networks, Goodfellow et al., 2014. [arXiv:1406.2661] VAE: Autoencoding Variational Bayes, Kingma \u0026amp; Welling, 2013. [arXiv:1312.6114] ","permalink":"https://revsic.github.io/blog/1-step-diffusion/","tags":["Machine Learning","Deep Learning","Generative","Bayesian","Diffusion","Variational Lower Bounds","DDPM","VAE","Autoencoder"],"title":"Essay: VAE as a 1-step Diffusion Model"},{"categories":["Writing"],"contents":"20년도부터 회고를 쓰고 있다. 작년 회고를 다시 보면서도 매년 쉽지 않다.\n2월 30년 계획\n올해 초에 30년 계획을 세웠다.\n작년부터 몸이 좋지 않았고, 쉽게 무기력증에 빠지곤 했다.\n원래라면 퇴근하고 블로그를 쓰거나, 게임을 하는 날이 많았지만 점점 집에 도착하면 무기력하게 누워 있는 날이 늘어갔다.\n몸이 아파서 그런 것인지, 아니면 다른 이유가 있는지는 몰라도 이 무기력함이 나아지길 바랐다.\n병원에서 무기력증을 이야기해도, 크게 도움받을 수 있는 것은 없었다.\n그러던 중 직장 동료가 30년 계획을 세우는 것을 보았다. 계획을 세우고 나면, 최소한 뭘 할지 몰라 누워있지는 않을 것 같았다.\n30년 계획 시작은 다음 4가지 질문이었다. 나는 무엇을 좋아하는가, 나는 무엇을 잘하는가, 어떤 일을 할 것인가, 어떤 것을 하고 싶은가.\n답변하기 어려웠다.\n어떤 일을 할 것인지, 어떤 것을 하고 싶은지는 있었다. 컴퓨터를 하고 살 것 같았고, 예전부터 교수를 하고 싶었다.\n교수가 되고 난 이후에 대해서 고민했다. 인생의 난도를 낮춘다거나, 이뤘을 때 행복할 것 같다는 거창한 목표를 두고 싶지는 않았다.\n그냥 도전해 볼 만한 것, 그 자체로 가치 있는 것들이어도 괜찮겠다. 꿈은 크게 지르는 거라고, 튜링상, 필즈 메달을 목표로 잡았다.\n30년 후 튜링상이라고 하니, 생각보다 바빠 보였다. 당장 튜링상을 받기 위해 어떤 것이 준비되어 있어야 하는지 모르니 일단 10년만 잡기로 했다.\n10년 후에는 무엇을 하고 있을까. 석사든, 박사든 학위가 필요할 것인고, 내 집도 있으면 좋겠다. 집 한편은 내 연구를 위한 서재로 만들 거다.\n연구 분야는 뇌 과학에서 영감을 받아볼까, 이런저런 고민을 하는 것만으로도 기분이 나아지는 것 같았다.\n그렇게 나는 30년 후 튜링상, 10년 후 학위와 내 집이라는 목표를 세웠다.\n6월 맥주\n올해는 맥주를 많이 못 마셨다. 작년 마지막 맥주가 65번이었는데, 딱 10캔 정도 더 마셨다.\n23.10.08.75번 맥주 스카치 피트에일\n운동을 시작하기도 했고, 올 초에 다녀온 건강검진에서 요산 수치가 높게 나온 것이 컸다.\n다행히 가을에는 다시 정상 수치로 돌아왔다.\n올해는 아사히 슈퍼 드라이가 유행을 많이 탔다. 당시에는 일본에서 산 맥주를 마시고 정말 마음에 들었는데, 서울에 들어온 후 마시려고 보니 매번 품절이어서 마시지 못한 것이 아쉬웠다.\n요즘은 좀 다시 들어왔는지 모르겠다.\n믿고 마시는 볼파스, 부담 없는 베어 비어 모두 만족스러웠다.\n내년엔 정말 100번 찍어본다.\n11월 마포고등학교 연사\n22년 당곡고등학교, 상명대학교에 이어 23년에는 마포고등학교에 다녀왔다.\n마포고등학교에는 고등학교 3학년 수학 선택 과목에 인공지능 수학이 있는데, 매달 현직자 1인을 초대해 업계의 이야기를 들려주는 시간을 가지고 있다고 한다.\n나는 지인을 통해 연락받았고, 생성 모델을 주제로 강연에 다녀왔다.\n23.11.28.마포고등학교\n고등학생 친구들에게 물어보니 인공지능 수학 시간에 제곱 오류, 경사 하강법 등을 배운다고 한다.\n실습하고 과제는 엑셀로 많이 하나 보다.\n강연에서는 당곡고등학교 때와 비슷하게 일상에서 딥러닝이 어떻게 사용되는지 이야기했다. 단순 생성 모델만 아니라 인식이나 추천 등의 이야기도 나누었다.\n이전에는 음성이나 영상 합성을 했다면, 현재 회사에서는 LLM을 하는 만큼, 언어 모델에 관한 이야기도 많이 나누었다.\n이후 질의응답 시간은 비슷했다. 대학 진학 준비는 어떻게 하는 것이 좋은지, 실제로 이런 수학 과목이 인공지능을 업으로 삼는 데 도움이 되는지\n수능이 막 끝난 시점에 만난 2학년 친구들인 만큼, 조금은 가벼우면서도 미래에 대한 걱정을 시작한 모습이 보였다.\n이번 역시 담당 선생님께서 오히려 질문을 더 많이 하셨는데,\n연봉만큼 가치를 정말 창출하고 있다 느끼는지 정말 일반 지능을 모사하거나 구축할 수 있을지, 전뇌화에 대해서는 어떻게 생각하는지 등 다양한 질문을 주고받았다.\n회사로 복귀하는 길에는 내가 정말 그만큼 가치를 창출하는가에 대한 고민을 이리저리 많이 했다.\n여행\n올해에도 여행을 많이 다니려 했다. 생각만큼은 못 갔지만 그래도 분기에 한 번은 다녀왔다.\n23.04.03.제주\n4월에는 제주에 다녀왔다. 가족과 함께 다녀왔는데, 예상보다 좋은 시간 보내고 왔다.\n줄곧 혼자 여행을 다녀오곤 했는데, 부모님께서 먼저 여행 제안을 주셔서 다녀왔다.\n비행기 예약은 내가 진행하고, 숙소는 부모님이 내셨다.\n여행 코스도 미리 정해놓지 않고, 그때그때 괜찮아 보이는 곳으로 갔다. 이것저것 많이 보기 위해 나다니는 여행보다는 좋은 곳에 가서 여유 있는 시간 잘 보내고 온 것 같다.\n해외로 나간다면 이러기 어렵겠지만, 제주도라 가능했던 것 같기도 하다.\n바다에 갔을 때, 가족들과 떨어져 혼자 걷고 있었는데\n어떤 분께서 갑자기 나를 부르더니, 사진이 너무 좋아 찍게 되었다고, 물어보지 않고 찍어 미안하다고 하셨다. 괜찮다면 에어드랍으로 보내줘도 괜찮겠냐고\n너무 신기한 마음에 사진을 받았는데, 정말 너무 잘 나와서 감탄했다.\n23.07.26.부산\n7월에는 연례 행사로 부산에 다녀왔다. 좋아하는 술집에, 좋아하는 숙소에서 잘 쉬고 왔다.\n항상 느끼지만 해운대의 바다가 너무 좋다. 파도 소리도 좋고, 배경도 너무 좋다.\n23.12.24.삼성\n이번 크리스마스는 삼성에서 지냈다.\n정말 크리스마스 예약은 늦어도 11월에는 해야 하더라. 이후에는 자리도 없고, 가격도 비싸 부담되었다.\n올해는 여행도 많이 못 다녔기에, 이번 연휴에 많이 쓸 생각으로 다녔다.\n압구정의 스시 히노와에 다녀왔는데, 첫 게살 요리가 너무 시어서 걱정이 많았다.\n전복 요리도 예상보다 비렸다.\n이후에 스시가 나왔고, 걱정과 달리 눈이 번뜩였다.\n감칠맛이 입에 맴돌았고, 원물이 신선했다. 특히 참치 원물이 역대급인 듯 보였다.\n흰살생선도 잘하고, 사케와도 어울려 너무나 만족스러웠다.\n크리스마스 잘 쉬고 왔다.\nLionrocket\n1월 Meverse\n22년 VeryMe 개발 이후 회사는 또 다른 제품을 고민했다.\nVeryMe가 손익분기점을 넘기기 위해서는 생존력이 필요했고, 이를 위한 캐시카우를 준비해야 한다는 것이다.\n당시 생성 업계는 Personalization의 바람이 불고 있었다. Prisma.ai의 Lensa가 남미에서 AI 아바타를 통해 거금을 쓸어 담았다는 것이다.\n사용자가 자신의 이미지를 제공하면, 개인화된 생성 모델을 서비스하는 방식이다. 판타지 세상 속의 내가 나오기도 하고, 미화된 내가 나오기도 한다.\n이후 유사한 서비스가 우후죽순 생겨났다. 특히 스노우와 같이 촬영 및 편집 어플을 주제품으로 하는 회사들이 많이 참전했다.\n우리는 시장의 흐름에 몸을 맡겨보기로 했다. 단타성 서비스로 단기 수익을 누적해 보겠다는 전략이었다.\n대부분의 제품은 이미지를 전달하면 몇 시간 후에야 결과를 확인할 수 있었다. StableDiffusion과 같은 생성 모델에 사용자가 제공한 이미지를 추가 학습하는 방식인 듯 보였다.\n당시 GAN은 다양한 이미지를 생성하는 것에 한계가 있었고, Diffusion을 사용하더라도 Few-shot generation으로는 객체 보존이 어려웠다.\nDreamBooth[arXiv:2208.12242]가 나온 지도 얼마 안 되었고, 10장에서 20장의 이미지 요구량과 시간 단위 지연을 가정한다는 것도 Finetuning임을 시사했다.\n상대사의 기술 스택은 추정하였지만, 여전히 문제가 있었다.\n안 그래도 Diffusion은 생성 시간이 긴데, 학습 리소스까지 서비스가 감당하기에는 GPU 사용량이 부담되었다.\n우리는 노선을 틀었다.\n학습 없이 개인화된 생성 모델을 만들기로 하였고, 입력으로 받을 이미지의 수도 줄어들길 원했다.\n또한 단타성 제품이기에 리서치보다는 기존의 제품을 재활용하길 원했다.\nAI 연구팀과 기술 프로덕션팀은 새로운 CRO 체제 아래에서 작업을 시작했다.\n아바타 컨셉에 맞는 이미지 후보군을 선택하고, Few-shot generation이 가능하도록 내재화되어 있던 생성 파이프라인을 재활용했다.\n그렇게 나온 서비스가 Meverse이다.\n23.01.31.라이언로켓, AI 아바타 앱 \u0026lsquo;미버스(Meverse)\u0026rsquo; 국내 출시, 매일경제\nFew-shot generation이기에 실제 인물과의 유사도는 타사에 비해 떨어졌지만, 20장 정도를 요구하는 타사와 달리, 1장으로 이미지를 합성할 수 있다는 점으로 차별화하였다.\n지금 생각해 보면, 저게 정말 사용자에게 매력적인 차별점이었는가 하는 고민이 들기도 한다.\n정말 사람들이 스노우를 20장이나 넣어야 해서 사용하지 않는 걸까, 정말 기다리는게 문제인가 하는 것들이다.\n예상보다 사람들은 AI 생성물이 오래 걸린다는 것을 쉽게 이해했다. 스노우 등 AI 기업들이 지연에 대한 인식을 많이 완화해 주었다.\n그렇다면 우리는 인물 유지와 다양한 컨셉, 미화에 더 집중해야 하는 것 아니었을까\n시장의 흐름에 맡긴 단타성 제품이었던 만큼, 여전히 결과물의 품질에 대해서는 아쉬움이 남기도 한다.\n미버스는 23년 상반기까지 서비스되었고, 이후 조용히 종료되었다.\n2월 음성팀 해체\n나는 19년도 9월, 음성 합성 연구원으로 라이언로켓에 합류했다.\n21년도 4월까지 전임 연구원, 이후 음성 합성 연구팀장으로 있었다. 21년 10월 영상 합성팀이 신설되었고, 22년 VeryMe가 회사의 주요 사업이 되며 음성 합성팀은 축소되었다.\n23년 2월 나를 제외하고 2명으로 구성되어 있던 음성 합성 연구팀은 1인의 산업기능요원 종료와 퇴사가 결정되며 1인 팀으로까지 축소되었다.\nOn-air studio의 관심이 줄어들며 음성 연구팀은 할 일이 더욱 줄어들었다.\n내부적으로 진행하던 음성 변조, Voice conversion에 대한 연구 성과는 인정받지 못하였고, 결국 음성 합성팀은 해체 수순을 밟게 되었다.\n아쉬움이 많이 남았다. 처음으로 입사하였고, 처음으로 팀장을 맡은 팀이었기에 그 끝을 보는 것이 어려웠다.\n음성 연구를 더 잘해야 했나, 더 열심히 경영진에 PR하여 팀을 유지해야 하나, 사업에 기술이 사용될 수 있도록 더 달려야 했나 여러 생각이 들었다.\n21년도부터 함께하던 음성 연구원은 영상 합성 연구팀으로 편입되었고, 3D 연구를 담당하게 되었다.\n전혀 다른 필드임에도 남아 있어 주었고, 그 이후에도 최선을 다해 일을 도와주었다.\n정말 너무나도 감사한 팀원이었지만, 퇴사를 확정 짓게 되었고, 결국 회사를 떠났다.\n이제 음성팀은 말 그대로 유산이 되었다.\n기술 전환\nDiffusion 계열 Text-to-Image 모델이 업계의 흐름이 되는 것은 자명해 보였다.\nOpenAI의 DALL-E에서는 확신하지 못하였지만, Stability AI의 StableDiffusion(이하 SD)이 오픈소스로 풀린 이후의 흐름은 달랐다.\nLoRA[arXiv:2106.09685] 등 LLM에서만 보이던 Finetuning 방법론이 SD에서 활용되기 시작했고, 이후 ControlNet[arXiv:2302.05543]까지 등장하며 이미지 생성 모델의 Controllability도 확보되었다.\n사업적으로 가장 문제였던 합성 결과물의 불확실성이 완화되어 가는 것이다.\n연구팀은 전환이 필요했다. Diffusion 계열 모델에 대한 팔로업이 필요했고, 이를 충분히 실험해 보며 감각을 잡아가야 했다.\nCRO님과 나는 이에 공감하였고, 1달간의 전환 기간을 가지기로 경영진과 합의하였다.\n1주일간은 매일 세미나를 운영했다. 오전 2시간에서 3시간, 연구팀원 모두가 리뷰한 페이퍼나 주제에 대해 발표하고 질의응답 하는 시간이다.\n오후에는 오전에 나온 페이퍼를 구현하거나 테스트해 보고, 이듬일 오전에 경험을 공유하는 시간을 가졌다.\n나는 디퓨전 모델의 시작에 대한 이야기를 나누었다.\n왜 Score matching인지, 어떤 이유에서 Score matching이 발생했는지, Langevin dynamics 얘기는 왜 나온 것인지, 그래서 현재의 Diffusion 모델은 어떻게 작동하는지 등 다양한 주제를 다뤘다.\n이후에는 Inversion에 관한 이야기, Feature map에 대한 분석과 Few-shot 합성 등 다양한 이야기가 오고 갔고, 연구팀은 그렇게 Diffusion 모델에 대한 감을 잡아갔다.\n그때 자료는 유실되었지만, 언젠가 블로그에 한번 정리해야겠다.\n3월의 신제품을 위한 준비는 끝났다.\n3월 Pokeit.ai\n단타성 제품 Meverse 이후 우리는 조금 더 긴 호흡을 가져갈 캐시카우를 준비했다.\n다양한 회사로부터 영감을 받았고, 그 중에서 뤼튼[wrtn.ai]이 가장 기억에 남는다.\n뤼튼은 Large Language Model(이하 LLM)을 자체 생산하는 회사가 아닌 듯 보였다.\nLLM은 일반 사용자에게 나타난, 기존에는 없던 새로운 도구에 가까웠고, 뤼튼은 이를 쉽게 이용할 수 있도록 포장하여 사용자에게 새로운 편리함을 제공하려는 회사로 보였다.\nFoundation Model이라 부르는 대형 모델은 학습과 추론 모두에 다량의 자원을 소모하기에 스타트업이 쉽게 도전할 만한 영역이 아니었고,\n이를 사용자에게 적절한 가치로 포장하여 제공한다는 뤼튼의 아이디어는 정석에 가까웠다.\n우리 또한 이에 공감하였고, LLM이 아닌 StableDiffusion 계열 모델을 활용하여 어떤 가치를 만들지 고민하였다.\n그렇게 우리는 [git+AUTOMATIC1111/stable-diffusion-webui]를 서비스로 재구성해 보기로 하였다.\nSD를 아는 사람들은 자신이 원하는 이미지를 생성하기 위해 여러 가지를 알아보고, 직접 WebUI 환경을 구축하여 이미지를 생성해 왔다.\n하지만 일반 사용자가 이를 따라 하기는 쉽지 않았고, 간단한 광고용 이미지, PPT용 이미지 등 수요에 따라 이미지를 생성할 수 있는 서비스를 구축하고자 했다.\n그렇게 우리는 StableDiffusion 기반의 Pokeit.ai를 제작했다.\nPokeit, Drawing the Future with AI, pokeit.ai\n당시 얼룩말 세로의 탈출 사건과 함께, 세로를 주제로 합성한 이미지들이 바이럴을 타며 초기 유입에 도움이 되었다.\n이후에는 합성에 대한 크레딧을 BM으로 하여 사업을 이어갔다. 단순 이미지의 스타일만 아니라, 특정 객체를 고정하기 위한 여러 LoRA 모듈에 대한 테스트도 이어갔다.\n꽤 괜찮은 BM으로 보였고, 기대되는 제품이었다.\n\u0026ldquo;탈출 얼룩말 꿈 이뤄주자\u0026rdquo;\u0026hellip; AI 이미지 하루만에 1천250건, 연합뉴스\n갈등\n회사에서는 또 다른 제품을 만들자는 이야기가 나왔다.\n초기 TTS 오디오북, On-air studio, VeryMe, Meverse, Pokeit에 이은 6번째 프로젝트였다. VeryMe를 시작으로 1년도 채 되지 않은 시점에서 4번째 제품이다.\nVeryMe가 예상보다 리텐션 유지와 수익화에 어려움을 겪자, 새로운 제품을 태핑 해봐야 한다는 결정이었다.\n이것이 기술의 문제로 합성 품질을 확보하지 못해 발생한 일인지, 정말 PMF에 맞는 제품이었는지, 그를 위한 운영에 문제는 없던 것인지 분석되거나 팀에 공유되지 않았다.\n여러 번의 시도로 PMF를 찾는다는 점에서는 동의하였으나, 이 정도로 빈번한 태핑이 정말 PMF로 가는 길인지, 조금 더 신중할 것은 없었을지 여러 고민이 들었다.\n연구팀에서는 기술 개발이 끝나면 제품이 피봇된다는 말이 있을 정도로, 피봇의 빈도가 잦다는 불만이 있었고, 이를 해소해 주는 것에 매니징 리소스가 많이 투자되었다.\n경영진과 연구팀 사이의 갈등은 깊어졌다.\n연구팀과 경영진은 서로 신뢰하지 못했다. 연구팀은 경영진의 경영 능력을, 경영진은 연구팀의 연구 능력을 믿지 못했다.\n경영진은 연구팀이 사업에 도움 될 결과물을 만들지 못한다 생각하는 듯 보였고, 연구팀은 결과물을 만들어가도 이해하지 못하고, 활용하지 못한다 생각했다.\n기술 프로덕션팀과 관련 경영진이 직접 연구에 나섰고, 연구팀은 주제품 연구에서 배제되었다.\n6월 Genvas\n그렇게 3월부터 준비한 신제품은 Genvas이다.\n우리나라 웹툰 시장은 굉장히 노동 집약적이기에, 생성 모델을 통해 웹툰 제작을 어시스트할 수 있다면 제작사들의 지불 의사가 있을 것이라는 판단이었다.\n경영진은 캐릭터를 곧장 학습하여 여러 자세에서 재현하는 연구를 수행했고, 연구팀은 그 과정을 세분화하여 단계별 연구를 수행했다.\n매일 오전 스크럼 과정에서 작일 진행한 실험과 결과를 브리핑하고, 오후에 진행할 실험의 방향성을 설정하고 분배했다.\n연구팀은 빠른 시간에 결과를 만들어낼 수 있었다. 단계별 결과물의 정확도는 높았고, 곧장 사용할 수 있는 수준으로 보였다.\n하지만 우리의 결과물은 있는 그대로 받아들여지지 않았다. 많은 양의 테스트가 이뤄졌음에도, 적극적인 세일즈로 이어지지 않았다는 감각을 받았다.\n경영진이 진행한 연구는 MOU로 이어졌고, 이는 사내에 홍보되었다. 연구팀의 결과물은 묻혔고, 능력 없는 부서로 비쳤다.\n7월 정리해고\n7월 14일 정리해고 통보를 받았다. 19년 합류 이후 3년 11개월이었다.\n끝이 좋지 않았다. 웃으며 끝내지 못했고, 상처만을 남겼다.\n하루아침에 연구 부서에서 2인을 제외한 전원이 해고되었고, 연구 부서는 해체에 가까웠다.\n인수인계는 없었고, 정말 하루 아침에 나의 4년을 놓고 나와야 했다.\n이제 우리는 없었다. 서로의 길도 응원하지 않았다.\n해방감, 배신감, 억울함 등 많은 감정이 들었다. 해고당한 사람들과 낮술도 하고, 집에 들어가 멍도 때렸다.\n퇴사 후\n마음을 추스른 후 1달간 이직 준비와 함께 휴식 시간을 가졌다.\n항상 좋은 회사를 정의하는 것이 안 좋은 회사를 정의하는 것보다 어렵다. 다음 회사가 더 나을 것이라 기대할 수 있는가, 그렇게 하기 위해 나는 입사 과정에 무엇을 확인해야 하는지 많이 고민했다.\n이직의 기준으로 몇 가지를 세웠다. 1, 순이익이 있는가 2, 대표가 HR과 기업 문화에 관심이 있고, 적극적으로 움직일 의지가 있는가\n면접에서 이를 확인하고 나면 최소한 같은 문제는 피할 수 있지 않을까 싶었다. 그러고 나면 새로운 문제는 그때 고민하기로 했다.\n이력서와 경력 기술서도 업데이트했다.\n회사에 다녔기 때문에 할 수 있었고, 창업 초기 멤버였기에 할 수 있었지만, 반대로 이 회사에서만 할 수 있었을까 더 아프지 않고 할 수는 없었을까 하는 회의감이 들었다.\n후일담으로 6월 마지막으로 진행했던 연구팀 성과는 퇴사 후에야 뒤늦게 검토되었고, 결과가 인정되어 세일즈를 준비하고 있단 소식을 전해 들었다.\n안타깝다.\n하나둘 면접을 보러 다녔다. 생각보다 두 기준을 넘는 회사는 많았다.\n경영진과 팀원 사이에 존중과 신뢰가 보였고, 모두가 합리적 판단을 위해 데이터를 가지고 이야기 나누었다.\n내가 대표였다면 저렇게 경영하지 않았을까 하는 회사도 있었다.\n면접을 보지 않는 날에는 집 앞 카페에 나갔다. 카페에서 책도 보고, 여유를 가지며 오랜만에 휴식을 취했다.\n아침에 일어나 운동을 가고, 저녁에는 카페에 가거나 친구들을 만났다.\n건강은 좋아져 갔다. 공황 발작도 없고, 여러모로 몸도 괜찮아졌다.\nTheori\n8월 입사\n2개 회사에 최종 합격했다.\n한 곳은 시리즈A 클로즈 단계인 회사로, 비전을 주로 한다. 한 곳은 보안 컨설팅을 서비스하는 티오리[theori.io]이다.\n전자는 AI가 중심인 회사이고, 후자는 보안이 중심인 회사이다. 전자는 연구팀원으로, 후자는 신설하는 AI팀의 팀장으로 입사하게 된다.\n둘 다 기업 문화에 관심을 가진 대표님이 계시고, 기업을 견인할 매출을 내고 있었다.\n다양한 고민을 했다.\n엔지니어인지 매니저인지, AI 중심 회사인지 아닌 회사인지, 기본급여인지 상여금인지, 컴포트 존인지 새로운 도전인지\n티오리는 AI for Offensive Security, AIOS라는 부서를 신설하여 AI를 통해 보안 컨설팅을 반자동화하는 목표를 가지고 있었다.\n새로운 부서를 창설하는 만큼, 많은 확인이 필요했다. 금방 사라질 부서는 아닌지, 어느 정도 자원의 투자를 고민하는지, 몇번의 실패까지 납득 가능한지 등 여러 이야기를 나눴다.\n마지막 면접 이후, 티오리에 최종 합류를 결정했다.\n팀빌딩\n8월 16일 입사 이후, 본격적인 팀빌딩을 시작했다.\nAI팀은 나와 팀원 하나, 총 2인이다.\n연구의 성과와 경영진의 투자가 선순환을 만들기 위해 목표와 로드맵 설정, 빠른 결과를 내는 것이 목표이다.\n주니어 위주의 이전 회사 팀빌딩과는 달리, 이번에는 좀 더 빠른 결과를 만들어내기 위해 중견급을 찾아 나섰다.\n가능하면 3년 이상으로, 보안 전문 인력 1인, 엔지니어 2인, 연구원 5인의 8인 정도 팀을 구상했다.\n본격적인 인바운드 문의를 받기 시작했고, 12월 1일까지 빠르게 5인 팀을 구성했다.\n내년엔 아웃바운드로 많이 접촉하여, 나머지 인원을 채울 예정이다.\n로드맵 작성도 병행하였다.\n우리팀의 미션과 비전은 무엇인지, 앞으로 어떤 기간에 무엇을 전달할지 설정하였다.\n한번 팀이 고장 나고 나니, 생각보다 존재 의의가 무겁게 느껴졌다. 그렇기에 더더욱 우리가 무엇을 하는 팀이고, 앞으로 어떤 것을 할 것인지 명시화하는 게 중요했다.\n우리는 보안의 자동화를 연구 개발하는 팀이고, 이를 통해 보안 서비스의 접근성을 높이겠다.\n모든 로드맵은 이를 이루기 위해 작동한다.\n시스템의 분석, 공격 표면 식별, 위협 모델 생성과 검증, 대응 방안 생성까지 시도할 수 있는 모든 부분을 25년까지 검토해 볼 예정이다.\n대표님과 로드맵을 합의하였고, 하나씩 준비해 나가야겠다.\n9월 온보딩\n9월, 10월은 팀빌딩 및 온보딩 기간을 거치며 LLM과 보안 데이터에 대해 감을 잡아갔다.\n음성, 영상만 보다가 자연어를 만지려니 완전히 새로 시작하는 기분이었다. 더군다나 보안을 접은지 꽤 되었다 보니 단어도 생소했다.\n가장 먼저 보안 관련 질문에 특화된 QnA 시스템을 만들어보기로 했다.\n검색어를 Paraphrasing하고, 구글 서치 엔진 API로 자료를 검색, 질문에 도움이 될 문단을 발췌하여 RAG하는 방식이다.\nLLM에 대해서도 알아보고, 프롬프트 엔지니어링, On-premise 모델의 실시간성 확보, 최종 데모 제작까지 수행하였다.\n아쉽게도 보안에 대한 전문성이 아직은 부족하다 판단하였고, 다음 프로젝트로 넘어갔다.\n11월 첫 프로젝트\n11월 첫 공식 프로젝트를 수행했다. 팀원들과 첫 합을 맞춘 프로젝트였다.\n조용하지만 충돌도 있었고, 불만도 있었다. 예상만큼의 결과도 있었지만, 기대만큼의 결과는 만들지 못했다.\n다음에 좀 더 자세한 이야기를 풀 수 있는 날이 있으면 좋겠다.\n30년 계획\n또 다른 질문은 무엇을 좋아하고, 잘 하는가였다.\n당시에는 무얼해도 자신이 없으니, 뭘 잘하는지 모르겠고, 뭘 좋아하는지도 확신이 없었다.\n그러다 이번 회사에서 동료 하나가 한 말이 인상 깊었다.\n이미 알고 있는데, 인정하지 않는 것 아니냐고. 스트레스 속에서 무뎌져 있던 것 아니냐는 것이었다.\non2023\n올해 정말 많은 일이 있었다.\n처음 이직하고, 창업 멤버가 아닌 직원으로 80명 규모 회사에 입사했다. AI가 아닌 사업의 AI팀을 신설하고, 두 번째 팀빌딩을 끌어냈다.\n매니저로는 증명하고 있다 느끼지만, Individual Contributor로 아쉬움을 하나둘 확인하기도 했다.\n새로운 공간, 새로운 사람들과 일을 한다.\n여전히 스트레스가 있지만, 무뎌져 있던 것들이 조금씩 회복되어 간다.\n24년은 복학의 기로에 서있다.\n복학할 것인지, 회사를 더 다닐지, 대학원 진학을 준비할지, 여전히 고민할 게 많다.\n그럼에도 24년은 더 나은 한해가 되었음 좋겠다.\n","permalink":"https://revsic.github.io/blog/on2023/","tags":["Writing","2023th"],"title":"On2023"},{"categories":["Generative"],"contents":"아래 글은 비공식적인 개인의 사견임을 밝힌다.\nVALL-E and residual quantization. Keyword: VALL-E, EnCodec, Residual Quantization, DDPM, Diffusion Introduction\n23년 1월 VALL-E[arXiv:2301.02111]라는 One-shot multi-speaker TTS 모델이 나왔다.\nTTS는 기본적으로 텍스트를 입력으로 받아 음성을 합성한다. 텍스트는 20~50hz, 음성은 16k~48khz 정도이기에 텍스트와 음성 사이의 correlation을 학습하는 데 어려움이 있다. 이를 해결하기 위해 대부분의 Neural TTS 모델은 중간 매개를 활용한다. 대체로 50~70hz 정도의 spectrogram을 활용하고, text로부터 spectrogram을 생성하는 acoustic model과 spectrogram을 음성 신호로 복원하는 vocoder model의 two-stage 구조를 가정한다.\nVALL-E는 중간 매개로 spectrogram 대신 Meta AI의 EnCodec[arXiv:2210.13438]을 활용한다. EnCodec은 neural audio compressor로 quantized vector를 bottleneck으로 두는 Auto-encoder 모델이다.\nVALL-E는 text와 reference audio를 입력으로 75hz 정도 되는 quantized vector의 index를 추론하도록 학습하고, EnCodec을 통해 quantized vector에서 audio를 복원한다.\n이번 글에서는 EnCodec이 어떻게 vector quantization을 수행하는지와 VALL-E가 이를 어떻게 모델링하는지 논의한다.\nResidual Vector Quantization\nEnCodec의 기저 논문인 SoundStream[arXiv:2107.03312]은 1초의 음성을 6000bit 안에 저장할 수 있는 Neural Codec 개발을 목표로 하였다. 24khz sampling rate, 16bit rate의 음성이라면 초에 384,000bit가 필요하기에, 6000bit까지 음성을 64배 압축 및 복원할 수 있어야 한다.\nVQVAE 아키텍처에 따라 24khz Sampling Rate(이하 SR)의 Audio가 입력으로 들어오면, Encoder를 통해 초당 75프레임까지 길이를 줄인 후(320 Strided-Convolution), Quantization을 통해 Discrete Embedding Vector에 대응시킨다. Embedding Vector는 Decoder를 통해 음성으로 복원된다.\n사용자는 Encoder를 통해 Codebook의 인덱스를 대응 및 저장해두었다가, 필요 시점에 인덱스를 Decoder에 통과시켜 원본 음성을 복원하는 Codec인 것이다.\n초당 75프레임이라면 프레임 당 80bit 정도의 정보를 할당할 수 있는데(6k = 75 x 80이므로), 기존의 Vector Quantization이라면 Codebook의 크기는 2의 80제곱(1.2e24)이고, 현실적으로 학습이 불가능한 크기이다.\n가장 먼저 떠오르는 아이디어는 Wav2Vec2.0[arXiv:2006.11477]과 같이 Product Quantization을 수행하는 것이다. Encoded Vector $e\\in\\mathbb R^E$가 주어질 때, $e$를 $G$개 벡터로 split하고 $e_i \\in \\mathbb R^{E/G}\\ (i=1,\u0026hellip;,G)$ 각각을 Codebook $C_i \\in \\mathbb R^{N\\times V}$에 대응하는 것이다. $G=8$로 잡는다면, 각각의 코드북은 1024개의 엔트리를 가진다($N=2^{10}$). 학습 가능한 크기까지 줄이면서도, 80bit의 데이터를 충분히 활용할 수 있다.\nSoundStream은 여기에 하나의 아이디어를 더 얹는다.\nFigure 2. The neural audio codec model revisit. (Wang et al., 2023.)\nEncoded Vector $e$를 split 없이 그대로 첫 번째 코드북에 대응한다 $e \\mapsto c_1$. 이후 잔차 $r_1 = e - c_1$를 두 번째 코드북에 대응한다 $r_1 \\mapsto c_2$. 이렇게 연쇄적으로 잔차 정보에 대응해가는 $(r_{i} = r_{i-1} - c_{i}) \\mapsto c_{i+1}$ 방법론을 SoundStream은 Residual Vector Quantization, 이하 RVQ라 정의하였다.\nProduct Quantization과 Residual Quantization은 대수의 Cartesian Product와 Direct Sum과 같은 관계로 비치기도 한다.\nRVQ는 기존 Quantization과 비교하였을 때, bitrate를 조절할 수 있다는 장점을 가진다. 첫 Stage 이후의 Quantization은 잔차값을 대상으로 하기에, $C_1$부터 $C_6$까지 6개 코드북만 가지고 Decoding을 진행해도 발화의 발음이나 기본적인 목소리를 인식하는 데에는 문제가 없기도 하다. 이 경우 프레임당 60bit, 초당 4500bit로 운용 가능한 손실 압축 Codec이다.\n이렇게 몇 번 코드북까지를 활용할 것인가에 따라 bitrate를 가변적으로 운용할 수 있다.\nVALL-E Decoder\nVALL-E는 Zero-shot TTS를 목표로 한다. G2P를 거친 phoneme sequence $x$와 reference audio의 embedding $\\tilde c_{t, \\le k} = \\sum^k_{i=1} \\tilde c_{t,i},\\ \\tilde C = \\tilde c_{:, \\le 8}$을 입력으로 8개 Codebook의 인덱스를 합성해야 한다.\nFigure 3. The structure of the conditional codec language model. (Wang et al., 2023.)\n첫 번째 코드북의 인덱스는 Autoregressive Manner로 생성한다.\n$$p(c_{:, 1}|x, \\tilde c_{:, 1}; \\theta_{AR})=\\prod_{t=1}^T p(c_{t, 1}|x,\\tilde c_{:, 1},c_{\u0026lt;t, 1}; \\theta_{AR})$$\n이후에는 별도의 모델을 하나 더 두어 Parallel(Non-AR) Manner로 생성한다.\n$$p(c_{:, {2:8}}|x, \\tilde C; \\theta_{NAR})=\\prod^{8}_{j=2} p(c _{:, j}|x, \\tilde C, c _{:, \u0026lt; j}; \\theta _{NAR})$$\nNAR 모델의 경우 하나의 파라미터로 2번부터 8번까지 7개 Codebook을 모두 커버해야 하므로, 몇 번 Codebook을 합성할 것인지 모델에 inform 할 수 있어야 한다. VALL-E는 Transformer의 Normalization 레이어를 $\\mathrm{AdaLN}(h, i) = a_i\\mathrm{LayerNorm}(h) + b_i$로 교체하여 $i$번째 Codebook 합성을 유도한다.\nWrap up\nVALL-E의 RVQ와 NAR Decoder는 DDPM[arXiv:2006.11239]과 유사한 컨셉을 보인다.\nVALL-E의 NAR Decoder와 DDPM은 모두 Corrupted Input에 대한 점진적인 Recovery를 제공한다. VALL-E는 Quantized Embedding에 대해 RVQ Residue를 추정하고, DDPM은 Noised Embedding에 대한 Score를 추정하여 Adaptive Manner로 Signal을 복원해 나간다. (e.g. VDM[arXiv:2107.00630])\n$$\\mathrm{VDM}: z_{t-1} = \\frac{1}{\\alpha_{t|t-1}}z_t + \\frac{\\sigma^2_{t|t-1}}{\\alpha_{t|t-1}}score_\\theta(z_t; t) \\\\ \\mathrm{RVQ}: c_{j+1} = c_j + nar_\\theta(\\tilde C, \\sum_{i\\le j}c_i; j)$$\n또한 VALL-E와 DDPM은 모두 Multiple-stage에 대해 동일한 모델을 사용하기 때문에, 현재가 몇번째 Codebook인지/몇번째 timestep인지 inform 하기 위해 Adaptation을 수행한다. 단순히 Embedding을 feature map에 더하기도 하고, Adaptive normalization을 활용하기도 한다.\n이를 반대로 활용하면, Image에 대해서도 Discrete Embedding을 기반으로 한 Generative Transformer를 구성해 볼 수도 있을 것이다. (e.g. MaskGIT[arXiv:2202.04200]) Diffusion 모델에 비해 적은 Step으로 competitive한 이미지 생성도 가능할지 기대해 본다.\nReference\nVALL-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers, Wang et al., 2023. [arXiv:2301.02111] EnCodec: High Fidelity Neural Audio Compression, Defossez et al., 2022. [arXiv:2210.13438] MaskGIT: Masked Generative Image Transformer, Chang et al., 2020. [arXiv:2202.04200] SoundStream: An End-to-End Neural Audio Codec, Zeghidour et al., 2020. [arXiv:2107.03312] VDM: Variational Diffusion Models, Kingma et al., 2021. [arXiv:2107.00630] Wav2Vec2.0: A Framework for Self-Supervised Learning of Speech Representations, Baevski et al., 2020. [arXiv:2006.11477] DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [arXiv:2006.11239] ","permalink":"https://revsic.github.io/blog/valle/","tags":["Machine Learning","Deep Learning","VALL-E","EnCodec","Audio Compression","Residual Quantization","DDPM","Diffusion"],"title":"VALL-E, Residual Quantization"},{"categories":["Generative"],"contents":"아래 글은 비공식적인 개인의 사견임을 밝힌다.\nEssay of generative models, Mode coverage Keyword: Excplicit, Implicit modeling, Contrastive learning Introduction\n근래의 Generative Models는 VAE[arXiv:2112.07804], Normalizing Flow[arXiv:1807.03039], Diffusion[arXiv:2006.11239], GAN[arXiv:1812.04948] 등의 프레임워크에 따라 학습된다.\n이들은 데이터의 분포를 학습하여, 데이터 포인트를 샘플링하기 위한 목적으로 학습 방식을 구성한다.\n생성 모델은 크게 2개 부류로 볼 수 있다.\nLikelihood-based Model: VAE, Flow, Diffusion 등 생성된 샘플에 대해 우도 함수를 최대화하는 방식 Implicit Model: GAN 등 Divergence와 같은 부차적 방식을 통해 분포를 학습하는 방식 이중 Normalizing flow만이 유일하게 invertible operations와 change of variables를 통해 exact likelihood의 추정이 가능하고, VAE와 Diffusion은 likelihood의 lower bound를 최대화하는 방식을 취한다.\nLikelihood를 기반으로 한 모델을 explicit 모델이라고 표현하기도 하고, 그 외 요소를 활용한 경우를 implicit 모델이라고 하는 듯 하다.\n[arXiv:2112.07804]에서는 생성 모델의 특성 3가지를 통해 이들을 분류한다.\nFigure 1: Generative learning trilemma. (xiao et al., 2021)\nGAN은 빠른 합성과 Sharp한 샘플링이 가능하지만, 고질적으로 Modal collapse를 포함하고 VAE와 Flow는 빠른 샘플링과 높은 Mode coverage를 보이지만, 데이터 샘플이 Smooth한 편이다. Diffusion은 Mode coverage, sharp sampling이 모두 가능하지만, 실시간 합성이 어렵다. 이를 Generative trilemma라고 일컬었으며, 이를 개선하기 위해 최근 여러 가지 시도들이 이뤄지고 있다.\n이 중 오늘 이야기 다뤄보고자 하는 것은 Mode coverage이다.\nWhy Modal collapse occurs on GAN\nGAN의 가장 흔한 설명은 경찰과 도둑의 이야기이다.\nGenerator가 데이터 샘플을 생성하면, Discriminator는 주어진 샘플이 합성된 것인지, 자연적으로 발생한 것인지 검측한다. Generator는 Discriminator가 합성 샘플을 자연 샘플로 여기도록 학습하고, Discriminator는 Generator의 샘플을 분류하도록 학습된다.\n$$\\min_G\\max_D \\mathbb E_{x\\sim p_\\mathrm{data}(x), z\\sim p(z)}[\\log D(x) + \\log (1 - D(G(z)))]$$\n다양한 GAN 모델은 Generator 1번, Discriminator 1번을 교차하며 학습하는 방식의 프레임워크를 선택했다.\n이 과정에서 Generator는 $x_\\ast = \\arg\\max_x \\log(D(x))$를 생성하는 single point generator가 될 수도 있고, Discriminator는 해당 single point만 분간하면 되는 단순한 모델이 될 수도 있다.\nGenerator가 샘플 전반의 Modal을 커버하지 않더라도, 이를 penalize 할 제약이 없기에, 여러 엔지니어링을 통해 Modal collapse를 완화할 수는 있지만, 근본적으로 해결하기란 쉽지 않다.\n반면 Likelihood-based 모델은 다르다.\nVAE, Diffusion의 경우 posterior $z \\sim q(x)$을 두고 $p(x|z)$의 conditional generation에 대한 likelihood를 취한다. 이 과정에서 데이터 포인트의 복원이란 제약이 발생하고, 모델은 Modality를 모두 커버하는 시도가 발생하게 된다.\nFlow의 경우 invertible operation을 통해 exact posterior $z = f(x)$와 conditional generation $x = f^{-1}(z)$를 보장받고, $p_z(f(x))$를 maximize 하는 것만으로 데이터 포인트의 관찰이 이뤄진다.\n현대의 3개 생성 프레임워크 중 GAN 프레임워크만이 데이터 포인트의 관찰과 커버에 대한 제약이 존재하지 않는 것이다.\n이번 글에서는 Likelihood-based 모델의 posterior encoder, sample generator 2개 관점에서의 collapse 해결법을 GAN에서는 어떻게 활용해야 할지 이야기해본다. 그리고 KL-Divergence, Contrastive learning, Generator Diversity Loss가 어떻게 연결될 수 있을지의 직관을 공유한다.\nKL-Divergence\n$$\\mathbb E_{x\\sim p_\\mathrm{data}(x)}[\\log p(x|q(x)) + \\log p(q(x))]$$\n고전 Autoencoder는 반대로 posterior의 diversity에 대한 constraint가 없었다. posterior distribution $z\\sim q(\\cdot|x)$에서 collapse가 발생할 수 있었고, prior에서 sampling을 하면 decoder 입장에서는 unseen point가 들어오는 것이 된다.\n$$\\mathbb E_{x\\sim p_\\mathrm{data}(x), z\\sim q(z|x)}[\\log p(x|z) + \\log \\frac{p(z)}{q(z|x)}]$$\nVAE[arXiv:1312.6114]에서는 posterior의 sampling과 entropy을 활용한다.\nconcrete point가 아닌 stochastic point를 활용하고, entropy term이 posterior collapse를 방지하는 regularizer로 작용한다.\n실제로 코드 수준에서 보면 entropy term은 $\\mu, \\sigma^2 = q(\\cdot|x)$ 에서 $\\sigma$를 최대화하는 방식으로 작동한다. encoder는 최대한 prior 내에서 작동하게 하고, decoder가 가능한 prior의 다양한 샘플 포인트를 보도록 구성한 것이다.\nPosterior approximator in GAN\n이는 AE에서의 문제만은 아니다.\n현대의 다양한 생성 모델은 unseen context의 generalization을 위해 embedding 보다 네트워크 기반의 information encoder를 사용하는 편이다.\nStarGAN 같이 style code를 생성하는, 일종의 posterior encoder를 가진 아키텍처가 있다고 가정하자. posterior encoder에서 collapse가 발생한다면, generator에서는 generalization 문제와 연쇄적인 modal collapse로 발전할 수 있다.\nGAN이라도 Information encoder를 가진 아키텍처라면, posterior collapse 방지를 위한 regularizer를 고려해볼 법하다.\nContrastive and Diversity loss\nposterior collapse는 entropy term을 활용한 regularization으로 해결하였다. 그렇다면 generator modal collapse는 어떻게 해결해야 할까\n2020년 전후로 Contrastive learning은 어느덧 representation learning의 메인 테마로 자리매김하였다. 비전에서는 SimCLR[arXiv:2002.05709], 음성에서는 Wav2Vec2.0[arXiv:2006.11477] 등의 representation들이 공개되었다.\n$$I(x_{t+k}, c_t) \\ge \\log N + \\mathbb E_{\\mathcal X}\\left[\\log\\frac{f_k(x_{t + k}, c_t)}{\\sum_{x_j \\in \\mathcal X}f_k(x_j, c_t)}\\right]$$\nContrastive learning의 major contribution은 기존까지 positive case에 대해서만 objective를 취하던 방식과 달리 negative case, contrastive case에 대해 objective를 취해 representation 사이의 mutual information을 최대화한다는 것이다. [arXiv:1807.03748]\n기존까지의 representation learning에서도 collapse 현상은 발생하고 있었고, 이를 negative case에 대한 penalizing으로 해결한 것이다. 그렇다면, 생성 모델에서도 negative case에 대한 penalizing이 이뤄진다면, modal collapse가 완화될 수 있을 듯 하다.\n가장 먼저 정의할 것은, 생성 모델에서 하나의 데이텀 포인트가 생성되면, 해당 샘플의 negative case가 무엇인가이다.\n만약 latent space의 크기가 데이터 공간의 크기보다 작거나 같다면, 모든 데이텀 포인트를 커버하기 위해 generator는 injective, 일대일 함수여야 한다. 이는 두 잠재 변수가 다르다면, 생성되는 두 결과물이 달라야 함을 의미한다.\n우리에게 negative case는 generator가 injective일 때, 다른 latent에서 생성되는 결과물이 같은 경우로 정의할 수 있을 것이다.\n$$\\mathbb E_{\\mathcal Z}[-\\log\\sum_{z_j \\in \\mathcal Z} f(G(z_j), G(z))]$$\n만약 샘플 포인트를 Laplacian으로 가정하면, $\\sum_{z_j \\in \\mathcal Z}||G(z_j) - G(z)||_1$로 표현할 수 있고, 이는 StarGAN.v2[arXiv:1912.01865]의 diversity loss에 대응한다.\n이에 GAN의 diversity loss는 Generator가 injective일 때 negative case에 대한 contrastive loss로 해석할 수도 있게 된다. 그리고 modal collapse의 완화를 위한 regularizer로 이해할 수 있다.\nWrap up\nPosterior collapse, representation collapse의 해결은 대체로 entropy term, negative case penalizer을 포함하는 방식으로 해결하였다.\n처음으로 돌아가 Likelihood-based model은 1) 데이터 포인트의 직접 관찰과 2) 커버 두 가지 방식으로 Modal collapse를 해결하였다. GAN은 injective 가정에서 diversity loss를 통해 coverage를 높이는 방식으로 현상을 완화하였지만, 데이터 포인트의 직접 관찰을 통한 복원 시도는 없기에 완전한 해결로 보기는 어렵다.\n이런 케이스는 Energy-based GAN 모델이나, Diffusion + GAN 모델을 조금 더 살펴보면 Modal collapse 해결을 위한 좋은 직관을 얻을 수 있지 않을까 싶다.\nAdditional intuition\n그럼 KL-divergence의 entropy term은 Contrastive objective, diversity loss과 본질적으로 다른가\n현재는 negative term이 분포 정의에서 자유로운 pratical한 entropy term으로 작용하는 것 아닐까 하는 직관이 있다. 결국 Entropy term, contrastive objective, diversity loss가 본질적으로 같은 것 아닐까 하는 것이다.\n그렇다면 우리는 좀 더 통합된 하나의 프레임워크를 구성해 볼 수도 있다.\n기본적으로 VAE, Flow 계열 모델은 prior distribution의 가정이 필요하다. GAN은 implicit model로 가정을 우회하고, 보다 sharp한 샘플을 지원한다. implicit model을 상정하고, practical한 entropy를 통해 regularizing할 수 있다면, sharpness와 coverage를 모두 챙길 수도 있을 것이다.\n반대로 데이터가 적은 상황이라면, prior에 대한 강한 가정과 analytic한 entropy를 통해 generalization을 일굴 수도 있다.\nSurVAE Flows[arXiv:2007.02731]에서는 이런 상황에서 한가지 논의를 더 이어나간다. \u0026ldquo;그렇다면 반반도 되는가\u0026rdquo;. implicit model에서 analytic entropy를 구한다거나, explicit model에서 pratical entropy를 구할 수 있는가, 이 때 얻을 수 있는 장점이 있는가의 질문을 던져본다.\nReference\nTackling the Generative Learning Trilemma with Denoising Diffusion GANs, Xiao et al., 2021. [arXiv:2112.07804] NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat and Kautz, 2020. [arXiv:2007.03898] Denoising Diffusion Probabilistic Models, Ho et al., 2020. [arXiv:2006.11239] Glow: Generative Flow with Invertible 1x1 Convolutions, Kingma and Dhariwal, 2018. [arXiv:1807.03039] A Style-Based Generator Architecture for Generative Adversarial Networks, Karras et al., 2018. [arXiv:1812.04948] Auto-Encoding Variational Bayes, Kingma and Welling, 2013. [arXiv:1312.6114] A Simple Framework for Contrastive Learning of Visual Representations , Chen et al., 2020. [arXiv:2002.05709] Wav2Vec2.0: A Framework for Self-Supervised Learning of Speech Representations, Baevski et al., 2020. [arXiv:2006.11477] Representation Learning with Contrastive Predictive Coding, Oord et al., 2018. [arXiv:1807.03748] StarGAN v2: Diverse Image Synthesis for Multiple Domains, Choi et al., 2019. [arXiv:1912.01865] SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows, Nielsen et al., 2020. [arXiv:2007.02731] ","permalink":"https://revsic.github.io/blog/coverage/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Likelihood","Coverage"],"title":"Essay: Generative models, Mode coverage"},{"categories":["Writing"],"contents":"다사다난한 22년이었다. 즐거운만큼 힘든 일도 많았던듯 하다.\n이번 회고도 지난 1년간의 일을 월별로 정리해본다.\n3월 코로나 확진\n3월 코로나에 확진되었다. 나름대로 외출을 자제하고, 위생 관리를 한다고 했지만 피해 가지 못했다.\n3월 당시 회사에서는 코로나 확진 소식이 심심치 않게 들려오고 있었다. 팀에서도 나왔고, 슬슬 차례가 오지 않았나 싶기도 헀다.\n확진 첫날 아침, 일어나자 목에서 갈라지다 못해 무언가에 베인 듯한 통증이 느껴졌다. 평소 농담처럼 했던 \u0026ldquo;걸린 줄 모르고 지나간 거 아닌가\u0026quot;와는 확연히 다르게, \u0026ldquo;아 걸렸구나\u0026rdquo; 하는 생각이 들었다.\n일어나자마자 근처 이비인후과에서 검사를 진행했다. 하지만 검사 당일에는 음성이 나왔고, \u0026ldquo;이게 아닌가\u0026rdquo; 하며 집으로 돌아갔다. 그날 오후에는 몸살 기운이 돌기 시작했고, 아닐리가 없다고 생각했다.\n다음 날 아침, 버티기 어려운 몸살과 근육통이 시작되었고, 보건소에서 확진 판정을 받았다.\n원래 당일에는 오전 근무까지 하려 했지만, 도저히 할 수가 없어 연차로 변경하고 목금토일 4일을 쉬게 되었다.\n첫 3일은 정말 죽은 듯 있었다. 이불 밖으로 나오면 오한이 덮쳐왔고, 몸살로 몸을 일으켜 세우기도 어려웠다.\n문득 19년도 2월에 독감에 걸렸던 것이 생각났는데, 그때는 고열과 몸살로 힘들었다면, 이번은 오한이 너무 심했다.\n기침도 많이 나왔지만, 목이 많이 아프지는 않았다.\n신기한 것은 미각, 후각은 그대로였고, 식욕은 그전보다 왕성해졌다. 몸은 아픈데 혼자 살고, 배고픈데 먹기가 힘드니 그렇게 서러울 수 없었다. 처음 며칠은 부모님께서 돌아가며 챙겨주셨지만, 이후에는 그렇지도 못했다.\n3일간의 고생 후 드디어 열이 떨어지고, 오한이 줄기 시작했다.\n이후에는 일상생활로 복귀할 수 있었고, 더 이상 \u0026ldquo;걸린 줄 모르고 지나갔다\u0026quot;를 믿지 않게 되었다.\n8월, 9월 고등학교, 대학교 연사\n올해 우연히 두 곳에서 강연을 하게 되었다.\n한 곳은 고등학교 모교 선생님께서 연락해 주셨다. 이번에 전근을 하셨는데, 그곳에도 소프트웨어 동아리가 있다고, 고등학생 대상으로 인공지능 기술의 소개를 요청주셨다.\n고민 없이 가게 되었고, 발표 자료를 준비했다.\n인공지능, 딥러닝이라는 것이 어떤 것인지, 우리의 일상생활에 어떻게 녹아들어 있는지, 연구 개발 직종을 위해 어떤 것들을 준비해야 할지 전달했다.\n22.08.30.당곡고등학교 소프트웨어 동아리 대상 인공지능, 딥러닝 기술의 소개\n사실 인공지능, 딥러닝이 무엇인지 설명할 때는 이미 친구들의 반은 졸고 있었다 어떻게 쓰이는지 보여줄 때 좀 관심을 보이다가, 입시 이야기가 나오니 점점 살아나기 시작하는 모습이 귀여웠다.\nQnA 시간에는 날 것 그대로의 질문이 많았다. 돈 많이 벌어요, 고등학생 때 공부 잘했어요 등등\n덕분에 여러모로 에너지도 많이 얻고 온 것 같다.\n22.09.22.상명대학교 제 2회 AI \u0026amp; Dining, 현업에서의 딥러닝 생성 기술 소개\n다음은 회사로 요청이 왔다.\n상명대학교에서 인공지능 관련 강연 자리를 주기적으로 만들고 있는데, 가상 인간에 대한 주제로 발표해줄 수 있는지였다.\n연구 개발도 어느 정도 정리된 기간이었기에, 흔쾌히 참여하게 되었다.\n비슷한 내용을 발표했지만, 이곳의 질문은 달랐다.\n어떻게 하면 하이퍼파라미터 튜닝을 효율적으로 하는지, 기업은 데이터를 어떻게 수집하는지, 심지어 교수님께서는 무엇이 인간답게 만드는지 물어보셨다.\n거의 기업 면접 보는 것 같았다 (ㅋㅋ).\n당시에는 이렇게 대답했다. \u0026ldquo;이제 기술은 충분히 인간의 기교를 묘사하기 시작했기에, 의도의 유무가 인간답게 만드는 것 같다\u0026rdquo;\n이러고 또 기계의 의도를 인간의 언어로 이해할 수 있게 되는 날 또 다른 기준을 고민하고 있을 것 같다.\n9월 피티 시작\n운동을 시작했다.\n처음에는 회사에서 복지 차원으로 챌린저스 서비스 활용 기념, 3개월간 매주 2회 인증을 하면 PT 비용을 환급해준다는 것이다.\n22.10.05.챌린저스 인증\n기회가 왔을 때 물어야 한다고, 바로 PT를 등록했다.\n첫 피티, 나는 말랑한 사람이었구나 싶었다. 근육이 없어서 맘처럼 자세는 안 나왔고, 처음에는 천천히 운동을 시작했다.\n다른 것도 힘들었는데, 하체 하는 날은 특히 억 소리가 났다.\n다리가 흔들리고, 힘이 들어가지 않는다, \u0026ldquo;하나만 더\u0026rdquo; 하면 정말 이를 악물다 못해 이가 갈리는 것 같았다.\n그러다 10월을 넘어 이제 조금씩 몸이 움직이기 시작했고, 나중에는 몸을 잘 쓰는 편이라는 이야기에 내심 기분이 좋았다.\nPT는 3개월이었고, 인증에 성공해 환급받을 예정이다. 이제는 그냥 혼자 3일 정도씩 꾸준히 가고 있다.\n올해 만든 습관 중에 가장 건강한 습관이다.\n12월 맥주일기\n올해도 열심히 맥주 일기를 남겼다. 22년 1월 11일, 22번 구스 아일랜드 IPA부터 23년 1월 4일, 65번 로켓필스까지 43개가 기록되었다.\n23.01.04. 65번 맥주 로켓필스\n그중에서 기억에 남는 맥주가 몇 개 있다.\n31번 칼스버그 필스너: 첫맛부터 엄청난 청량감이 있다. 우르겔만큼 쇠비린내가 나지는 않은데, 터프하게 압도당한다.\n45번 옥토버훼스트 바이젠: 첫맛은 밀맥주의 묵직하고 풍부한 고소함이 있다가, 뒷맛은 부드럽고 가볍다. 대비가 뚜렷하다.\n46번 첫즙라거: 라거 특유의 고소함이 너무 맛있다. 탄산도 적당히 있고, 라거의 본분에 너무나도 충실하다.\n50번 나인스트리트: 와인을 마시면 나는 포도향과 알콜향이 섞인 올라오고, 강한 탄산이 필스너 같기도 하다.\n55번 흑백 임페리얼 스타우트: 첫입은 에일 느낌의 쇳내가 났는데, 혀에 닿을 때는 흑맥주 풍미가 남. 알콜향이 필스너 같기도 하고, 끝은 쓴맛과 탄산감에 압도됨\n내년 목표는 100번 채우기이다. 너무나도 소중한 취미가 되었고, 생활의 한 축이 되었다.\n여행\n올해는 여행을 3번 다녀왔다. 바다가 좋아 이번에도 바다로 많이 다녔다.\n5월은 여수에 다녀왔다. 혼자 다니면 항상 끼니가 문제다.\n관광지는 어딜 가나 2인분 이상만 팔고, 혼자 가도 2인분은 시켜 먹어야 한다.\n여수에서는 돌문어 삼합을 혼자 2인분 잘 땡기고 왔다. 사진을 보여주니 누구랑 갔냐고 지인들이 많이 물어보았지만, 그런 거 없다.\n22.05.06. 여수\n10월 초에는 강릉에 다녀왔다. 면허를 따고 처음으로 혼자 장거리 운전에 도전했다.\n가는 길은 정말 긴장을 많이 했던 것 같다. 도착하고 나니 얼마나 긴장했는지, 어깨가 다 아렸다.\n안전히 도착하고 나서는 바다 구경도 하고, 술에 회도 한접시 먹었다.\n강릉 바다는 불빛이 많지 않아, 밤에 나가기는 조금 무서웠다. 바다도 지역마다 분위기가 다르다.\n그리고 돌아오는 길, 고속도로가 정체되어 차가 서 있었는데, 내 뒤/뒤 차가 뒤 차를 박아 2중 추돌 사고가 났다.\n다행히 크게 다치지는 않았는데, 처음으로 난 사고라 놀라 차를 앞으로 빼느라 추돌 증거가 남지 않아 차 범퍼 내려앉은 것 수리비도 못 받았다.\n부모님과는 안 다치고 사고 경험도 해봤으니 됐다고 하고 지나갔다.\n22.10.10. 강릉\n매년 가을쯤 부산을 다녀오는 것 같다.\n루트도 비슷하다. 오션뷰 방을 잡고, 회 한접시 하고, 장어 덮밥 먹고, 돌아오는 날은 2시간이고 3시간이고 해변을 걷다가 돌아온다.\n올해도 같았다. 해변을 걸을 때 유독 생각이 많았다. 회사 일도 많고, 건강도 안 좋으니 생각이 많을 수밖에 없나 싶기도 하다.\n그래서 더더욱 바다를 많이 오는 것 같다. 멍도 때려보고, 연락도 무시해보고, 파도 소리도 듣고 그러다 가면 좀 놓아주고 오는 것 같다.\n22.10.27. 부산\n라로 - 연구팀장 1월\n22년 1월 음성 연구에서 온전히 손을 떼게 되었다.\n21년 10월 비전팀 창설 이후로, 연구와 매니징의 비중에 관하여 꾸준히 이야기 나눠왔고, 결국 매니징에 올인하는 방향으로 잠정적인 결정이 내려졌다.\n10월에 입사했던 신입 비전 연구원들은 3개월 차가 되었고, 각자 주제를 맡아 연구를 진행하게 되었다.\n영상 합성과 이미지 합성 2가지로 대주제가 나뉘게 되었고, 새로운 연구 주제를 지휘해야 했다.\n당시에는 마이크로 매니징이 필요하다고 생각했다. 신임 연구원들이었고, 기업에서 설정한 목표 보다는 개인의 흥미에 치중될 가능성이 높다고 보았다.\n비전팀 주니어 3인의 모든 실험의 설계에 참여하기 시작했고, 모든 실험에 우선순위를 강제하기 시작했다. 우선순위의 판단은 당연히 나였다.\n일부 팀원은 뭘 해야 할지 모르기에 차라리 업무를 주는 것이 낫다고 했고 어떤 팀원은 안 될 것 같은 걸 시킨다고 의문을 표현하거나, 업무를 수행하지 않기도 했다. 이때 특히 갈등이 많았던 것 같다.\n우선은 인사팀의 추천을 받아 1on1 미팅을 시작했다. 결과를 만들기 위해 팀원들이 무엇을 하고 싶은지, 어떻게 일하고 싶어 하는지 알아야 했다.\n3월\n1on1을 시작한 지 3개월 정도가 지나, 드디어 갈등이 있던 팀원이 이야기를 꺼내기 시작했다.\n\u0026quot;\u0026rdquo;\u0026rdquo; 사실 본인은 많은 고민을 거쳤다. 때로는 안 될 것 같은 실험은 까먹은 척 일부로 안 하기도 하고, 모든 것을 포기하고 시키는 대로 해봤으며, 이제는 그 둘을 섞어서 진행한다. \u0026quot;\u0026quot;\u0026quot;\n많은 고민이 시작되었다. 정말 모든 팀원이 마이크로 매니징을 원하는지, 원하지 않는 팀원은 주제만 전달하더라도 결과를 만들어낼 수 있을지, 그렇지 않다면 어떤 방식으로 결과를 만들어내야 할지\n4월 베리미 프로젝트\n회사에서 새로운 프로젝트를 준비하기 시작했다.\nVeryMe: https://veryme.ai/ 부캐가 새로운 컨텐츠로 자리잡기 시작하였고, 자신의 비식별화 도구로써 가상 아바타를 이미지나 영상에 합성해주는 서비스이다.\nAppStore: VeryMe - 버추얼 페이스 카메라 앱\nVeryMe를 위한 새로운 PO도 입사하였고, 팀을 꾸려 필요한 인력을 채용하기 시작했다.\n신기했다. 기존까지 회사에서 개발된 제품들은 대부분 연구 조직과의 공유 없이, 있는 것들을 가지고 제품화 하는 과정이 많았기에, 제품 기획 과정을 볼 일이 없었다. 어찌보면 그런 과정을 처음으로 시작부터 지켜볼 수 있는 기회였다.\n기술 방향성\nPO는 입사 후 시장과 사용자 니즈를 조사하기 시작했다.\n기존에는 기업에서 제품을 개발할 때, \u0026ldquo;우리가 기술이 있으니, 이거로 할 수 있는 제품을 만들어보자\u0026quot;에 가까웠다.\nPO는 정반대의 사람이었다. \u0026ldquo;시장과 니즈가 있는 곳에 제품을 두고, 거기에 맞는 기술을 개발하자\u0026quot;에 가까웠다.\n그러다 보니 연구팀과의 소통 방식이 달랐다.\n기존에는 \u0026ldquo;기본적인\u0026rdquo; 기술 수준이 갖추어졌을 때 제품 기획이 들어갔다면, 이번에는 제품 기획에 맞추어 기술의 \u0026ldquo;스펙\u0026quot;이 결정되었다.\n\u0026ldquo;기본적인\u0026rdquo; 기술은 의사결정권자와 시장을 만족 시킬 수 있어야 한다. 타겟팅할 시장이 결정되지 않았기에, 기술은 범용적이어야 했고, 범용적인 기술 개발을 위해 시간을 소모하면, 시장은 변화하고 기준이 바뀐다.\n무기한으로 \u0026ldquo;기본적인\u0026rdquo; 기술 수준을 맞추기 위해 달리다 보면, 그 누구도 만족할 수 없는 상황이 지속된다.\n반면 스펙이 결정되고 나니 개발부서의 방향성은 너무나도 명확했다. 시장이 타겟팅 되고 나니, 스펙만을 만족 시킨 최소 기술만 개발하면 되었고, 연구 난이도도 상대적으로 낮아, 시간은 단축되었다.\n둘 모두 만족할 수 있는 상황이 발생한 것이다.\n제품 기획\n시장을 조사하고 니즈를 파악하는 과정도 신기했다.\n현대의 사람들은 어떤 것에 관심을 가지는지, 무엇을 원하는지, 그것이 지속성을 가지는지, 그걸 해소해줬을 때 지불의 의향이 있는지\n그런 고민을 함께하고, 이의 근거를 찾아 리스트업하는 과정이 연구와 너무나도 비슷했다.\n그렇다 보니 초기에 가졌던 걱정은 하나, 둘 정리되어 갔다. 그럼에도 당시 인공지능 생성 시장은 다양한 사회적 논의가 오가고 있었고, 우리의 제품이 정말 우리의 목적대로 쓰일 것인지, 악용의 우려는 없는지 고민되었다.\n그를 위한 새로운 기술 피쳐가 논의되기도 하였고, 리서치를 추가해가며 기획은 하나둘 정리되어 갔다.\n기술 스펙이 결정되니, ML 연구 및 파이프라인 구축이 최우선 과제가 되었다. 그렇게 6월부터 9월, 비전팀은 하나의 목적지를 두고 기존과는 다른 방향으로 달려 나갔다.\n6월 연구원 퇴사\n6월 적지 않은 연구원들이 퇴사하였다.\n씁쓸했다. 내가 해줄 수 있는 최대한을 지원해주고, 도와줬다고 생각했다. 나는 여기서 더 해줄 수 있는 것이 없는 것 같았다.\n퇴사 면담 때 물어보았다. 왜 나가는 건지, 어떤 것이 원인이었는지.\n다들 다른 이유를 이야기했다. 누군가는 처우 수준이 마음에 들지 않아서, 누군가는 다른 곳에 이직하게 되어서, 누군가는 복합적인 사정에 의해서였다.\n내가 더 해줄 수 있는건 없는지, 내가 바뀌었을 때 남아 있어 줄 수 있을지, 물어보았다.\n돌아오는 답은 해줄 수 있는 건 모두 해주었고, 그것을 알기에 나 때문에 나가는 것이 아니라고 했다.\n지금도 그 말이 진심인지, 아니면 좋게 퇴사하기 위한 말인지는 모르겠다.\n하지만 너무나도 무력했다. 처음 겪는 팀원들의 퇴사였고, 너무나 혼란스럽기도 했다.\n정말 좋은 사람들이고, 함께 일하고 싶었는데 어쩌지, 그럼 나는 앞으로 어떤 매니저가 되어야 하는 거지, 당장 저 사람들이 나가면 저 일은 모두 내가 해야 하는 건지\n처음으로 퇴사 프로세스를 구축하기 시작했고, 여러 번의 퇴사 면담을 하며 느낀 것은 \u0026ldquo;갈 사람은 가는구나\u0026quot;였다.\n그러고 나니 한결 생각이 단순해지기도 헀다. 나는 해줄 수 있는 최선을 다해주고, 나간다면 그들의 앞날을 축복해야겠다.\n그럼에도 팀원이 와서 \u0026ldquo;영중님.. 잠깐 커피 한잔 하실래요..?\u0026ldquo;이러면 심장 떨린다.\n새로운 프로젝트가 시작되었고, 연이은 퇴사자에 본인도 결국 리서치에 다시 투입되었다.\n리서치가 시작되니 모든 실험을 트래킹하는 것이 어려웠다. 7개월 지난 시점에 주니어들도 업무에 익숙해졌다 느꼈기에, 이후부터는 마이크로 매니징을 접고, 주제만을 공유하기 시작했다.\n팀원들의 만족도는 급속도로 올랐다. 생각한 것을 바로 점검해볼 수 있어서 좋기도 하고, 연구에 대한 제재가 없으니 편하다는 것이다.\n당시에는 본인의 연구 개발 더 우선이었기에, 팀원의 결과를 걱정할 겨를이 없었다.\n1on1을 통해 팀원들에게 전달 할 수 있는 메시지는 \u0026ldquo;모든 선택은 자유롭게 하시되, 결과로 보여주세요\u0026rdquo; 하나 뿐이었다.\n7월 비전 연구원\n연구, 개발해야 하는 스펙들이 적지 않았다.\n2년을 생성 연구만 해왔지만, 이제는 탐지, 인식, 분류, 추천까지 할 수 있어야 했다.\n다행히도 탐지-인식 쪽은 상업 사용 가능한 오픈소스 제품들이 많았다. 탐지, 인식 쪽 모델 중 SOTA라 이야기한 모델들 위주로 검토를 진행했고, 간간이 페이퍼도 리뷰해야 했다.\n검토된 모델들은 실제 자사 데이터나 입력으로 들어올 수 있는 사전 QA 셋에서 검수 되었고, 과정에서 생성 때는 못 느꼈던 것들이 많았다.\n논의가 많던 생성 쪽 metric을 다루다 인식으로 넘어오니, 수치에 대한 합의가 너무 편리했다. 그럼에도 새로 신경 쓸 것들이 많았다. 임계치를 어떻게 잡을지, FN, FP 비율을 어떻게 잡을지 이미지는 피쳐를 어떻게 잡아야 하는지, 어떻게 해야 분류나 추천이 유의미할지도 고민해야 했다. 특히 임계치에 대한 논의가 많았다. 이상 케이스가 QA 셋에 추가될 때마다 FN, FP의 비율은 달라져 갔고, 이에 맞게 꾸준히 임계치를 수정해 나가야 했다.\n이미지 분류 역시 가장 단순한 커널 기반 분류부터, 딥러닝 기반 분류까지 검토해보았다.\n특이하게도 이 케이스는 커널 기반 분류가 가장 잘 되었지만, 그 역시 스펙을 만족시키지 못해 기획을 수정해야 하기도 했다.\n3인의 퇴사자 업무를 전부 부담해야 했기에, 일이 정말 많고, 커버할 분야도 굉장히 넓었다.\n검수를 위한 단순 작업도 많았고, 스펙에 맞게 ML API까지 구성해야 했다.\n생성만 하던 업체였기에, 인식, 탐지, 분류, 추천에 대한 API 작업은 밑바닥부터 시작해야 했다.\n나중에는 이러다 탈진한다고, 단순 작업이라도 도와줄 인턴이나 신임 연구원에 대한 니즈를 많이 어필했던 것 같다.\n정말 힘들었지만, 실제로 신입 연구원을 선발하기도 했고, 프로덕트에 대한 신뢰와 오랜만의 연구, 개발의 재미로 버텼던 것 같다.\n농담 반 진담 반으로, 지금 회사 프로덕트의 ML 인터페이스는 내가 다 만들었다.\n9월 재고\n새로운 프로젝트에 필요한 연구 개발은 마무리가 되었고, 다시 팀원들의 연구를 관찰하기 시작했다.\n팀원들은 \u0026ldquo;나라면 안 했을 실험\u0026quot;을 돌리고 있었다. 굉장히 경험적이고 귀납적인 실험을 통해 현상을 관찰한다.\n연구 결과가 나오기 시작했다. 모델의 성능은 빠른 속도로 올라갔으며, PoC에서 프로덕션 수준까지 개발이 이뤄지고 있었다.\n신기했다. 연역적인, Model-centric AI를 고수하고 있었기에 귀납적인, Data-centric AI를 통해 나온 결과는 영감을 주기까지 했다.\n어쩌면 마이크로 매니징은 내 오만이었을지도 모른다. 팀원들은 충분히 성장하였고, 연구 업무를 능숙히 보고 있었다.\n그러고 나니 개인에게 맞는 매니징 포지션이 있지 않을까 싶었다. 누군가는 논의를 함께할, 의사 결정을 도와줄 조력자가 필요하기도 할 것이고, 누군가는 주제만 전달하고, 모든 자율성을 전달받고자 하기도 할 것이다.\n그런 개인에 맞는 포지션을 선정하면서도, 결과를 만들어낼 수 있는 매니저가 내 23년 목표이다.\n우리 팀원들이 존경스럽다.\n11월 공황\n6월부터였던 것 같다.\n팀원들의 퇴사가 이어지고, 회사의 여러 뜬 소문에 계속 신경을 쓰고 있었다.\n퇴사자의 업무는 모두 나에게 돌아왔고, 가중되는 업무 속에서 스트레스는 쌓여만 갔다.\n어느 날은 의사결정권자가 직접 연구에 나섰다. 본인의 아이디어를 구현해주길 원했고, 프로덕트 개발 외에 새로운 연구 업무가 들어오기 시작했다.\n외부에서는 연구팀이 진행했던 업무에 끊임없는 질문이 들어왔고, 하루 8시간 근무 중 이완 없이 항시 긴장 상태로 대기했다.\n나 자신이 점점 감정적으로 변한다고 느꼈다. 회의 중에 언성이 높아지는 경우가 생겼고, 점점 심장이 무리하게 뛴다는 느낌을 받았다.\n그러던 일요일 밤 잠이 들기 전 극심한 공포감이 찾아왔다. 숨을 쉬기 어려웠고, 이러다 질식으로 의식을 잃겠다는 생각이 들었다. 시간이 지나고, 몸은 다시 진정되었다.\n몸이 정상이 아님을 인정해야 했다. 다음 날 월요일, 이제는 회의 중에 의사결정권자가 별 이야기를 하지 않아도 목소리에 심장이 반응하기 시작했다.\n회의가 끝난 후, 바로 병원 진료를 예약했다. 병원에 가기까지 용기가 필요하다는 생각보다, 치료받지 않으면 안 될 것 같다는 느낌을 받았다.\n그렇게 병원에 다니기 시작했다.\n이 이상 회의에 참여하거나, 인원이 많은 공간에서 업무를 보기 어려웠다.\n결국 논의를 통해 매니저를 그만두고, 혼자 업무를 볼 수 있는 연구원으로 포지션을 변경하려 했다.\nCEO와는 합의를 보았지만, 인사팀의 의견은 조금 달랐다.\nCRO의 입사 프로세스가 진행되고 있었고, CRO가 입사한다면, 대외 업무를 분리해갈 테니 그 후엔 테크 리드의 포지션을 잡고, 치료에 집중하는 것이 좋지 않겠냐는 것이었다.\n일반 연구원으로 돌아가더라도, 지금까지 수행해온 매니저의 롤에 팀원들의 관성이 이어질 테니, 천천히 롤을 분리해가는게 안전할 것 같다는 의견도 있었다.\n이후 꾸준한 논의와 시도가 있었다. 더 악화될 경우, 회의에 들어오지 않고 서면 대체하기로 하였고, 테크 리딩 외 내외부 매니징을 모두 1달간 임시 보류하기로 하였다.\n시간이 지나니, 감정이 격해지는 경우도 줄어들었고, 비정상적인 심박도 줄어들었다.\n정말 CRO의 입사만을 바라보며 1달을 신경 안정제와 함께 버텼다.\n12월\n기존까지는 팀 내/외 매니징을 모두 전담하고 있었다.\n팀 내 연구 관리나 실험 기획에 대한 디테일부터 팀 외 분기 단위 연구 로드맵 설계나, 프로덕트 니즈 파악, 시장 기술 점검 등 다양했다.\n연구하기 위한 리소스를 내는 것은 거의 불가능했고, 일주일은 팀 내 연구 방향성 관리 아니면 팀 외 부서 간 회의로 보냈다.\n그러던 중 11월 CRO가 입사하였고, 팀 외 매니징에 관한 리소스를 인계하게 되었다.\n업무가 줄어들고 나니, 병세도 호전되었고, 그러고 나니 문득 연구를 다시 하고 싶다는 생각이 들었다. 팀원들이 결과를 보인 것처럼 나도 연구로 다시 한번 증명해 보이고 싶었다.\nCRO, CEO와 관련된 이야기를 나누었고, 끝내 22년 12월부터 다시 음성 연구원으로써 업무를 보기 시작했다.\n굉장히 설렜고, 해보고 싶은 것도 많았다. 비전 연구 당시에 얻었던 인사이트들도 적용해 보고 싶었고, 지식 관리 체계에 대해 실험해 보고 싶은 것도 있었다.\n12월, 굉장히 빠른 속도로 결과가 나오기 시작했고, 그래도 1년 헛보내진 않았구나 싶었다. 기쁘기도 했지만, 안도의 감정이 더 컸던 듯 싶다.\n결과물에 대한 부담, 연구원과 매니저\n어찌 보면 나는 결과에 대한 강한 부담을 가지고 있던 것 같다.\n음성연구원 당시부터 괄목할만한 연구 성과가 없다고 생각했고, 그렇기에 오히려 매니저가 나한테 더 잘 어울리나 생각했다.\n그러다 보니 오히려 매니저가 되어서 나를 입증하고 싶었다. 우리 팀이 결과를 냈으면 좋겠고, 그게 실제 프로덕트로 이어졌으면 좋겠다. 그래서 더더욱 매니저 초기에 팀원들을 압박한 것이 아닌가 싶기도 하다.\n그러다 3분기를 넘어 4분기가 되고, 자율성을 얻은 팀원들이 오히려 결과에 압박감을 느끼기 시작했다.\n그런 팀원들에게 1on1 때 이야기해주었다. \u0026ldquo;우리는 실패보단 시행착오를 하는 부서였음 하고, 우리의 결과가 시행착오라면 그 역시 성과다\u0026rdquo;\n어떻게 보면 자신에게 가장 먼저 했어야 하는 말이지 않았나 싶다.\n나는 시행착오를 잘하는 사람은 맞는 것 같다. 결과를 분석하고, 현상으로부터 지식을 축적하는 것은 자신이 있었다. 단지 나의 지식이 프로덕트로 이어지지 않았다.\n지식이 프로덕트로 이어지도록 잘 가이딩할 수 있고, 이어진 프로덕트가 시의적으로 시장에 맞아떨어진다면, 그것이 스타트업 초기 내가 내고 싶던 성과이다.\n이젠 회사에 후자를 도와줄 사람이 생겼기에, 23년 나는 다시 연구원에 욕심을 내서, 전자를 더 잘해보고 싶단 생각이 든다.\non2022\n연구 지식이 많이 늘지는 않았다. 매니징에 치중한 만큼 21년보다 논문도 덜 보고, 코드도 덜 작성했다. 내가 직접적으로 얻은 경험은 그렇게 많지 않았다.\n그럼에도 시도는 다양했던 것 같다. 음성 연구를 넘어 이미지나 비디오 합성 연구를 시작했고, 팀원들의 연구 방식을 보며 여러 영감도 많이 얻었다. 앞으로 할 수 있는 연구의 방향이 다양해진 것 같다.\n매니저로 있으면서 느낀 것도 많다.\n기업에 있으려면 어찌 되었든 기술이 가치로 이어져야 한다는 것, 가치를 통해 기업에 이익이 남아야 한다는 것, 그렇기에 연구는 속도감만큼 방향성도 중요하다는 것이다.\n기술이 단순히 기술로만 남지 않고, 가치를 통해 제품에 랜딩 되어 사용자에게 전달될 수 있어야 한다.\n그만큼 사용자의 니즈도, 기술의 가치도 모두 중요해졌다.\n또 세상엔 다양한 사람이 있다. 각자의 이야기가 다르기에, 이해도 다르고, 원하는 것도 다르고, 할 수 있는 것도 다르다.\n내가 이들을 재단하지 못한다면, 내가 맞추어 가며 최대의 가치를 창출해내야 한다.\n이 모든 걸 동시에 잘 하는 슈퍼맨이 되기는 어렵기에, 23년에는 우선 기술의 가치를 증명해 보이겠다.\n","permalink":"https://revsic.github.io/blog/on2022/","tags":["Writing","2022th"],"title":"On 2022"},{"categories":["Portfolio"],"contents":"Cyber Security\nAIxCC 본선 지원, 2024.11.~2025.08. : 미국 고등국방연구계획국 DARPA 주관, 오픈소스 프로젝트 취약점 발굴 자동화 시스템 개발 경연 대회 R\u0026amp;R: 보안 자동화 연구원, 취약점 발굴 자동화에 관한 연구\nTBD;\nLLM 시스템 위협 분석, 2024.08.~2024.11. : LLM 시스템 도입 시 발생 가능한 위협 정립, AI 보안 컨설팅 프레임워크 초안 개발 R\u0026amp;R: AI팀 팀장, 금융권 망 분리 규제 완화 후 LLM 시스템 도입에 관한 AI 보안 컨설팅 사업 기획\nTBD;\nLLM 기반 위협 시나리오 생성, 2024.01.~2024.08. : 프로젝트 코드가 주어진 환경에서의 위협 발굴 자동화 시스템 개발 R\u0026amp;R: 보안 자동화 연구원, 취약점 발굴 자동화에 관한 연구\nTBD;\nVision\nStable Diffusion 기반 선화 채색, 2023.04.~2023.07. : 웹툰 선화 자동 채색 어시스턴트 개발 R\u0026amp;R: 영상 합성 연구원, 합성 이미지의 일관성에 관한 연구\n웹툰 시장에 대한 비즈니스 수요를 확인한 이후, 웹툰 제작 어시스턴트 개발을 태핑 하였습니다. 가장 먼저 점검한 기술은 선화의 1차 채색 단계를 반자동화하는 것이었습니다.\nStable Diffusion(이하 SD)에는 LineArt ControlNet[HF]이 있어, 선화를 조건으로 합성된 이미지가 선화를 유지하며, 빈 영역을 채색한 이미지를 제공합니다. 하지만 채색된 이미지에 비현실적 음영이 들어가 있거나, 이미지마다 의상의 색상이 다른 등 일관성에 문제를 가지고 있었습니다.\n또한 SD 위에서 LoRA를 통해 웹툰 캐릭터를 학습하여도, ControlNet이 도입되고 나면 색상 일관성이 유지되지 않는 등 Perturbation에 유약한 모습을 보입니다.\n이를 해결하기 위하여 학습 파이프라인에 ControlNet 입력을 함께 두어 LoRA가 ControlNet에 의한 Perturbation 위에서 색상을 학습할 수 있게 두었고, SD의 결과물을 그대로 사용하는 것이 아닌 선화용 Segmentation 모듈과 각 세그먼트에 대한 Repainter 모듈 등을 개발하여 후처리에 사용-부족한 일관성을 개선하였습니다.\nStable Diffusion 기반 Image-to-Video Style Transfer, 2023.03. : 이미지 생성 모델 기반 영상 합성 확장 R\u0026amp;R: 1인 연구, 영상 합성 연구원, 합성 이미지의 일관성, 연속성에 관한 연구\n영상 합성 모델을 내재화하는 과정에서 Runway/Gen-2의 \u0026ldquo;04.Stylization\u0026rdquo; 데모를 인상 깊게 보아, 사내에서도 이미지의 스타일을 비디오에 Transfer할 수 있는지 PoC를 수행하였습니다.\nVideo Translation에서 SD를 사용하기 위해서는 비디오의 각 프레임을 Image-to-Image Translation해야 합니다. 하지만 Stable Diffusion(이하 SD)은 합성되는 이미지의 높은 분산으로 인해 일관되고 연속된 이미지를 생성하기 어렵습니다. (Video Diffusion 모델은 사내 GPU 리소스로는 운용이 어려웠습니다.)\n첫 번째 프레임을 SD와 ControlNet(Depth, Skeleton, Colorization)을 기반으로 I2I Transfer 하여 그럴듯한 이미지를 확보하더라도, 두 번째 프레임 합성 결과가 첫 번째와 연속적으로 이어지지 않습니다.\nDDIM Latent Inversion[arXiv:2010.02502], Edit-friendly inversion[arXiv:2304.06140], Null-text inversion[arXiv:2211.09794] 등 당시 inversion 기법은 latent-spatial correlation의 한계를 가지고 있었습니다. 이상적으로는 영상 내 객체의 움직임에 따라 style pattern이 함께 이동해야 하지만, inverted latent가 spatial bias를 가져 style pattern의 위치는 이미지 내에 고정되고, 영상 내 객체가 패턴 위를 지나가는 듯한 부자연스러운 artifact를 발생시켰습니다.\n이를 완화하기 위해 MasaCtrl[arXiv:2304.08465] 등 방법론에 영감을 받아 ControlNet 사용을 가정한 상태에서 SD의 Self-attention을 Inter-frame Cross-attention layer로 교체하고, latent variable을 영상의 움직임에 따라 warping하여 spatial correlation을 자연스럽게 재구성하는 등의 작업을 수행하였습니다.\nUnique Image Synthesis, 2022.06. : 합성 이미지의 다양화에 관한 연구 R\u0026amp;R: 영상 합성 연구원, 생성 모델의 분산에 관한 연구\n생성 모델은 대개 유한한 분산을 가집니다. 특히나 적은 데이터로 Finetuning한 모델이 생성하는 이미지의 분산은 경험적으로 기존의 것보다 작습니다. 중복을 허용하지 않을 때, 모델이 생성할 수 있는 최대한의 이미지를 합성하기에 random sampling은 충분히 효율적인 방법론이 아닙니다.\n제품에 출시할 가상 인간을 최대한 많이, 다양하게 만들기 위해, 잠재 변수 공간을 탐색하는 알고리즘을 구축하였습니다.\n가장 먼저 이미지의 유사도를 정의하고, threshold를 설정하였습니다. latent space를 분석하여 유사도와 정렬된 축을 찾고, 해당 축을 기준으로 공간 탐색을 시도하였습니다. 탐색을 진행할 때는 이전까지 합성되었던 이미지들과 유사도를 비교하여 임계점을 넘는 이미지만을 데이터베이스에 추가하였습니다.\n기존 random sampling에 비해 7~10배 빠르게 이미지를 합성하는 속도 개선을 확인하였습니다.\nSpeech\nNANSY++, 2022.10. ~ 2023.01. : 음성 변조를 위한 목소리 분석/재합성 모델 구축 R\u0026amp;R: 2인 연구, 음성 합성 연구원, 음성 변조 모델 개발을 위한 연구 개발\n음성 변조(Voice Conversion, 이하 VC) 모델은 언어적 신호(Linguistic Signal)와 화자의 발화 습관(음색, 높낮이, 크기, 발음 습관, etc.)을 분석하여 재합성하는 방식으로 이뤄집니다.\nNANSY(Neural Analysis and Synthesis, arXiv:2110.14513) 는 Supertone에서 개발한 모델로, 음성으로부터 언어 신호와 화자의 특성을 분리한 후, 재합성하는 음성 모델입니다. 이를 통해 음성의 높낮이를 바꾸거나, 목소리를 바꾸는 등(VC)의 변조가 가능합니다.\n음성 변조에 대한 비즈니스 수요가 확인된 이후, 당시 SOTA VC 모델인 NANSY와 후속 연구인 NANSY++[arXiv:2211.09407]을 재현하는 업무를 수행하였습니다.\n공개된 구현체가 없었기에, Yingram, CQT 기반 Pitch Tracker, Sinusoidal Signal Generator 등의 기반 모델을 구현하고, NANSY를 최종 학습 시도하였습니다.\nNANSY: https://github.com/revsic/torch-nansy NANSY++: https://github.com/revsic/torch-nansypp Stable TTS, 2021.09. ~ 2021.12. : TTS 합성 실패 방지의 이론적 해결책에 관한 연구 R\u0026amp;R: 1인 연구, 음성 합성 연구원, 합성 실패 방지를 위한 연구 수행\n근래의 대부분 딥러닝 모델은 BatchNorm이나 InstanceNorm을 활용합니다. 이 중 BatchNorm은 학습 과정에서 추정한 이동 통계량을 기반으로 표준화를 진행합니다. 만약 학습에 활용한 데이터의 양이 충분하지 않아 통계치가 일반화되지 않았다면 miss-normalization 문제가 발생할 수 있습니다.\n저량의 데이터로 학습된 합성 모델에서 음성이 오합성 되는 이슈가 있었고, 분석 결과 BatchNorm의 miss-normalization에 의한 feature map의 variance exploding 현상을 원인으로 확인하였습니다.\n이를 해결하기 위해 RescaleNet[NeurIPS2020], LayerScale[arXiv:2103.17239], InstanceNorm 등으로 대체하는 연구를 진행하였습니다.\nLatent system, 2021.04. ~ 2021.08. : non-parallel 데이터와 unseen property의 일반화 가능성에 관한 연구 R\u0026amp;R: 1인 연구, 음성 합성 연구원, 다국어 모델 개발을 위한 연구 수행\n음성은 크게 발화자/언어/비언어 표현 3가지 관점에서 관찰할 수 있습니다. 이중 각 도메인의 클래스 간 모든 조합을 데이터로 구성하는 것을 parallel data, 일부 케이스가 비는 것을 non-parallel data라고 할 때, non-parallel 환경에서 문장 내 화자와 언어 정보를 분리하는 것은 natural하게 이뤄질 수 없습니다.\nex. [인물A/B, 영어/한글], parallel: 인물A/한글, 인물A/영어, 인물B/한글, 인물B/영어 natural: 케이스가 비는 경우, 별도의 장치 없이 화자와 언어를 조건화하는 것만으로는 unseen pair의 합성 품질을 보장할 수 없습니다. 따라서 non-parallel 환경에서 다화자-다국어 음성 합성 모델을 개발하는 경우, 특정 화자에서 관측되지 않은 언어 정보, unseen property에 대한 일반화가 이뤄질 수 있어야 합니다.\nLatent System 연구에서는 VAE와 GAN 등 방법론을 통해 Latent variable을 도입하고, 정보의 흐름을 보다 명확히 관리하는 것을 목표로 합니다. CLUB[arXiv:2006.12013]을 활용한 국소-전역부의 잠재 변수 분리, CycleGAN[arXiv:1703.10593]을 활용한 unseen-property 일반화 등을 가설로 연구를 수행하였습니다.\n다음은 당시 모델로 만들었던 프로토타입 영상입니다.\nyoutube:Lionrocket Semi-Autoregressive TTS, 2020.12. ~ 2021.04. : 합성 속도와 음질상 이점의 Trade-off에 관한 연구 R\u0026amp;R: 음성 합성 연구원, 베이스라인 개선 실험 수행\nTTS 모델은 Autoregressive(이하 AR) 모델과 Duration 기반의 Parallel(이하 PAR) 모델로 나뉩니다. AR 모델은 대체로 합성 속도가 음성의 길이에 비례하여 느려지지만 전반적인 음질 수준이 높고, PAR 모델은 상수 시간에 가까운 합성 속도를 가지지만 전반적으로 노이즈 수준이 높은 편입니다.\nSemi-Autoregressive TTS 연구는 이 둘을 보완하기 위한 연구입니다. AR TTS의 병목은 대부분은 AR 방식의 Alignment에서 오기에, Alignment는 Duration 기반의 PAR 모델을 따르고, 이후 Spectrogram 생성은 Autoregression하는 방식의 가설로 삼았습니다. 이는 DurIAN[arXiv:1909.01700], NAT[2010.04301]와 유사합니다.\n이후 추가 개선을 거쳐 실시간에 가까운 AR 모델을 개발하였지만, 음질의 중요성이 높아지며 추가 개선 및 배포가 보류된 프로젝트입니다.\nTTS Baseline, 2019.09. ~ 2020.10. : Text-to-Speech 음성 합성 모델 베이스라인 선정에 관한 연구 R\u0026amp;R: 음성 합성 연구원, 오픈소스 검토, 논문 구현, Ablation\nTTS 모델의 베이스라인 선정에 관한 연구입니다. Autoregressive 모델인 Tacotron[arXiv:1703.10135]부터 Duration 기반의 parallel 모델인 FastSpeech2[arXiv:2006.04558] 등을 폭넓게 검토하였습니다. 검토 과정에서 어떤 백본을 썼을 때 발음이나 음질 오류가 줄어드는지 검토하고, Duration을 어떤 모델을 통해 추정할지, Joint training이 가능한지를 연구하였습니다.\nAcoustic 모델이 완료된 후에는 Vocoder 군에서 Autoregressive 모델인 WaveNet[arXiv:1609.03499], WaveRNN[arXiv:1802.08435] LPCNet[arXiv:1810.11846]과 Parallel 모델인 MelGAN[arXiv:1910.16711] 등을 검토하였습니다. 이후 LPCNet에서 영감을 받아 Source-filter 기반의 방법론을 GAN 기반의 Parallel 모델에 적용하여 음질 개선이 이뤄질 수 있는지 연구하였습니다.\n연구된 베이스라인은 TTS 서비스인 On-air studio에서 활용하고 있습니다.\n다음은 그 외 사이드 프로젝트로 구현한 TTS 모델입니다. torch-retriever-vc [GIT], 2023.01. : *Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph, Yin et al., 2022.\ntorch-diffusion-wavegan [GIT], 2022.03. : Parallel waveform generation with DiffusionGAN, Xiao et al., 2021.\ntorch-tacotron [GIT], 2022.02. : PyTorch implementation of Tacotron, Wang et al., 2017.\ntf-mlptts [GIT], 2021.09. : Tensorflow implementation of MLP-Mixer based TTS.\njax-variational-diffwave [GIT], [arXiv:2107.00630], 2021.09. : Variational Diffusion Models\ntf-glow-tts [GIT] [arXiv:2005.11129], 2021.07. : Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search\ntf-diffwave [GIT] [arXiv:2009.09761], 2020.10. : DiffWave: A Versatile Diffusion Model for Audio Synthesis, Zhifeng Kong et al., 2020.\nEngineering\nface_provider [GIT:lionrocket-inc/private], 2022.06 : All-in-one Face generation API 얼굴 인식, 검색, 합성, 분류, 추천 목적 통합 서비스 지원 프레임워크 Skills: Python, PyTorch, dlib, opencv, FAISS R\u0026amp;R: 1인 개발\n통합 얼굴 이미지 지원 프레임워크입니다. 이미지 내 얼굴 탐지를 시작으로 정렬, 인식, 분류, 벡터 데이터베이스에서의 검색과 추천을 지원합니다.\n얼굴 탐지와 인식 과정에는 입력 이미지의 회전량에 따라 인식 성능이 떨어지는 문제가 있었고, 이를 보정하기 위해 두상의 회전량을 추정하여 이미지를 정면으로 정렬하거나, 인식이 불가능한 이미지를 사전에 고지할 수 있게 구성하였습니다.\n이후 검색과 분류, 추천 과정이 실시간으로 이뤄져야 한다는 기획팀의 요청이 있었고, 벡터 검색 과정은 MetaAI의 벡터 검색 시스템 FAISS를 활용하여 최적화를 진행하였습니다. 얼굴형에 관한 초기 분류 모델은 dlib의 Facial Landmark를 기반으로 작동하였으나, dlib은 실시간 구성이 어렵다는 문제가 있었고, 추후 Mediapipe 교체를 고려하고 있습니다.\nCULICULI [GIT:lionrocket-inc/private], 2020.07.10 : CUDA Lib for LionRocket C++ CUDA Native를 활용하여 딥러닝 추론 속도를 10배 가량 가속화한 프레임워크 Skills: C++, CUDA, Python, PyBind R\u0026amp;R: 1인 개발\n음성 합성 파이프라인의 추론 가속화를 위해 C++ CUDA Native를 활용하여 10배가량 합성 시간을 단축시킨 프로젝트입니다. C++과 CUDA를 통해 기본적인 Tensor 객체와 BLAS(Basic Linear Algebra Subroutines)를 구성하고, 합성 속도를 최적화한 후, PyBind를 통해 python 인터페이스를 제공하였습니다.\n당시 TTS 모델에는 음성의 길이에 합성 시간이 비례하는 문제가 있었고, 단위 시간을 줄여 거의 실시간에 가까운 합성 속도를 구성할 수 있어야 했습니다. 이를 위해 C++로 BLOB-Shape Tuple 형태의 Tensor 객체를 구축하고, 템플릿 프로그래밍을 통해 이를 CUDA Native에서도 활용할 수 있게 두었습니다.\nBLAS 구현과 POC 이후 병목이 메모리 할당에 있음을 확인하여, 메모리 풀과 CUDA API를 활용하지 않는 자체적인 메모리 할당 방식을 구성, 대략 5~7배의 속도 향상을 확인할 수 있었습니다.\n이렇게 만들어진 프레임워크를 팀에서 활용하고자 했고, LR_TTS에서 학습된 체크포인트를 파이썬 인터페이스로 실행 가능하도록 PyBind를 활용하였습니다.\nLR_TTS [GIT:lionrocket-inc/private], 2019.09 : PyTorch implementation of TTS base modules 음성 데이터 전처리, 모델 구현, 학습, 데모, 패키징, 배포까지의 파이프라인을 구성한 프레임워크 Skills: Python, PyTorch, Librosa, Streamlit, Tensorboard R\u0026amp;R: 기획, 개발, 배포, 총책임\n음성 합성팀의 통합 연구 환경을 위한 플랫폼 개발 프로젝트입니다. 당시 PyTorch에는 Keras나 Lightning과 같이 단순화된 프레임워크가 부재했기에 데이터 생성부터 연구, 개발, 학습, 패키징, 평가, 배포, 데모 등 일련의 과정을 프로세스화 하고 코드 재사용성을 극대화하여 적은 리소스로 연구자가 부담없이 배포가 가능하도록 구성했습니다.\n자사 내의 데이터 전처리 구조를 단순화하고, 모든 학습이 고정된 프로토콜 내에서 가능하도록 모델 구조와 콜백 함수를 추상화하여 연구 프로세스를 정리했습니다. 또한 패키징과 배포의 단순화를 위해 모델 구조와 하이퍼파라미터를 분리, 각각을 고정된 프로토콜에 따라 저장, 로딩하는 모든 과정이 자동화될 수 있도록 구성했습니다.\n개발 중 UnitTest와 CI를 도입해보았지만, 딥러닝 모델의 테스트 방법론이 일반적인 소프트웨어 테스트 방법론과는 상이한 부분이 존재했고, 끝내 테스트가 관리되지 않아 현재는 테스트를 제거한 상태입니다.\nCI의 경우에는 이후 PR 생성에 따라 자동으로 LR_TTS의 버전 정보를 생성하고, on-premise framework에 모델을 자동으로 배포할 수 있도록 구성하였습니다.\nBehavior based Malware Detection Using Branch Data [GIT], 2019.08. : Classify malware from benign software using branch data via LSTM based on Tensorflow 브랜치 데이터를 통한 행위 기반 멀웨어 탐지 기법 연구 Skills: C++, Windows Internal, PE, Cuckoo Sandbox, Python, Tensorflow R\u0026amp;R: 1인 연구\nVEH를 기반으로 분기구문(branch instruction)을 추적하는 Branch Tacer를 구현한 후, DLL Injection 방식을 통해 보안 가상 환경(sandbox)에서 멀웨어와 일반 소프트웨어의 분기 정보(branch data)를 축적, 딥러닝 기반 탐지 모델을 개발하였습니다.\nSandbox 환경 내에서는 MSR을 사용할 수 없어 VEH를 통해 branch tracer를 직접 구현해야 했고, 분기문 탐색을 위해 디스어셈블러의 일부를 직접 구현하면서 기술적 어려움을 겪었습니다. 이는 후에 인텔 매뉴얼을 참고하며 tracer를 완성하였고, 이후 이를 발전시켜 VEH 기반의 DBI(Dynamic Binary Instrumentation)[GIT:cpp-veh-dbi] 도구를 구현할 수 있었습니다.\n딥러닝 모델은 LSTM 기반의 간단한 시퀸스 모델을 이용하였고, 결과 88% 정도의 정확도를 확인할 수 있었습니다.\n이는 당시 논문의 형태로 정리되어 정보과학회 2017년 한국컴퓨터종합학술대회 논문집[PAPER]에 고등학생 부문으로 기재되었습니다.\n","permalink":"https://revsic.github.io/blog/project/","tags":["Portfolio"],"title":"Project Overview"},{"categories":["Attention"],"contents":" Survey of Neural Text-to-Speech models and Attention Alignment Keyword: TTS, Attention, Alignment Introduction\n16년도 WaveNet[arXiv:1609.03499], 17년도 Tacotron[arXiv:1703.10135]을 기점으로 딥러닝 기반의 음성 합성 TTS 모델들이 현재까지 꾸준히 발전해 오고 있다. 19년도부터 21년도까지 음성 합성 연구원으로 재직하며 보고 느꼈던 TTS의 발전에 관해 정리해보고자 한다.\nTTS: Text-to-Speech\nTTS는 텍스트를 조건으로 발화 음성을 합성하는 생성 분야를 이야기할 수 있다.\n자연에 존재하는 발화 신호는 기계 신호로 양자화하는 과정에서 1초에 몇 개의 샘플을 획득할 것인지의 Sample Rate(이하 SR)와 샘플을 몇 가지 수로 나타낼 것인지의 Bit Rate로 2가지 변수를 가진다.\nTTS 합성 분야에서 SR은 과거 16kHz부터, 이후 22.05kHz와 24kHz, 현재 32kHz, 44.1kHz, 48kHz까지 꾸준히 증가해왔다. Nyquist 이론에 근거하면 SR의 절반이 획득할 수 있는 주파대역의 상한이므로, TTS는 과거 최대 8khz에서 24khz까지 점점 더 높은 주파대역을 복원할 수 있게 되었다.\nIntermediate representation\nTTS가 처음부터 높은 SR의 음성을 생성할 수 없었던 이유는 1.) 1초에 2만여개 프레임을 포함하는 sparse input으로부터 context를 추정할만큼 넓은 receptive field를 가진 아키텍처가 없었고 (WaveNet[arXiv:1609.03499] 이전) 2.) 음소의 발화 시간은 대략 10~50ms으로 1초에 20~50여개 정도이지만, 음성은 1초에 2만에서 4만여개 프레임으로 1k배 정도 길이 차 사이의 관계성을 학습시키기 어려웠으며 3.) 고주파대역으로 갈 수록 임의성이 짙어져 확률 모델 도입 없이 고주파 정보의 구현이 어려웠기 때문이다.\n이를 해결하기 위해 TTS 모델은 Spectral feature를 중간 매개로 두고, 텍스트에서 spectral feature을 합성하는 acoustic 모델과 spectral feature로부터 음성을 복원하는 vocoder 모델 2단계 구조를 구성하기 시작했다.\nSpectral feature로는 대체로 Short-time Fourier Transform(이하 STFT)으로 구해진 fourier feature의 magnitude 값(이하 power spectrogram)을 활용했다. 오픈소스 TTS 구현체에서는 주로 12.5ms 주기마다 50ms 정도의 음성 세그먼트를 발췌하여 주파 정보로 변환하였다. 이렇게 되면 spectral feature는 1초에 80개 정도의 프레임을 가지고, 텍스트에서 대략 2~4배, 음성까지 250~300배 정도로 구성된다.\nFourier feature를 활용할 수 있었던 이유는 1.) 음성의 발화 신호가 기본 주파수(F0)와 풍부한 배음(harmonics)로 구성되기에 fourier transform을 통해 각 주파대역별 세기를 나타내는 power spectrogram으로 표현하더라도 정보 유실이 크지 않았고 2.) Source-filter 이론에 근거하였을 때 발화 신호 중 발음 성분이 spectral magnitude의 형태(filter)에 상관관계를 가지기 때문에, 텍스트로부터 발음 정보를 만드는 문제로 치환한 것이다.\n그럼에도 발음 정보에 대응 가능한 quefrency 영역의 cepstral feature(ex. MFCC)를 사용하지 않은 이유는, 기본 주파수 등의 정보 손실이 커 음성 신호로 복원하는 보코더의 문제 난이도를 어렵게 했기 때문이다.\nLog-scale, Mel-filter bank\nFigure 1: Power spectrogram\n대체로 오픈소스 TTS 구현체에서는 STFT의 frequency bins를 1024개 혹은 2048개로 설정한다. 이때 TTS 모델이 합성해야 하는 프레임당 벡터의 길이는 spectral feature 중 허수 반전을 제외한 513개 혹은 1025개이다.\n인간의 청각 체계는 음의 세기와 높낮이에 모두 log-scale로 반응한다. 신호의 세기가 N배 커지더라도, 실제로는 logN 정도로 인식하는 것이다. 이를 반영하여 인간이 실제로 듣는 신호의 세기와 높낮이 대역을 강조하기 위해 TTS에서는 power spectrogram (linear spectrogram)을 곧장 활용하기보다는 주파대역의 인지적 선형화를 위해 filterbank를 취하고, 세기의 인지적 선형화를 위해 log를 취한다.\nfilterbank는 주로 2가지를 활용하는 듯하다. 가장 많이 쓰이는 Mel-scale filterbank와 LPCNet[git:xiph/LPCNet] 등에서 간간이 보이는 Bark-scale filterbank이다. 대체로 오픈소스 TTS 구현체에서는 0Hz ~ 8kHz의 영역을 나눈 STFT 기존 513개~1025개 frequency bins를 80개~100개로 축약하는 mel-scale filterbank를 활용하는 편이다.\nMel-scale filterbank를 활용하는 경우를 log-Mel scale spectrogram이라고 하여, 간략히 mel-spectrogram이라 일컫는다.\nFigure 2: log-Mel scale spectrogram\nVocoding\n보코더는 음성을 압축/복원하는 기술을 통칭한다. TTS에서는 algorithmic 하게 구해진 spectrogram(mel-scale)을 음성으로 복원하는 모델을 이야기한다.\n단순히 STFT만을 취했다면 발화 신호 특성상 iSTFT만으로도 충분한 음성을 복원해낼 수 있지만, mel-spectrogram 변환 과정에서 1.) 주파대역별 세기를 측정하기 위해 실-허수 신호를 실수 신호로 축약하는 Absolute 연산 2.) 500~1000여개 bins를 80~100개로 압축하는 filter bank 연산의 2가지 손실 압축을 거치기에 algorithmic한 복원에는 한계가 존재한다.\nTacotron[arXiv:1703.10135]에서는 power-spectrogram을 활용하여 filter bank 연산이 없었고, 허수부(phase) 복원에는 griffin-lim 알고리즘을 활용하였다.\n상용화하기 어려운 음질이었고, 부족한 주파대역과 허수(phase) 정보 복원을 위해 Tacotron2[arXiv:1712.05884]에서는 2016년 WaveNet[arXiv:1609.03499]을 별도의 경험적 보코더로 두어, mel-spectrogram에서 time-domain signal을 복원하도록 학습하여 활용하였다.\nBit-rate\n음성은 과거와 현재 크게 다르지 않게 16bit를 bitrate로 산정하여, 음성 신호를 대략 6만여개 실수로 양자화하였다.\nWaveNet을 경량화한 WaveRNN[arXiv:1802.08435]에서는 신호 복원 문제를 6만여개 클래스의 분류 문제로 바꾸고자 했는데, 현실적으로 6만개 클래스를 분류하는 것에는 네트워크 학습에 어려움이 있었다.\n이를 위해 시간축 신호 역시 청각 구조에 따른 인지적 선형화를 진행하며 16bit를 8bit로 2차 양자화하였다. 대체로 mu-law를 활용하였으며, 8bit 256개 클래스로 분류하는 보다 쉬운 문제로 치환하였다.\n하지만 mu-law 역시 손실 압축이기 때문에, 복원된 8bit 음성을 algorithmic 하게 16bit로 복원하는 과정에서 배경 노이즈가 섞이는 이슈가 있었다.\n이는 이후 GAN 기반 신호 복원 방법론인 MelGAN[arXiv:1910.06711] 등이 등장하며 bitrate 상관없이 [-1, 1]의 실수 범위 신호를 직접 복원하게 된다.\nNow-on\n근래에는 24khz, 32khz, 48khz의 SR과 16bitrate의 데이터셋을 주로 활용하고 있으며, 대체로 1024bins/12.5ms(or 256frame)/50ms(or 1024frame)의 STFT, 80~100bins log-Mel scale spectrogram을 활용하는 듯하다. [git:seungwonpark/melgan, git:jik876/hifi-gan] 아무래도 Tacotron2의 영향이지 않을까 싶다. [git:NVIDIA/tacotron2]\n이외로 preemphasis 필터를 거치거나, 기준 세기를 잡아 amplitude 영역의 주파정보를 decibel 단위로 변환하기도 하고, [-1, 1] 범위로 값을 scaling 하기도 한다. [git:keithito/tacotron]\nAcoustic Model - Sequence-to-Sequence\nAcoustic model은 텍스트에서 mel-spectrogram으로의 가변 길이 Sequence-to-Sequence 모델을 상정한다.\n주로 문장 단위로 음성을 전처리하는데, 입력으로 들어온 문장은 표기 문자인 자소를 그대로 쓰기도 하고, 소리 문자인 음소로 변환하여 활용하기도 한다. 이 과정을 grapheme-to-phoneme(이하 G2P)라 하며, [git:Kyubyong/g2p]의 카네기 멜론 대학 음소 사전(CMU-Dictionary)를 활용하거나 [git:bootphon/phonemizer]의 International Phonetic Alphabet(이하 IPA)을 활용하기도 한다.\nSequence-to-Sequence 모델은 기본적으로 Encoder-Alignment-Decoder 3개 모듈로 이뤄진다. 음소/자소 열은 Text Encoder에 들어가게 되고, Alignment를 통해 텍스트와 합성하고자 하는 spectrogram의 관계를 정립/정렬한다. 이후 정렬된 텍스트 인코딩은 Spectrogram Decoder에 의해 mel-spectrogram으로 합성된다.\nEncoder와 Decoder를 어떻게 구성할지를 TTS의 Network Backbone 관련 연구에서 다루고, 어떻게 텍스트와 spectrogram의 관계를 정의하고, Alignment 모듈을 학습할 것인지를 Attention Alignment 관련 연구에서 다룬다.\n텍스트와 spectrogram의 관계가 다른 Sequence-to-Sequence 태스크와 다른 점은 1.) 발화 특성상 음소가 동일한 문장이어도 사람마다, 녹음마다 발화의 길이가 달라질 수 있어 음소만으로는 발화 길이의 추정이 어려울 수 있다는 점과 2.) 텍스트와 발화 음성 모두 시간 축에 따라 정렬되기 때문에 둘의 관계성이 순증가(monotonic) 하는 특성을 띤다는 것이다.\nTTS에서는 이러한 특성을 활용하여 Alignment 모듈을 Joint training 하기도 하고, 외부에서 학습한 모듈을 활용해 Distillation 하기도 한다.\n이를 토대로 특성에 따라 TTS를 분류한다면 다음과 같이 나눌 수 있을 것 같다.\nDecoding: Autoregressive, Parallel Backbone: CNN, RNN, Transformer AR Alignment: Forced-Align, Content-based, Location-based PAR Alignment: Distillation, Joint-Distillation, End-to-End Autoregressive TTS\nTTS 모델은 일차적으로 spectrogram의 디코딩 방식에 따라 2가지로 나눌 수 있다. $x_t$를 t번째 spectrogram frame, $c$를 텍스트 입력이라 할 때, Autoregressive 모델은 t번째 프레임 생성에 이전까지 생성한 프레임을 참조하는 방식 $\\prod_{t=1}^T p(x_t; x_{\\cdot \u0026lt; t}, c)$, Non-autoregressive(or parallel) 모델은 이전 프레임의 참조 없이 텍스트로부터 spectrogram을 합성하는 방식이다 $p(x_{1:T}; c)$.\n전자의 경우 대체로 첫 번째 프레임부터 마지막 프레임까지 순차적으로 합성해야 하기에 합성 속도가 느리지만, 이전 프레임을 관찰할 수 있기 때문에 대체로 단절음이나 노이즈 수준이 적은 편이고, 후자는 GPU 가속을 충분히 받아 상수 시간 안에 합성이 가능하지만 상대적으로 단절음이나 노이즈가 발견되는 편이다.\nWaveNet: A Generative Model for Raw Audio, Oord et al., 2016. [arXiv:1609.03499] Category: Autoregressive, CNN, Forced-Align Problem: Inefficiency of increasing receptive field Contribution: Dilated convolution, exponential field size Future works: Reduce real-time factor(RTF \u0026gt; 1), remove handcrafted features\nFigure 3: Visualization of a stack of dilated causal convolutional layers. (Wavenet, 2016)\n기존까지의 TTS 시스템은 크게 두 가지로 나뉘었다. 1.) Unit-selection/Concatenative: 사전에 녹음된 음성을 규칙에 따라 이어 붙이는 방식 2.) Statistical Parametric TTS: HMM을 기반으로 보코더 파라미터를 추정, 합성하는 방식\n이러한 시스템들은 대체로 음소, 음소별 발화 길이, F0 등의 입력을 요구하였고, 그럼에도 기계가 발화하는 듯한 음성을 합성해 내는 특성을 가지고 있었다.\n기존까지 음성 신호를 직접 합성하지 않고 보코더 파라미터를 추정하였던 이유는 초당 2만여개 프레임을 감당할만한 receptive field의 현실적 확보가 어려웠기 때문이다. 예로 strided convolution을 활용한다면, receptive field의 크기는 네트워크의 깊이에 비례하고, 2만여개 프레임을 커버하기 위해 2만개의 레이어가 필요하다.\nWaveNet은 이를 Dilated convolution(or atrous convolution)을 통해 해결하였다. 인접 프레임을 커널과 합성곱 하는 것이 아닌, N개 프레임마다 1개 프레임을 선출하여 합성곱 하는 방식을 활용한다. 이때 N을 dilation이라고 하며, N을 지수에 따라 늘려가면 receptive field의 크기를 레이어 수의 지수에 비례하게 구성할 수 있다. 2만여개 프레임을 커버하기 위해 14개 레이어면 충분한 것이다. (jax/flax에서는 input의 dilation을 transposed convolution의 stride, kernel의 dilation을 dilated convolution의 dilation이라고 표현, ref:jax.lax.conv_general_dilated)\n이에 신호를 직접처리할 수 있게 되었고, WaveNet은 사전에 구한 음소별 발화 길이와 log-F0를 추가 입력으로 하여 음성 신호를 생성하는 TTS를 구현하였다.\nHMM 기반 TTS 혹은 Forced Aligner을 통해 구한 음소별 발화 길이를 기반으로 텍스트 토큰을 길이만큼 반복, 음성과 정렬 (ex.MFA: Montreal Forced Aligner) 반복/정렬된 음소는 conditional input으로 전달 이전까지 합성된 음성 프레임을 dilated convolution으로 encoding 하여 최종 다음 프레임을 합성 합성은 8bit mu-law에 따라 압축한 음성을 256개 클래스의 분류 문제로 치환 합성 과정 중에는 음소별 발화 길이를 텍스트로부터 추정하는 별도의 모듈을 학습하여 활용 MFA: Text-Speech align sample (ResearchGate, Zhiyan Gao)\nWaveNet은 16khz 음성을 대상으로 했기에 1초에 16k개 프레임을 생성해야 했으며, 프레임마다 dilated convolution을 구동해야 했기에 합성 속도가 실시간보다 느린 문제가 있었다. 그럼에도 음성은 기존 시스템보다 자연스러웠으며, 보코더 파라미터가 아닌 음성을 직접 모델링할 수 있었다는 기여를 가진다.\nTacotron: Towards End-to-End Speech Synthesis, Wang et al., 2017. [arXiv:1703.10135] Category: Autoregressive, CNN + RNN, Content-based alignment Problem: Large RTF of Wavenet, handcrafted features required Contribution: Bahdanau attention, Spectrogram synthesis Future works: Noisy output, instability of attention mechanism\nFigure 1: Model Architecture. (Tacotron, 2017)\n이후 17년도 구글은 Tacotron이라는 TTS 모델을 공개한다. 1.) Learnable 한 Attention mechanism을 도입하여 음소별 발화 길이가 필요하지 않고 2.) Spectrogram을 생성하도록 목표를 재설정하여, 3.) RNN 기반의 Decoding을 통한 효율화를 가능케 했다.\nLearnable Attention Mechanism 기존까지 TTS는 HMM 등을 활용하여 음소별 발화 구간을 추정하는 별도의 모델을 두고, 이를 통해 음소를 반복, 음성과 정렬하는 방식을 많이 사용하였다. 이 경우 구간 추정 모델과 TTS를 이중으로 학습해야 했기에, Tacotron에서는 Bahdanau et al., 2014.[arXiv:1409.0473]의 Joint training이 가능한 learnable alignment를 활용하였다.\n기계 번역(Neural Machine Translation, 이하 NMT) 분야 역시 가변 길이의 Seq2Seq 문제를 상정한다. NMT에서는 생성하려는 토큰과 입력의 관계를 명시하여 학습/추론 과정을 안정화하기 위해 \u0026ldquo;Alignment\u0026quot;라는 것을 도입하였다. 이는 다음 토큰을 생성하기 위해 입력으로 들어온 텍스트 토큰 중 어떤 것을 관찰할지를 결정하는 Bipartite 그래프의 간선들을 의미한다.\nTTS에서는 다음 프레임을 합성하기 위해 텍스트의 어떤 부분을 관찰할지 결정하는 map을 alignment라고 한다. 음소는 대략 20~50ms의 발화 구간을 가지고, spectrogram frame은 대략 10~20ms으로 구성되기 때문에 alignment는 음소 별로 1~3개 프레임을 순차적으로 할당하는 역할을 한다.\n이렇게 alignment를 명시하고 명확히 제약할수록 관계 해석에 대한 Encoder와 Decoder의 부하가 줄어 TTS의 학습이 가속화되는 이점이 있다.\nFigure 3: Attention alignments on a test phase. (Tacotron, 2017)\n이때 발화는 음소를 순서대로 읽는 방식으로 작동하기 때문에, NMT와 달리 TTS의 Alignment는 순증가(순차 할당) 하는 특성을 가진다.\n대체로 Alignment를 활용하는 Autoregressive TTS는 $x_{1:S}$를 S개 음소로 이뤄진 입력 문장, $y_{1:T}$를 T개 프레임으로 이뤄진 출력 spectrogram이라 할 때 다음과 같이 fomulation 된다.\n$$\\begin{align*} \u0026amp;s_{1:S} = \\mathrm{TextEncoder}(x_{1:S}) \\in \\mathbb R^{S\\times C} \\\\ \u0026amp;q_t = \\mathrm{SpecEncoder}(y_{1:t - 1}) \\in \\mathbb R^{C}\\\\ \u0026amp;a_{t, \\cdot} = \\mathrm{Attention}(Wq_t, Us_{1:S}) \\in [0, 1]^{S} \\\\ \u0026amp;h_t = \\sum_{i=1}^S a_{t, i}s_i \\\\ \u0026amp;y_t = \\mathrm{SpecDecoder}(q_t, h_t) \\end{align*}$$\n이렇게 텍스트 $x_s$와 spectrogram $y_t$의 관계성을 나타내는 map $a_{s, t}$을 attention alignment라 부르게 된다. $a_{s, t}$가 0이라면 s번째 음소와 t번째 프레임은 독립인 것이고, 1에 가까울수록 s번 음소에 의해 t번 프레임이 합성될 확률이 높아지는 것이다.\nTacotron에서는 Bahdanau의 alignment mechanism을 그대로 활용한다.\n$$\\begin{align*} \u0026amp;e_{t, \\cdot} = v^T\\mathrm{tanh}(Wq_t + Us_{1:S}) \\\\ \u0026amp;a_{t, \\cdot} = \\mathrm{softmax}(e_{t, \\cdot}) \\\\ \u0026amp; \\mathrm{where} \\ W, U \\in \\mathbb R^{C \\times H}, \\ v \\in \\mathbb R^H \\end{align*}$$\n이러한 alignment mechanism을 additive attention이라고도 하고, 입력 텍스트와 이전 프레임의 정보를 통해서만 alignment를 결정하기 때문에 content-based attention이라고 한다.\n별도의 constraint 없이도 정상적으로 학습된 Tacotron은 monotonic 한 alignment로 유도된다. 하지만 monotonic 한 align이 정상적으로 학습되지 않는 경우도 종종 있고(학습 불안정성), 이 경우 Autoregressive Decoding을 통해 음성을 정상 합성할 수 없다.\n또한 content-based attention이기 때문에 경우에 따라 문장 내에 동일한 음소가 2개 이상 있는 경우 alignment가 현 발화 시점 이전 혹은 이후의 텍스트에 attending 하기도 한다. 이 경우 반복/누락 등의 발음 오류를 만든다.\nRepeating issue, [discourse.mozilla:julian.weber]\nSpectrogram Retarget, RNN-decoding 기존의 WaveNet이 음성 신호를 직접 복원하고자 하였다면, Tacotron은 Spectrogram으로 합성 대상을 변경한다.\n앞서 이야기하였듯 spectrogram은 reasonable 한 선택이었다. 기존의 시스템은 높은 SR로 인해 RNN을 학습하는 것이 어려웠고, CUDA 등 GPU toolkit에 의해 well-optimizing 된 프로시져를 활용하지 못하는 아쉬움이 있었다.\nspectrogram은 초에 80여 프레임, 이마저도 한 번에 N개 프레임을 동시에 디코딩하는 reduction heuristic을 적용하면 80/N개 프레임으로 축약된다. Tacotron에서는 N=2를 가정하며, 초에 40개 프레임을 구성한다. 20~40개 음소로 구성되는 텍스트와도 관계성이 단순해져 Bahdanau attention의 부하도 줄일 수 있다.\n또한 초당 프레임 수가 줄어들었기에 Decoder을 RNN으로 구성할 수 있고, GPU toolkit의 최적화된 연산을 충분히 활용하여 실시간에 가깝게 합성할 수 있다.\n다만 기존 WaveNet과 달리 spectrogram을 활용할 경우 별도의 음성 복원 방법론이 필요했고, Tacotron에서는 linear spectrogram을 생성, griffin-lim 알고리즘을 통해 phase를 복원하는 방식을 채택하였다.\n대체로 속도는 빨라졌지만, griffin-lim을 통해 복원된 음성은 기계음이 섞인 음성을 만들어내는 이슈가 있었다.\nEnd of decode Autoregressive decoding에서 가장 중요한 것은 종료 시점이다. WaveNet에서는 발화 길이에 따른 forced alignment를 활용하여 decoding 전에 신호의 길이를 미리 알 수 있다. 하지만 Bahdanau attention을 쓰는 Tacotron에서는 align과 decoding이 동시에 이뤄지기 때문에 decoding 과정에서 음성의 길이나 종료 시점을 추정할 수 있어야 한다.\nTacotron 구현체에서는 종료 시점에 관해 몇 가지 휴리스틱을 활용하는데, 1.) 묵음에 해당하는 spectrogram이 일정 프레임 이상 합성되면 정지하거나 [git:r9y9/tacotron_pytorch] 2.) Alignment가 텍스트의 마지막 토큰에서 일정 프레임 이상 머무르면 멈추기도 하고, 3.) 음소당 3~5개 프레임을 합성한다는 배경지식을 토대로 음성의 길이를 \u0026ldquo;음소의 수 x 4\u0026rdquo; 정도로 설정하여 고정된 길이를 합성하기도 한다.\n그리고 이 3가지 방법론에는 모두 단점이 존재한다. 1.) 임계치를 잘못 설정하면 쉼표나 띄어쓰기의 묵음부에서 디코딩이 멈추기도 하고, 2.) 앞서 이야기한 alignment 반복 등의 이슈로 무한히 디코딩하는 현상이 발생하거나 3.) 음성 길이 추정에 실패해 합성 도중에 강제 종료되기도 한다.\n이후 논문들에서는 이러한 종료 시점에 관한 엔지니어링 코스트를 줄이기 위해 별도의 방법론을 도입하기도 한다.\nTacotron2: Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions, Shen et al., 2017. [arXiv:1712.05884] Category: Autoregressive, CNN + RNN, Location-sensitive alignment Problem: Spectorgram inversion, Content-based attention Contribution: Location-sensitive attention, WaveNet vocoder Future works: Unconstrained monotonicity, stop token misprediction\nFigure 1: Block diagram of the Tacotron 2 system architecture. (Tacotron2, 2017)\nTacotron2는 Tacotron의 후속작으로 Neural TTS의 가장 기본적인 baseline을 제시한다.\nMel-spectrogram retarget, WaveNet Vocoder 기존의 Tacotron은 Linear spectrogram과 griffin-lim을 활용하였다. 하지만 앞서 이야기하였듯 linear spectrogram은 인지적 선형화가 이뤄지지 않은 feature이고, 강조될 필요 없는 고주파 대역까지의 복원을 목표로 해야 하기에 Decoder의 network capacity를 높여야 하는 등의 이슈가 있었다.\nTacotron2에서부터는 mel-spectrogram을 활용하여 기존 500bins spectral feature를 80bins까지 압축하였고, network capacity를 덜 고려한 단순한 아키텍처로도 음성 모델링이 가능케 했다.\n가장 큰 문제는 mel-spectrogram이 linear-spectrogram에 비해 압축률이 높은 feature라는 것이고, 이를 음성으로 복원하기 위해서는 별도의 경험적 보코더가 필요했다.\nTacotron2에서는 이를 위해 mel-spectrogram을 조건으로 time-domain의 음성 신호를 복원하는 WaveNet을 학습하여 보코더로 활용하였다.\nNeural TTS는 Tacotron2 이후 mel-spectrogram을 생성하는 acoustic 모델과 음성 신호를 복원하는 vocoder 모델 2개의 분야로 세분화되었다. NVIDIA에서는 Tacotron2의 구현체[git:NVIDIA/tacotron2]를 공개하였고, [git:seungwonpark/melgan] 등의 오픈소스 보코더가 NVIDIA 구현체와의 호환을 지원하면서 Tacotron2의 세팅은 학계의 pivot처럼 작동하였다.\nLocation-sensitive attention 기존의 Tacotron은 content-based additive attention을 상정하였다.\n$$a_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(Wq_t + Us_{1:S}))$$\n음성은 문자를 순차적으로 발화한 신호이기 때문에, TTS 혹은 ASR(Automatic Speech Recognition, 음성 인식) 분야에서는 Alignment가 시간 축에 따라 순증가 해야 한다는 사전 지식이 존재한다.\n하지만 $q_t$와 $s_{1:S}$로만 이뤄진 alignment mechanism은 연산에 순증가의 사전 지식이 반영되어 있지 않다.\n[arXiv:1506.07503]에서는 ASR에 이러한 순증가의 사전 지식을 적용하기 위해 다음과 같은 formulation을 제안한다.\n$$a_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(Wq_t + Us_{1:S} + F \\ast a_{t - 1, \\cdot}))$$\n$\\ast$는 convolution 연산으로, 이전의 alignment에 convolution을 취해 energy 연산에 더하는 방식이다.\n간단한 예로 F가 크기 3의 [1, 0, 0] 커널이어서 PyTorch 기준 F.conv1d(a[:, None], [[[1, 0, 0]]], padding=1)의 연산으로 구현된다면, 이는 F.pad(a, [1, -1])로 alignment의 modal이 다음 텍스트로 이동한 것과 동치가 된다.\n즉 과거 alignment를 convolution하는 것은 alignment의 이동 방식에 관한 prior knowledge를 연산에 반영하는 것이고, content-based attention에 비해 상대적으로 안정적인 alignment 학습과 추론이 가능해진다.\n이렇게 과거 alignment를 활용하는 방식을 cumulative attention이라고도 하고, location-sensitive attention이라고도 한다.\n하지만 이 역시 kernel F의 작동 방식을 완전히 순증가 하도록 제약한 것이 아니기 때문에 기존 보다는 완화되었지만 여전히 반복과 누락 등의 이슈가 발생한다.\n이후 [git:coqui-ai/TTS] 등의 오픈소스에서는 순증가의 제약을 강제하기 위해 이전 align 시점의 근방에 대해서만 softmax를 취하는 휴리스틱을 적용하기도 한다.\n# PyTorch # previous_align: [B, S] # energy: [B, S] for i, p in enumerate(previous_align.argmax(dim=-1)): energy[i, :p] = -np.inf energy[i, p + 3:] = -np.inf # [B, S] align = torch.softmax(energy, dim=-1) Stop-token prediction Tacotron에서는 decoding의 종료 시점을 명시적으로 모델링하지 않아 여러 heuristic에 따라 종료 시점을 판단해야 했다.\nTacotron2에서는 NLP의 End-of-sentence(이하 EOS) 토큰과 유사히 어느 시점부터 합성을 종료할지 판단하는 Stop token을 명시적으로 모델링한다.\n가변 길이 시퀀스는 배치로 묶는 과정에서 패딩을 붙여 고정된 크기의 텐서로 변환하는데, spectrogram이 존재하는 부근을 false, 패딩이 존재하는 부근을 true로 하는 binary classification 문제를 decoding 할 때마다 추론하게 하는 것이다.\n이렇게 되면 decoding 과정에서 프레임마다 stop token을 추론하여 decoding을 지속할지 멈출지 판단할 수 있는 근거로 작동시킬 수 있다.\n하지만 이 역시도 모델의 판단에 맡기는 것이기 때문에 합성 중 잘못 추론하는 경우 조기 종료되거나 장기화되는 이슈가 발생할 수 있다. 이에 stop token이 연속 N번 발생하면 종료하는 heuristic을 설정하여 안정성을 높이는 방식을 채택하기도 한다.\n대체로 Align과 Autoregressive Decoding을 동시에 진행하는 모델은 종료 시점에 대한 엔지니어링 이슈가 상시 발생할 수밖에 없다. 이는 추후 TTS field가 AR 모델에서 병렬 합성 모델로 이동하는 원인이 되기도 한다.\nAR TTS - Architecture\nTacotron2가 Neural TTS의 baseline으로 선정된 이후 TTS의 백본 네트워크를 어떻게 잡는 것이 합성 품질을 높이는가의 추가 연구가 있었다.\nDCTTS: Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention, Tachibana et al., 2017. [arXiv:1710.08969] Category: Autoregressive, CNN, Content-based alignment Contribution: CNN-based architecture, SSRN\nFigure 1: Network Architecture. (DCTTS, 2017)\nDCTTS는 그중에서 전체 아키텍처를 convolution으로 구성한 TTS 모델이다.\n특이한 점 한가지는 attention alignment에 additive attention이 아닌 dot-product attention을 썼다는 것이다. 이 경우 역시 monotonicity에 관한 prior knowledge는 연산상에 반영되지 않는다.\n$$a_{t, \\cdot} = \\mathrm{softmax}(K^TQ/\\sqrt d) \\ \\ \\mathrm{where} \\ \\ K=Us_{1:S}, \\ Q = Wq_t$$\n저자는 대신 guided-attention loss라는 목적 함수를 제시한다. attention alignment가 \u0026ldquo;nearly diagonal\u0026quot;이 되도록 유도하는 방식으로, monotonic한 alignment가 대각 성분에서 값을 가지는 꼴로 표현되는 현상을 구현한 것이다. 연산 상에서 순증가성을 반영하지는 않았지만, 목적함수를 통해 유도하는 방식으로 학습 안정성을 도모한다.\n$$\\mathcal L_\\mathrm{att}(A) = \\mathbb E_{t, s}[A_{t, s}W_{t, s}] \\\\ \\mathrm{where} \\ \\ W_{t, s} = 1 - \\exp\\{-(t / T - s / S)^2/g^2\\}$$\nFigure 3: Comparison of the attention matrix. (DCTTS, 2017)\n또 한 가지 특이한 점은 SSRN: Spectrogram Super-resolution Network를 활용한 점이다.\nDCTTS에서는 mel-spectrogram을 1/4배로 downsampling(mean-pool)한 결과물을 spectrogram decoder가 생성하도록 학습한다. 대체로 음소 1개에 대응되는 spectrogram은 4개 프레임인 것에 착안하여 텍스트의 길이와 downsampling된 spectrogram의 길이 비가 대략 1대1이 되도록 구성한 것이다.\n대신 생성된 1/4-scale의 spectrogram을 원본 길이로 복원하기 위해 별도의 경험적 upsampler를 구성하며, 이것이 SSRN이다. 기본적으로 autoregressive decoding은 연산 비용이 높기 때문에, AR decoding에서는 downsample된 spectrogram을 합성하고, SSRN에서는 parallel한 convolution 연산을 상정하여 연산을 가속한 것으로 보인다.\nTacotron의 reduction heuristic이 한 번에 N개 프레임을 합성하는 대신 iteration을 T/N으로 줄였다면, DCTTS는 T/N개 프레임을 합성한 후에 T개 프레임으로 SR 하는 방식을 차용했다는 차이점이 있다.\nTransformerTTS: Neural Speech Synthesis with Transformer Network, Li et al., 2019. [arXiv:1809.08895] Category: Autoregressive, Transformer, Content-based alignment Contribution: Transformer-based architecture\nFigure 3: System architecture of our model. (TransformerTTS, 2018)\nTransformer TTS는 engineering 관점에서 연구가 많이 이뤄졌다.\nSinuositional encoding의 범위는 [-1, 1]인 것에 반해, Prenet의 output이 ReLU일 경우 $[0, \\infty]$의 범위를 가져 feature map의 center point가 다르게 잡히는 현상이 발생했고, 이것이 실제 성능 저하로 이뤄짐을 확인했다. 저자는 이를 방지 하기 위해 prenet에 projection layer를 추가하고 PE 앞에 weighted term을 두었다.\n$$l_i = W\\mathrm{prenet}(x_i) + \\alpha PE_i$$\nStop token prediction에서는 true와 false의 비율이 다른 unbalanced classification 문제임을 지적하였고, 패딩에 해당하는 true 케이스의 목적함수에 가중치를 곱하였다고 이야기한다.\nTransformer TTS도 DCTTS와 마찬가지로 dot-product attention을 활용하였다. 다른 점은 Transformer에서 제안한 multihead attention을 활용한 점이다.\n개인적인 경험으로는 TTS에서 attention이 여러 개일 때 monotonicity가 유도되는 alignment map은 대체로 1개만 나오는 편이다. 나머지 alignment들은 해석이 불가능하거나, 무의미한 경우가 많다. 저자는 attention head가 4개일 때 보다 8개일 때 MOS가 높았다고 이야기하였다. 이 경우 어떤 이유에서 좋아진 것인지, single-head일 때와 multi-head일 때의 alignment plot을 첨부해주었다면 어땠을까 하는 아쉬움이 있다.\nAR TTS - Alignment\nContent-based attention의 문제점이 지적되며, attention의 순증가성을 연산에 어떻게 강제할 것인지, content를 energy 연산에서 제거할 수 있는지의 추가 연구도 있었다.\nForward Attention in Sequence-to-sequence Acoustic Modeling for Speech Synthesis, Zhang et al., 2018. [arXiv:1807.06736] Category: Location-sensitive alignment Problem: Training instability, lack of monotonicity prior Contribution: Forcing monotonicity Future works: Content inputs\nFigure 1: Grey circles represent a possible alignment path. (Forward Attention, 2018)\nForward attention은 CTC(Connectionist Temporal Classification, Graves et al., 2016.)에서 영감을 받아, 현재의 attending phoneme에서 다음 음소로 이동할지, 현재의 음소에 남아 있을지를 확률로 판단하고자 한다.\nContent-based attention은 TTS가 기존까지 어떤 음소들을 attending 하였는지 고려하지 않고, 현재 시점에서 가장 가능도가 높은 지점을 선택한다. 하지만 alignment의 연속성과 순증가를 기저로 한다면, 현재의 attending point는 이전 프레임의 attending point와 현재 시점의 가능도를 모두 고려해야 한다.\n연속성(Continuity): 음소의 누락 없이 alignment는 모든 음소를 순차적으로 1회 이상 attending 해야 한다. 순증가(Monotonicity): alignment의 attending point(가장 확률이 높은 지점)는 양의 방향으로만 이동한다. 예로 t번 프레임에서 s번 음소가 attending 될 확률은 t-1번 프레임의 s-1번 확률(이동)과 s번 확률(유지)을 더한 후, content 상에서 t번 프레임의 s번 확률(실체화 가능성)을 곱해야 한다. 과거 프레임에 의해 전이될 확률을 더하고, 실체화될 가능성을 곱하는 것이다.\n즉 \u0026ldquo;content 상에서 실체화될 가능성\u0026rdquo;(=content-based energy)과 \u0026ldquo;continuity \u0026amp; monotonicity에 의해 attending 될 가능성\u0026rdquo;(=attending probability)을 분리한다. 이렇게 되면 기존 content-based attention과 달리 연속성과 순증가의 기저에 따라 attending될 가능성을 고려할 수 있다.\ncontent-based energy를 $y$, attending probaility를 $a$라 하면 다음과 같이 표현 가능하다.\n$$\\begin{align*} \u0026amp;y_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(Wq_t + Us_{1:S})) \\\\ \u0026amp;a_{t, s} = (a_{t - 1, s - 1} + a_{t - 1, s})y_{t, s} \\\\ \u0026amp;\\hat a_{t, s} = a_{t, s} / \\sum^S_{i=1} a_{t, s} \\\\ \u0026amp;h_t = \\sum^S_{i=1}\\hat a_{t, i}s_i \\end{align*}$$\n위 표현은 이동 확률$\\alpha_{t-1, s-1}$과 유지 확률$\\alpha_{t - 1, s}$을 동일하게 0.5로 보고 있다. Forward attention에서는 이동 확률과 유지 확률 또한 학습 가능한 대상으로 보았고, transition agent $u$라는 확률을 도입한다.\n$$a_{t, s} = (u_{t - 1}a_{t - 1, s - 1} + (1 - u_{t - 1})a_{t - 1, s})y_{t, s}$$\n경우에 따라 content-based energy를 location-sensitive attention 꼴로 formulation 하기도 한다. attending 확률을 분리한 것과 별개로, energy의 연산상에도 monotonicity가 반영될 수 있도록 유도하는 것이다.\n$$y_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(Wq_t + Us_{1:S} + F\\ast y_{t - 1}))$$\nFigure 2: Alignmnts of an utterance. (Forward Attention, 2018)\nForward attention은 alignment map의 확률적 표현을 통해 alignment에 continuity와 monotonity를 부여하였다. 이를 통해 실제 학습 안정성은 더욱 올라왔고, 기존 보다 확률이 양단화된 hard한 attention의 꼴로 표현되었다.\n그럼에도 강제하는 수준은 아닌만큼 여전히 이전 프레임의 attending point를 기반으로 alignment map을 마스킹하기도 한다.\nDCA: Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis, Battenberg et al., 2019. [arXiv:1910.10288] Category: Location-sensitive alignment Contribution: Remove contents from energy\nAttention alignment는 대체로 장기성 문제를 가지고 있었다. 문장의 길이가 길어질수록 누락/반복 등의 합성 실패 확률이 높아지는 것이다. DCA에서는 이를 해결하기 위해 2가지 방법론을 제안한다.\nGMM-based Attention 하나는 attending point를 직접 가정하는 방식이다. 기존까지는 content를 기반으로 energy를 계산했다면, 이번에는 content를 통해 몇번째 음소를 attending할지 직접 추정하는 것이다.\nNetwork $P_\\theta$는 query와 text encodings를 통해 $\\mu_t$번째 프레임을 attending 할 것이라고 명시한다. 이후 alignment는 Gaussian likelihood를 통해 $\\mu_t$를 기준으로 weight가 확산되는 꼴로 표현된다.\n$$\\begin{align*} \u0026amp;\\alpha_{t, s} = \\mathrm{softmax}\\left(-\\frac{(s - \\mu_t)^2}{2\\sigma_t^2}\\right) \\\\ \u0026amp;\\mathrm{where} \\ \\ \\mu_t, \\sigma_t = P_\\theta(Wq_t, Us_{1:S}) \\end{align*}$$\n이 때 monotonicity와 continuity는 $\\mu_t$를 이동량 $\\delta_t$로 표현하여 자연스럽게 획득할 수 있다.\n$$\\begin{align*} \u0026amp;\\delta_t, \\sigma_t = P_\\theta(Wq_t, Us_{1:S}) \\\\ \u0026amp;\\mu_t = \\mu_{t - 1} + \\delta_t \\ \\ \\mathrm{where} \\ \\ \\delta_t \\in [0, 1]\\end{align*}$$\nDCA에서는 하나의 프레임이 multiple point를 attending할 수 있다는 가정 아래, unimodal gaussian을 multimodal gaussian mixture로 확장한다. 이를 GMM-based attention이라 부른다.\n$$\\alpha_{t, s} = \\sum^{K}_{k=1}\\frac{w _{t, k}}{Z _{t, k}}\\exp\\left(-\\frac{(s - \\mu _{t, k})^2}{2\\sigma _{t, k}^2}\\right)$$\nDynamic convolution attention 다른 하나는 energy 연산에서 직접적인 content의 영향력을 배제하는 것이다.\n$$a_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(Wq_t + Us_{1:S} + F \\ast a_{t - 1, \\cdot}))$$\n기존까지의 location-sensitive attention은 $Wq_t$와 $Us_{1:S}$를 통해 content의 직접적 영향력을 행사한다. 이는 query가 과거의 context에 매칭되었을 때 alignment가 backward 할 수 있다는 문제점을 가진다.\n이를 방지하기 위해 content 요소를 완전히 제거하면, alignment는 location convolution을 통해 항상 고정된 만큼만 움직일 수 있다. 이를 해결하기 위해 제안된 것이 dynamic convolution이다.\n$$\\begin{align*} \u0026amp;a_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(F\\ast a_{t - 1, \\cdot} + \\mathcal G_\\psi(h_{t - 1}, q_t) \\ast a_{t - 1})) \\\\ \u0026amp;h_t = \\sum^S_{i=1}a_{t, i}s_i \\end{align*}$$\ndynamic convolution은 network $\\mathcal G_\\psi$를 통해 kernel을 생성하여 convolution 연산을 수행한다. 이렇게 weight를 런타임에 생성하는 네트워크를 hyper network라고도 부른다.\nDCA에서는 content 정보를 에너지에 직접 반영하는 대신, content를 기반으로 alignment를 얼마나 움직일지 추정한다. 이렇게 되면 query와 text를 직접 매칭하지 않기 때문에 content에 의한 backward를 방지하면서, query를 기반으로 현시점이 attending point를 이동할 시점인지 추정할 수 있게 된다.\n하지만 이 역시 $\\mathcal G_\\psi$의 추정에 따라 attending point가 backward로 이동할 수 있다. DCA는 이를 방지하기 위해, 항상 앞으로 움직이는 고정된 kernel $\\mathcal P$를 prior로 제공한다.\n$$a_{t, \\cdot} = \\mathrm{softmax}(v^T\\mathrm{tanh}(F\\ast a_{t - 1} + \\mathcal G_\\psi(h_{t - 1}, q_t) \\ast a_{t - 1} + \\mathcal P \\ast a_{t - 1}))$$\nprior kernel $\\mathcal P$는 beta bernoulli의 likelihood 값을 활용하며, 다음은 prior kernel을 convolution 했을 때의 실제 alignment 이동을 도식화한 것이다.\nFigure 1: Initial alignment encouraged by the prior filter. (DCA, 2019)\n이렇게 구성된 DCA는 다른 alignment 보다 빠르게 수렴하기 시작하고, 문장이 길어지더라도 오합성률이 크게 늘어나지 않는다.\nFigure 2: Alignment trials for 8 different mechanisms. (DCA, 2019)\nFigure 3: Utterance length robustness. (DCA, 2019)\nMove to Parallel TTS\nAutoregressive 모델은 꾸준히 발전해왔지만, 태생적으로 합성 속도와 alignment에 대한 engineering cost는 극복할 수 없다.\n이에 연구자들은 다시금 발화 길이를 기반으로 forced align을 구성하는 것에 관심을 가지기 시작했고, 이렇게 개발된 것이 FastSpeech[arXiv:1905.09263]이다.\n다음 글에서는 FastSpeech와 이후의 Parallel TTS에 관해 이야기 한다.\nReference\nA Survey on Neural Speech Synthesis, Tan et al., 2021. [arXiv:2106.15561] Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks, Graves et al., 2006. WaveNet: A Generative Model for Raw Audio, Oord et al., 2016. [arXiv:1609.03499] Tacotron: Towards End-to-End Speech Synthesis, Wang et al., 2017. [arXiv:1703.10135, git:keithito/tacotron, git:r9y9/tacotron_pytorch] Neural Machine Translation by Jointly Learning to Align and Translate, Bahdanau et al., 2014. [arXiv:1409.0473] Tacotron2: Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions, Shen et al., 2017. [arXiv:1712.05884, git:NVIDIA/tacotron2] Attention-Based Models for Speech Recognition, Chorowski et al., 2015. [arXiv:1506.07503] DCTTS: Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention, Tachibana et al., 2017. [arXiv:1710.08969] TransformerTTS: Neural Speech Synthesis with Transformer Network, Li et al., 2019. [arXiv:1809.08895]- Forward Attention in Sequence-to-sequence Acoustic Modeling for Speech Synthesis, Zhang et al., 2018. [arXiv:1807.06736] Forward Attention in Sequence-to-sequence Acoustic Modeling for Speech Synthesis, Zhang et al., 2018. [arXiv:1807.06736] DCA: Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis, Battenberg et al., 2019. [arXiv:1910.10288] WaveRNN: Efficient Neural Audio Synthesis, Kalchbrenner et al., 2018. [arXiv:1802.08435] LPCNet: Improving Neural Speech Synthesis Through Linear Prediction, Valin and Skoglund, 2018. [arXiv:1810.11846, git:xiph/LPCNet] MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis, Kumar et al., 2019. [arXiv:1910.06711, git:seungwonpark/melgan] FastSpeech: Fast, Robust and Controllable Text to Speech, Ren et al., 2019. [arXiv:1905.09263] g2p: English Grapheme To Phoneme Conversion, [git:Kyubyong/g2p] phonemizer: Simple text to phones converter for multiple languages, [git:bootphon/phonemizer] TTS: a deep learning toolkit for Text-to-Speech, battle-tested in research and production, [git:coqui-ai/TTS] ","permalink":"https://revsic.github.io/blog/alignment/","tags":["Machine Learning","Deep Learning","TTS","Attention","Alignment","Monotonic"],"title":"Survey: Neural TTS and Attention Alignment"},{"categories":["Writing"],"contents":"21년도 한 해가 지났다. 학교와 회사를 병행한 20년도였다면, 21년은 자신과 회사 일의 균형을 맞춘 한 해였다.\n올해의 회고는 지난 1년간의 일을 월별로 정리해보려 한다.\n1월 라로 - Ablation Study\n21년 1월 처음으로 개발 중이던 모델에 Ablation Study를 진행했다.\nAblation Study는 모델의 각 요소를 제거해보고, 대체하며 현상을 확인하는 작업이다. 딥러닝이란 분야적 특성도 있고, 이전까지 연구 방법론에 대한 프로세스가 정립되지 않았었기에 각 요소가 어떤 역할을 하는지, 중간 표현은 어떤 의미를 가지는지 전혀 모르고 있었다.\nAblation Study는 이를 확인하기 위한 작업이었고, 현행 TTS 모델에 대해 아주 많은 인사이트를 얻어갈 수 있었다.\n연구는 텍스트 인코더, 어텐션 메커니즘, 스펙트로그램 디코더로 나눠 진행했으며, 어떤 아키텍처가 발음 문제에 강하고 음질 수준에 도움을 주는지, 각 어텐션 메커니즘이 최종적으로 회귀하는 옵티멀한 선택지가 있는지 등을 알아보았다.\n한참이 지나 11월에는 단순 연구 노트의 실험 기록과 정리를 넘어 지식의 형태로 남기길 바랐고, 이에 Wiki를 만들어 각 컴퍼넌트와 품질의 상관관계를 글로 정리했다.\n연구 조직에서 활동하다 보면 성공보다 실패의 경우가 많고, 작동 방식이나 구성 요소에 관한 연구를 진행하는 것이 실질적인 성과로 이어지지 않는 때도 있다. 그렇기에 더더욱 연구 조직은 성과로 가는 길에 체크포인트를 둘 수 있어야 하고, 꾸준히 과정 자체를 결과물로 기록해둘 수 있어야 하는 것 같다. Wiki와 중간 샘플 공유는 이의 결과물이고, 실패를 성과화 할 수 있는 방법론이었다.\n2월 라로 - 모델 배포\n19년도 9월부터 대략 1년 6개월의 장정 끝에 처음으로 모델을 배포했다. 가칭 PTv2 모델은 Tacotron을 시작으로 한 우리 회사의 첫 Parallel TTS 모델이었다. 당연히 합성 품질이 이전 같지 않다는 문제가 있었지만, 당시에는 실시간 합성이 가능한 딥러닝 TTS 모델이 필요했고, PTv2는 이에 가장 알맞은 모델이었다.\n첫 배포였기에 학습 정량화부터 진행하였다. 추가 튜닝 없이 다양한 데이터셋에서 어느 정도의 품질을 냈는지, 의도한 품질까지 얼마만큼의 데이터셋 규모와 학습량이 필요한지 등을 실험적으로 구하였다.\n이는 엔진 제작팀으로 전달되었고, 12월인 지금까지도 PTv2 모델을 가장 기본으로 사용하고 있다.\n이후 모델은 프로덕트에서 더욱 다양한 데이터셋과 사용자 입력을 만나며 다양한 버그가 리포트 되었다. 하지만 대부분의 버그는 딥러닝 특성상 모델 구성 수준에서 해결하기 어려웠다. 실험적으로 더 많은 데이터를 넣어 결과를 확인하거나, 개별적으로 파라미터 튜닝을 하는 것 정도가 일차적인 해결방안이었다.\n의미도 모를 중간 표현을 관찰하는 등 디버깅은 계속됐다. 관찰 도중 중간 표현의 분포가 특정 입력에서 변화하는 현상을 확인했고, 9월에는 이를 모델 구성 수준에서 해결하기 위한 연구가 진행되었다.\n이후 버그는 1/4 수준으로 줄어들었고, 새로이 모델의 배포를 준비 중이다. 이 외에도 중간 표현을 관찰하여 자동으로 이상을 탐지하는 딥러닝 디버거 개발 등을 앞두고 있다.\n딥러닝 모델을 디버깅할 수 없다는 건 이제 옛말일지도 모른다. 연구팀은 주어진 환경에서 문제를 정의하고, 이제 원인을 밝혀낼 수 있어야 한다. 내년에는 이에 대한 프로세스를 확립하고 공유할 수 있으면 좋을 것 같다.\n3월 독립\n지난 3월 본가를 나와 교통편이 좋은 곳에서 자취를 시작했다.\n원래도 정거장 수만 세면 본가에서 사무실이 멀지는 않았는데, 본가에서 역으로 나가 환승하는 것까지 고려하면 대략 왕복 2시간 정도가 소요되었다. 2년 정도는 이렇게 출퇴근했었고, 이는 생각보다 생활 패턴을 망쳐갔다.\n지금 회사는 8시에서 11시 사이에 출근하는 탄력 근무제를 시행하고 있다. 처음에는 9시에 출근해 6시에 퇴근했었는데, 6시의 지옥철을 타고 1시간을 퇴근하는 것은 절대 쉬운 일이 아니었다. 그렇게 피로감을 느끼고 7시 집에 도착, 8시에 저녁을 먹고 나면 8시부터 10시는 낮잠 시간이었다.\n낮잠을 자고 나니 밤잠을 늦게 자게 되고, 생활 패턴은 꼬여만 갔다. 늦잠 몇 번에 출퇴근 시간이 늦어지고 나니 퇴근 후 개인 시간이 존재하지 않았고, 퇴근-저녁-잠-출근의 워크 앤 워크 사이클로만 시간이 채워져 갔다.\n감정 상태나 피로감에 대한 충분한 이완 없는 사이클은 번아웃으로 이어졌다. 어떻게든 일을 지속하려면 이를 타파해야 했고, 몇 가지 시작한 생활 습관이 있다.\n우선 부모님과 이야기 중이던 독립을 앞당겼고, 교통편이 좋은 곳에서 자취를 시작했다. 자취방에서 사무실은 전철로 10분 거리고, 문에서 문으로 20분 정도면 도착한다. 왕복 시간이 줄어들면서 근본적인 출퇴근 피로감을 많이 줄일 수 있었다.\n또 체력이 부족하다고 생각해서 근래에는 조금씩 운동을 시작하고 있다. 확실히 운동하고 나면서 낮잠을 자는 빈도도 많이 줄어든 것 같다.\n이렇게 생활 패턴이 정상화된 이후로는 8시 출근, 5시 퇴근을 하면서 저녁 시간도 챙겨가고 있다. 기타도 사서 하고 싶던 취미 생활도 시작하고, 온라인 게임이나 저녁 약속 잡는데도 부담이 줄었다. 저녁이 생기고, 감정적 이완이 가능해지니 번아웃도 많이 줄어들었다.\n나는 생활력이 꽤 있는 편인 것 같다.\n친구들과 독립에 대해 이야기할 때에도 너는 걱정 없다는 이야기를 많이 들었던 것 같다. 밥도 해먹고, 요리도 잘 하고, 청소도 매일 하고 그러고 지내고 있다. 자취방 근처에 밥집이 없는 것도 한몫한 것 같다.\n먼저 자취하던 친구들은 외롭다는 이야기도 많이 했었는데, 나는 혼자 있는 것에 크게 외로움을 느끼지는 않는 편이어서 다행인 것 같다. 오히려 내 생활 패턴에 온전히 집중할 수 있고, 모든 상황이 의지 아래 조절 가능하단 점이 너무 좋다. 어쩌면 고등학생 때부터 이어진 결벽의 만족감일 수도 있겠다.\n좀 이른 나이에 경제적 독립과 주거의 독립을 이뤘지만, 굉장히 만족하는 삶을 살고 있다.\n글을 마무리 짓기도 전에 이 문장을 수정할 줄 몰랐다.\n겨울이 되니 집에 하자가 많다. 온수가 안 나오고, 후드를 열 때마다 물 폭탄이 떨어진다. 집을 알아볼 때부터 그런 것은 아니었다. 3월에는 온수도 잘 나왔고, 후드는 말라 있었다.\n그러던 12월 초, 영하의 온도가 찾아오면서 아침에 샤워하려는데 온수가 안 나오기 시작하고 요리 중에 후드를 열면 결로가 고여 있다가 후두둑 떨어진다. 덕분에 아침마다 샤워를 고민하고, 요리도 여럿 버렸다.\n지금 집은 집주인 아저씨가 와서 직접 고치시는데, 차라리 기사를 불렀으면 하는 마음이다.\n자취 참 쉽지 않다.\n4월 라로 - 첫 단독 연구\n모델을 배포하고 난 후의 4월, 해외 진출에 관한 이야기가 시작되면서 연구팀으로 다국어 모델에 대한 요청이 들어왔다. 한국어 데이터셋만 가지고 영어를 말하게 만드는 연구였다.\n여느 때처럼 arxiv와 paperswithcode에 들어가 다국어 모델에 대한 조사를 시작했다. 회사에서는 병렬 합성 모델을 배포한 이후였고, 애드온과 같은 방식으로 기존 모델 위에 올렸으면 하는 상황이었다.\n하지만 parallel tts의 연구가 등장한 지 얼마 되지 않은 시점이었기에 대부분의 다국어 연구는 Tacotron 위에서 작동했다. 그마저도 원하는 퀄리티가 아니었고, 회사 데이터셋 환경과 호환이 되지도 않았다.\n약간의 힌트와 데이터셋, 모델의 제약만 존재하는 상황이었고, 처음으로 남들이 공개하지 않은 미지의 영역에 발을 딛은 느낌이었다.\n이는 굉장한 설렘으로 다가왔다. 첫 개인 연구이기도 하고, 연구자로 유의미한 발자국을 남길 기회라 생각했다.\n베이스라인부터 차근차근 시작했다. Tacotron 기반 다국어 모델에서 필요한 요소들을 적용해 보면서 최초 현상을 관찰했다. 어느 부분에서 문제가 생겼을지 현상과 직관을 기반으로 가설을 세우고 하나둘 실험을 통해 검증해갔다.\n처음에는 언어 표현을 어떻게 해야 할지, 어떤 방식으로 언어 정보를 첨가해야 할지 고민했고, 이후에는 비언어적 특성을 화자에서 분리해낼 수 있는지, 혹은 이를 모사해낼 수 있는지 등을 고민했다.\n시간은 6월 훈련소 가기 전까지 2달 정도로 촉박했고, 하루에 8개 정도의 실험을 꾸준히 돌려 가며 대략 200여 개의 모델을 구성해 보았다.\n그 결과가 다음의 영상이다. 2달의 연구 기간, 첫 단독 연구였기에 이 정도 음성은 꽤 만족스러웠다. parallel tts에서의 비언어적 특성과 정보 전이란 주제로 무언가 발자국을 남긴 기분이었다. 이 모델은 1차 배포가 진행되었지만, 이후 발음 이상이나 음질 문제로 아직 프로덕트에 가진 못했다.\n그렇게 6월 훈련소를 갔다 오고, 다른 프로젝트에 우선순위가 돌아가며 다국어 연구는 중단되었다.\n이 외에도 연구 프로세스나 기간 산정, 성과 평가 등 연구 정량화에 관한 이야기가 이때를 기점으로 시작되었다. 현재에 연구팀에 공유되고 있는 연구 프로세스라는 문서도 이 시기의 경험을 기반으로 작성되었다.\n성과도 만족스러웠지만, 프로세스를 확립하고 정량화에 대한 논의가 시작되었단 점에서도 긍정적이다.\n라로 - 연구팀장\n19년도 9월, 음성 연구원으로 입사한 이후 1년 6개월 정도의 기간 동안 TTS 모델만을 연구해 왔다. 이후로 여러 인턴과 연구원분들이 왔다 갔다 했지만, 회사 규모는 여전히 10명 정도였고, 팀은 기획-마케팅과 R\u0026amp;D 정도로만 나뉘어 있었다.\n그러던 중 4월에 인사팀장님과 연구원을 공격적으로 채용하면서 연구팀의 운영에 수요가 생겼다. 대표님이 먼저 연구팀장의 위치를 제안해주셨지만, 처음에는 할 생각이 없었고, 거절했다.\n나는 특성화고를 나와 졸업하자마자 취업한 여러 친구의 고생을 보며 알게 모르게 회사란 존재에 적대감을 가지고 있었다. 이러한 적대감은 내가 연구에는 몰입할지언정, 회사에는 몰입하지 못하게 했다.\n지금 보면 창업 초기 멤버로 시작해 2년간 일한 회사에 몰입하지 못하는 것도 아이러니하긴 하다.\n이러한 배경 속에서 나는 굳이 팀장 자리를 맡을 이유가 없었고 처음에는 그저 연구원으로 자리를 물렀다.\n그러던 중 회사에 첫 퇴사자가 나왔다. 회사는 안 믿어도 사람은 좋아하던 나에겐 꽤 충격적인 일이었다. 당시에는 모두가 어렸고, 모두에게 첫 창업이자 첫 직장이었다. 서로에게 너무나도 쉽게 상처를 줄 수 있었고, 그렇게 떠나갔다.\n나는 이를 기점으로 최소한 내가 뽑은 사람들은 이런 일이 없었으면 하는 마음이 생겼다.\n나는 연구팀의 운영에 다시 관심을 가지기 시작했고, 나라는 필터를 통해 우리 팀원들이 상처받지 않았으면 했다. 강한 피드백이 온다면 좀 더 돌려서 전달할 수 있는 환경이었음 했고, 모두가 서로를 견제하기보다는 으쌰으쌰 하며 시너지를 낼 수 있었으면 좋겠다고 생각했다.\n이왕 하는 김에 연구자들의 목소리도 전달 할 수 있으면 좋을 것 같았다.\n당시에는 연구를 중단하고 다른 프로젝트로 넘어가는 일이 허다했다. 왜 이 연구를 해야 하는지 설득할 채널도 없었고, 연구 방향이 사업과 정렬되어 있지 않아 주제를 트는 경우도 다반사였다.\n연구자는 연구에 애정을 붙이기 어려운 환경이었고, 동력이 떨어진 후에는 이전만큼 열심히 하지 않았다.\n나는 다시 대표님을 찾아가 연구팀장 자리를 제안했다. 기술 대표님이 총괄하던 R\u0026amp;D에서 연구팀을 분리했고, 주간 회의에도 참여하여 연구자 대표의 입장에서 왜 이 연구를 해야 하고, 앞으로의 사업 방향성에 맞추기 위해 이런 주제나 연구가 필요하다고 이야기하기 시작했다.\n팀이 생기니 할 일이 많아졌다.\n보다 본격적인 연구 활동을 위해 연구 프로세스를 정립하기 시작했고, 연구 기간에 대한 정량화를 진행했다.\n굉장히 막막한 일이었다. 주변 대학원생 형들은 연구 프로세스라는 것이 있냐고 오히려 반문해왔다. 대학원은 이를 논문 쓰기라는 과목에서 가르치고는 있었지만, 프로젝트 단위의 기간이나 리소스 사용량을 정량화하는 정도는 아니었다.\n결국 4월에 진행한 다국어 연구를 기반으로 하나둘 기준을 잡아갔다. 한 번의 연구 시도를 몇 개의 실험으로 잡고, 대략 몇 개의 시도 정도에 얼마만큼의 성과 가능성이 있는지 기록했다.\n실제로 주간 회의에서의 연구 공유는 이 포맷을 통해 이뤄졌고, 여전히 꽤 유의미하게 들어맞고 있어 신기하다.\n정량화가 끝나니 본격적인 매니징이 시작되었다.\n내 연구만을 보던 나는 처음으로 타인의 연구를 보고 공유하기 시작했다. 원활한 소통을 위해 연구 포맷을 맞추고, 연구 방향성과 방식에 대한 피드백을 진행하기도 했다.\n처음 하는 일이다 보니 굉장히 많은 리소스를 잡아 먹었다. 내 연구를 못할 정도는 아니었지만, 이전만큼 집중하지 못하기도 했다. 그뿐만 아니라 다른 사람의 연구 성과도 내가 책임을 지게 되니 어깨는 무거워져 갔다.\n이후 매니징의 부담감은 10월 비전팀 신설과 함께 굴러 나가기 시작했고, 결국 번아웃으로 이어졌다.\n5월 오마카세\n6월 훈련소 입소가 확정이 나고, 5월 코로나로 못 보던 사람들을 만나기 시작했다. 그 중엔 옥찬호 형도 있었는데, 꽤 오랜만에 만나 스시 오마카세에 가게 되었다.\n오마카세를 자주 갈 만큼 잘 먹고 다니는 편은 아니었다 보니 먹으러 가는 길 자체가 설렜던 것 같다.\n21.05.22.스시 스미레\n평소에도 회나 초밥류를 굉장히 좋아하는 편이었기에 만족도는 하늘을 찔렀다. 나는 특히 청어나 고등어를 좋아하는 편인데, 자칫 비릴 수 있는 생선이지만 산미와 함께 깔끔히 잘 표현해 더욱 맘에 들었다.\n참치도 굉장히 맛있었고, 성게알의 크리미함은 말할 필요도 없다.\n5월엔 특히 매니징에 대한 고민이 많았던 시기라 찬호형의 고민 상담과 맛있는 스시는 훈련소 가기 전 체증을 씻어 내리는 것만 같았다.\n훈련소에 다녀온 7월에 한 번 더 오마카세에 들리기로 하며 현실로 돌아갔다.\n21.07.11.스시 사토시\n7월엔 사토시에 들렀다. 여기는 처음에 받은 오징어 회부터 굉장한 이목을 끌었다. 해조류와 미소가 올라가 있었는데, 산뜻하면서도 미소의 고소함과 오징어의 식감이 잘 어우러져 있었다.\n아귀 간도 이날 처음 먹어봤는데, 성게알과는 또 다른 크리미함과 고소함이 만족도를 최상으로 끌어올렸다.\n청어, 고등어 회는 물론 솥밥까지 뭐 하나 놓칠 것이 없었다.\n돈 많이 벌어서 세상 맛있는건 다 먹고 살아야겠다고 생각했다.\n6월 훈련소\n머리를 밀고 훈련소에 다녀왔다.\n2월부터 산업기능요원으로 일하면서 한 번은 다녀와야 했다. 우리 회사는 일찍 갔다 오는 분위기였고, 나는 자리가 남는 가장 빠른 일정으로 6월에 다녀왔다.\n당시 훈련소는 코로나 이슈가 산재해 있었다. 4월에 다녀온 팀원은 2주간 샤워는커녕 양치질도 마음대로 못 했고, 손도 못 씻게 해 물티슈와 손 세정제 이후 식사를 했다고 했다.\n다행히 5월에 훈련소 배식과 함께 이 문제가 사회 문제로 대두되었고, 그래도 6월은 다르지 않겠냐며 걱정 아닌 걱정을 했던 것 같다.\n6월의 훈련소는 다행히 하루 한 번 샤워를 시켜줬고, 화장실은 자유, 하루 2회 세면과 양치질을 할 시간도 줬다.\n달라지지 않은 것은 10일 격리 기간 동안 아무것도 시키지 않는다는 것이다. 동기들은 둘째 날부터 말을 트고 친해지기 시작했고, 숫자 야구, 마피아 게임, 오목 별별 것을 다 하며 시간을 보낸 것 같다.\n10일이 지난 시점부터 매일같이 훈련이 시작되었다. 초여름인 만큼 기온은 높아져만 갔고, 구름 한 점 없는 운동장을 기어 다녔다.\n첫 10일은 시간이 안 갔는데, 이후 10일은 훈련만 하고 오면 피곤해 잠만 자기를 반복했다.\n3주가 지나고 느낀 점은 훈련보다는 인간관계가 피곤했던 것 같다. 정말 밖에서는 못 봤던 다양한 사람을 만났고, 많은 사회 현상을 이해할 수 있었다.\n한 번은 가도 두 번은 못 간다.\n9월 혼자 부산 여행\n나는 달을 주기로 텐션이 올라갔다 떨어지기를 반복했다. 월말이 되면 월간 목표 설립과 회고 과정에서 텐션이 떨어졌고, 중순이 되면 실험 결과에 대한 희망에 부풀어 있었다.\n이는 감정적으로 굉장히 피곤했고, 달에 한 번 정도 리프레시를 위한 여행을 다녔다.\n9월은 처음으로 혼자 여행을 기획해 다녀오기로 했다. 나는 바다를 그냥 멍하니 보기만 해도 좋아 대부분 바닷가로 여행을 다녔고, 혼자 가는 만큼 부담 없이 자주 가본 부산을 다녀오기로 했다.\n21.10.01.해목\n비행기를 타고 도착해 첫날 점심은 해운대 해목에서 장어덮밥을 먹었다. 운이 좋게 브레이크 타임 15분 전에 도착했고, 예전 그 맛 그대로의 덮밥에 만족스러운 한 끼를 가졌다.\n21.10.01.신라 호텔\n호텔은 오션뷰가 있는 신라 호텔로 예약했다. 점심을 먹고 들어선 호텔에 누워 저녁을 고민했다.\n원래는 보리문디라는 이자카야에서 회와 술을 마시는 게 목표였는데, 아쉽게도 당일 예약이 되지 않아 이자카야 나카요시라는 곳에서 모둠회를 시켜 먹었다.\n21.10.01.나카요시\n급하게 찾았지만, 만족도는 굉장히 높았다. 회 종류도 엄청 많았고, 굉장히 신선했다. 부산에 왔으니 대선 소주를 먹어야 한다며 한 병 놓고 혼자서 잘 먹은 것 같다.\n당시에는 행복에 대한 고민이 많았다.\n매니징을 시작하면서 연구에 집중할 수 없는 환경이 계속됐고, 매니저와 연구원 사이 R\u0026amp;R의 모호함, 더 이상 재미를 찾기 힘든 업무 환경에 이젠 퇴근 후에 취미를 찾자, 나는 무엇을 좋아할까 고민하고 있었다.\n그렇게 기획한 여행이었고, 그냥 간단히 파도 소리가 좋아서 부산으로 향했다.\n21.10.01.해운대\n해운대는 그런 배경에서 너무나도 만족스러운 공간이었다. 업무에서 멀어지고 자신에 집중할 수 있는 시간이었다.\n10월 비전팀 신설과 신입 사원 채용이 확정된 상황에서, 더 많은 매니징 리소스를 요구할 것이고, 연구원으로의 나는 잠시 멈출 것이란걸 알았기에 마지막 위안이라 생각하고 잠이 들었던 것 같다.\n21.10.02.광안리 키쉬미뇽, 톤쇼우\n둘째 날은 광안리를 찾았다. 키쉬미뇽에서 커피도 마시고, 톤쇼우에서 돈카츠도 먹었다. 후회하지 않을 만큼 보자고 해서 2시간 가까이 바다만 걸어 다닌 것 같다.\n많이 여행 다녔지만, 9월 말의 여행을 잊을 수 없다.\n10월 라로 - 첫 주니어 온보딩\n회사에 동영상 합성에 대한 니즈가 지속되면서 비전팀 신설을 고려하고 있었다. 그에 따라 음성, 영상 상관 없이 주니어 딥러닝 연구원을 채용하기로 했고, 9월에 산업기능요원 채용을 진행했다.\n그렇게 채용 인원이 확정된 후, 아쉽지만도 모두 비전팀을 희망하여 비전팀장 채용, 비전팀 임시 운영체계 확립, 주니어 온보딩이라는 막대한 매니징 리소스를 감당하게 되었다.\n그중 가장 부담으로 다가온 것은 주니어 온보딩이었다. 당시에는 내가 음성팀장으로 남고, 비전팀장을 따로 뽑는 분위기였기에, 비전팀장 채용은 인사팀장님이 도와주실 것이고, 임시 운영은 음성 연구팀 하던 데로 하면 됐다.\n이전까지는 경력직을 뽑기도 했고, 온보딩 없이 알아서 하는 분위기가 컸기에, 온보딩에 대한 필요성이나 교육 계획이 전혀 없는 상황이었다.\n급하게 딥러닝 연구원으로 있는 다른 친구들에게 연락을 돌렸다. 어떤 온보딩이 이뤄지고 있는지 레퍼런스가 필요했다.\n여러 이야기를 참고하여 논문 리뷰 기간, 토이 프로젝트 기간, 실제 배포 기간의 총 3개 정도의 경험을 만드는 것을 목표로 했다.\n논문 리뷰는 하루에 토픽을 하나 정하고, 논문을 골라 리뷰한 후 공유하는 방식이었다. 반응은 굉장히 좋았다. 이른 시간 안에 여러 토픽을 훑고, 학계의 전반적인 흐름을 공유한다는 것에 공감받을 수 있었다.\n문제는 토이 프로젝트였다. 현재 회사는 통합 음성 연구 개발 환경을 구축해서 활용 중인데, 주니어 온보딩 프로젝트로 비전 연구 개발 환경을 구축하자고 했다가 난이도 조절 실패로 많은 원망을 들었다.\n그래도 주니어분들이 적극적으로 도와주셔서 프로젝트는 1차적으로 마무리 지을 수 있었고, 현재도 이를 잘 활용하고 있다.\n온보딩이 끝난 후, 실제 연구부터 배포에 투입되어 현재도 잘 업무를 수행해 주시고 있다. 개인적으로 온보딩은 난이도 조절을 제외하면 성공적이었던 것 같다. 주니어를 채용하여 1달에 업무 투입까지 올 수 있었던건 개개인 모두의 노력과 나름의 온보딩 프로세스 덕이 아니었나 싶다.\n라로 - 비전팀 신설\n비전팀 온보딩의 1달 동안 비전 연구팀장을 채용하지 못했다. 비전 연구팀은 좌초될 것 같았고, 또다시 주니어들이 바닥에 나앉을 것 같았다.\n오랜 고민이 필요했다. 스피치팀 운영을 넘어 비전팀까지 내가 매니징할 수 있을지 확신이 들지 않았고, 연구에 손을 떼야 하는 상황이 올 것만 같았다.\n하지만 처음 연구팀장을 했던 이유가 생각이 났고, 결국 단일 연구팀을 운영하기로 했다. 나는 얼떨결에 7명의 팀원이 생겼고, 이젠 거의 PM에 가까운 R\u0026amp;R을 가지고 있다.\n비전팀 운영 초기에는 스트레스를 굉장히 많이 받았다.\n내가 전문으로 하지 않는 분야의 매니징을 해야 했고, 최대한 따라가기 위해서는 시간을 쪼개 영상 논문을 리뷰해야 했다. 피로감은 쌓여갔고, 결국 11월에 번아웃이 찾아왔다.\n그래도 생각보다 주니어부터 미들까지의 모든 팀원이 잘 따라줬다. 실험 계획이나 방향성 공유도 충분히 이뤄졌고, 점점 태스크에 능숙해지는 것이 눈에 보일 정도로 빠르게 성장하고 있다.\n가끔 실험 관리 부족으로 태스크에 지연이 생기거나, 연구 부채가 쌓인 실험을 보여주곤 하지만 이는 해결 가능한 문제로 보고 있다.\n근래에는 오히려 나를 걱정해주는 것 같아 괜히 헛헛해지기도 한다.\n간혹 그런 이야기를 듣는다. 공격적인 피드백은 꼭 필요하고, 이를 수용하지 못하면 무난하게 침몰하는 배가 될 수 있다고 말이다.\n나는 이 말에 반은 수긍한다. 특히 리더 그룹 내에서의 방향성 설정과 정렬은 필수적이고, 모든 판단이 치명적일 수 있기에 피드백을 통해 빠른 수정이 요구될 수 있고, 때론 이 과정이 공격적일 수 있다.\n하지만 반은 수긍하지 못한다. 모든 사람이 해당 피드백을 있는 그대로 수용할 수 있는 것은 아니다. toxic한 개발자의 말투가 오랜 논점이 된 것에는 충분히 그럴만한 이유가 있다. 사람에 따라 공격적이지 않게 피드백하더라도 충분히 받아들일 수 있고, 공격적인 피드백은 단지 빨라 보이는 길일 뿐이다.\n나는 이를 잘 조절 할 수 있는 사람이 되고 싶다. 외부에선 경쟁이 있더라도 내부에선 협업이 있었으면 좋겠다. 목표는 높게 잡되, 중간중간 만족할 수 있는 지점을 만들고 이를 통해 독해지지 않아도 될 동기가 충분했으면 좋겠다.\n물론 이 과정에는 외부의 경쟁을 이길 만큼의 성과가 필요함을 알고 있다. 이는 독해져야만 가능한 것이 아님을, 독해지지 않아도 가능하단 걸 보이고 싶다.\n그게 내가 팀장으로 남고 싶은 모습이다.\n11월 라로 - 이사\n내가 처음 본 라로의 모습은 19년 7월 학교 기숙사에 있던 3인의 창업 동아리였다. 그러다 20년 초 7명 정도의 초기 멤버와 함께 을지로의 공유 사무실로 이사를 왔다.\n직원은 21년을 기점으로 폭발적으로 늘었다. 이제 직원 수는 30명이 넘어갔고, 코로나로 직장 내 인원수 제한에 추가 공유 사무실을 임대해야 했다.\n21.10.25.라이언로켓 사무실\n21년 10월 말 드디어 회사는 공유 사무실을 벗어나, 한층 전체를 임대하는 전용 공간을 얻었다.\n21년 4월을 기점으로 회사에 좋은 감정도 많이 생기고, 적대감도 많이 줄어들다가 사무실까지 생기니 여러 복잡한 감정이 들었다. 4명이었던 회사가 30명이 넘어가고, 기숙사에서 시작하여 전용 공간이 생겼다. 팀원 7명을 책임지는 팀장이 되었고, 연구도 틈틈이 진행하며 기술에도 기여하고 있다.\n내 기여점이 얼마나 될지 모르겠지만, 같이 만들어간다는 것이 마냥 사기꾼의 단어는 아니구나 싶었다. 좋은 경험이든 싫은 경험이든 결국 스타트업이라 할 수 있었던 것 같다.\n맥주 일기\n이사도 오고, 비전팀도 신설되었다. 본격적인 통합 연구팀이 운영되며 매니징에 부담감을 느끼고 있었고, 근래에는 연구 태스크까지 추가되며 과중한 업무에 결국 11월 번아웃이 찾아왔다.\n집에 도착하면 아무것도 할 수 없었고, 그저 자다 깨다 자다 깨면 아침이 밝아 왔다.\n무언가 긴장을 이완할 취미를 찾아보고 싶었다. 7월에는 기타를 쳤었지만, 새로 배운다는 부담감에 2달 정도 치고 잠시 내려두었다.\n배워서 하지 않아도 좋고, 충분히 부담 없이 편하게 할 수 있는 것을 찾아보다가 편의점 맥주가 눈에 들어왔다.\n맥주로 무얼 할까 생각하다가, 맥주를 마시고 일기를 남겨보기로 했다. 맥주에 크게 관심이 있던 것이 아닌지라 맛 표현을 어떻게 해야 할지부터가 난관이었다.\n21.11. 맥주 일기\n20개 정도를 기록하다 보니 몇 가지 표현이 정리되었다. 탄산감이나 청량함이 어떤지, 목 넘김은 어떤지, 향이 추가된 맥주인지, 쓴맛은 어떤지 정도가 있다.\n그리고 내 기호에 대해서도 알게 되었다. 나는 호가든이나 블랑처럼 향이 추가된 벨기에식 맥주나, 파울러나 에딩거처럼 적당한 쓴맛과 곡물 향이 섞인 독일식 밀맥주를 좋아한다.\n실제로 번아웃에 도움이 되었다. 퇴근 후에 업무에 대한 고민 없이 오늘은 어떤 맥주를 마셔볼까 하는 설렘도 도움이 되었고, 내가 뭘 좋아하는지 찾는 과정도 좋았다. 농담 삼아 주류가 가진 이완의 힘도 있었던 것 같다.\n요즘도 종종 마시면 일기를 남기고 있다. 아무래도 주류인 만큼 자주 마시거나 주기적으로 마시는 것 보다는 마실 때마다 남기는 편이다.\n일기는 공개되어 있지만, 따로 링크를 남기지는 않는다.\n12월 크리스마스\n12월 크리스마스를 보냈다. 좋은 사람을 만나 좋은 곳에서 시간을 보내고 왔다.\n추운 날 목도리를 매고, 대학로의 극장을 찾았다.\n21.12.24. 쉬어매드니스\n쉬어매드니스는 참여형 추리극으로 관객이 사건을 보고 투표를 통해 범인을 밝혀나간다. 앞은 조금 지루할 수 있지만, 관객 참여가 시작되면 분위기가 바뀐다. 생각보다 관객 참여도 굉장히 좋았다. 나는 알리바이가 나온 배우님께 잘 들어가시라고 인사했다가 2층 인사남으로 찍히기도 했다.\n호텔은 명동으로 예약했고, 저녁은 매드포갈릭에서 먹었다.\n21.12.24. 칭찬왕 와인\n23일인 이브 전날 회사에서 farewell 파티가 있었는데, 이때 칭찬왕 선발대회의 2등으로 뽑혀 부상으로 샴페인을 받았었다.\n저녁을 먹고 돌아와 마신 와인도 굉장히 만족스러웠다.\n21.12.25. 조식\n아침은 조식을 먹으러 갔다. 코로나 여파로 뷔페식보다는 준비된 요리가 나왔고, 아메리칸 브랙퍼스트라는 이름에 맞게 적당한 식사가 나왔다.\n올해는 감정적으로 굉장히 유동적이었던 만큼, 9월의 여행과 크리스마스의 휴식이 더 달콤했던 것 같다.\n많은 일이 있던 21년도였다. 코로나로 비대면 생활이 이어지면서 20년도, 21년도의 경계가 모호했다고 느꼈다.\n하지만 이렇게 정리해보고 나니 꼭 그렇지만도 않은 것 같다. 나는 20년도와 21년도에 다른 사람이었고, 내년에 또 다른 사람일 것 같다. 무조건 긍정적으로 나아지는 것도 아니고, 후회도 여전히 있을 것이다.\n그렇다고 잘못되었다고 생각하진 않는다.\n내년엔 그저 좀 더 마음 편하게 먹고, 할 수 있는 일을 하며 더 만족하며 살아야겠다.\n","permalink":"https://revsic.github.io/blog/on2021/","tags":["Writing","2021th"],"title":"On 2021"},{"categories":["Bayesian"],"contents":" Variational Diffusion Models, Kingma et al., 2021, arXiv:2107.00630 Keyword: DDPM, Variational Lower Bounds Problem: Unstable noise scheduling, finite step diffusion process. Solution: Continuous-time diffusion process, joint training of noise scheduler. Benefits: Improved theoretical model understanding, faster optimization, better perceptual quality. Contribution: Simplifying model expression with variational lower bounds in terms of SNR. Introduction\n최근 Diffusion 모델은 이미지, 오디오 등 생성 분야에서 높은 perceptual quality를 보인다. [Ho et al., 2020]의 DDPM과 [Kong et al., 2020, Chen et al., 2020]의 DiffWave, WaveGrad의 경우, 일전 포스트에서 다룬 적이 있다. [post]\nVariational Diffusion Models, 이하 VDM에서는 이에 더 나아가 signal-to-noise ratio와 variational lower bounds를 통한 formulation의 단순화, infinite steps를 상정한 process의 유도와 noise scheduler의 joint training 가능성에 관한 이야기를 나눈다.\nDiffusion Models\n생성 모델의 가장 중요한 concept는 dataset과 관측치 $x$가 있을 때, marginal distribution $p(x)$를 추정하는 것이다. Diffusion 모델은 latent variable model로 latent의 hierarchy를 상정하고, variational lower bounds, 이하 VLB를 통해 marginal loglikelihood의 lower-bound를 maximize 하는 학습 방식을 취한다. 이러한 프로세스는 [Nielsen et al., 2020.]의 SurVAE Flows [post]에서 Stochastic transform을 활용한 flow의 일종으로 일반화되기도 한다.\nFigure 2: The directed graphical model considered in this work. (Ho et al., 2020)\n기존까지의 Diffusion 모델은 finite step의 markov chain을 가정하며, 매 transition 마다 noise를 더해가는 방식을 취한다. latent sequence $z_t$가 있다면, t=0 부터 t=1까지의 forward-time diffusion process를 정의할 수 있다.\n$$q(z_t|x) = \\mathcal N(\\alpha_t x, \\sigma_t^2 \\mathrm{I})$$\n이때 $\\alpha_t,\\ \\sigma_t^2: [0, 1] \\to \\mathbb R^+$의 실수 함수는 smooth하여 정의역에서 미분이 유한함을 가정한다. 또한 $\\alpha_t^2/\\sigma_t^2$의 비율이 단조 감소하여, t가 증가함에 따라 noise의 비율이 커지도록 구성한다. 이에 t=0에서 데이터 $x$에 가까울 것이고, t=1에서 gaussian noise에 가까워질 것이다.\n$0\\le s \\lt t \\lt u \\le 1$의 latent $z_s, z_t, z_u$와 joint distribution은 first-order Markov chain으로 가정하여 $q(z_u|z_t, z_s) = q(z_u|z_t)$를 상정한다. 이에 따른 conditional distribution은 다음과 같이 표기할 수 있다.\n$$q(z_t|z_s) = \\mathcal N(\\alpha_{t|s}z_s, \\sigma^2_{t|s}\\mathrm I), \\ \\ \\mathrm{where} \\ \\alpha_{t|s} = \\alpha_t / \\alpha_s \\ \\mathrm{and} \\ \\sigma^2_{t|s} = \\sigma^2_t - \\alpha^2_{t|s}\\sigma^2_s$$\nreverse time process의 경우에는 다음과 같다.\n$$q(z_s|z_t, x) = \\mathcal N(\\mu_Q(z_t, x; s, t), \\sigma^2_{Q, s, t}\\mathrm I) \\ \\ \\mathrm{with} \\ \\sigma^2_{Q, s, t} = \\sigma^2_{t|s}\\sigma^2_s/\\sigma^2_t \\\\ \\mathrm{and} \\ \\ \\mu_Q(z_t, x; s, t) = \\frac{1}{\\alpha_{t|s}}(z_t + \\sigma^2_{t|s}\\nabla_{z_t}\\log q(z_t|x)) = \\frac{\\alpha_{t|s}\\sigma^2_s}{\\sigma_t^2}z_t + \\frac{\\alpha_s\\sigma^2_{t|s}}{\\sigma_t^2}x$$\nReverse time process as Generative model\nDiffusion model은 reverse time process를 근사하는 방식의 생성 모델이며, 위 formulation에서 data 부분을 denoising model $\\hat x_\\theta(z_t, t)$로 대체하게 된다.\n$$p(z_s|z_t) = q(z_s|z_t, x = \\hat x_\\theta(z_t; t)) = \\mathcal N(z_s; \\mu_\\theta(z_t; s, t), \\sigma^2_{Q, s, t}\\mathrm{I})$$\n이에 따라 네트워크는 $\\mu_\\theta(z_t; s, t) \\approx \\mu_Q(z_t, x; s, t)$의 근사를 목표로 하게 된다.\n$$\\mu_\\theta(z_t; s, t) = \\frac{\\alpha_{t|s}\\sigma^2_s}{\\sigma^2_t}z_t + \\frac{\\alpha_s\\sigma^2_{t|s}}{\\sigma^2_t}\\hat x_\\theta(z_t; t) = \\frac{1}{\\alpha_{t|s}}z_t - \\frac{\\sigma^2_{t|s}}{\\alpha_{t|s}\\sigma_t}\\hat\\epsilon_\\theta(z_t; t) = \\frac{1}{\\alpha_{t|s}}z_t + \\frac{\\sigma^2_{t|s}}{\\alpha_{t|s}}s_\\theta(z_t; t)$$\n이는 model의 관점에 따라 3가지의 해석이 가능하다.\n$z_t$의 noised data로부터 원본을 복원하는 denoising model $\\hat x_\\theta(z_t; t)$ $z_t$에 포함된 noise를 추정하는 noise estimation model $\\epsilon_\\theta(z_t; t) = (z_t - \\alpha_t\\hat x_\\theta(z_t; t)) / \\sigma_t$ gradient를 추정하는 score matching model $s_\\theta(z_t; t) = (\\alpha_t \\hat x_\\theta(z_t; t) - z_t)\\sigma^2_t$ 3번의 경우 optimal model이 실제 scores를 추정하여, $s^*(z_t; t) = \\nabla_z\\log q(z_t)$, reverse time process의 최초 formulation과 일치해진다.\nVDM은 DDPM에서 제안한 noise estimation objective를 취할 것이고, 편의상 formulation은 denoising model을 상정할 것이다.\nRelation between prior works\n기존의 Diffusion model은 기본적으로 finite step T를 상정하므로, 위 formulation에서 segment size $\\tau = 1 / T$를 잡고, [0, 1]의 범위를 T개의 segment로 discretize한 형태로 볼 수 있다. 다음은 diffusion 모델에서 상정하는 marginal likelihood이다.\n$$p(x) = \\int_z p(x|z_0)\\left(\\prod^T_{i=1}p(z_{s(i)}|z_{t(i)})\\right)p(z_1) \\\\ \\mathrm{where} \\ \\ s(i) = (i - 1) / T, \\ t(i) = i / T$$\n각각의 diffusion 모델은 $\\alpha_t, \\sigma_t$를 적절히 구성하여 $q(z_1|x) \\approx \\mathcal N(z_1; 0, \\mathrm{I})$의 standard gaussian과 근사히 둔다. 마찬가지로 initial latent와 데이터의 reconstruction을 위해 $\\sigma_0$ 대비 $\\alpha_0$의 크기를 키움으로써 true distribution에 가깝게 근사하도록 구성한다.\nSignal-to-noise ratio\n위의 가정에서 중요한 점은 [$\\sigma_t$ 대비 $\\alpha_t$의 비율]을 적절히 가정함으로써 $p(z_1)$은 standard gaussian에, $p(z_0)$는 data distribution에 근사하고자 한다는 점이다.\n이때 $z_t = \\alpha_t x + \\sigma_t\\epsilon$에서 $\\alpha_t$는 실제 신호의 비, $\\sigma_t$는 noise의 비로, [$\\sigma_t$ 대비 $\\alpha_t$의 비율]은 신호 대 잡음의 비율이라 볼 수 있고, 이를 SNR, signal-to-noise ratio라고 한다.\n$$\\mathrm{SNR}(t) = \\alpha_t^2/\\sigma^2_t$$\n이 중 DDPM에서는 $\\alpha_t = \\sqrt{1 - \\sigma^2_t}$를 상정하여 variance-preserving diffusion process를 가정한다. 일부 모델에서는 $\\alpha_t=1$의 상수로 잡고 $\\sigma_t$를 늘리는 variance-exploding diffusion process를 상정하기도 한다. 이는 SNR(t)로도 재작성될 수 있다.\n$$\\alpha^2_t = \\mathrm{SNR}(t) / (1 + \\mathrm{SNR}(t)), \\ \\ \\sigma^2_t = 1 / (1 + \\mathrm{SNR}(t))$$\n일전의 가정에 따라 diffusion 모델에서 SNR 함수는 단조 감소 함수가 된다. 기존까지 모델에서는 이 SNR 함수가 well-engineered 함수로 가정되었다면, VDM에서는 SNR을 trainable한 component로 가정할 것이다.\nVariational Lower Bounds\nDDPM에서는 VLB를 통해 diffusion process로부터 KL-divergence 기반의 objective를 구성한다. 이때 $\\mathcal L_T(x)$는 diffusion loss이다.\n$$-\\log p(x) \\le D_\\mathrm{KL}(q(z_1|x)||p(z_1)) + \\mathrm E_{q(z_0|x)}[-\\log p(x|z_0)] + \\mathcal L_T(x) \\\\ \\mathcal L_T(x) = \\sum^T_{i=1}\\mathbb E_{q(z_{t(i)}|x)}D_\\mathrm{KL}[q(z_{s(i)}|z_{t(i)}, x)||p(z_{s(i)}|z_{t(i)})]$$\n그리고 이는 DDPM에서 weighted noise estimation loss의 형태로 reparametrized된다.\n$$\\mathcal L_{\\mathrm{simple}}(x) = \\mathbb E_{\\epsilon\\sim p(\\epsilon)}[||\\epsilon - \\hat\\epsilon_\\theta(\\alpha_t x + \\sigma_t \\epsilon; t)||_2^2]$$\nVDM에서는 denoising model을 formulation으로 활용한다.\n$$\\mathcal L_T(x) = \\frac{1}{2}\\mathbb E_{\\epsilon \\sim \\mathcal N(0, \\mathrm{I}), i \\sim U\\{1, T\\}}\\left[\\frac{(\\mathrm{SNR}(s) - \\mathrm{SNR}(t))}{1/T}||x - \\hat x_\\theta(z_t; t)||^2_2\\right]$$\nVariational Diffusion Models\nVDM의 contribution은 다음과 같다.\n$T \\to \\infty$를 상정하여 continuous-time loss를 유도한다. noise scheduler에 continuous-time loss가 invariant 함을 보인다. noise scheduler를 학습 가능한 네트워크로 구성하고, objective를 제안한다. Fourier feature를 통해 finer-scale에서의 perceptual quality를 높였다. 아래에서는 이에 대해 하나씩 풀어본다.\nWhy continuous time\n이전 실험들에서는 diffusion steps가 많아질수록 학습이 안정화되고 perceptual quality가 높아짐을 실험적으로 확인할 수 있었다.\n$$\\mathcal L_{2T}(x) - \\mathcal L_T(x) = \\mathbb E_{t, \\epsilon}\\left[c(t\u0026rsquo;)(||x - \\hat x _\\theta(z _{t\u0026rsquo;}; t\u0026rsquo;)||^2_2 - ||x - \\hat x _\\theta(z_t; t)||^2_2) \\right] \\\\ \\mathrm{where} \\ \\ t\u0026rsquo; = t - \\frac{1}{2T}, \\ \\ c(t) = \\mathrm{SNR}(t\u0026rsquo; - \\frac{1}{2T}) - \\mathrm{SNR}(t\u0026rsquo;)$$\ndiffusion step이 다른 두 loss를 빼게 되면, $t\u0026rsquo; \u0026lt; t$이므로 $z_{t\u0026rsquo;}$이 상대적으로 원본에 가까운 latent이고, $\\hat x_\\theta$가 충분히 학습된 모델이라면 원본 복원이 쉬운 latent 쪽의 loss가 작게 구성될 것이다.\n따라서 거의 항상 $\\mathcal L_{2T}(x) - \\mathcal L_T(x) \u0026lt; 0$을 상정할 수 있고, diffusion steps가 늘어날수록 VLB를 통해 더 높은 likelihood lower-bounds를 추정할 수 있게 된다.\nVDM에서는 $T\\to\\infty$의 극한을 취해 VLB의 하한을 높이고자 한다. 이렇게 되면 segment size $\\tau = 1 / T$는 0에 가까워지고, continuous time에 대한 loss로 취급할 수 있다. 그리고 실제로 이러한 concept가 perceptual quality의 향상에도 영향을 끼쳤음을 보였다.\nContinuous-time loss\n$T\\to\\infty$와 $\\tau = 1 / T\\to 0$를 상정한다면, $\\mathcal L_\\infty(x)$는 다음으로 유도할 수 있다.\n$$\\begin{align*} \\lim_{T\\to\\infty}\\mathcal L_T(x) \u0026amp;= \\lim_{T\\to\\infty}\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, \\mathrm{I}), i\\sim U\\{1, T\\}}\\left[\\frac{(\\mathrm{SNR}(s) - \\mathrm{SNR}(t))}{1/T}||(x - \\hat x_\\theta(z_t; t)||^2_2\\right]\\\\ \u0026amp;= \\lim_{T\\to\\infty}\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, \\mathrm{I}), i\\sim U\\{1, T\\}}\\left[\\frac{\\mathrm{SNR}(t - \\tau) - \\mathrm{SNR}(t)}{\\tau}||x - \\hat x_\\theta(z_t; t)||^2_2\\right] \\\\ \u0026amp;= -\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, \\mathrm{I}), t\\sim\\mathcal U(0, 1)}\\left[\\frac{d\\mathrm{SNR}(t)}{dt}||x - \\hat x_\\theta(z_t; t)||^2_2\\right] \\end{align*}$$\nepsilon estimation의 관점에서는 다음과 같이 쓸 수 있다.\n$$\\mathcal L_\\infty(x) = -\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, \\mathrm{I}), t\\sim\\mathcal U(0, 1)}\\left[\\log\\mathrm{SNR\u0026rsquo;}(t)||\\epsilon - \\hat\\epsilon_\\theta(z_t; t)||^2_2\\right]$$\n이 때 $\\log\\mathrm{SNR}\u0026rsquo;(t) = d\\log[\\mathrm{SNR}(t)]/dt = \\mathrm{SNR}\u0026rsquo;(t)/\\mathrm{SNR}(t)$이다.\nInvariance to the noise schedule in continuous time\nVDM은 continuous-time loss의 변수 t를 $v = \\mathrm{SNR}(t)$의 snr변수로 reparametrize하여 관찰한다. SNR이 단조 감수이므로 $dv = \\mathrm{SNR}\u0026rsquo;(t)dt$에 따라 치환하면 다음과 같다.\n$$\\begin{align*} \\mathcal L_\\infty(x) \u0026amp;= -\\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, \\mathrm{I}), t\\sim\\mathcal U(0, 1)}\\left[\\mathrm{SNR}\u0026rsquo;(t)||x - \\hat x_\\theta(z_t; t)||^2_2\\right] \\\\ \u0026amp;= -\\frac{1}{2}\\mathbb E_{\\epsilon \\sim\\mathcal N(0, \\mathrm{I})}\\int_0^1 \\mathrm{SNR}\u0026rsquo;(t)||x - \\hat x_\\theta(z_t; t)||^2_2dt \\\\ \u0026amp;= \\frac{1}{2}\\mathbb E_{\\epsilon\\sim\\mathcal N(0, \\mathrm{I})}\\int_\\mathrm{SNR_{min}}^\\mathrm{SNR_{max}}||x - \\hat x_\\theta(z_v, v)||_2^2dv \\\\ \\mathrm{where} \\ \u0026amp;\\mathrm{SNR _{min}} = \\mathrm{SNR}(1), \\mathrm{SNR _{max}} = \\mathrm{SNR}(0) \\\\ \u0026amp;z_v = z _{\\mathrm{SNR}^{-1}(v)}, \\hat x _\\theta(z, v) = \\hat x _\\theta(z, \\mathrm{SNR}^{-1}(v)) \\end{align*} $$\n이 식에서 중요한 점은 $\\mathcal L_\\infty$를 결정하는 요소가 양단점인 $\\mathrm{SNR_{min}}$과 $\\mathrm{SNR_{max}}$ 뿐이란 것이고, SNR 함수가 어떻게 생겼는지와는 무관하다는 점이다. 즉 SNR의 양단이 같은 두 continuous-time loss는 equivalence임을 알 수 있다.\n또한 $v = \\alpha^2_v / \\sigma^2_v$에 따라 $\\sigma_v = \\alpha_v / \\sqrt v$로 정리할 수 있고, $z_v = \\alpha_v x + \\sigma_v \\epsilon = \\alpha_v(x + \\epsilon / \\sqrt v)$로 고정된 v에 대해 $\\alpha$와 $\\sigma$의 변인을 축약할 수 있다. 이는 서로 다른 variance policy에 대해 rescale 관계로 표현할 수 있다는 점이고, $z^A_v = (\\alpha^A_v / \\alpha^B_v)z^B_v$, 이에 따라 $\\hat x^B_\\theta(z^B_v, v) = \\hat x^A_\\theta((\\alpha^A_v/\\alpha^B_v)z^B_v, v)$의 model equivalence도 구성할 수 있다.\nWeighted continuous-time loss\nDDPM에서는 이를 noise estimation loss의 형태로 바꾸면서 reweighting을 진행했고, 이는 continuous-time loss에서도 적용할 수 있다.\n$$\\mathcal L_\\infty(x, w) = \\frac{1}{2}\\mathbb E_{\\epsilon \\sim \\mathcal N(0, \\mathrm{I})}\\int^\\mathrm{SNR_{max}}_\\mathrm{SNR _{min}} w(v)||x - \\hat x _\\theta(z _v, v)||^2 _2dv$$\nVLB는 아니지만 noisier data를 강조하는 등의 policy를 통해 실제 FID, IS 등 perceptual quality를 측정하는 metric에서 때에 따라 성과를 보이기도 한다.\nMonte-carlo estimation\n하지만 실상 적분을 하는 것은 intractable 하기 때문에 샘플링을 통한 estimation이 필요하다. 이에 VLB objective를 단순화하고, sampling과 batch stats를 활용한 monte-carlo estimation을 시행한다.\n$$\\mathcal L^{MC}_\\infty(x, w, \\gamma) = \\frac{1}{2}\\gamma\u0026rsquo;(t)w(\\gamma(t))||\\epsilon - \\hat\\epsilon _\\theta(z_t; \\gamma(t))||^2_2$$\n이때 $\\gamma$는 noise scheduler로 $\\gamma(t) = -\\log\\mathrm{SNR}(t) = \\log[\\sigma^2_t/\\alpha^2_t]$를 상정하고, $z_t = \\alpha_t x + \\sigma_t\\epsilon$, $\\epsilon \\sim \\mathcal N(0, \\mathrm{I}), t \\sim \\mathcal U(0, 1)$의 샘플링을 진행한다. 여기서는 reweighting 함수는 $w(\\cdot) = 1$의 상수 함수로 가정한다.\n또한 VDM은 보다 효율적인 시간축 샘플링을 위해 최초 시점 $u_0 \\sim \\mathcal U(0, 1)$을 잡고, batch size k에 대해 $t_i = \\mathrm{mod}(u_0 + i/k, 1)$의 선형 보간 방식을 취한다. 이렇게 하는 것이 [0, 1] 범주에서 더 uniform하게 분포한 시간점들을 샘플링 할 수 있고, 실제로 MC의 분산을 줄일 수 있었다고 한다.\nLearning noise scheduler\n기존까지의 모델들이 고정된 SNR 함수를 활용했다면, VDM은 파라미터 $\\eta$를 통해 학습 가능한 SNR 함수 $\\mathrm{SNR}(t) = \\exp(-\\gamma_\\eta(t))$를 상정한다. 이는 SNR 함수가 단조 감소 함수이기 때문에 $\\gamma_\\eta(t) = -\\log\\mathrm{SNR}(t)$로 두어 단조 증가 함수의 꼴로 네트워크를 모델링 하기 위함이다.\n실제로 VDM에서 제안하는 learnable noise scheduler는 다음과 같다.\n# t: [B] l1 = Linear(1, 1)(t) l2 = Linear(1, 1024)(l1) l3 = Linear(1024, 1)(sigmoid(l2)) v = l1 + l3 여기서 projection weight가 모두 양수라면 t가 0에서 1로 증가함에 따라 $\\gamma_\\eta(t) = -\\log\\mathrm{SNR}(t)$도 단조 증가 하는 것이 보장된다.\n하지만 이렇게 학습된 noise scheduler는 실상 양단점을 제외하면 continuous-time loss에 영향을 미치지 않음을 앞서 보였다. 따라서 VDM은 noise scheduler 학습의 목적성을 다른 방향으로 잡는다.\nVDM은 Monte-carlo estimation의 분산을 줄이는 objective를 통해 $\\gamma$를 학습하며, $\\mathbb E[\\mathcal L^{MC} _\\infty(x, w, \\gamma)^2] = \\mathcal L _\\infty(x, w)^2 + \\mathrm{Var}[\\mathcal L^{MC} _\\infty(x, w, \\gamma)]$의 첫 번째 term $\\mathcal L _\\infty(x, w)^2$은 $\\eta$와 무관하므로 loss 제곱을 줄이는 방향으로 학습한다.\n$$\\mathbb E[\\nabla _\\eta \\mathcal L^{MC} _\\infty(x, w, \\gamma _\\eta)^2] = \\nabla _\\eta\\mathrm{Var}[\\mathcal L^{MC} _\\infty(x, w, \\gamma _\\eta)]$$\n이 경우 역전파를 두 번 해야 하는 문제가 있으며, 이를 효율적으로 처리하기 위해 $\\gamma$ 함수 이전에 역전파 함수를 hooking하는 방식을 제안한다.\n$$\\frac{d}{d\\eta}[\\mathcal L^{MC}_\\infty(x, \\gamma _\\eta)^2]=2\\frac{d}{d\\mathrm{SNR}}[\\mathcal L^{MC} _\\infty(x, \\mathrm{SNR})]\\odot\\mathcal L^{MC} _\\infty(x, \\mathrm{SNR})\\frac{d}{d\\eta}[\\mathrm{SNR}(\\eta)]$$\n앞선 식에서 $2\\mathcal L^{MC} _\\infty(x, \\mathrm{SNR})$를 제외하면 기존의 역전파 방식과 일치하므로, hooking을 통해 gradient에 loss를 곱하는 방식이다. 이 경우 불필요한 연산을 줄일 수 있다.\n이런 식으로 분산을 조절하는 방식은 실제로 학습 속도를 높이는데 도움을 주었다고 한다.\nFourier features\nVDM에서는 finer detail을 위해 fourier feature를 denoising model의 입력에 concat하여 넘겼다. 실제로 이 접근은 high frequency detail에 도움을 주었다고 한다. $n\\in\\{7, 8\\}$일 때 다음을 상정한다.\n$$f^n_{i, j, k} = \\sin(z_{i, j, k}2^n\\pi), \\ \\ g^n_{i, j, k} = \\cos(z_{i, j, k}2^n\\pi)$$\nExperiments\nTable 1: Summary of our findings for density modeling tasks. (Kingma et al., 2021)\n다음은 T에 따른 BPD이다. 실제로 train과 eval의 샘플링 수 모두에서 T가 증가할 수록 BPD가 줄어드는 것을 확인할 수 있었다.\nFigure 4: Our learned continuous-time variance-minimizing noise schedule SNR(t) for CIFAR-10, (Kingma et al., 2021)\nDiscussion\nContribution과 글의 전개가 무척 깔끔했다. Diffusion의 소개와 formulation 방식에 따른 해석 가능성을 정리하고, 품질 향상을 위한 지점으로 유한한 timestep을 상정, continuous-time으로 확장과 MCMC의 안정성 확보를 위한 learnable noise scheduler까지 문단 문단이 꽉 찬 느낌이었다.\nVDM을 활용해 DiffWave를 개선한 코드를 개인적으로 작성해 보았다. 아직 결과가 나오기엔 시간이 필요하지만, 좋은 결과를 기대하고 있다.\nrevsic/jax-variational-diffwave: Jax/Flax implementaton of Variational-DiffWave. Reference\n[1] Ho, J., Jain, A. and Abbeel, P. Denoising Diffusion Probabilistic Models. In NeurIPS 2020. [2] Kong, Z., Ping, W., Zhao, K. and Catanzaro, B. DiffWave: A Versatile Diffusion Model for Audio Synthesis. In ICLR 2021. [3] Chen, N., Zhang, Y., Zen, H., Weiss, R. J., Norouzi, M. and Chan, W. WaveGrad: Estimating Gradients for Waveform Generation. [4] Kingma, D. P., Salimans, T., Poole, B. and Ho, J. Variational Diffusion Models.\n","permalink":"https://revsic.github.io/blog/vdm/","tags":["Machine Learning","Deep Learning","Generative","Diffusion","DDPM","Variational Lower Bounds","VLB","Variational Diffusion Models"],"title":"Variational Diffusion Models"},{"categories":["Bayesian"],"contents":" SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows, Nielsen et al. In NeuRIPS 2020, arXiv. Keyword: Bayesian, Normalizing Flow, SurVAE Flows Problem: Specialized network architectures of normalizing flows Solution: Unifying several probabilistic models with surjections Benefits: Modulized, composable framework for probabilistic models Weakness or Future work: - Series: Normalizing flow\nNormalizing flow, Real NVP [link] Glow, Flow++ [link] ANF, VFlow [link] i-ResNet, CIF [link] SurVAE Flows [this] Normalizing Flows\nNormalizing flow, 이하 NF는 differentiable bijective를 활용하여 expressive한 확률 모델을 구성하는데 기여해 왔다. NF는 1) forward 2) inverse 3) likelihood의 크게 3가지 interface를 통해 composable 하고 modular 한 형태로 구성되며, Rezende and Mohamed, 2015[1]를 시작으로 꾸준히 발전해 왔다.\n이 과정에서 NF의 여러 가지 문제가 발견되었고, 그중 대표적으로 dimensionality problem은 ANF[5], VFlow[6]에서 augmentation을 도입하며 해결, misspecified prior의 문제는 CIF[7]에서 continuous index를 도입함으로써 해결하고자 했다.\n그 외의 확률 모델로는 VAE와 GAN 정도가 대표적이며, VAE의 경우에는 ANF[5]에서 일반화하고자 하는 시도가 있었다.\n이번에 소개하고자 하는 논문은 여러 확률 모델을 unifying 할 수 있는 composable하고 modular한 framework를 구성할 수 있는가에 대한 물음에서 시작한다. 그를 위해 저자들은 SurVAE Flows라는 framework를 제안하며, 여러 확률 모델을 unifying 하면서도 max pooling, absolute, sorting, stochastic permutation 등을 NF에 접목할 수 있게 구성하여, 더욱 expressive한 확률 모델 구성이 가능함을 보일 것이다.\nPreliminaries\n$x\\in\\mathcal X, \\ z \\in \\mathcal Z$의 두 개 변수와 각각의 prior distribution $x \\sim p(x), \\ z \\sim p(z)$을 상정한다. 이때 deterministic mapping $f: \\mathcal Z \\to \\mathcal X$가 bijective이기 위해서는 surjective하고 injective 해야 한다.\nsurjective: $\\forall x \\in \\mathcal X, \\exists z \\in \\mathcal Z: \\ x = f(z)$ injective: $\\forall z_1, z_2 \\in \\mathcal Z, \\ f(z_1) = f(z_2) \\Rightarrow z_1 = z_2$ 만약 mapping이 deterministic 하지 않다면, stochastic mapping이라 하고 $x \\sim p(x|z)$로 표기한다.\nNF는 기본적으로 bijective를 통한 change of variables $p(x) = p(z)|\\det \\nabla_x f^{-1}(x)|$를 근간으로 한다. VAE의 경우에는 stochastic transform을 차용하여 generative process $p(x) = p(z)p(x|z)$를 구성하고, variational posterior $z\\sim q(z|x)$를 통해 likelihood의 lower bound $\\mathbb E_{z\\sim q(z|x)}\\log [p(x, z)/q(z|x)]$ 를 추정한다.\nUnifying Stochastic Transform\n기본적으로 NF는 1) forward transform $f: \\mathcal Z \\to \\mathcal X$ 2) inverse transform $f^{-1}: \\mathcal X \\to \\mathcal Z$ 3) likelihood의 3가지 interface로 구성한다. SurVAE Flows[8]에서는 stochastic transform에 대해서도 이에 맞게 구성할 수 있도록 framework를 확장한다.\nForward Transform conditional distribution $x\\sim p(x|z)$를 상정한다. deterministic mapping에 대해서는 dirac delta를 통해 구성한다. $p(x|z) = \\delta(x - f(z))$\nInverse Transform 마찬가지로 deterministic mapping에 대해서는 $p(z|x) = \\delta(z - f^{-1}(x))$를 상정한다. 반면에 stochastic mapping에 대해서는 $p(z|x)$의 연산이 intractable 하므로 variational $q(z|x)$를 상정하고 lower bound를 추정하는 식으로 접근한다.\nLikelihood deterministic map과 stochastic map의 likelihood 구성은 다음과 같다.\n$$\\log p(x) = \\log p(z) + \\log|\\det J|, \\ \\ z = f^{-1}(x)\\\\ \\log p(x) = \\log p(z) + \\log \\frac{p(x|z)}{q(z|x)} + \\mathbb D_\\mathrm{KL}[q(z|x)||p(z|x)], \\ \\ z \\sim q(z|x)$$\n이때 $|\\det J|$는 $|\\det \\nabla_x f^{-1}(x)|$이다.\n여기서 중요한 것은 framework를 확장하는 과정에서 deterministic transform의 분포를 Dirac delta $\\delta(\\cdot)$를 통해 구성하였고, 이를 기반으로 한 ELBO가 NF의 change of variables formulation과 같아진다는 것이다.\n$$ p(x|z) = \\delta(x - f(z)), \\ \\ p(z|x) = \\delta(z - f^{-1}(x))$$ $$\\begin{align*} \\Rightarrow \\log p(x) \u0026amp;= \\log p(z) + \\log|\\det J| \\\\ \u0026amp;= \\log p(z) + \\log\\frac{p(x|z)}{q(z|x)}\\\\ \u0026amp;\\mathrm{where} \\ \\ q(z|x) = p(z|x) \\end{align*}$$\n정리하면 Change of variables의 전개는 ELBO에서 deriving 할 수 있고, VAE와 NF는 동일한 formulation을 통해 구성되는 하나의 확률 모형이었단 것이다. 이에 따라 둘은 forward와 inverse를 모두 stochastic transform으로 상정한 경우(VAE)와 모두 deterministic transform으로 상정한 경우(NF)의 mapping 방식에 따른 special case가 된다.\nVAE와 NF가 precise 한 상관관계를 가진다는 것이 증명된 지점이다.\nTheorem. Change of variables formula는 ELBO에서 deriving 가능하다.\npf. Dirac $\\delta$-function을 통해 다음을 얻을 수 있다.\n$$\\int\\delta(g(z))f(g(z))\\left|\\det\\frac{\\partial g(z)}{\\partial z}\\right|dz = \\int\\delta(u)f(u)du, \\ \\ u = g(z) \\tag{1}$$ $$\\exists! z_0: g(z_0) = 0 \\Rightarrow \\delta(g(z)) = \\left|\\det\\frac{\\partial g(z)}{\\partial z}\\right|_{z=z_0}^{-1}\\delta(z-z_0) \\tag{2}$$\n(필자는 Eqn.1 좌항의 determinant term을 우항으로 옮기고, delta 함수가 trigging 되는 시점인 $z_0$의 determinant 값이 실체화되는 방식으로 이해함, dirac delta의 적분은 정의상 1이므로)\n위 유도는 g가 미분가능하고, f는 compact support를 가지며, root는 unique하고, jacobian은 가역 행렬임을 가정한다.\n$f: \\mathcal Z \\to \\mathcal X$가 $f$와 $f^{-1}$ 모두에서 미분가능일 때 (i.e. diffeomorphism), deterministic conditionals에 대해 다음의 유도가 가능하다.\n$$p(x|z) = \\delta(x - f(z)), \\ \\ p(z|x) = \\delta(z - f^{-1}(x)) \\tag{3}$$ $$p(x|z) = \\delta(z - f^{-1}(x))|\\det J| = p(z|x)|\\det J| \\tag{4}$$\n이때 jacobian은 $J^{-1} = \\left.\\partial f(z)/\\partial z\\right|_{z=f^{-1}(x)}$를 상정한다.\n또한 deterministic transform에 따른 true posterior $p(z|x)$를 알고 있으므로, $q(z|x) = p(z|x) = \\delta(z - f^{-1}(x))$에서 ELBO를 deriving 하면 다음과 같다.\n$$\\begin{align*}\\log p(x) \u0026amp;= \\mathbb E_{z\\sim q(z|x)}\\left[\\log p(z) + \\log\\frac{p(x|z)}{q(z|x)} + \\log\\frac{q(z|x)}{p(z|x)}\\right] \\\\ \u0026amp;= \\log p(z) + \\log|\\det J|\\end{align*}$$\n이 과정에서 두 likelihood의 tractable한 contribution은 $\\log[p(x|z)/q(z|x)] = \\log|\\det J|$에 따라 같아지고, variational posterior와 true posterior가 동치이므로 KL-term $\\log[q(z|x)/p(z|x)] = 0$으로 소거된다.\nLikelihood Contribution and Bound Gap\nSurVAE Flows[8]는 이렇게 unifying 된 framework의 likelihood 연산을 위해 전체 term을 likelihood contribution $\\mathcal V(x, z)$과 boundary gap $\\mathcal E(x, z)$으로 분리한다. expectation은 single monte carlo sample에 대한 evaluation으로 대체한다.\n$$\\log p(x) \\simeq \\log p(z) + \\mathcal V(x, z) + \\mathcal E(x, z), \\ \\ z \\sim q(z|x)$$\nlikelihood contribution은 전체 likelihood term 중에서 연산할 수 있고, 실제 gradient 기반의 optimization에 활용되는 부분이다. change of variables term $\\log|\\det J|$나 variational lower bound $\\log[p(x|z)/q(z|x)]$가 이에 해당한다.\nboundary gap은 lower bound estimation 과정에서 발생하는 true posterior와의 gap을 상정한다. VAE의 경우에는 $\\log[q(z|x)/p(z|x)]$의 variational gap이 존재하고, NF의 경우에는 true posterior를 그대로 사용 가능하므로 0으로 소거된다.\n이후 multiple layers에 대해서는 NF에서 compositional structure에 따라 각각의 log-determinant를 더해갔던 것처럼, stochastic map에 대해서도 동일하게 likelihood contribution을 더해가는 방식으로 일반화 가능할 것이다.\nAlgorithm 1: log-likelihood(x) (Nielsen et al., 2020)\nSurVAE Flows\n지금까지 framework 확장 과정에서 stochastic transform과 deterministic transform의 likelihood 연산 과정을 통합하고, 그를 위한 알고리즘을 구성해 보았다. 이 과정에서 NF는 forward, inverse가 모두 deterministic, VAE는 모두 stochastic 한 special case라는 것 또한 확인했다.\n그렇다면 forward는 deterministic, inverse는 stochastic 하거나, inverse는 deterministic, forward는 stochastic한 케이스도 존재 가능한 것인가에 대한 의문이 있을 수 있다.\n그리고 만약 위와 같은 구성이 가능하다면 bijective의 exact likelihood evaluation과 stochastic map의 dimension alternation 같은 이점들을 수집할 수 있는가에 대한 기대도 있을 것이다.\nSurVAE Flows[8]의 저자들은 surjective transform을 통해 bijective와 stochastic map 사이의 격차를 메꿔보고자 했다.\n우선 surjective이고 non-injective인 deterministic transform을 정의한다. 이는 이하 surjections 혹은 surjective transform으로 일컬을 것이다. 이렇게 surjections를 정의하게 되면 다수의 입력이 하나의 출력으로 매핑될 수 있고, 이 과정에서 inversion이 보장되지 않는다. 이에 저자들은 다음과 같은 interface를 구성한다.\nForward Transform bijective와 같이 dirac-delta를 통한 deterministic forward $p(x|z) = \\delta(x - f(z))$를 상정한다.\nInverse Transform bijective와 달리 surjective $f: \\mathcal Z \\to \\mathcal X$는 invertible 하지 않다. 이는 right inverse만 존재하고, left inverse는 존재하지 않기 때문이다. (i.e. $\\exists g: \\mathcal X \\to \\mathcal Z: \\ f\\circ g(x) = x \\ \\ \\forall x\\in \\mathcal X$)\nSurVAE Flows는 이에 stochastic right inverse를 inverse 대신 차용한다. $q(z|x)$의 stochastic posterior를 상정하고, $x$의 preimage 위에 support를 가지게 한다.\n이렇게 되면 위에서 언급한 forward는 deterministic, inverse는 stochastic 한 케이스가 된다. 이를 generative surjections라 하고, 반대로 $\\mathcal X \\to \\mathcal Z$ 방향에 surjections를 가정하면 forward는 stochastic, inverse는 deterministic 한 inference surjections가 된다.\nLikelihood Contribution continuous surjections에 대한 likelihood contribution term은 다음과 같다.\n$$\\mathbb E_{q(z|x)}\\left[\\log\\frac{p(x|z)}{q(z|x)}\\right], \\ \\mathrm{as} \\left\\{\\begin{matrix} \u0026amp; p(x|z) \\to \\delta(x - f(z)), \u0026amp; \\mathrm{for\\ gen.\\ surj} \\\\ \u0026amp; q(z|x) \\to \\delta(z - f^{-1}(x)), \u0026amp; \\mathrm{for\\ inf.\\ surj} \\end{matrix}\\right.$$\ngenerative sujrections의 경우에는 stochastic posterior로 인해 likelihood의 lower bound를 추정해야 하지만, inference surjections의 경우에는 deterministic true posterior를 활용할 수 있으므로 exact likelihood evaluation이 가능하다.\n이에 SurVAE Flows에서는 forward/inverse의 두 가지 방향과 deterministic/stochastic의 두 가지 mapping 방식에 대해 총 4가지 composable building blocks를 구성할 수 있다.\nTable 1: Composable building blocks of SurVAE Flows (Nielsen et al., 2020)\nExamples\nTensor slicing $z = (z_1, z_2) \\in \\mathbb R^d$에 대해 slice $x = f(z) = z_1$을 상정하면, 이는 generative surjections이다. 우선 이에 따른 forward와 inverse의 stochastic transformation을 정의한다.\n$$p(x|z) = \\mathcal N(x|z_1, \\sigma^2I), \\ \\ q(z|x) = \\mathcal N(z_1|x, \\sigma^2I)q(z_2|x)$$\n이때 $\\sigma^2\\to 0$이면 $p(x|z) \\to \\delta(x - f(z))$의 deterministic transform으로 수렴하므로 likelihood contribution은 다음과 같아진다.\n$$\\mathcal V(x, z) = \\lim_{\\sigma^2\\to 0}\\mathbb E_{q(z|x)}\\left[\\log\\frac{p(x|z)}{q(z|x)}\\right] = \\mathbb E_{q(z_2|x)}[-\\log q(z_2|x)]$$\n그리고 이는 $q$의 entropy를 maximize 하는 방향으로 학습이 진행될 것이다. ANF[5]나 VFlow[6]에서 제안했던 augmentation과 동치이다.\n반대로 $x = (x_1, x_2) \\in \\mathbb R^d$에 대한 slice $z = f(x) = x_1$을 상정한다면, 다음과 같이 inference surjections가 정의될 것이고, likelihood contribution은 $p(x|z)$가 $z$로부터 나머지 $x_2$를 복원하기 위한 형태로 구성될 것이다.\n$$\\mathcal V(x, z) = \\mathbb E_{q(z|x)}\\left[\\log\\frac{p(x|z)}{q(z|x)}\\right] = \\mathbb E_{p(z|x)}[\\log p(x_2|z)]$$\nRounding rounding $x = \\lfloor z\\rfloor$를 상정하면, forward transform은 deterministic surjection으로 구성된다.\n$$p(x|z) = \\mathbb I(z \\in \\mathcal B(x)), \\ \\ \\mathcal B(x) = \\{x + u|u\\in [0, 1)^d\\}$$\ninverse를 variational posterior$q(z|x)$에 대한 stochastic transform으로 구성하면, Flow++[4]에서 언급되었던 variational dequantization과 동치가 된다.\n$$\\mathcal V(x, z) = \\mathbb E_{q(z|x)}[-\\log q(z|x)]$$\nAbsolute $z = |x|$의 절댓값 연산을 상정한다면 이는 inference surjections이고, sign s에 대한 bernoulli 분포를 다루는 방식으로 작동할 것이다.\n$$\\begin{align*}\u0026amp;p(x|z) = \\sum_{s\\in\\{-1, 1\\}}p(x|z, s)p(s|z) = \\sum_{s\\in\\{-1, 1\\}}\\delta(x - sz)p(s|z) \\\\\\ \u0026amp;q(z|x) = \\sum_{s\\in\\{-1, 1\\}}q(z|x, s)p(s|x) = \\sum_{s\\in\\{-1, 1\\}}\\delta(z - sx)\\delta_{x, \\mathrm{sign}(x)}\\end{align*}$$\nSurVAE Flows[8]는 그 외에도 flow framework에서 사용해볼 법한 몇 가지 layer를 더 제안한다. 이를 토대로 nonlinearities의 부재와 architecture의 constraint를 겪던 flow framework에 reasonable한 디자인을 추가할 수 있게 되었단 점에서 또 하나의 의의가 있을 것이다.\nConnection to previous works\nSurVAE Flows는 4가지 mapping 방식에 대한 generalized framework를 제안하면서 기존까지의 다양한 확률 모델과의 접점을 만들어 냈다.\nbijective를 통한 modeling 과정에서 dimensionality, discrete data, misspecified prior에 대한 여러 문제점이 제기되었었고, 이에 따른 individual solutions를 하나의 framework 내에서 구성할 수 있게 된 것이다.\nTable 3: SurVAE Flows as a unifying framework. (Nielsen et al., 2020)\nDiffusion[9]은 이전 post에서 다뤘던 주제로, inverse에 noise를 더해가는 diffusion steps를 두고, forward에서 denoising을 objective로 하는 모델을 구성하는 방식이다. forward와 inverse가 모두 stochastic 한 formulation으로 구성된다.\nDequantization의 경우에는 continuous flow를 discrete data에 모델링하는 과정에서 degenerate point에 density가 몰리는 현상을 방지하고자, rounding operation을 상정하고 variational posterior를 통한 dequantization을 구성하는 method이다. 이는 rounding에 대한 generative surjections으로 구성된다. (post: Glow, Flow++)\nANF[5]와 VFlow[6]는 dimensionality problem의 해결을 위해 channel axis에 부가적인 latent를 부여하는 augmentation을 제안한다. 이는 tensor slicing에 대한 generative surjections로 구성된다. 반대로 RealNVP[2]에서 제안한 multi-scale architecture는 연산의 효율성을 위해 각 resolution에 대한 latent를 slicing 함으로 inference surjection에 해당한다. (post: NF, RealNVP, ANF, VFlow)\nCIF[7]의 경우에는 misspecified prior를 활용한 상황에서의 real data fitting과 bi-Lipschitz constant에 대한 tradeoff를 보이며, 이에 대한 해결책으로 augmentation과 latent의 surjectivity를 통한 re-routing을 제안한다. 하지만 ANF[5], VFlow[6]와는 달리 hierarchy를 구성하므로 최종에서는 모든 latent를 사용하지 않고, re-routing에 해당하는 latent를 slicing 한다. (post: i-ResNet, CIF)\nExperiments\nFigure 4: Comparison of flows with and without absolute value surjections (Nielsen et al., 2020)\n가장 먼저 한 실험은 symmetric data에서 실제로 absolute value surjection이 유용한가에 대한 실험이다. 실제로 동일한 flow에 absolute surjections를 추가한 것만으로 bits/dim이 줄어든 것을 확인할 수 있다.\nFigure 5: Point cloud samples from permutation-invariant SurVAE Flows (Nielsen et al., 2020)\n두 번째 실험은 SpatialMNIST에 대한 실험이다. point cloud는 집합으로 permutation-invariant 한 특성을 가진다. SurVAE Flows에서는 sorting surjections나 stochastic permutation을 통해 입력에 순서 정보를 제거할 수 있다. 또한 stochastic permutation에 대해서는 coupling layer에 positional encoding을 사용하지 않는 transformer를 활용함으로서 permutation invariant 한 모델을 구성했다.\n실제로 PermuteFlow는 SortFlow에 비해 좋은 성능을 보였고, i.e. -5.30 vs -5.53 PPLL (per-point log-likelihood), 다른 non-autoregressive 모델에 비해서도 SOTA performance를 보였다.\nModeling image data with MaxPoolFlow (Nielsen et al., 2020)\n마지막은 이미지 데이터에 대해 max pooling을 활용하여 downsampling을 구성한 MaxPoolFlow이다. Baseline은 RealNVP[2]의 multi-scale architecture를 활용하였다.\n실험 결과 slicing surjection에 비해 maxpool이 더 높은 bits/dim를 보이긴 했으나, IS/FID 에서는 더 좋은 visual quality를 갖는다 평가받았다.\nDiscussion\n이로써 normalizing flow에 대해 기획했던 게시글을 모두 작성하였다.\nNF에 대한 소개와 연구 초기에 소개되었던 RealNVP 어떤 layer와 architecture를 구성할지에 대해 소개했던 Glow, Flow++ dimensionality problem에 대한 해결책을 제시한 ANF, VFlow residual network의 invertibility와 그 한계를 소개한 i-ResNet, CIF 마지막으로 모든 걸 unifying하고 NF의 새로운 지평을 연 SurVAE Flows\n시작은 SurVAE Flows[8]를 접한 뒤였다. 당시 NF에 관심이 있었고, surjection을 통해 기존까지의 확률 모델 전반을 통합한 논문은 굉장한 호기심으로 다가왔다.\n이를 위해 reference를 조사하고, 그렇게 하나둘 리뷰를 하던 중 연재물로써 NF의 글을 쓰고 다른 사람들과 공유할 수 있음 좋을 것 같다는 생각이 들었다.\n하지만 글을 잘 쓰는 편도 아니고, 거의 논문을 번역해둔 듯한 글에 큰 의미가 있을까 고민도 했던 것 같다.\n그래도 뭐라도 남겨두고, 한글로 되어 있음 참고할 사람은 참고할 수 있지 않을까 하는 생각이 들어 장장 5편의 NF 논문을 리뷰한 것 같다.\n공부하면서 flow처럼 문제 제기와 해결, 추상화와 통합이 자연스레 순차적으로 이루어진 분야는 처음 보았다. 굉장히 많은 양의 머신러닝/딥러닝 관련 논문이 쏟아져 나오는 요즘, 이 정도의 스토리 라인을 구성할 수 있다는 점에서도 연구자분들에 대한 큰 감사함을 느낀다.\n필자는 학부 휴학생 신분으로 음성 합성 연구를 시작하면서 연구는 어떻게 해야 하는지, 무엇을 만들어야 하는지에 대한 개념도 없이 일을 시작했던 것 같다. 그리고 1년 반, 2년 차가 되어가는 시점에서 flow를 공부한 것은 그 방향성을 잡는데에도 큰 도움을 준 것 같다.\n그 외에도 NF라는 주제가 가지는 다양한 발전 가능성과 현실 세계에서의 적용 가능성에 대해 긍정적으로 바라보고 있고, 다양한 분들이 이 글을 통해 조금이나마 도움을 받았음 좋겠다.\nReference\n[1] Rezende, D. J. and Mohamed, S. Variational inference with normalizing flows. In ICML 2015. [2] Dinh, L., Sohl-Dickstein, J. and Bengio, S. Density estimation using Real NVP. In ICLR 2017. [3] Kingma, D. P. and Dhariwal, P. Glow: Generative Flow with Invertible 1x1 Convolutions. In NIPS 2018. [4] Ho, J. et al. Flow++: Improving flow-based generative models with variational dequantization and architecture design. In ICML 2019. [5] Huang, C., Dinh, L. and Courville, A. Augmented Normalizing Flows: Bridging the Gap Between Generative Flows and Latent Variable models. 2020. [6] Chen, J., et al. VFlow: More Expressive Generative Flows with Variational Data Augmentation. In ICML 2020. [7] Cornish, R., Caterini, A., Deligiannidis, G., Doucet, A. Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows. In ICML 2020. [8] Nielsen, D., Jaini, P., Hoogeboom, E., Winther, O., Welling, M. SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows. In NeurIPS 2020. [9] Ho, J., Jain, A., Abbeel, P. Denoising Diffusion Probabilistic Models. In NeurIPS 2020. [10] Kingma, P, D. and Welling, M. Auto-Encoding Variational Bayes. In ICLR 2014.\n","permalink":"https://revsic.github.io/blog/survaeflow/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","SurVAE Flows"],"title":"SurVAE Flows"},{"categories":["Bayesian"],"contents":" Invertible Residual Networks, Behrmann et al. In ICML 2019, arXiv. Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows, Cornish et al. In ICML 2020, arXiv. Keyword: Bayesian, Normalizing Flow, i-ResNet, ResFlow, Invertibel ResNet, CIF, Continuously Index Flows. Problem: Bijective and misspecified prior, topological mismatch. Solution: Surjective, augmentation, hierarchical structure. Benefits: Correcting misspecified posterior. Weakness or Future work: Is Augmented Flow can correct misspecified prior? Series: Normalizing flow\nNormalizing flow, Real NVP [link] Glow, Flow++ [link] ANF, VFlow [link] i-ResNet, CIF [this] SurVAE Flows [link] Residual Network\nNeural network의 발전에 있어서 하나의 아키텍쳐로 여러 문제를 풀 수 있다는 것은 굉장한 이점으로 작용해 왔다. 하지만 근래에 들어서는 아키텍쳐의 발전이 domain-specific 하게 작용하고 있으며, 특히 VAE, Flow, GAN 등으로 나뉘어 발전한 generative task에서 이 점이 두드러진다.\n그 중 discriminative task와 generative task의 여러 architecture design은 서로 다른 방향성을 띄어 갔고, 다양한 tuning 방법론들이 등장하며 점점 그 구성은 복잡해져만 갔다.\n이에 저자들은 discriminative task와 generative task 모두에서 사용 가능한 어떤 universal architecture를 디자인하고자 했고, 그렇게 주목하게 된 구조가 invertible flow이다.\n이번 글에서는 residual network의 invertibility와 free-form jacobian의 연산에 관해 이야기하고, Lipschitz-constraint와 invertible flow의 관계성, 한계의 해결방안에 대해 알아본다.\nEnforcing Invertibility in ResNets\n$$x_{t+1} \\leftarrow x_t + g_{\\theta_t}(x_t) \\ \\ \\mathrm{where} \\ x_t \\in \\mathbb R^d$$\nresidual block은 입력과 연산의 결과를 더하는 방식으로 구성된다. 이에 invertibility를 부여하기 위해서는 $x_{t+1}$이 주어졌을 때, $x_t$를 연산해 낼 수 있어야 한다.\n$$x_t \\leftarrow x_{t+1} - g_{\\theta_t}(x_t)$$\nTheorem 1. (Sufficient condition for invertible ResNets). residual block은 Lipschitz-constant가 1보다 작을 때 invertible 하다.\n$$\\mathrm{Lip}(g_{\\theta_t}) \u0026lt; 1$$\nRemark. (Banach fixed point theorem)\ncomplete metric space $(X, d)$에서 $T: X \\to X$의 함수가 다음을 만족할 때 $T$를 contraction이라 한다.\n$$\\exists q \\in [0, 1) : d(T(x), T(y)) \\le qd(x, y) \\ \\forall x, y \\in X$$\nBanach fixed point theorem에 의해 contraction은 unique fixed point를 가지며, i.e. $\\exists ! x^* \\in X : T(x^*) = x^*$, 임의점 $x_0 \\in X$으로부터 iteration을 통해 fixed point $x^*$를 찾을 수 있다.\n$$\\{x_n = T(x_{n-1})\\}_{n\\ge 1} \\Rightarrow \\lim _{n\\to 1}{x_n} = x^*$$\npf.\nLipschitz-constant는 complete metric space $(X, d)$에서 어떤 함수 $T: X \\to X$에 대해 다음과 같이 정의한다.\n$$\\mathrm{Lip}(T) = \\inf \\{q: d(T(x), T(y)) \\le qd(x, y) \\ \\forall x, y \\in X\\}$$\n이때 residual block의 inverse 연산을 contraction으로 본다면, $\\mathrm{Lip}(x \\mapsto x_{t+1} - g_{\\theta_t}(x))$가 1보다 작아야 할 것이고, 이에 따라 unique fixed point $x^* = x_{t+1} - g_{\\theta_t}(x^*)$가 존재할 것이다. 그리고 이 값은 유일하므로, inverse solution과 $x_t = x^ *$의 unique fixed point가 동치가 된다.\n따라서 inverse 연산이 contraction이라면 fixed point iteration을 통해 이전 residual block의 출력값을 찾아낼 수 있고, l2-norm $||\\cdot||_2$과 euclidean distance $d(x, y) = ||x - y||_2$에 대해 Lipschitz-constant의 제약을 풀어내면 다음과 같다.\n$$\\begin{align*} \u0026amp;\\mathrm{Lip}(x \\mapsto x_{t+1} - g_{\\theta_t}(x)) \\\\ \u0026amp;= \\inf \\{q: d(x_{t+1} - g_{\\theta_t}(x), x_{t+1} - g_{\\theta_t}(y)) \\le qd(x, y) \\ \\forall x, y \\in X\\} \\\\ \u0026amp;= \\inf \\{q: ||(x_{t+1} - g_{\\theta_t}(x)) - (x_{t+1} - g_{\\theta_t}(y))||_2 \\le q||x - y||_2 \\ \\forall x, y \\in X\\} \\\\ \u0026amp;= \\inf \\{q: ||g _{\\theta_t}(x) - g _{\\theta_t}(y)||_2 \\le q||x - y||_2 \\ \\forall x, y \\in X\\} \\\\ \u0026amp;= \\inf \\{q: d(g _{\\theta_t}(x), g _{\\theta_t}(y)) \\le qd(x, y) \\ \\forall x, y \\in X\\} \\\\ \u0026amp;= \\mathrm{Lip}(g _{\\theta_t}) \\lt 1 \\end{align*}$$\n즉 $g_{\\theta_t}$의 Lipschitz-constant가 1보다 작을 때 residual block은 invertibility를 갖는다.\n또한 fixed point iteration은 exponential scale에 따라 수렴하게 되므로, Lipschitz-constant가 작아질수록 더 적은 연산으로 unique point를 찾아낼 수 있다.\n$$||x - x_n||_2 \\le \\frac{\\mathrm{Lip}(g)^n}{1 - \\mathrm{Lip}(g)}||x_1 - x_0||_2$$\nSatisfying the Lipschitz Constraint\ni-ResNet[1]에서는 residual block을 contractive nonlinearities (e.g. ReLU, ELU, tanh)와 convolution으로 구성한다.\nSN-GAN[3]에서는 정의에 따라 matrix A에 대한 spectral norm $\\sigma(\\cdot)$을 largest singular value of A로 연산하고, linear transform $g$의 Lipschitz norm $\\mathrm{Lip}(g) = ||g||_\\mathrm{Lip}$을 다음과 같이 보인다.\n$$||g||_\\mathrm{Lip} = \\sup_h \\sigma(\\nabla g(h)) = \\sup_h \\sigma(W) = \\sigma(W)$$\n이에 따라 convolution으로 구성된 residual block이 Lipschitz-constant를 만족하기 위해서는 각각의 convolutional weights에 spectral norm을 취해 1 이하로 둘 수 있어야 한다. contractive nonlinearities $\\phi$를 상정한다면 전개는 다음과 같다.\n$$\\mathrm{since} \\ ||g_1 \\circ g_2||_\\mathrm{Lip} \\le ||g_1|| _\\mathrm{Lip}||g_2|| _\\mathrm{Lip}, \\\\ ||W_2\\phi(W_1)|| _\\mathrm{Lip} \\le ||W_2|| _\\mathrm{Lip}||\\phi|| _\\mathrm{Lip}||W_1|| _\\mathrm{Lip} \\le ||W_2|| _\\mathrm{Lip}||W_1|| _\\mathrm{Lip} \\\\ \\Rightarrow \\mathrm{Lip}(g) \\le 1, \\ \\ \\mathrm{if} \\ ||W_i|| _\\mathrm{Lip} \\le 1$$\nSpectral norm은 power-iteration 방식으로 근사하여 취급한다.\nDeterminant of Free-form Jacobian\ninvertible resnet, 이하 i-ResNet[1]은 jacboian의 norm에 일정 constraint를 요구하지만, coupling layer와 같이 matrix의 form 자체에 제약을 걸지는 않는다. 따라서 기본적으로 determinant 연산까지 $\\mathcal O(d^3)$의 cubic complexity를 가정해야 하고, 이에 high-dimensional data에서는 intractable 하다는 문제를 가진다.\n이에 log-determinant term 자체를 효율적으로 근사하기 위한 방법론이 필요하다.\n우선 data $x$와 prior $z \\sim p_z(z)$에 대해 Lipschitz-constrained $F(x) = x + g(x)$를 상정한다. $F$는 invertible하고, $z = F(x)$로 둘 때 change of variables에 의한 likelihood 전개가 가능하다.\n$$\\ln p_x(x) = \\ln p_z(z) + \\ln|\\det J_F(x)|$$\n이때 eigen values $\\lambda_i$와 다음의 전개에 따라 determinants를 양수로 상정할 수 있다.\n$$\\begin{align*} \u0026amp; \\lambda_i(J_F) = \\lambda_i(J_g) + 1 \\land \\mathrm{Lip}(g) \u0026lt; 1 \\\\ \u0026amp; \\Rightarrow |\\lambda_i(J_g)| \u0026lt; 1 \\\\ \u0026amp; \\Rightarrow \\det J_F = \\Pi_i(\\lambda_i(J_g) + 1) \u0026gt; 0 \\end{align*}$$\n또한 non-singual matrix A에 대해 $\\ln\\det(A) = \\mathrm{tr}(\\ln(A))$ 이므로, trace of matrix logarithm의 power series에 의해 다음과 같은 전개가 가능하다.\n$$\\begin{align*} \\ln p_x(x) \u0026amp;= \\ln p_z(z) + \\mathrm{tr}(\\ln(I + J_g(x))) \\\\ \u0026amp;= \\ln p_z(z) + \\sum^\\infty_{k=1}(-1)^{k+1}\\frac{\\mathrm{tr}(J_g^k)}{k} \\end{align*}$$\n이에는 여전히 computational drawbacks가 존재하는데, 1) trace of jacobian을 square complexity로 상정하거나, d개 diagonal entry에 대해 g를 매번 연산하여 더해야 하고 2) matrix power가 필요하며 3) series가 무한하다는 것이다.\n이 중 1)은 automatic differentiation 과정에서 연산량을 줄일 수 있고, 2) matrix trace는 $v \\sim N(0, I)$를 통해 stochastic approximation이 가능하다고 한다.\n$$\\mathrm{tr}(A) = \\mathbb E_{p(v)}[v^TAv]$$\n지금까지는 unbiased estimation을 상정했지만, 3)의 해결을 위해 infinite series의 truncation이 불가피하고, approximation 과정에서 biased estimator로 변모한다.\nn-th truncation error는 다음에 의해 상한을 가진다.\n$$\\left|\\sum^\\infty_{k=n+1}(-1)^{k+1}\\frac{\\mathrm{tr}(J_g^k)}{k}\\right| \\le \\sum^\\infty_{k=n+1}\\left|\\frac{\\mathrm{tr}(J_g^k)}{k}\\right| \\le d\\sum^\\infty_{k=n+1}\\frac{\\mathrm{Lip}(g)^k}{k} \\\\ \\mathrm{since} \\ \\sum^\\infty_{k=1}\\frac{\\mathrm{Lip}(g)^k}{k} = -\\ln (1 - \\mathrm{Lip}(g)) \\\\ d\\sum^\\infty_{k=n+1}\\frac{\\mathrm{Lip}(g)^k}{k} = -d\\left(\\ln(1 - \\mathrm{Lip}(g)) + \\sum^n_{k=1}\\frac{\\mathrm{Lip}(g)^k}{k}\\right)$$\n이는 추후 ResFlow[2]라는 후속 논문에서 russian roullete estimation을 통해 unbiased estimation을 구현해 내고, softplus나 elu의 vanishing second order derivatives 현상과 training instability를 보완하기 위해 LipSwish를 제안하기도 한다.\nLipschitz Constraints and Pushforwards\n(이하는 개인의 이해보다는 논문의 표기를 그대로 따르며, 내용의 소개 정도를 목표로 한다.)\nNormalizing flow는 density estimation의 pushforward에 해당한다. 이는 prior measure $P_Z$와 bijective $f: \\mathcal Z \\to \\mathcal X$에 대해 measure $P_X := f \\# P_Z := P_Z\\circ f^{-1}$를 정의한다.\ntopological view에서 support of $P_Z$는 직관적으로 $P_Z$가 밀도를 할당하고 있는 region of $\\mathcal Z$를 의미한다. 따라서 target $P_X^*$와 pushforward $P_X$가 완벽히 일치하기 위해서는 두 support가 동치여야 한다. ($\\overline A$는 closure of A이다.)\n$$\\mathrm{supp} P_X^* = \\overline{f(\\mathrm{supp}P_Z)}$$\n이때 normalizing flow는 bijective f를 가정하므로, 두 support가 일치하기 위해서는 $P_X^*$와 $P_Z$의 support가 homeomorphic 해야 한다 (i.e. topological space에서의 isomorphic을 의미한다.).\n$$\\mathrm{supp}P_X = \\mathrm{supp}P_X^* \\ \\ \\mathrm{only \\ if} \\ \\mathrm{supp} P_Z \\simeq \\mathrm{supp} P_X^*$$\n이 의미는 $P_Z$와 $P_X^*$의 support가 같은 topological properties를 공유한다는 것인데, 예를 들면 holes, knots, connected components의 수가 같아야 한다.\n따라서 현재 단순 gaussian prior를 상정한 normalizing flow는 complex real-world densities를 학습하기에 topological mismatch의 불가항력이 존재한다.\n이 condition을 완화하기 위해서는 $P_X \\approx P_X^*$로 두어 topological misspecified prior를 사용할 수 있게 하거나, pushforward f의 bijectivity를 완화해야 할 수 있어야 한다.\nBehrmann et al. (2020)[4]에서는 numerical invertibility의 척도로 bi-Lipschitz constant를 상정한다. ([4]에서는 수학적으로 잘 정의된 inverse도 precision의 한계를 가지는 머신 위에서 numerical inverse가 명확하지 않을 수 있음을 보인다.)\n$$\\mathrm{BiLip} f = \\max \\left( \\mathrm{Lip}(f), \\mathrm{Lip}(f^{-1}) \\right)$$\nbi-Lipschitz constant는 $f$나 $f^{-1}$가 한 번에 jump 할 수 있는 정도를 의미한다. 이때 $f$가 injective하지 않으면 $\\mathrm{BiLip} f = \\infty$이고, $\\mathrm{BiLip} f \u0026lt; \\infty$이면 $f$는 homeomorphism이다.\n다음은 $P_Z$와 $P_X^*$가 homeomorphic하지 않을 때 $f$의 bi-Lipschitz constant가 근사를 위해 임의로 커질 수 있음을 의미한다.\nTheorem 2.1. $P_Z$와 $P_X^*$가 $\\mathbb R^{d_\\mathcal{Z}}$와 $\\mathbb R^{d_\\mathcal X}$의 measure이고, $\\mathrm{supp}P_Z \\not\\simeq \\mathrm{supp}P_X^ *$일 때, sequence of measurable $f_n: \\mathbb R^{d_\\mathcal{Z}} \\to \\mathbb R^{d_\\mathcal X}$에 대해 $\\lim_{n\\to\\infty}\\mathrm{BiLip}f_n = \\infty$이어야만 $f_n\\#P_Z \\overset{D}{\\to} P_X^ *$이 만족한다.\n이 때 $\\overset{D}{\\to}$는 weak convergence이며, 이는 KL, JS, Wasserstein metric과 같은 statistical divergence의 minimisation을 의미한다. Theorem2.1.은 다른 말로 bi-Lipschitz constant가 임의로 커질 수 있어야 pushforward가 원하는 measure에 수렴할 수 있음을 이야기한다. 또한 이 과정에서 $d_\\mathcal Z = d_\\mathcal X$를 가정하지 않으므로 GAN과 같은 injective pushforward를 포함한다.\nPractical Implication\n이 정리의 가장 직접적인 영향을 받는 것이 i-ResNet[1]과 ResFlow[2]이다. 이들은 invertibility를 위해 spectral normalization으로 residual layer의 Lipschitz-constant가 1 이하가 되도록 구성하였다.\n$$f^{-1}_l(x) = x + g_l(x), \\ \\ \\mathrm{Lip}(g_l) \\le \\kappa \u0026lt; 1$$\ni-ResNet[1]의 Lemma2에서는 이를 토대로 bi-Lipschitz constant의 upperbound를 구하게 되며, 이것이 Theorem 2.1.에 의해 non-homeomorphic prior $P_Z$의 근사에 제약이 발생함을 의미한다.\n$$\\mathrm{BiLip}f\\le\\max(1+\\kappa, (1 - \\kappa)^{-1})^L \u0026lt; \\infty$$\n이는 $\\kappa\\to1$을 통해 relax 할 수 있을 것으로 보이나, 반대로 russian roullete estimator의 variance를 높여 determinant의 수렴을 어렵게 한다. $L\\to\\infty$를 상정한다면, layer 수의 증가를 의미하므로 computational cost의 증대로 이어진다.\n그 외의 대부분 normalizing flow는 architecture에 bi-Lipschitz constraint를 걸지 않으므로, Theorem2.1.의 영향을 받지 않는다.\n반면 Behrmann et al. (2020)[4]에서는 well-defined inverse에서도 numerically noninvertible 할 수 있기에, 명시적으로 $\\mathrm{BiLip}f$를 제약하라고 제안하기도 한다. 즉 Theorem2.1.은 expressivity에 대한 numerical stability와 layer 수의 fundamental tradeoff를 시사한다.\nCIF: Continuously Indexed Flow\n이에 대해 CIF, Continuously Indexed Flow[7]는 ANF[5]와 VFlow[6] 때와 같이 augmentation을 그 해결책으로 제안한다.\nCIF[7]는 coninuous index $\\mathcal U \\subseteq \\mathbb R^{d_\\mathcal U}$와 bijective indexed family $\\{F(\\cdot;u): \\mathcal Z \\to \\mathcal X\\}_{u\\in \\mathcal U}$를 상정한다. 이에 대한 generative process는 다음과 같다.\n$$Z\\sim P_Z, \\ \\ U \\sim P_{U|Z}(\\cdot|Z), \\ \\ X := F(Z; U)$$\n저자들은 bijective f를 통해 $p_{U|Z}$와 $F$를 다음과 같이 모델링한다.\n$$p_{U|Z}(\\cdot|z) = \\mathrm{Normal}(\\mu^p(z), \\Sigma^p(z)) \\\\ F(z; u) = f(\\exp(-s(u)) \\odot z - t(u))$$\n여기서 $F^{-1}$를 활용해 likelihood를 구성하면 다음과 같다.\n$$z = F^{-1}(x; u) \\\\ p_{X, U}(x, u) = p_Z(z)p_{U|Z}(u|z)|\\det DF^{-1}(x; u)|$$\n이에 대한 marginal은 intractable 하므로 variational posterior $q_{U|X}$를 두어 lower bound를 추정한다.\n$$\\mathcal L(x):= \\mathbb E_{u\\sim q_{U|X}(\\cdot|x)}\\left[\\log\\frac{p_{X, U}(x, u)}{q_{U|X}(u|x)}\\right] \\\\ q_{U|X}(\\cdot|x) = \\mathrm{Normal}(\\mu^q(x), \\Sigma^q(x))$$\n이는 augmented flow로 추상화할 수 있는데, VFlow[6]에서는 latent u를 conditional flow로 모델링했다면, CIF[7]에서는 단순 gaussian으로 모델링 한 것이고, VFlow[6]에서 multiple coupling block을 두어 latent u와 data x사이의 정보 공유를 상정했다면, CIF[7]에서는 latent u만이 x의 모델링에 관여하는 single coupling block을 상정했다고 볼 수 있다.\n단 이렇게 되면 이전 augmented flow의 post에서도 이야기하였듯 u와 x 사이에 hierarchy가 발생하여 bottleneck problem의 해결로 이어지긴 어려울 듯하다.\n그럼에도 CIF[7]에서 hierarchy와 augmentation을 상정한 이유는 다음의 두 가지 정리 떄문이다.\nProposition 4.1. $\\phi \\in \\Theta$에 대해 $f: \\mathcal Z \\to \\mathcal X, F_\\phi(\\cdot; u) = f(\\cdot) \\ \\ \\forall u \\in \\mathcal U$를 가정한다. 그럼 density $r$ on $\\mathcal U$에 대해 trivial posterior $p^\\phi_{U|Z}(\\cdot|z) = q^\\phi_{U|X}(\\cdot|x) = r(\\cdot) \\ \\ \\forall z \\in \\mathcal Z, x \\in \\mathcal X$에도 다음이 만족한다.\n$$D_\\mathrm{KL}(P^*_X||P^\\theta_X) \\le D _\\mathrm{KL}(P^ *_X||f\\#P_Z) \\ \\ \\mathrm{if} \\ \\ \\mathbb E _{x\\sim P_X^ *}[\\mathcal L^\\theta(x)] \\ge \\mathbb E _{x\\sim P^ *_X}[\\mathcal L^\\phi(x)]$$\n이는 trivial posterior를 통해 likelihood의 lower-bound를 가정할 때, 학습된 모델이 KL divergence라는 measure에 대해 더 잘 작동한다는 것을 의미한다.\nCIF[7]에서는 이 현상을 $P_{U|Z}$를 통해 $P_X^*$의 support 외부에 존재할 수 있는 z를 rerounting 할 수 있었기 때문이라고 이야기한다. 예로 $z\\in \\mathcal Z$와 $f$에 대해 $f(x) \\in \\mathrm{supp} P_X^ *$라면 $F(z;u) = f(z) \\ \\ \\forall u \\in \\mathcal U$로, $f(z) \\not\\in \\mathrm{supp} P_X^ *$더라도 $F(z; U) \\in \\mathrm{supp}P_X^ *$를 구성할 수 있도록 $P_{U|Z}(\\cdot|z)$의 support가 $\\{u\\in \\mathcal U: F(z; u) \\in \\mathrm{supp}P_X^ *\\}$에 존재하게 하는 것이다.\n물론 이 과정에서 f가 충분히 단순하다면, $P_{U|Z}$는 굉장히 complex 해질 것이고, ELBO가 loose 해져 performance 역시 떨어질 것이다. 저자들은 이를 방지하기 위해 f를 10-layer ResFlow 같이 충분히 complex 한 모델을 상정하고, 일부 누수가 생기는 것을 $P_{U|Z}$가 보정하는 정도의 역할을 부여받을 수 있게 구성했다.\nProposition 4.3. $F(z;\\cdot): \\mathcal U \\to \\mathcal X$가 모든 $z\\in\\mathcal Z$에 대해 surjective이면 $P_{U|Z}$가 존재하여 $P_X=P_X^*$이다.\n물론 CIF[7]에서 제안한 component들이 위 조건을 필수적으로 만족하거나, variational posterior가 충분히 expressive 하지 않았을 수 있다. 하지만 최소한 misspecified prior를 수정하기 위한 mechanism을 제안한 점에서 의의가 있다.\nANF[5], VFlow[6]와의 차이가 있다면, 기존의 augmented flow는 마지막에 [z, u] 모두를 latent로 차용하지만, CIF[7]는 z만을 latent로 활용하여 u에 대한 slicing을 구성한다. hierarchy에 따라 bottleneck을 해결하지 못하더라도 surjectivity에 따른 misspecified prior의 수정을 수식적으로 증명했음에 또 다른 의의가 있다.\nExperiments\nTable 2. Comparison of i-ResNet to a ResNet-164 baseline architecture. (Behrmann et al., 2019)\nTable 4. MNIST and CIFAR10 bits/dim results. (Behrmann et al., 2019)\nTable 1: Mean ± standard error (over 3 seeds) of average test set log-likelihood (in nats). Higher is better. (Cornish et al., 2020)\nDiscussion\n(사견)\n꽤 긴 시간 공부해서 글을 쓰게 되었다. 정확한 이야기를 전달하고 싶었지만, 유난히 확신이 서지 않는다.\nNormalizing flow는 bijectivity를 근간으로 하기에, prior와 real data 사이의 topological mismatch를 bi-Lipschitz constant를 발산시킴으로써 해결해야 했다.\n이 과정에서 precision 상 한계를 가진 머신은 inversion에 numerical stability를 보장하지 못한다는 문제가 제기되었고, 이 해결책으로 bi-Lipschitz constant를 제한하자면서 trade-off의 관계가 발생했다.\nCIF[7]는 이를 위해 normalizing flow에 hierarchy를 구성하고, additional latent를 통해 misspecified prior의 보정이 가능함을 이야기하였다.\n개인적으로는 이러한 surjective의 전제와 증명이 ANF[5]나 VFlow[6]의 성능을 증명하는 것에도 활용될 수 있을 것으로 보인다.\n이렇게 Normalizing flow의 여러 문제와 해결안이 제기되고 있고, 그에 augmentation과 surjectivity가 종종 등장하고 있다. 추후 연구에서도 이를 통해 다른 확률 모델과의 연관성이나 universality 같은 이야기가 충분히 이뤄져 이제는 \u0026ldquo;왜 되는지 아는 모델\u0026quot;의 한 축이 되었음 좋겠다.\nReference\n[1] Behrmann, J., Grathwohl, W., Chen, T. Q., Duvenaud, D. and Jacobsen, J.-H. Invertible Residual Networks. In ICML 2019. [2] Chen, T. Q., Behrmann, J., Duvenaud, D. and Jacobsen, J.-H. Residual Flows for Invertible Generative Modeling. In NeurIPS 2019. [3] Miyato, T., Katoka, T., Koyama, M. and Yoshida, Y. Spectral Normalization for Generative Adversarial Networks. In ICLR 2018. [4] Behrmann, J., Vicol, P., Wang, K.-C., Grosse, R. B., Jacobsen, J.-H. On the Invertibility of Invertible Neural networks. 2019. [5] Huang, C., Dinh, L. and Courville, A. Augmented Normalizing Flows: Bridging the Gap Between Generative Flows and Latent Variable models. 2020. [6] Chen, J., et al. VFlow: More Expressive Generative Flows with Variational Data Augmentation. In ICML 2020. [7] Cornish, R., Caterini, A., Deligiannidis, G., Doucet, A. Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows. In ICML 2020.\n","permalink":"https://revsic.github.io/blog/resflow/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","i-ResNet","ResFlow","Invertible ResNet","Lipschitz constant","bi-Lipschitz constant","CIF","Continuously index flow"],"title":"Invertible ResNet and CIF"},{"categories":["Bayesian"],"contents":" ANF, Augmented Normalizing Flows: Bridging the Gap Between Generative Flows and Latent Variable Models, Huang et al., 2020, arXiv VFlow: More Expressive Generative Flows with Variational Data Augmentation, Chen et al., 2020, arXiv Keyword: Bayesian, Normalizing Flow, ANF, VFlow Problem: Dimensionality problem on normalizing flow Solution: Augmentation Benefits: Can propagate higher features to flow, better quality, bpd, etc. Weakness or Future work: - Series: Normalizing flow\nNormalizing flow, Real NVP [link] Glow, Flow++ [link] ANF, VFlow [this] i-ResNet, CIF [link] SurVAE Flows [link] Normalizing flow - Bottleneck problem\nNormalizing flow는 latent variable model의 한 축으로 자리 잡아 가고 있다. bijective를 통한 change of variables를 근간으로 하기에, 1) network의 inversion이 efficient 해야 하고, 2) log-determinant of jacobian 연산이 tractable 해야 하며, 3) 네트워크가 충분히 expressive 해야 한다.\n1)과 2)를 위해서는 기존과 같은 nonlinearity 기반의 레이어를 활용할 수 없었기에, 주로 jacobian의 형태를 제약하는 방식의 부가적인 engineering이 요구되었다.\n이 과정에서 mapping의 형태에 제약이 발생했고, 이에 따른 표현력 절감을 완화하기 위해 Glow[3], Flow++[4]과 같이 engineered bijective에 대한 연구가 등장했다.\nbijective로의 constraint는 tensor의 dimension도 바꿀 수 없게 하였다. 간단하게 tensor slice를 상정한다면, inverse 과정에서 유실된 slice를 복원해야 하고, 충분히 잘 구성된 상황을 가정하지 않은 이상, 이 과정은 analytic 하게 구성되지 않을 것이다.\n$$y = x_{1:d} \\ \\ \\mathrm{where} \\ x \\in \\mathbb R^D, \\ d \u0026lt; D \\\\ x_{1:d} = y, \\ \\ x_{d+1:D} = \\ ?$$\nUniversal approximation theorem에서부터 WideResNet[5]으로 이어져 오면서 network의 width는 성능에 중요한 factor가 되었다.\n이러한 상황에서 tensor의 dimension을 임의로 조작하지 못해 하위 flow에 internal hidden layers의 higher dimensional feature를 충분히 전달하지 못하면, flow는 매번 부족한 정보를 local-dependency부터 다시 추출해야 한다. 이렇게 개개 블럭의 표현력이 떨어진 flow는 block의 수를 늘림으로써 이를 해결해야 했고, computational inefficiency로 이어졌다.\n이 때문에 Flow++[4]에서는 global-dependency를 보다 효율적으로 탐색하기 위해 Transformer[6] 기반의 internal network를 제안하기도 한다.\nDimension problem, bottleneck problem의 요점은 high-resolution, low-dimension의 입력에서부터 high-dimension의 feature를 연산하고, 재사용할 수 있는지에 존재한다.\nAugmented Normalizing Flow, 이하 ANF[1]와 VFlow[2]는 서로 다른 논문이지만 normalizing flow의 dimension 문제에 대해 augmentation이라는 동일한 해결책을 제시한다.\nAugmentation\n흔히 Augmentation이라 하면 데이터의 양을 늘리거나, 모델의 robustness를 위한 preprocessing 작업 정도를 상상하겠지만, normalizing flow에서는 input에 추가적인 latent를 concat 하여 입출력 dimension을 직접 늘리는 행위를 이야기한다.\nFigure 1: Bottleneck problem in Flow++ and solution VFlow. (Chen et al., 2020)\nANF Perspective\nANF[1]는 dimension을 늘리기 위해 독립 변수 $e \\sim q(e) = \\mathcal N(0, I)$를 상정하고, family of joint density models $\\{ p_\\pi(x, e): \\ \\pi \\in \\mathfrak B\\mathcal{(X \\times E)} \\}$를 구성한다. 이 과정에서 $p_\\pi(x)$의 marginal likelihood 대신에 $p_\\pi(x, e)$의 joint likelihood를 다루게 되었다.\n$$\\hat\\pi_\\mathcal{A} := {\\arg\\max}_{\\pi \\in \\mathfrak B(\\mathcal{X\\times E})}\\mathbb E _{(x, e) \\sim \\hat q(x)q(e)}[\\log p _\\pi(x, e)]$$\n이렇게 확장된 estimator를 ANF[1]에서는 Augmented Maximum Likelihood Estimator (AMLE)라 명명하고, 학습에는 entropy $H(e)$를 활용한 maximizer $\\mathcal{L_A}(\\pi; x) := \\mathbb E_e[\\log p_\\pi(x, e)] + H(e)$를 정의하여 이용하게 된다. 이렇게 되면 marginal과의 차이는 KL divergence로 유도되고, 원문에서는 이를 augmentation gap이라 칭한다.\n$$\\begin{align*} \u0026amp;\\log p_\\pi(x) - \\mathcal{L_A}(\\pi; x) \\\\ \u0026amp;= \\log p_\\pi(x) - \\mathbb E_e[\\log p_\\pi(x) + \\log p_\\pi(e|x)] - H(e) \\\\ \u0026amp;= D_\\mathrm{KL}(q(e)||p_\\pi(e|x)) \\end{align*}$$\nexact marginal likelihood는 analytic 하게 연산할 수 없으므로, $q(e)$의 K개 i.i.d. sample을 통해 값을 추정해야 한다.\n$$\\hat{\\mathcal L_{A, K}} := \\log\\frac{1}{J}\\sum^K_{j=1}\\frac{p_\\pi(x, e_j)}{q(e_j)}$$\n네트워크는 affine coupling으로 구성하며, Glow[3]에서 split-concat을 활용했던 것과 유사하게 입력 데이터로 구성된 block $x$와 augmentation block $e$를 두고 coupling을 진행한다.\n$$\\begin{align*} \u0026amp;g_\\pi^\\mathrm{enc}(x, e) = \\mathrm{concat}(x, s_\\pi^\\mathrm{enc}(x) \\odot e + m_\\pi^\\mathrm{enc}(x)) \\\\ \u0026amp;g_\\pi^\\mathrm{dec}(x, e) = \\mathrm{concat}(s_\\pi^\\mathrm{dec}(e)\\odot x + m_\\pi^\\mathrm{dec}(e), e) \\end{align*} \\\\ G_\\pi = g_{\\pi_N}^\\mathrm{dec} \\circ g_{\\pi_N}^\\mathrm{enc} \\circ \u0026hellip; \\circ g_{\\pi_1}^\\mathrm{dec} \\circ g_{\\pi_1}^\\mathrm{enc}$$\nVFlow Perspective\nVFlow[2] 또한 마찬가지로 additional random variable $z \\in \\mathbb R^{D_z}$를 상정하고, data $x \\in \\mathbb R^{D_X}$와 augmented distribution $p(x, z; \\theta)$을 구성한다.\n$$e = f(x, z; \\theta) \\in \\mathbb R^{D_X + D_Z}$$\n이렇게 되면 marginal이 intractable 하기에, VFlow[2]에서는 variational $q(z|x; \\phi)$를 상정하고, lower bound를 objective로 구성한다.\n$$\\log p(x; \\theta) \\ge \\mathbb E_{q(x|z; \\phi)}[\\log p(x, z; \\theta) - \\log q(z|x; \\phi)]$$\n마찬가지로 density estimation은 sampling을 통해 진행한다.\n$$\\log p(x; \\theta) \\simeq \\log\\left(\\frac{1}{S}\\sum^S_{i=1}\\frac{p(x, z_i; \\theta)}{q(z_i|x; \\phi)}\\right) \\ \\ \\mathrm{where} \\ \\ z_1, \u0026hellip;, z_S \\sim q(z|x; \\phi)$$\n이 때 variational $q(z|x; \\phi)$는 보다 유연한 근사를 위해 또 다른 conditional flow로 구성한다.\n$$z = g^{-1}(e_q; x, \\phi) \\Rightarrow \\log q(z|x; \\phi) = \\log p_\\epsilon(e_q) - \\log\\left|\\frac{\\partial z}{\\partial e_q}\\right|$$\nBetween ANF and VFlow\n두 접근 모두 augmentation을 통해 bottleneck problem을 풀었다는 것에는 동일하나, formulation이 사뭇 다르게 보인다.\nANF의 경우에는 $q(e)$를 standard normal로 가정하여, entropy of e를 통해 lower bound를 산출해 낸다. 이 경우 augmentated gap $D_\\mathrm{KL}(q(e)||p_\\pi(e|x))$은 $x$에 독립인 marginal $q(e)$를 모델링하는 과정에서의 incapability에 의해 발생한다.\n하지만 VFlow의 경우에는 augmented distribution을 variational $q(z|x)$로 상정하여 intractable marginal의 lower bound에 접근하면서 augmented gap $D_\\mathrm{KL}(q_\\phi(z|x)||p(z|x))$을 줄일 가능성을 제시한다.\n이 두 formulation을 보면 언뜻 ANF는 joint를 VFlow는 marginal을 학습하는 차이가 있어 보이지만, entropy가 더해진 ANF의 maximizer $\\mathcal{L_A}(\\pi; x)$는 사실 variational distribution을 $q(z|x) = p(z) = \\mathcal N(0, I)$의 independent standard gaussian으로 상정한 VFlow의 marginal formulation과 동일하다.\n$$\\begin{align*} \u0026amp;\\log p(x; \\theta) \\\\ \u0026amp;\\ge \\mathbb E_{z\\sim q(z|x)}[\\log p(x, z; \\theta) - \\log q(z|x)]\\\\ \u0026amp;= \\mathbb E_{z \\sim p(z)}[\\log p(x, z; \\theta)] + \\mathbb E_{z \\sim p(z)}[- \\log p(z)] \\\\ \u0026amp;= \\mathbb E_{z \\sim p(z)}[\\log p(x, z; \\theta)] + H(z) \\\\ \u0026amp;= \\mathcal{L_A}(\\theta;x) \\end{align*}$$\n즉 ANF는 trivial distribution을, VFlow는 conditional flow를 기반으로 한 variational distribution을 상정한 것에 차이가 있다.\nConnection to Vanilla Generative Flows\n이렇게 bottleneck problem을 해결했다지만, 정말로 marginal likelihood의 향상에 도움이 있는지 VFlow[2]에서는 그 증명을 통해 알아본다.\n이론상 증명을 알아보기 이전에 notation을 정리한다.\nvanilla generative flow는 $p_x(\\mathbf x; \\theta_x), \\ \\theta_x \\in \\Theta_x$로 정의, $\\Theta_x$는 parameter space. $D_Z \u0026gt; 0$일 때, VFlow는 $p_a(\\mathbf x, \\mathbf z; \\theta_a), \\ z \\in \\mathbb R^{D_Z}, \\ \\theta_a \\in \\Theta_a$, 그리고 marginal $p_a(\\mathbf x; \\theta_a)$ $D_Z \u0026gt; 0$일 때, variational $q(z|x; \\phi), \\ z \\in \\mathbb R^{D_Z}, \\phi \\in \\Phi$ 이때의 maximum liklihood는 vanilla의 경우 $\\max_{\\theta_x}[\\log p_x(\\mathbf x; \\theta_x)]$, vflow의 경우 $\\max_{\\theta_a, \\phi}\\mathbb E_{\\hat p(x)q(z|x; \\phi)}[\\log p_a(\\mathbf x, \\mathbf z; \\theta_a) - \\log q(z|x; \\phi)]$로 구성될 것이다.\nVFlow[2]는 다음과 같은 가정을 한다.\nA1. (high-dimensional flow can emulate low-dimensional flow) 모든 $\\theta_x \\in \\Theta_x$와 $D_Z \u0026gt; 0$에 대해 다음을 만족하는 $\\theta_a \\in \\Theta_a$가 존재한다.\n$$p_a(\\mathbf x, \\mathbf z; \\theta_a) = p_x(\\mathbf x; \\theta_x)p_\\epsilon(z) \\ \\forall \\mathbf x, \\mathbf z$$\nA2. (the variational family has an identity transformation) 모든 $D_Z \u0026gt; 0$에 대해 $\\phi \\in \\Phi$가 존재하여, $q(\\mathbf z|\\mathbf x; \\phi) = p_\\epsilon(\\mathbf z) \\ \\forall \\mathbf x, \\mathbf z$를 만족한다.\n이는 RealNVP[8], Glow[3] 대부분의 invertible transformation에 성립한다고 한다.\n간단한 예로 orthonormal matrix $\\theta_x \\in \\Theta_x$에 대한 invertible linear flow $\\epsilon = \\mathbf x\\theta_x$를 상정한다면, $\\theta_a$를 적절히 취함으로써 A1을 만족시킬 수 있다.\n$$\\theta_a = \\left[\\begin{matrix}\\theta_x \u0026amp; 0 \\\\ 0 \u0026amp; I\\end{matrix}\\right] \\\\ p_a(\\mathbf x, \\mathbf z; \\theta_a) = p_\\epsilon\\left([\\mathbf x, \\mathbf z]\\left[\\begin{matrix}\\theta_x \u0026amp; 0 \\\\ 0 \u0026amp; I\\end{matrix}\\right]\\right) = p_\\epsilon(\\mathbf x \\theta_x)p_\\epsilon(\\mathbf z)$$\n또한 $q(\\mathbf z|\\mathbf x; I) = p_\\epsilon(\\mathbf z I) = p_\\epsilon(z)$이므로 A2도 만족한다. 추가적인 transform에 대한 증명은 VFlow[2]의 Appendix A.에서 확인 가능하다.\nTheorem. A1과 A2의 가정 하에 $D_Z \u0026gt; 0$을 취하면 다음을 얻을 수 있다.\n$$\\max_{\\theta_x \\in \\Theta_x}\\mathbb E_{\\hat p(\\mathbf x)}\\log p_x(\\mathbf x; \\theta_x)] \\le \\max_{\\theta_a \\in \\Theta_a, \\phi \\in \\Phi}\\mathbb E_{\\hat p(\\mathbf x)q(\\mathbf z|\\mathbf x; \\phi)}[\\log p_a(\\mathbf x, \\mathbf z; \\theta_a) - \\log q(\\mathbf z|\\mathbf x; \\phi)]$$\npf. vanilla $p_x(\\mathbf x; \\theta_x)$에 대해 A1과 A2를 가정하면 다음을 구성할 수 있다.\n$\\theta(\\theta_x) \\in \\Theta_a$에 대해 $p_a(\\mathbf x, \\mathbf z; \\theta(\\theta_x)) = p_x(\\mathbf x; \\theta_x)p_\\epsilon(\\mathbf z)$을 구성. 이는 z를 최소한으로 활용하는 경우를 가정한다. $\\phi \\in \\Phi$에 대해 $q(\\mathbf z|\\mathbf x; \\phi) = p_\\epsilon(\\mathbf z)$. 이는 posterior의 정보를 활용하지 않는 경우를 가정한다. 이의 lower bound는 vanilla와 동일해진다.\n$$\\log p_a(\\mathbf x, \\mathbf z; \\theta(\\theta_x)) - \\log q(\\mathbf z|\\mathbf x; \\theta_x) = \\log p_x(\\mathbf x; \\theta_x)$$\n이에 대해 다음과 같은 전개가 가능하다.\n$$\\begin{align*} \u0026amp;\\max_{\\theta_x \\in \\Theta_x} \\mathbb E_{\\hat p(\\mathbf x)}[\\log p_x(\\mathbf x; \\theta)] \\\\ \u0026amp;= \\max_{\\theta_a \\in \\Theta_a, \\phi \\in \\Phi} \\mathbb E_{\\hat p(\\mathbf x)p_\\epsilon(\\mathbf z)}[\\log p_x(\\mathbf x; \\theta) + \\log p_\\epsilon(\\mathbf z) - \\log p_\\epsilon(\\mathbf z)] \\\\ \u0026amp;= \\max_{\\theta_x \\in \\Theta_x} \\mathbb E_{\\hat p(\\mathbf x)}[\\log p_a(\\mathbf x, \\mathbf z; \\theta(\\theta_x)) - \\log p_\\epsilon(\\mathbf z)] \\\\ \u0026amp;\\le \\max_{\\theta_a \\in \\Theta_a} \\mathbb E_{\\hat p(x)}[\\log p_a(\\mathbf x, \\mathbf z; \\theta_a) - \\log p_\\epsilon(\\mathbf z)] \\tag 1\\\\ \u0026amp;= \\max_{\\theta_a \\in \\Theta_a} \\mathbb E_{\\hat p(x)}[\\log p_a(\\mathbf x, \\mathbf z; \\theta_a) - \\log q(\\mathbf z|\\mathbf x; \\phi)] \\\\ \u0026amp;\\le \\max_{\\theta_a \\in \\Theta_a, \\phi \\in \\Phi}\\mathbb E_{\\hat p(\\mathbf x)}[\\log p_a(\\mathbf x, \\mathbf z; \\theta_a) - \\log q(\\mathbf z|\\mathbf x; \\phi)] \\tag 2 \\end{align*}$$\n1번 식에서는 $\\theta_a$의 자율성에 의해, 2번 식에서는 variational $q(z|x;\\phi)$의 학습에 의해 부등호가 성립한다. 따라서 이는 ANF와 같이 trivial $q(\\mathbf z|\\mathbf x) = p_\\epsilon(\\mathbf z)$를 상정하더라도 기존보다 성능향상이 있음을 의미한다.\nVFlow[2]에서는 실험적으로도 channel 수에 따른 bpd 감소를 보였다.\nFigure 6. Bpd on training (light) and validation (dark) dataset of Flow++ and VFlow under a 4-million parameter budget (not fully converged) (Chen et al., 2020)\naugmentation의 문제를 parameter의 증가라 볼 수도 있는데, VFlow[2]는 hidden layers의 크기를 줄여 parameters 수를 일정 수준 유지하더라도, dimension 자체를 늘리는 것이 더욱 효율적이었음을 보인다.\nTable 3. Parameter efficiency on CIFAR-10. (Chen et al., 2020)\nConnection to VAE\nVAE[7]는 1-step augmented flow의 special case로 볼 수도 있다. joint distribution을 gaussian factorizing $p(x, z) = \\mathcal N(z; 0, I)\\mathcal N(x; \\mu(z), \\exp(\\sigma(z))^2)$을 통해 affine coupling의 1-step flow로 구성하면, vflow의 variational $q(z|x)$에 대해 Gaussian VAE와 동치이다.\n$$\\epsilon_Z \\sim q(z|x) \\ \\ \\epsilon_X \\sim \\mathcal N(0, I) \\\\ z = \\epsilon_Z, \\ \\ x = \\mu(\\epsilon_Z) + \\exp(s(\\epsilon_Z)) \\circ \\epsilon_X$$\nVFlow[2]는 $p(x, z) = p(z)p(x|z)$라는 hierarchy를 가정하지 않는다는 점에서 보다 일반화된 모델로 볼 수 있다. 또한 이렇게 hierarchy를 구성하면 여전히 $p(x|z)$의 dimension은 고정되고, 정보 공유가 없기에 bottleneck problem은 해결되지 않는다.\nVAE[7]는 또한 이러한 hierarchy에 의해 variational $q(z|x)$의 표현력이 중요해지는데, VFlow[2]에서는 이 역할이 $p(x, z)$로 분배되기 때문에 unconditional $q(z|x) = p(z)$를 가정하더라도 ANF[1]와 같이 충분히 좋은 성능을 보일 수 있었다.\nFigure 4: 5-step ANF on 1D MoG. (Huang et al., 2020)\n실제로 ANF[1]에서는 실험을 통해 step 수에 따른 latent의 gaussianize 여부를 plotting 해보았는데, step 수가 많아짐에 따라 latent가 gaussian prior에 더욱 근접했음을 확인할 수 있었다.\nFigure 4: Visualization of learnt transformation on toy data. (Chen et al., 2020)\nModeling Discrete Data\nFlow++[4]에서는 discrete data를 위해 variational dequantization을 이야기했었는데, VFlow[2]에서는 augmentation $\\mathbf z$와 dequantization $\\mathbf u$의 hierarchy를 두어 dicrete modeling을 구성하였다.\n$$\\log P(\\mathbf x) \\ge \\mathbb E_{r(\\mathbf u|\\mathbf x),q(\\mathbf z|\\mathbf x + \\mathbf u)}[\\log p(\\mathbf x + \\mathbf u, \\mathbf z) - \\log r(\\mathbf u|\\mathbf x) - \\log q(\\mathbf z | \\mathbf x + \\mathbf u)]$$\nHierarchical ANF\nANF[1]는 이를 한단계 더 일반화한 Hierarchical ANF를 제안한다. dequantization과 single augmentation이 아닌, augmentation latents $\\{z_i\\}_{l=1}^L$를 두고 각각의 latent에 hierarchy를 구성하는 방식이다.\n$$p(x, z-1, \u0026hellip;, z_L) = p(x|z_1, \u0026hellip;, z_L)\\prod^L_{l=1}p(z_l|z_{l+1}, \u0026hellip;, z_L) \\\\ q(z_1, \u0026hellip;, z_L|x) = \\prod^L_{l=1}q(z_l|z_1, \u0026hellip;, z_{l-1}, x)$$\nExperiments\nTable 1. Bits-per-dim estimates of standard benchmarks (the lower the better). (Huang et al., 2020)\nTable 1. Density modeling results in bits/dim (bpd). (Chen et al., 2020)\nTable 2. Evaluation on Inception Score (IS, the higher the better) and Fréchet Inception Distance (FID, the lower the better) (Huang et al., 2020)\nFigure 8. Left: comparison of linear and rescaled interpolations. Right: rescaled interpolation of input data (first and last columns). (Huang et al., 2020)\nANF[1]는 gaussian prior에서의 linear interpolation은 non-smooth transition을 포함하고 있다고 이야기한다. 이는 gaussian samples가 shell 근처에 중심적으로 분포해 있기 때문이기에, 이에 맞춘 rescaled interpolation이 필요하다는 것이다.\n$$h\u0026rsquo;(u, v, t) = \\frac{h(||u||, ||v||, t)}{||h(u, v, t)||}\\cdot h(u, v, t)$$\n이에 대한 비교는 ANF[1]의 Appendix A.에서 확인 가능하다.\nDiscusion\n사견:\n이번에는 augmented flow에 대해 알아보았다. 기존보다 정량적, 정성적 향상이 있었음을 확인했고, VAE와 동치인 case도 보였다. GAN, VAE, Flow라 불리던 stochastic model의 한 축이 통합된 현장이다.\n이 외에도 다음에 알아볼 논문에서는 diffusion, rad와 같은 접근까지 unifying 한 framework를 제안하기도 한다. 어쩌면 미래에는 GAN과의 연관성을 통해 major 확률 모델의 통합을 이뤄낼지도 모른다.\nrepresentation learning, unsupervised, probabilistic modeling 등 데이터의 표현에 대한 여러가지 연구가 있었지만, 그들을 엮어냈다는 점에서 특히 눈에 띄는 논문인 것 같다.\nReference\n[1] Huang, C., Dinh, L. and Courville, A. Augmented Normalizing Flows: Bridging the Gap Between Generative Flows and Latent Variable models. 2020. [2] Chen, J., et al. VFlow: More Expressive Generative Flows with Variational Data Augmentation. In ICML 2020. [3] Kingma, D. P. and Dhariwal, P. Glow: Generative Flow with Invertible 1x1 Convolutions. In NIPS 2018. [4] Ho, J. et al. Flow++: Improving flow-based generative models with variational dequantization and architecture design. In ICML 2019. [5] Zagoruyko, S. and Komodakis, N. Wide Residual Networks. 2016. [6] Vaswani, A., et al. Attention is all you need. In NeurIPS 2017. [7] Kingma, D. P. and Welling, M. Auto-encoding variational bayes. In ICLR 2014. [8] Dinh, L., Sohl-Dickstein, J. and Bengio, S. Density estimation using Real NVP. In ICLR 2017.\n","permalink":"https://revsic.github.io/blog/anfvf/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","Augmented Normalizing Flow","VFlow"],"title":"ANF, VFlow"},{"categories":["Bayesian"],"contents":" Glow: Generative Flow with Invertible 1x1 Convolutions, Kingma and Dhariwal, 2018, arXiv Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design, Jonathan Ho et al., 2019, arXiv Keyword: Bayesian, Normalizing Flow, Glow, Flow++ Problem: Inexpressiveness of engineered bijectives Solution: Invertible 1x1 convolution, variational dequantization, mixture of logistics Benefits: Lower bits/dim, better sample quality Weakness or Future work: - Series: Normalizing flow\nNormalizing flow, Real NVP [link] Glow, Flow++ [this] ANF, VFlow [link] i-ResNet, CIF [link] SurVAE Flows [link] Normalizing flow\nlatent variable model은 high-dimensional data로부터 내재된 패턴들을 축약한, 유의미한 latent space를 구성하고자 한다. 이는 주로 확률 모델로 구현되며, 크게 VAE, Flow와 같은 likelihood 기반의 모델과 GAN 부류의 모델로 구분할 수 있다.\nFlow의 경우 데이터 $x \\sim p_X^*(x)$에 대해 bijective sequence $\\{f_k\\}^L_{k=1}$를 통한 change of variables를 근간으로 한다. 자세한 정의는 이전 글을 따른다.\n$$z = f_L \\circ \\ \u0026hellip; \\ \\circ f_1(x) \\\\ \\log p_X(x) = \\log p_Z(z) + \\sum^L_{k=1}\\log\\left|\\det\\frac{\\partial f_k}{\\partial f_{k-1}}\\right| \\ \\ \\mathrm{where} \\ \\ f_0 = x$$\ntransform에 bijective라는 constraint가 붙은 만큼 몇 가지 이점을 갖는다.\nVAE의 경우 intractable posterior로 인해, variational inference를 통한 log-likelihood의 lower-bound 추정을 objective로 하지만, normalizing flow의 경우에는 change of variables를 통한 exact log-likelihood estimation과 inference가 가능하다.\n또한 그 과정에서 encoder, decoder가 별개의 네트워크가 아닌, 파라미터를 공유하는 하나의 네트워크로 구성되므로 memory efficient 한 모델링이 가능하다.\n이전 글에서 Rezende \u0026amp; Mohamed(2015)[1], RealNVP[2]로 물살을 탄 normalizing flow를 이번 글에서는 engineered bijective 관점에서 어떠한 발전이 있었는지 알아본다.\nGlow\nGlow[3]는 RealNVP[2]의 multi-scale architecture를 기반으로 더욱 풍부하고 다양한 engineered bijective를 하나의 flow block으로 구성한 모델이다.\n기존의 RealNVP[2]가 Affine coupling, Batchnorm의 두 개 layer를 하나의 flow block으로 구성했다면, Glow는 ActNorm, Invertible 1x1 convolution, Affine coupling 3개 layer를 하나의 flow block으로 구성한다.\nActNorm RealNVP[2]에서는 deep models가 학습 중 겪게 되는 여러 문제를 해결하고자 batch normalization을 도입하였다. 하지만 batch norm의 경우 batch size에 영향을 받고, 그 크기가 작아짐에 따라 성능이 절감된다. 특히나 image의 경우 tensor size가 커 memory에 많은 양의 batch를 구성하지 못할 때에 치명적일 수 있다.\n이에 Glow[3]에서는 activation normalization, 이하 actnorm을 제안한다. actnorm은 첫 번째 minibatch의 mean과 variance로 초기화한 parameter로 normalization을 진행한다. 이는 DDI(data-dependent initialization)을 따르고, 초기화된 이후에는 데이터와 독립된 일반적인 trainable parameter로 취급한다.\nBatchnorm이 data에서 연산한 running statistics를 통해 normalization을 진행했다면, actnorm은 첫 번째 batch에서 연산한 statistics로 초기화한 파라미터를, 이후에는 데이터에 독립적인 trainable parameter로 상정하고 normalization을 진행한다는 점에서 차이가 존재한다.\n물론 이렇게 학습된 parameter가 실제로 hidden state의 statistics를 따르지는 않는다.\n$[h\\times w \\times c]$의 image tensor가 주어진다면, actnorm은 channel dimension에서 작동한다.\n$$y \\leftarrow \\frac{x - \\hat\\mu}{\\sqrt{\\hat\\sigma^2 + \\epsilon}}, \\ \\ \\log\\left|\\det\\frac{\\partial y}{\\partial x}\\right| = -h \\cdot w \\cdot\\sum\\log\\sqrt{\\sigma^2 + \\epsilon}$$\nInvertible 1x1 convlution RealNVP[2]와 같은 기성 모델은 coupling layer의 활용으로 인해 일부 channel에 identity map이 적용되었고, 모든 channel에 transform을 적용하기 위해 고정된 permutation operation을 활용하였다.\nGlow[3]에서는 이 대체재로 invertible 1x1 convolution을 제안한다. invertible matrix를 근간으로 하는 linear projection은 어떤 basis로의 permutation으로 일반화되며, 1x1 conv는 이 과정에서 channel axis에 대한 일반화된 learnable permutation을 진행한다.\ninvertible 1x1 convolution의 log-determinant는 determinant of weight matrix로 귀결되며 다음과 같이 정리된다.\n$$\\log\\left|\\det\\frac{d \\mathrm{conv2D}(h; W)}{dh}\\right| = h \\cdot w \\cdot \\log\\left|\\det W\\right|$$\n문제는 weight matrix $W$의 determinant 연산은 $\\mathcal O(c^3)$의 cubic 연산이기 때문에 channel의 크기가 커짐에 따라 intractable 하다는 특성을 가진다.\nGlow[3]는 이를 위해 LU Decomposition을 제안한다. invertible matrix W를 두고, LDU factorized $L, D, U$를 trainable parameter로 가정한다. 그럼 non-zero diagonal matrix $D = \\mathrm{diag}(s)$에 대해 다음과 같이 weight matrix W를 재구성할 수 있다. (이 때 permutation P는 고정이다.)\n$$W = PL(U + \\mathrm{diag}(s))$$\n이에 log-determinant를 $\\mathcal O(c)$의 linear time에 연산해낼 수 있게 된다.\n$$\\log\\left|\\det W\\right| = \\sum \\log |s|$$\nAffine coupling 기존의 RealNVP[2]에서의 affine coupling에 몇 가지 trick을 제안한다.\n우선 zero initialization이다. coupling layer는 affine transform에 활용할 파라미터를 NN을 통해 연산해내는데, 이때 NN 이후 추가 convolution을 하나 더 두고, 이의 weight을 0으로 두어 학습 초기에 identity function이 되도록 강제한다. 이것이 very dep networks의 학습에 도움을 주었다고 한다.\n두 번째는 permutation에 관해서이다. Glow[3]는 invertible 1x1 convolution을 통해 permutation을 일반화하였으므로, RealNVP[2]와 같은 checkerboard pattern 형식의 mask가 큰 의미가 있지 않다. 따라서 Glow[3]에서는 단순히 절반의 channel을 split하고 concat하는 방식을 차용하였다고 한다.\nFlow++\nFlow++[4]의 저자는 Rezende \u0026amp; Mohamed, 2015[1], RealNVP[2], Glow[3]를 넘어선 여러 가지 normalizing flow에 관한 연구가 있었지만, 여전히 다른 generative model보다 표현력이 부족하다는 것을 느꼈다.\n그는 그 문제점으로 3가지를 들었다.\n1. uniform dequantization이 loss와 generalization의 suboptimal choice라는 것 2. affine coupling layer가 충분히 expressive 하지 않다는 것 3. coupling layer의 conditional network로 convolution은 충분히 powerful 하지 않다는 것\n그리고 다음에서 그 대체재를 소개하고자 한다.\nVariational dequantization 이미지나 음성 데이터의 경우에는 continuous signal을 discrete representation으로 바꿔 저장하고, 이를 모델링하게 되는데, 단순히 continuous density model을 이에 fitting 하면, 대부분의 probability mass가 discrete point에 치중되며 품질이 떨어지는 현상이 발생한다.\n이를 해결하기 위해 RNADE[5]에서는 dequantization을 제안했으며, 이는 uniform noise를 통해 data를 continous form으로 만들어 degenerate point로의 collapse를 방지하는 것이다.\n$$P_\\mathrm{model}(x) := \\int_{[0, 1)^D}p_\\mathrm{model}(x + u)du$$\n또한 다음 전개에 의해서 dequantized data $y = x + u$의 log-likelihood를 discrete data $x$의 lower-bound로 볼 수 있다.\n$$\\mathbb E_{y \\sim p_\\mathrm{data}}[\\log p_\\mathrm{model}(y)] \\\\ = \\sum_x P_\\mathrm{data}(x) \\int_{[0, 1)^D}\\log p_\\mathrm{model}(x+u)du \\\\ \\le \\sum_x P_\\mathrm{data}(x)\\log\\int_{[0, 1)^D}p_\\mathrm{model}(x+u)du \\\\ = \\mathbb E_{x\\sim P_\\mathrm{data}}[\\log P_\\mathrm{model}(x)]$$\n이를 통해 probability mass가 discrete point에 치중되고, degenerate mixture로 collapse 하는 현상을 막을 수 있었지만, 단순 unit hypercube $x + [0, 1)^D$로 모델링하기엔 uninformative 하고 unnatural 하다.\n따라서 variational dequantization에서는 dequantization noise distribution을 variational $q(u|x)$로 상정하고 lower bound를 objective로 학습시킨다.\n$$\\mathbb E_{x\\sim P_\\mathrm{data}}[\\log P_\\mathrm{model}(x)] \\\\ = \\mathbb E_{x\\sim P_\\mathrm{data}}\\left[\\log\\int_{[0, 1)^D}q(u|x)\\frac{p_\\mathrm{model}(x+u)}{q(u|x)}du\\right] \\\\ \\ge \\mathbb E_{x\\sim P_\\mathrm{data}}\\left[\\int_{[0, 1)^D}q(u|x)\\log\\frac{p_\\mathrm{model}(x+u)}{q(u|x)}du\\right] \\\\ = \\mathbb E_{x\\sim P_\\mathrm{data}, \\ u \\sim q(\\cdot|x)}\\left[\\log\\frac{p_\\mathrm{model}(x+u)}{q(u|x)}\\right]$$\n이때 variational distribution $q$는 flow-based model로 상정하여 $u = q_x(\\epsilon), \\ \\mathrm{where} \\ \\epsilon \\sim p(\\epsilon) = \\mathcal N(\\epsilon; 0, I)$로 둔다. 이후 likelihood는 change of variables로 estimation이 가능하고 $q(u|x) = p(q_x^{-1}(u))\\cdot|\\partial q_x^{-1}/\\partial u|$, lower bound objective는 다음과 같이 쓸 수 있다.\n$$\\mathbb E_{x \\sim P_\\mathrm{data}}[\\log P_\\mathrm{model}(x)] \\le \\mathbb E_{x \\sim P_\\mathrm{data}, \\ \\epsilon \\sim p}\\left[\\log \\frac{p_\\mathrm{model}(x + q_x(\\epsilon))}{p(\\epsilon)\\left|\\partial q_x/\\partial \\epsilon\\right|^{-1}}\\right]$$\n이에 발생하는 true likelihood와의 차는 $\\mathbb E_{x\\sim p_\\mathrm{data}}[D_{KL}(q(u|x)||p_\\mathrm{model}(u|x))]$이다. 이는 $q$를 uniform과 같은 inexpressive distribution을 상정했을 때 lower bound가 loose 해질 수 있음을 의미한다. 따라서 flow 기반의 $q$를 사용함으로써 더움 flexible 한 modeling이 가능하게 하였고, 실제로 train loss나 generalization에서 더 나은 성능을 보였다.\nImproved coupling layers 근래의 flow-based model은 대부분 affine coupling과 permutation layer을 활용했다. coupling layer의 경우 conditioning network $a_\\theta, b_\\theta$를 상정하여 입력 일부로부터 parameter를 설정, 이를 토대로 나머지 입력을 transform 한다.\n$$y_1 = x_1, \\ \\ y_2 = x_2 \\cdot \\exp(a_\\theta(x_1)) + b_\\theta(x_1)$$\nFlow++[4]의 저자들은 실험을 통해 더욱 expressive 한 coupling layer를 제안한다. 이는 mixture of logistics를 활용하여 invertible nonlinear transform을 가능케 한다.\n$$x \\mapsto \\sigma^{-1}(\\mathrm{MixLogCDF}(x;\\pi, \\mu, s)) \\cdot \\exp(a) + b \\\\ \\mathrm{where} \\ \\ \\mathrm{MixLogCDF}(x; \\pi, \\mu, s) := \\sum^K_{k=1}\\pi_i\\sigma((x - \\mu_i)\\cdot\\exp(-s_i))$$\n이 때 $\\{\\pi_i, \\mu_i, s_i\\}_{i=1}^K, a, b$는 모두 neural network로 parameterizing한다.\nExpressive conditioning architectures with self-attention 기존까지는 coupling layer에서 conditioning network로 convolutional layer를 주로 상정했다면, 이번에는 multihead self-attention 기반의 network(Vaswani et al., 2017[6])를 활용해본다.\nnetwork는 stack of blocks로 구성되고, 각 block은 아래와 같이 구성된 뒤 residual connection과 layer normalization을 통해 연결된다.\n$$\\mathrm{Attn = Input \\to Conv_{1x1} \\to MultiHeadSelfAttention \\to Gate}$$\n이때 $\\mathrm{Gate}$는 gated activation unit을 의미한다. network는 input tensor를 여러 개의 block에 forward하고, 마지막에 convolutional layer를 통해 coupling에 필요한 파라미터 수 만큼 channel을 늘리게 된다.\nExperiments\nTable 1: Unconditional image modeling results in bits/dim. (Ho et al., 2019)\nRealNVP[2], Glow[3], FlowW++[4]로 넘어오는 과정이 정량적으로 잘 나타났다.\nTable 2: CIFIAR10 ablation results after 400 epochs of training. (Ho et al., 2019)\n또한 실제로 ablation study를 통해 component별 향상치도 확인할 수 있다.\nFigure 6: Manipulation of attributes of a face. (Kingma \u0026amp; Dhariwal, 2018)\nDiscusion\n(사견)\nFlow는 bijective라는 constraint로 인해 기존의 nonlinearity를 근간으로 하는 expressiveness를 충분히 누리지 못했다. 그렇기 때문에 Flow 발전 초기에는 더욱 bijective block을 충분히 engineering 하여 표현력을 높이고자 하는 연구가 많았던 것 같다.\n그 과정에서 actnorm, invertible 1x1 convolution, logistic coupler, variational dequantization 등 다양한 블럭이 나왔고, 이번 기회에 이를 소개하고자 했다.\n이후에는 i-ResNet, ResFlow 등에서 residual network를 inversion 하는 시도 등을 통해 최대한 많은 feature에 nonlinearity를 활용하고자 하였고, 본격적으로 vae와의 통합을 위한 발판을 마련하기도 한다.\nReference\n[1] Rezende, D. J. and Mohamed, S. Variational inference with normalizing flows. In ICML 2015. [2] Dinh, L., Sohl-Dickstein, J. and Bengio, S. Density estimation using Real NVP. In ICLR 2017. [3] Kingma, D. P. and Dhariwal, P. Glow: Generative Flow with Invertible 1x1 Convolutions. In NIPS 2018. [4] Ho, J. et al. Flow++: Improving flow-based generative models with variational dequantization and architecture design. In ICML 2019. [5] Uria, B., Murray, I. and Larochelle, Hugo. RNADE: The real-valued neural autoregressive density-estimator. In NeurIPS 2013. [6] Vaswani, A. et al. Attention is all you need. In NeurIPS 2017.\n","permalink":"https://revsic.github.io/blog/glowflowpp/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","Glow","Flow++"],"title":"Glow, Flow++"},{"categories":["Bayesian"],"contents":" Variational Inference with Normalizing Flows, Rezende and Mohamed, 2015, arXiv Density Estimation using Real NVP, Dinh et al., 2017, arXiv Keyword: Bayesian, Normalizing Flow, Real NVP Problem: inflexibility of variational posterior Solution: probabilistic modeling with bijective and change of variables Benefits: simple sampling, exact log-likelihood estimation Weakness or Future work: determinant, inverse and architecutral constraint Series: Normalizing flow\nNormalizing flow, Real NVP [this] Glow, Flow++ [link] ANF, VFlow [link] i-ResNet, CIF [link] SurVAE Flows [link] Variational Inference\n우리는 데이터에 대한 insight를 얻고자 할 때 probabilistic modeling을 통해 데이터가 어떤 분포를 가지는지 추정한다. 그 과정에서 latent variable을 도입하기도 하고, marginalize 과정에서 발생하는 적분의 intractability로 인해 variational inference를 활용해 posterior를 known distribution으로 근사하기도 한다.\n$$\\log p_\\theta(x^{(i)}) = D_{KL}(q_\\phi(z|x^{(i)})||p_\\theta(z|x^{(i)})) + \\mathbb E_{q_\\phi}\\left[ \\log \\frac{p_\\theta(x, z)}{q_\\phi(z|x)} \\right]$$\n이 중 연산이 가능한 두번째 RHS term만을 발췌해 variational lower bound라 부른다.\n$$\\log p_\\theta(x^{(i)}) \\ge \\mathbb E_{q_\\phi}\\left[\\log\\frac{p_\\theta(x, z)}{q_\\phi(z|x)}\\right] = \\mathbb E_{q_\\phi(z|x^{(i)})}\\left[ \\log p_\\theta(x^{(i)}|z) \\right] - D_{KL}(q_\\phi(z|x^{(i)})||p_\\theta(z))$$\nRezende \u0026amp; Mohamed(2015)[1]에서는 성공적인 variational inference를 위해 1) derivatives of log-likelihood $\\nabla_\\phi\\mathbb E_{q_\\phi(z)}\\left[\\log p_\\theta(x|z)\\right]$ 연산의 효율성과 2) approximate posterior $q(\\cdot)$의 유연함이 필요하다 이야기한다.\n전자의 경우에는 VAE[2]에서와 같이 Monte carlo approximation과 reparametrization을 통해 gradient를 연산하는 방식을 취할 수 있다.\n$$z \\sim \\mathcal N(z|\\mu, \\sigma^2) \\Leftrightarrow z = \\mu + \\sigma \\epsilon, \\ \\ \\epsilon \\sim \\mathcal N(0, 1) $$\n하지만 이렇게 되면 variational posterior가 gaussian과 같은 분포로 한정되고, 이 경우 true posterior로의 근사가 어려울 수 있다.\n따라서 이상적인 variational distribution $q_\\phi(z|x)$는 true posterior의 근사를 위해 highly flexible해야 하고, 저자는 그 solution으로 normalizing flow를 제안한다.\nNormalizing Flow\nNormalizing flow는 invertible map을 통해 probability density를 순차적으로 변형시켜 나가는 모델이다. 각각의 invertible map은 change of variables를 통해 initial density를 변형시켜 나가고, density의 변환 흐름, \u0026lsquo;flow\u0026rsquo;를 표현하게 된다.\nChange of variables\n확률변수 $X \\in \\mathbb R^d$의 CDF $F_X$와 어떤 단조함수 $g: \\mathbb R^d \\to \\mathbb R^d$에 대해 $Y=g(X)$이면, 다음이 성립한다.\n$$F_Y(y) = P(Y \\le y) = P(g(X) \\le y) = P(X \\le g^{-1}(y)) = F_X(g^{-1}(y))$$\n이때 양변을 미분하면 $Y$에 대한 density를 구할 수 있게 되고, sample에 대한 exact log-likliehood의 연산이 가능해진다.\n$$f_Y(y) = f_X(g^{-1}(y))\\left|\\det\\frac{\\partial g^{-1}}{\\partial y}\\right| \\\\ \\log f_Y(y) = \\log f_X(g^{-1}(y)) + \\log\\left|\\det\\frac{\\partial g^{-1}}{\\partial y}\\right|$$\nFinite Flows\nNormalizing flow는 simple invertible map을 순차적으로 합성해 나가며 initial density를 임의의 complex distribution으로 만들어나간다.\ninitial random variable $z_0$와 distribution $q_0$에 대해 sequence of invertible map $f_1, \u0026hellip;, f_K$을 chain으로 구성하면 $x=z_k$의 sampling과 exact log-likelihood의 연산이 가능하다.\n$$z_K = f_K \\circ \\ \u0026hellip; \\ \\circ f_2 \\circ f_1(z_0) \\\\ \\ln q_K(z_K) = \\ln q_0(z_0) - \\sum^K_{k=1}\\ln\\left|\\det\\frac{\\partial f_k}{\\partial z_{k-1}}\\right|$$\n이때 initial distribution $q_0(z_0)$부터 $z_k = f_k(z_{k-1})$로 구성된 path를 flow라 한다.\n이는 LOTUS(law of unconscious statistician)으로도 불리며, 이 경우 $q_K$로 구성된 expectation을 분포에 대한 정보가 없이 연산 할 수 있게 된다. 이를 활용해 posterior를 모델링 하면 최종 분포상 제약이 없어 보다 유연한 근사가 가능하다.\n또한 기존의 확률 모델이 complexity를 높이기 위해 nonlinear transform을 활용하면서 invertibility를 포기하고, ELBO를 통해 log-likelihood의 lower bound를 추정했다면,\nnomarlizing flow는 NN을 활용한 engineered linear transform을 순차적으로 적용해 나가며 exact log-likelihood의 연산과 single forward-pass의 sampling이 가능하다는 것에 의의가 있다.\nReal NVP: Modeling bijectivity\nNormalizing flow는 여러가지 이점을 가지는 대신에 determinant와 inverse map이 tractable 해야 한다는 architecture의 constraint를 가진다.\nRealNVP[3]는 이러한 constraint에 대해 well-engineered transform을 제안한다.\nCoupling layers determinant와 jacobian을 고차원 데이터와 함수에 대해 연산한다는 것은 일반적으로 굉장히 computationally expensive하다. 이를 위해서 RealNVP[3]가 한 선택은 bijective에 제약을 가하여 jacobian을 triangular matrix로 구성하는 것이다.\nAffine coupling layer은 D-dimensional input $x \\in \\mathbb R^D$에서 $d \\lt D$의 일부 $x_{1:d}$를 활용하여 나머지 $x_{d+1:D}$를 affine transform한다.\n$$y_{1:d} = x_{1:d} \\\\ y_{d+1:D} = x_{d+1:D} \\cdot \\exp(s(x_{1:d})) + t(x_{1:d})$$\n이때 $s$와 $t$는 NN으로 구성한 scale과 translation function $\\mathbb R^d \\mapsto \\mathbb R^{D-d}$이다.\n이 경우 jacobian matrix는 lower-triangular matrix로 구성되고, log-determinant는 scale의 합으로 연산된다.\n$$\\frac{\\partial y}{\\partial x} = \\left[ \\begin{matrix} \\mathbb I_d \u0026amp; 0 \\\\ \\frac{\\partial y_{d+1:D}}{\\partial x_{1:d}} \u0026amp; \\mathrm{diag}(\\exp(s(x_{1:d}))) \\end{matrix} \\right] \\\\ \\log\\left|\\det\\frac{\\partial y}{\\partial x}\\right| = \\sum s(x_{1:d})$$\n이뿐만 아니라 coupling 기반의 layer는 inverse도 쉽게 연산해낼 수 있다.\n$$x_{1:d} = y_{1:d} \\\\ x_{d+1:D} = (y_{d+1:D} - t(y_{1:d})) \\cdot \\exp(-s(y_{1:d}))$$\n1.1. Masked Convolution\nRealNVP[3]에서는 partitioning을 binary mask를 통해 일반화 한다.\n$$y = b \\odot x + (1 - b) \\odot \\left( x \\odot \\exp(s(b \\odot x)) + t(b \\odot x) \\right)$$\ncoupling layer 특성상 input의 일부에는 transform이 이뤄지지 않기 때문에, 연속된 coupling layer를 구성할 때는 binary mask를 alternating 하면서 모든 feature가 transform 될 수 있도록 구성한다.\nFigure 3: Masking schemes for affine coupling layers. (Dinh et al., 2017)\nRealNVP[3]에서는 checkerboard pattern의 mask를 상정했으며 even index와 odd index를 번갈아 가며 trigging하는 방식으로 binary mask를 구성한다.\nMulti-scale architecture RealNVP[3]는 input의 spatial size와 channel size 사이의 tradeoff를 위해 squeezing을 활용한다. 2x2xC의 subsquare를 1x1x4C로 squeezing 한다면 channel을 4배가량 늘릴 수 있게 된다.\nRealNVP[3]는 multiple squeezing operation과 inter-coupling layer를 통해 여러 scale에서의 latent를 뽑고자 했다. 이때 전체 dimension이 유지되는 normalizing flow의 특성상 computational, memory cost는 고수준에서 유지되고, 부담을 줄이기 위해 각 scale에서 절반의 feature를 factorizing 한다.\n$$h^{(0)} = x \\\\ (z^{i+1}, h^{i+1}) = f^{(i+1)}(h^{(i)}) \\\\ z^{(L)} = f^{(L)}(h^{(L-1)}) \\\\ z = (z^{(1)}, \\ \u0026hellip; , z^{(L)})$$\n이 경우 latent z는 명시적으로 coarser scale의 정보와 finer scale의 정보를 분리하여 다룰 수 있게 된다. 이는 RealNVP[3]의 Appendix D.에서 확인 가능하다.\nFigure 4: Composition schemes for affine coupling layers. (Dinh et al., 2017)\n또한 intermediate representation을 직접 활용하기 때문에 gradient의 전달과 학습이 용이하다는 장점을 가진다.\nBatch normalization training signal의 효율적인 전파를 위해 여러 모델은 batch normalization을 활용한다. RealNVP[3]에서는 running statistics를 활용하여 normalization을 구성한다.\n$$x \\mapsto \\frac{x - \\tilde \\mu}{\\sqrt{\\tilde\\sigma^2 + \\epsilon}}$$\n이 경우 linear rescaling과 동일하므로 jacobian은 $\\sigma$의 곱으로 구성된다.\n$$J = \\left(\\prod_i(\\tilde\\sigma^2 + \\epsilon)\\right)$$\nTraining, Sampling\n이렇게 bijective를 활용한 invertible map $g: X \\to Z$을 구성했다면, $x \\in X$의 입력에 대해 forward pass로 latent $z = g(x) \\in Z$를 구하고, 해당 latent를 통해 log-likelihood를 추정한다.\n$$\\log p_X(x) = \\log p_Z(z) + \\log\\left|\\frac{\\partial g}{\\partial x}\\right|$$\n원문에서는 prior $p(z)$를 gaussian으로 상정하였고, 추정된 log-likelihood를 maximize 하는 방식으로 네트워크를 학습시킨다.\nsampling의 경우 prior에서 sampling한 noise $z \\in Z$를 inverse pass하여 $x = g^{-1}(z) \\in X$ 바로 사용할 수도 있고, 데이터로부터 latent를 구하여 interpolation 등 후처리 후 사용할 수도 있다.\n$$z \\sim p(z) \\mapsto g^{-1}(z) \\in X$$\nResults\nTable 1: Bits/dim results. (Dinh et al., 2017)\nFigure 6: Manifold generated from four examples in the dataset. (Dinh et al., 2017)\nDiscusion\n(사견)\nNormalizing flow의 시작이 Rezende \u0026amp; Mohamed (2015)[1]는 아니었다. density estimation을 위해 Tabak \u0026amp; Vanden-Eijnden (2010)[4], Tabak \u0026amp; Turner (2013)[5]에서 제안이 되었고, 딥러닝을 활용한 probabilistic modeling으로 Rezende \u0026amp; Mohamed (2015)[1]에서 크게 유명해졌다.\n비록 determinant와 inverse의 tractability로 인한 architectural constraint를 가지고 있지만, sampling이 single-forward pass로 가능하고, exact log-likelihood의 연산이 가능하다는 점에서 충분한 매력을 가진 모델이다.\n추후 bijective에 대한 연구, VAE와의 상관성, 통합 가능성이 연구됨에 따라 더 많은 이야기가 남은 모델이므로 관심 가지고 봐도 좋을 것 같다.\nReference\n[1] Rezende, D. J. and Mohamed, S. Variational inference with normalizing flows. In ICML 2015. [2] Kingma, D. P. and Welling, M. Auto-encoding variational bayes. In ICLR 2014. [3] Dinh, L., Sohl-Dickstein, J. and Bengio, S. Density estimation using Real NVP. In ICLR 2017. [4] Tabak, E. G. and Vanden-Eijnden, E. Density estimation by dual ascent of the log-likelihood. Communications in Mathematical Sciences, 2010. [5] Tabak, E. G. and Turner, C. V. A family of nonparametric density estimation algorithms. Communications on Pure and Applied Mathmatics, 2013.\n","permalink":"https://revsic.github.io/blog/realnvp/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","Real NVP"],"title":"Normalizing Flow, Real NVP"},{"categories":["Writing"],"contents":"올해로 1년 좀 넘게 음성 합성 리서치 업무를 보고 있다. 이번 글에선 19년 9월, 입사부터 20년 말까지 한 활동을 조심히 정리해보려 한다.\n[대학교 3학년의 2020] On 2020 as student [딥러닝 리서처의 2020] 현재 글\n입사 당시 입사 당시 우리 회사는 설립된 지 반년 정도 된 학부생 스타트업이었다.\n처음에는 대표님의 요청으로 비전 프로젝트 외주를 진행했었고, 9월에 입사하여 본격적으로 음성 업무를 보기 시작했다.\n당시 회사 인원은 나 포함 5명이었고, 각자 역할이 부여된 상황이었다. 그중 나는 TTS 리서처로 들어왔다.\n당연히 사수는 없었다. TTS 연구 개발 프레임워크는 리팩토링이 시급해 보였고, 그를 기반으로 딥러닝 리서치를 진행하는 과정이 확립되어 있지 않았다.\n모든 것을 처음부터 시작해야 하는 상황이었다. 하지만 이제 막 2학년이 끝난 학부생은 모든 게 패기로웠다.\n딥러닝 리서처 업무 음성 합성 리서치의 목표는 합성된 음성의 발음이 또렷해야 하고, 자연스러우면서, 음질이 좋아야 한다. 이후에는 다국어, 다화자, 감정 등 추가 기능 지원이 들어간다.\n논문 리뷰\n회사 들어와서 가장 먼저 한 리서치 업무는 음성 합성 논문 리스트를 만들고 쭉 리뷰 한 것이었다.\n처음 입사했을 때에는 푸리에 변환이 뭔지도 모르고 시작했다. 그냥 이렇게 저렇게 만든 스펙트로그램이란 피쳐가 있고, 딥러닝 모델이 텍스트에서 스펙트로그램으로의 매핑을 학습한다는 정도만 나이브하게 알고 있었다.\n신호처리 공부도 해야 했고, 딥러닝 모델 논문도 봐야 했다. 그렇게 1년 동안 대략 60편 정도의 논문을 보고 20개 가까이 구현해본 것 같다.\n입사 전에도 그랬지만, 시작부터 다독을 목표로 했다. 리뷰가 진행된 논문이던, 안 된 논문이던, 메이저 학회에 통과한 논문이던, 그저 arXiv에 올라온 글이던 가리지 않았다.\n논문 볼 때 정리했던 내용\n논문을 보면 항상 5가지 항목에 대해서 정리했다.\n어느 분야에서 이전 논문들에서 어떤 문제점을 발견했고 어떤 해결방법을 제시했으며 이때 생기는 이점과 발견되었거나 예상되는 약점은 무엇인지 그렇게 해서 학계의 흐름을 쫓고 있고, 올해 말부터는 이제 본인만의 실험을 기획하기 시작했다.\n딥러닝에 관심을 가지고 있던 적당한 학부생이었고, 어디서 연구하는 방법이란 것을 배워본 적이 없었기 때문에 모든 게 서툴렀다.\n논문을 볼 때 어느 것이 중요하고, 어떻게 쫓아야 하고, 무엇을 이야기하고 싶은건지, 저 5가지 질문을 확립하는데에도 꽤 시간이 걸렸던 것 같다.\n신호처리 관련 공부\n문제는 어느 시점부터, 음성 분야 논문이 단순 스펙트로그램을 넘어서 여러 가지 피쳐나 기성 신호처리 알고리즘들을 차용하여 성능을 높이는 시도가 등장했다는 것이다.\n따로 물리나 신호처리학을 공부해본 적이 없었기 때문에, 어디서부터 무엇을 공부해야 할지도 몰랐고, 처음부터 공부해서 이른 시일 안에 현업에 사용할 자신도 없었다.\n그래서 모르는 단어가 나오면, 탑다운 방식으로 구글에 단어를 검색하고, 대학 강의에 쓰인 pdf 파일을 보면서 공부했다.\n(생각보다 검색하면 잘 나옴)\n그러다 보니 틀리게 이해한 내용도 많았고, 이곳저곳 빈 곳도 많았다.\n하지만 탑다운도 결국 수렴한다고, 결국에는 틀린 이해를 정정하고, 꽤 많은 빈 곳을 채웠다는 생각이 든다.\n모델 구현\n기존에는 tensorflow를 많이 활용했었다. 하지만 회사에서는 pytorch를 사용하고 있었고, 이에 맞추기 위해 하루에서 이틀 정도는 파이토치에 적응을 좀 했던 거 같다.\n모델을 구현하기에 앞서 원저자가 구현한 오픈소스 코드가 있는지 확인했다.\n처음에는 하루 정도면 모델 하나 구현할 수 있다고, 오픈소스 찾아볼 게 있냐고 처음부터 짜는 객기를 부렸지만,\n딥러닝 코드는 버그를 잡기 어렵고, 이미 구현된 코드가 있으면 I/O 정도만 수정해서 바로 실험해볼 수 있으므로 오픈소스를 참고해서 회사 스타일에 맞게 정리하는 게 빠르다. 물론 라이센스 확인은 필수다.\n또한, 논문에 기재되지 않은 디자인 초이스나 휴리스틱이 존재할 수 있으므로 원작자의 코드 존재 여부를 우선 파악하는 것이 맞는 것 같다.\n만약 이해되지 않는 디자인이나, 기재되지 않은 하이퍼 파라미터 정보가 있다면 레딧에 물어보는 것도 괜찮은거 같다.\n(생각보다 관심을 많이 받아서 신기했음)\n실험, 문제점, 해결책\n이렇게 구현이 끝난 모델은 사전에 선정한 데이터셋으로 학습해 보고, 여러 지표를 통해 모델을 평가했다.\n문제는 생성된 음성은 원본과 1대1로 비교하는 것이 무의미하다. 음의 높낮이가 다르더라도 충분히 자연스러울 수 있고, 파형이 다르더라도 같은 발음 성분을 가지고 있을 수 있다.\n이러다 보니 1대1로 비교하는 것은 무의미하고, 길이가 다른 시퀀스의 유사도나, ASR 모델을 활용하여 의미 있는 평가를 자동화하기 위한 여러 추가 연구도 진행했었다.\n그렇게 모델을 평가하고 나면 문제점이 나타난다. 이 모델은 발음을 못 한다, 이 모델은 음질이 안 좋다. 등등 그럼 기존까지 관찰된 여러 모델의 현상을 통해 단점을 커버하기 위한 추가 실험을 진행한다.\n아직은 딥러닝이라는 분야가 특정된 데이터셋과 컴퍼넌트의 상호작용을 연역적으로 분석하기 어려우므로 현상과 실험적인 접근이 최선인 것 같다는 생각이 든다.\n그래서 조금 답답하기도 하다.\n연구하는 방법을 배운 기분\n위에 엄청 대단한 거 마냥 글을 썼지만, 사실 당연한 연구 루틴이었을지도 모른다.\n앞서 이야기했듯, 나는 그냥 딥러닝에 관심이 있던 학부생이었고, 연구라는 것을 해보거나 배워본 적이 없기 때문에 1년 동안은 정말 벽에 부딪치며 연구하는 방법을 배운 거 같다.\n실제로 처음에는 그냥 성능을 높이는 게 목적이니 닥치는 대로 논문을 읽고, 시간 되는 대로 구현하고, 뭐가 안되면 모델 잘못이네, 수정은 하이퍼 파라미터 튜닝하는 정도였다.\n그러다 이제 타임라인이 현재에 도달해서, 과거 논문을 구현하는 것이 아니면 추가로 볼 논문이나 모델이 없는 시점에 왔다. 이제는 모델 탓만 할 것이 아닌, 어떤 문제가 있고, 어떻게 해결해야 할지에 대한 고민을 해야 하는 상황이다.\n올해 말이 되어서야 나는 가설이라는 걸 세워보고, 실험을 통해 증명하고, 개선하는 일련의 프로세스를 확립해서 업무에 적용해 보고 있다.\n그 과정에서 평가 지표도 자동화했고, 컴퍼넌트랑 지표의 상관성, 현상과의 연관성도 하나씩 알아보고 있다.\n결과를 보는 그 과정이 재미로 다가왔다. 이제야 길이 환해진 느낌이 든다.\n엔지니어링 업무 입사해서 연구 관련 업무만을 볼 수는 없었다.\n딥러닝 프레임워크\n딥러닝 모델 개발은 생각보다 여러 가지 코드를 수반한다.\n단순 텍스트 파일과 wav 파일로 이뤄진 데이터를 전처리하여 저장하기 위한 코드도 필요하고,\n저장된 데이터를 불러와 모델에 전달, loss를 계산하여 업데이트하는 학습 과정,\n학습이 얼마나 잘 되어 가고 있는지, 모델이 어느 정도 수준을 성취했는지 기록하는 과정,\n마지막으로 모델을 통해 서비스를 작동시킬 수 있도록 캡슐화시키고 배포하는 과정 등이 있다.\n나는 개발, 학습, 기록, 캡슐화 정도의 과정을 맡았고, 전처리, 후처리, 서비스 개발 및 배포 과정은 다른 분이 맡았다.\n이 중에서 배포 과정을 뺀 모델 개발 전 과정을 하나의 구조로 엮은 프레임워크가 있었는데,\n코딩 컨벤션이나 문서화도 따로 되어 있지 않았고, 깃은 단순 코드 보관용, 모델 캡슐화는 코드 전체와 체크포인트를 복붙하여 압축파일(?)로 저장하는 구조로 되어 있었다.\n9월에 입사한 나는 회사 규모가 커졌을 때, 이 모든 코드가 레거시로 남을게 뻔히 보여 더 커지기 전에 갈아엎을 것을 제안했고, 팀장님도 이에 수긍하셔 11월까지 3개월간의 대규모 리팩토링에 들어간다.\n협업 약속\n가장 먼저 제안한 것은 브랜치, PR, 코드 리뷰의 3가지 과정이다.\n기존까지 모든 코드는 마스터로 들어가고 있었고, 혼자 개발하고 계셨기 때문에 브랜치나 PR의 개념이 없었다.\n이젠 둘이 개발해야 하는 상황이고, 마스터는 항상 stable한 상태로 두어야 한다는 전제를 깔았다. 그러고 나니 브랜치, PR, 코드 리뷰는 당연히 쫓아오는 과정이었다.\n또 하나는 문서화를 제안했다. 당장 리팩토링을 하려고 보니, 음성 합성 지식이 전무했던 나에겐 주석 하나 없는 코드가 어떤 역할을 하는지 몰랐다.\n당시에는 회사에 오래 있을지 모르는 상황이었기에, 다음 사람이 오면 똑같은 일이 일어날 것이고, 이제는 코딩 컨벤션과 주석을 의무적으로 달아야 한다고 전달했다.\n의견은 모두 받아들여졌고, 가장 근간이 되는 토대를 확립하고 나서야 리팩토링을 진행할 수 있었다.\n리팩토링\n가장 먼저 한 것은 각 과정에 맞게 레이어를 분리한 것이다.\n모델 클래스를 추상화하고, 이를 토대로 학습, 기록, 추론 과정을 어플리케이션 레이어로 분리했다.\n모델을 개발하면 더 이상 복사 붙여넣기 없이, hyper-parameter와 체크포인트만 가지고 모델을 작동시킬 수 있게 되었다.\n딥러닝 컴퍼넌트 중 중복된 코드는 분리하고, 어텐션 모듈같이 추상화가 요구되는 것들은 레이어를 하나 더 두었다.\n문제는 전처리 코드였는데, 이 부분은 음성 합성 지식이 전무한 나에겐 함부로 건드릴 수 없는 부분이었다. 결국 전처리 레이어를 두고, 어플리케이션에서 사용 가능하게 두되, 내용물은 레거시 코드에서 가져온 것을 래핑 해둔 정도로 놔둬야 했다.\n쓰다 보니 정말 당연한 리팩토링 수순을 밟았지만, 그렇게 만들어진 당시의 프레임워크는 정말 간결했고, 개발자 친화적이었다.\n돌고 돌아\n하지만 리팩토링된 프레임워크는 1년이 된 시점에서 망가지기 시작했다.\n회사는 바빴고, 코드 퀄리티가 떨어지더라도 당장에 작동하는 듯 보이는 코드가 필요했다.\n처음과 달리 코드 리뷰는 약식화 되어 갔고, 코드에 구멍이 나기 시작했다. 점점 핫픽스 브랜치가 늘어났고, 원인과 여파의 분석 없이 당장 필요한 부분만 작동하면 머지를 해야 했다.\n한 1년 즈음 까지는 나라도 붙잡고, 나라도 리뷰 열심히 해야지 하고 이런저런 리뷰를 남겼지만, 어느 순간부터 나도 포기했다.\n회사는 결국은 돈을 벌어와야 했고, 회사가 요구하는 연구 방향이나 개발 방향이 설정된다. 급하다는 이유로 언제 터질지 모르는 구멍을 보고도 모른 척 하게 된 것이다.\n이제는 프레임워크가 거의 제구실을 하지 못한다.\n작동하는 모델은 상용화된 것 몇 개 뿐이고, 연구용으로 남긴 모델은 작동하지도 않는다. 중간에 experimental feature라고 분리도 해봤지만, 이젠 마스터 브랜치의 모델도 돌아가는 것은 몇 개 없다.\n그 외에 학계의 움직임에도 영향을 받았다.\n이젠 기성 신호처리 기법들이 딥러닝과 연계되어 들어왔고, 프레임워크는 그에 필요한 새로운 피쳐나 출력물들까지 모두 처리할 수 없었다.\n입출력 파이프라인은 난잡해졌고, 결국 안 좋은 의미의 레거시로의 길을 걷고 있는 것 같았다.\n앞으로\n올 11월 즈음, 나는 더 이상 가면 되돌릴 수 없다는 걸 깨달았다.\n하지만 새로운 서비스를 준비하고 있던 팀에는 그걸 모두 뜯어고칠 시간이 없었다. 매일 새로운 실험을 통해 모델을 개선해야 했고, 모델 변형, 실험, 정리, 새 실험 기획만 하다가도 날이 저물었다.\n결국 이번 모델 개발이 끝나면, 기간을 잡고 리팩토링을 하거나 새로운 프레임워크를 구성하자는 이야기를 꺼냈다.\n이다음에 프레임워크를 재구성하게 된다면, 그때는 지금과 다를 수 있을지 의문이 들기는 한다.\nCUDA까지 내려갔다 오면 음성은 보통 초당 16k, 22k, 44k 정도의 프레임을 샘플링 하는데, 19년 말, 20년 초까지만 해도 이 프레임 수에 합성 시간이 비례했다.\n음성 길이가 길어지면 합성 시간도 길어졌고, 1초의 음성을 만드는데 대략 10초 정도 걸렸던 거 같다.\n당연히 실시간 서비스에 사용하기는 어려웠고, 프레임 수에 합성 시간이 비례하지 않는 모델을 찾아봤지만, 음질이 좋지 않아 결국 돌아오게 되었다.\n모델 가속화\n올해 초 모델을 가속화 하라는 특명이 떨어졌다. 대략 1초 합성에 1초 언저리 즈음 걸리도록\n여러 가지 찾아봤다. TensorRT, TorchScript JIT, ONNX 등등\n하지만 공통적인 문제가 있었다.\n기본적으로 당시 음성 합성 기술은 대부분이 하나의 프레임을 만들고, 해당 프레임을 토대로 새로운 프레임을 만드는 자기 회귀(autoregressive) 방식으로 작동하고 있었고, 언제 회귀를 끝낼지는 동적으로 판단하기 때문에\niteration 수가 정해져 있어야 하고, 자기 회귀 없이 forwarding만을 지원하는 가속화 도구 대부분을 사용할 수 없었다.\n모델을 분리하여, 병목이라도 가속화 해보려 했지만, 극적인 성능 향상 없이 대부분 1.7배, 2배 정도만 빨라졌다.\n목표는 10배이고, 상용 프레임워크는 불가능했기에, 결국 눈을 질끈 감고 CUDA 프레임워크를 개발하기로 했다.\n결국 CUDA\n팀 내에서 CUDA를 다룰 줄 아는 사람은 없었기에, 급하게 CUDA 서적을 구매해 예시 코드 몇개 적어보고 가속화 작업에 착수했다.\n결론부터 이야기하면, 대략 2주 만에 7배 빠른 추론 가속화용 CUDA C++ 프레임워크를 개발해냈다.\n내 손으로 텐서플로를 만들어 본다는 기분으로 시작했다.\nCUDA 메모리를 추상화하고, shape과 blob으로 구성된 텐서 구조체를 설정하고, 텐서에서 작동하는 여러 연산을 CUDA 커널로 구현했다.\n이후 문제의 모델을 C++에서 재구현하고, 파이토치 체크포인트에서 weight을 불러올 수 있는 기능을 추가했다.\n그렇게 만든 CUDA 프레임워크는 처음에 PyTorch보다 느렸다. 당시 야근을 하고 있었는데, 팀장님이랑 같이 한숨부터 쉰 기억이 있다.\n이제 하나씩 최적화를 시작했다. 그 중 몇 가지만을 소개하려 한다.\n가장 먼저 한 것은 TensorView를 만든 것이었다.\nreshape, transpose나 slice의 경우에는 값의 수정 없이 tensor를 보는 관점만 바뀐 것인데, 연산 과정에 매번 값을 복사하여 새로운 Tensor를 만드는 것은 비효율적이다. 따라서 같은 메모리를 공유하되, 값은 수정하지 못하고, stride나 shape만을 수정 가능한 view를 두는 것이 좋다.\n두 번째는 메모리 매니저를 따로 둔 것이다.\n자기 회귀(AR) 모델처럼 연산이 가볍지만, 반복이 많은 경우에는, 프로파일링을 해보면 연산보단 메모리의 할당과 해제에 병목이 걸리는 경우가 많았다.\n당시에 힙 메모리와 malloc 관련 공부를 하고 있었고, 메모리 관리 기법에서 영감을 얻었다.\nCUDA 에서 할당받은 메모리는 사용 직후 바로 반환하기보다는, 크기별로 분류해 두었다가, 메모리 요청이 왔을 때 적절한 메모리가 있으면 CUDA를 안 거치고 반환, 아니면 CUDA 에서 추가 할당받는 식으로 매니저를 구성해서 시간을 많이 줄일 수 있었다.\n그렇게 해서 총 7배 정도가 빨라졌고, 대략 1.5초에 1초 음성 정도를 만들었다.\n이후에 pybind11 활용해서 파이썬으로도 매핑하고, C++ 개발자 아니어도 쓸 수 있게 구성을 해놨지만\n여러 이유로 프로젝트는 폐기되고, 죽은 기술이 되었다.\n회사에 묶여서 공개하지 못하는 게 아쉽기도 하다.\nCUDA 개발 정리하면서\nCUDA 개발하면서 그래도 느낀 점이 좀 있었다.\n왜 torch에는 view와 reshape이 따로 있을지, contiguous가 필요한 이유가 뭘지, 왜 채널 크기는 32의 배수로 설정되는 것인지 등등 실상은 많은 디자인이 GPU와 CUDA 에 의해 결정되고 있었다.\n딥러닝 하는 분들한테 추천해볼 법한 프로젝트였던 것 같고, 죽은 기술로만 두는 것이 아쉬워 이번 겨울에 개인적으로 러스트와 rustacuda를 통해 재구현해 볼 생각이다.\n정리 다사다난한 한 해였다. TTS, 보코더 연구부터 프레임워크, CUDA 개발까지 여러 가지 해본 것도 많았다.\n회사 인원도 거진 20명에 가까워지고 있고, 팀과 역할도 더욱 세분되어 동아리처럼 시작했던 것이 더욱 회사 같아졌다.\n내년에 목표가 있다면, 지금 정리 중인 모델을 마무리 짓고 개인적으로 논문도 한 편 써 보고 싶다.\n한 해를 잘 정리한 거 같아 후회는 없다. 내년에도 딱 이만큼만 했으면 좋겠다.\n","permalink":"https://revsic.github.io/blog/on2020dev/","tags":["Writing","2020","Researcher","TTS"],"title":"On 2020 as researcher"},{"categories":["Writing"],"contents":"첫 회고 사실 작년 이맘때부터 회고를 써야겠다 고민을 했는데, 미루고 미루다 결국 올해 끝이 되어서야 회고를 쓰게 되었다.\n어떤 이야기를 써야 할까 고민을 하다가 올해를 정리하는 의미에서 큰 부담 없이 2020년에 한 일을 돌아보려 한다.\n첫 글에는 대학교 3학년으로의 2020년, 두 번째 글은 2년 차 딥러닝 리서처로의 2020년에 관해 쓸 것이다.\n[대학교 3학년의 2020] 현재 글 [딥러닝 리서처의 2020] On 2020 as researcher\n신종코로나 COVID-19 2020년 하면 당연히 코로나를 빼놓을 수 없는 거 같다.\n19년 12월 말, 중국 우한에서 원인 불명의 바이러스성 집단 폐렴이 발생했다. 이후 이는 신종코로나 바이러스, COVID-19라고 명명되었고 전 세계를 팬데믹에 몰아넣는다.\n당장 백신은 없고, 사망하는 사람은 생기고, 전염성마저 강하니 거리 두기와 마스크는 생활화되어 갔다.\n문제는 당장 내일 출근할 때 쓸 마스크를 구하기 어려울 정도로 마스크의 공급이 수요를 따르지 못했고, 사재기도 있었을 테지만, 직장 동료분이 막 급하게 \u0026ldquo;지금 ! 쿠팡 열렸어요 !\u0026rdquo; 하면 대기하다 알트탭 쳐서 마스크 사는 일도 있었다.\n마스크를 구하는 것만이 문제는 아니었다. 평소 황사 철 아니면 쓰지도 않던 마스크를 근무 내내 끼고 있으니 피부가 버티질 못해 트러블이 생기고, 마스크 쓰고 출퇴근을 하면 숨이 가빠 평소보다 더 힘든 기분이었다.\n(그래도 마스크 열심히 쓰고 다녔음)\n사회적 거리 두기는 그래도 할만했다. 어차피 책상에서 멀리 가는 성격도 아니고, 원래도 집에서 잘 안 나갔는데 합법적으로 집에 있는 기분이었다.\n이런 생활이 1년간 이어지다 보니, 이젠 지각할 거 같으면 마스크 쓰고도 역에서 회사까지 뛰어가고 그런다. 오히려 밖에서 담배를 피우거나 이런 사람도 많이 줄어든 거 같고, 중국발 황사도 줄어 봄철 피부염도 거의 없었다. 자택 근무도 너무 적응해버린 거 아닌가 싶을 때가 있다.\n이제 백신도 나왔고, 슬슬 줄어들 때가 된 거 같아 다행이다. 빨리 줄어들어서 맘 놓고 놀러 다니고 싶다.\n3학년 학교 생활 올해 한 가장 큰 실수는 역시 학교랑 회사랑 같이 다닌 거 같다.\n코로나라 자택 근무까지 하니까, 퇴근 시간 아끼는 만큼이라도 공부할 거 같았는데, 막상 시험 기간 아니면 잘 안 하게 되더라. 뭔가 한 가지에 집중한 것도 아니고, 이것저것 얕게 보는 느낌이었다.\n그래도 시험 기간이나, 회사 스퍼트 기간에는 한쪽에 집중하려 노력한 거 같다. 시험 기간에는 9시-6시 칼퇴근하고 남는 시간에 시험공부 하고, 스퍼트 때는 자기 전에 실험 결과 확인하고 추가 실험 기획해 놓기도 했다.\n뭔가 나이 대비 빠르게 경력이나 졸업을 당기는 데는 도움이 될 수 있어도, 내가 어떤 것에 숙련할 수 있는가를 보면 썩 좋은 선택은 아닌 거 같다.\n(500페이지 정도 분량 써가면서 공부함 그래도 ㅠ)\n컴공 3대장 - 컴퓨터구조론, 운영체제, 컴파일러\n개인적으로 컴공 3대장이 있다면 컴구, 운체, 컴파일러 3개이지 않을까 싶다. 이 중 운영체제와 컴파일러 과목을 각각 3-1, 3-2에 듣게 되었다.\n2학년 2학기에 C로 DB를 만드는 수업이 있었고, 이때 워낙 고생을 많이 했던 터라 같은 교수님이 운영체제를 맡으셨을 때는 고민을 좀 했던 것 같다.\n교수님은 정말 좋은 분이셨기에, 적당히 수업 들으면서 과목별 투자 시간에 대한 가성비 싸움을 할지, 아님 운체에 올인을 하고 다른 과목의 시간을 나눌지, 아니면 다른 교수님 강의를 들을지 고민했다.\n결국 수업을 포기할 수는 없었기에 전자를 골랐고, 그거랑 별개로 그냥 기한이 있는 줄 몰랐던 과제 OT 7개를 놓쳐서 성적은 반 토막 났다..ㅎ\n과제는 xv6에 MLFQ 기반의 CPU Scheduler, Thread 기능 추가, Filesystem 최대 크기 확장 등이 있었다. 이 중 MLFQ, Thread 정도를 선택과 집중했고, 성적과 별개로 만족스러운 수업이었다.\n컴파일러 역시 정말 좋은 교수님이 수업을 여셨고, 운체와 달리 과제가 많은 교수님은 아니셨기에, 과제 공지가 올라오면 하루 날 잡고 완성했던 것 같다.\n실제로 loucomp tiny C를 시작으로 컴파일러를 재구성하는 수업이었고, 언어 스펙에 따라 파싱을 위한 state machine을 구성하고, 타입을 체크하는 루틴을 추가하였다.\n[OS]: github HYU-ELE3021 [Compiler]: github HYU-ELE4029\n수학과 부전\n드디어 꿈꿔오던 수학과 수업을 정식으로 듣게 되었다.\n고등학교 때부터 수틀리면 컴퓨터 전공 때려치우고 수학과 가겠다고 담임 선생님한테 투정을 부렸었는데, 결국 돌고 돌아 컴퓨터 전공에 부전공을 수학으로 잡게 되었다.\n문제는 학교 정책상 부전공으로 이수해야 하는 과목 수가 정해져 있는데, 수학과는 학년당 3과목 정도가 책 한 권을 1년 동안 배우다 보니 (선대1, 선대2 등) 졸업을 위해서 무조건 들어야 하는 과목들이 몇 개 있다.\n그중 하나가 선형대수였는데, 나는 심지어 공대에서도 선형대수를 들어 총 3학기의 선형대수를 듣게 되었다. (1학년 2학기, 3학년 1,2학기)\n물론 조금 다르긴 하지만, 수강한 교수님 특성상 응용 파트가 많다 보니 실상은 크게 다르지 않았다. 오히려 대수를 많이 못 다뤄 아쉬웠다.\n그리고 또 하나는 해석학이었다. 일전에 해석학 공부하겠다고 혼자 책을 사 와서 폈는데, 첫 장부터 문제를 못 풀어 접었던 기억이 있다.\n실은 이것 때문에 더욱 수학과 부전에 대한 기대가 있었지만, 교수님이 증명 팁을 알려주시는 그런 건 없었고 그냥 연습 문제 풀다 보니 되더라 ! 가 정답인 거 같다.\n주변의 권유로 4학년 과목인 확률론도 들었다. 선이수 과목인 실해석학을 안 듣고 온 사람이 나 말고도 더 있어서, 수업 초반부는 그 설명으로 시간을 좀 쓴 것 같다.\n아무래도 딥러닝, 머신러닝 하면서 확률을 다루는 사람이다 보니, 그 기저에는 어떤 정의와 연역으로 구성되었을지에 대한 기대가 좀 있었다. 나는 딥러닝에서도 음성 응용을 다루다 보니, 직접적으로 도움이 되었다 ! 보다는, 학술적으로 이러한 의미와 가치가 있었구나에 대해 새로 알게 된게 컸다.\n그렇게 해서 3학년에 선형대수, 해석학, 확률론 3개 과목을 들었고, 2학기 해석학 확률론 성적이 1학기에 비해 반토막 난 걸 보니 눈물이 찔끔 났다.\n나름 올인했었는데.. 그래서 난 대수가 더 좋다.\n여행 올해 코로나로 여행도 잘 못 다녔다. 그러다 보니 무슨 일이 있지 않고서야 멀리 갈 엄두도 못 냈던 거 같다.\n부산 친구 군대 보내기\n3학년쯤 되니 친구들이 다 군대에 갔다. 남아 있는 친구들이 손에 꼽을 정도이다.\n나는 이유는 모르겠지만 경남 출신 친구들이 많았고, 군대 간다고 휴학한 친구 만나러 부산에 당일치기로 놀러 갔었다.\n부산에 도착했을 때는 정말 충격이었던 게 4월 당시 부산 확진자 수는 굉장히 적었고, 마스크를 쓰는 사람도 거의 없었다. 마스크를 쓰고 있으면 여행객인가 ? 싶을 정도였다.\n가서 텐동도 먹고, 장어덮밥도 먹고, 바닷가도 걸으며 이런저런 얘기를 했었다.\n(텐동 맛있엉)\n호캉스 - 시그니엘 서울\n여름이 되었고, 연차는 썼고, 뭐라도 하고 싶다는 생각이 강하게 들었다. 코로나라 돌아다니거나 멀리 가는 건 힘들 거 같아서, 간단히 호캉스나 1박 2일 다녀와야겠단 생각이 들었다.\n이곳저곳 알아보다가 자본주의를 좀 느껴보잔 생각에 롯데 시그니엘을 가기로 마음먹었다. 100층 가볼 일이 얼마나 있겠어~ 라는 생각으로 객실을 예약했다.\n(사진이 몇장 없음 ㅠ)\n호텔에 도착해서 100층까지 가는 엘리베이터를 처음 타봤다. 중간에 멈추는 구간은 몇 개 없었고, 부우우웅 하고 올라가더니 귀가 먹먹했다.\n도착해서는 라운지에서 샴페인도 마시며 즐거운 시간을 보내고 왔다.\n중간에 수영장도 갔는데, 초등학생 이후 수영을 해본 적이 없었기에 이게 되려나 ? 싶다가도 몸은 기억한다고 그새 또 막 돌아다니고 있는 게 신기했다.\n저녁은 룸서비스를 시켜 먹었고, 조식은 뷔페를 가서 먹었다.\n(진짜 후회 안할만큼 맛있었음)\n함께 사 온 와인이랑 룸서비스로 시킨 스테이크, 파스타 모두 잘 어울렸다. 조식 뷔페는 샐러드, 빵, 육류 3가지 정도로 구성된 파트가 있었고, 뭐 하나 빠짐없이 깔끔했다.\n잘 먹고, 잘 놀다 집에 돌아오니 이래서 호캉스, 호캉스 하는구나 싶었다.\n운전면허 드디어 운전면허를 땄다.\n작년 말부터 딸거다 딸거다, 말만 하다가, 이번 11월에 드디어 운전 연습 학원을 등록했다.\n10시간 강습, 거의 80만원 가까운 등록금에, 시험은 때마다 5만원씩 내야 하니 한 번에 합격해도 거진 100만 원 가까이 쓰게 된다.\n정말 한 번에 붙어야겠다는 일념으로 연습 열심히 했다.\n기능 때는 노란선 한 번 밟고 컷트라인에 걸쳐서 한 번에 붙고, 주행 때는 합격 했는데 점수를 안 알려줘서 뭘 실수했을지는 잘 모르겠다.\n면허가 발급되고, 가족이랑 같이 연습 삼아 운전을 좀 하고 돌아다녔는데, 확실히 10시간 교육받고 면허까지 따니 큰 문제 없이 잘 돌아 다녔다.\n정리 회사랑 학교랑 같이 다니다 보니, 일하다 공부하다 1년이 지나갔다. 코로나 때문에 금방 간 건가 싶기도 하다.\n그래도 사람 종종 만나고, 확진자 적을 때는 여행 아닌 여행도 다녀와서 만족스럽게 한 해를 보낸 거 같다.\n내년부터는 아마 휴학계를 내고, 회사 일에 전념할 것 같다.\n당분간은 얕고 넓게 보다는, 회사에서는 음성 딥러닝 쪽을, 개인적으로는 관심 있던 논문 리뷰, 구현하며 한 토픽에 대해 깊이 있는 공부를 해볼 예정이다.\n그 외의 부분에 대해서는 딱 올해만큼만 살았으면 좋겠다.\n다음 글 [딥러닝 리서처의 2020] On 2020 as researcher\n","permalink":"https://revsic.github.io/blog/on2020stud/","tags":["Writing","2020","Student","Undergraduate"],"title":"On 2020 as student"},{"categories":["Vocoder"],"contents":" Diffusion: Ho et al., 2020, arXiv:2006.11239 WaveGrad: Nanxin Chen et al., 2020, arXiv:2009.00713 DiffWave: Zhifeng Kong et al., 2020, arXiv:2009.09761 Keyword: Denoising, Diffusion, Vocoder Problem: Quality and generation speed trade off on mel-inversion procedure. Solution: Denoising and diffusion based raw audio sampling. Benefits: Explicit trade off between speed and quality in single framework. Contribution: First use of denoising \u0026amp; diffusion model on vocoder, high fidelity audio generation, explicit trade off, etc. Weakness or Future work: - Mel-inversion\nNeural Text-to-Speech (TTS) 분야는 WaveNet(Oord et al., 2016), Char2Wav(Sotelo et al., 2017), Tacotron(Wang et al., 2017)을 거쳐 발전해 왔다. 그 중 Tacotron의 경우 text에서 mel-spectrogram을 예측하여 vocoder를 통해 raw-audio signal로 mel-inversion 하는 방식을 취한다.\n현재는 많은 mel-inversion 모델들이 개발되었고, autoregressive 구조로 raw-audio와의 likelihood를 maximizing 하는 WaveNet(Oord et al., 2016), WaveRNN(Kalchbrenner et al., 2018), ExcitNet(Song et al., 2019a), LPCNet(Valin \u0026amp; Skoglund, 2019) 등의 모델이 있다.\n하지만 이 경우 high sample rate를 가진 음성을 생성할 때 방대한 양의 frame 수에 비례하는 샘플링 시간을 가진다는 점에서 autoregressive의 근본적인 한계를 가지고 있었다.\n이를 해결하고자 non-autoregressive vocoder의 연구가 활발해졌고, IAF를 기반으로 한 PWN(Oord et al., 2018), Glow를 기반으로 한 WaveGlow(Prenger et al., 2019), FloWaveNet(Kim et al., 2019), GAN을 기반으로 한 WaveGAN(Donahue et al., 2018), MelGAN(Kumar et al., 2019), PWG(Yamamoto et al., 2020), HooliGAN(McCarthy \u0026amp; Ahmed, 2020) 등이 발표되었다.\nWaveGrad는 non-autoregressive vocoder 연구의 연속으로 raw signal의 log-density에서 gradient를 estimation 하는 방식으로 작동한다. 이를 통해 모델은 refinement step의 수를 조절함으로써 inference speed와 sample quality 사이의 trade off를 직접적으로 조절할 수 있게 되었고, autoregressive와 non-autoregressive 사이의 격차를 잇는 역할을 한다.\nDenoising Diffusion Proabilistic Models, Jonathan Ho et al., 2020\nWaveGrad와 DiffWave의 모델링은 기본적으로 Denoising Diffusion Model(Ho et al., 2020)을 따른다.\nFigure 2: The directed graphical model considered in this work. (Ho et al., 2020)\nDiffusion 모델은 finite step의 markov chain을 가정하여, 매 transition마다 sample에 noise를 더해간다. 이후 denoising을 위한 NN 모델을 두고 Diffusion의 reverse process를 학습하여 gaussian noise로부터 sample을 순차적으로 denoising하는 방식이다. 학습은 analytic 하게 구한 diffusion의 posterior와 denoising process 사이의 KL-divergence를 줄이는 방식으로 작동한다.\nFormulation\nDenoising model은 gaussian $p(\\mathrm x_T) = \\mathcal N(\\mathrm x_T; 0, I)$을 시작으로, 동일한 dimension을 가지는 latent $\\mathrm x_{T-1}, \u0026hellip;, \\mathrm x_{1}$을 거쳐 sample $\\mathrm x_0 \\sim q(\\mathrm x_0)$로 향하는 latent variable model로 표현한다.\n$$p_\\theta(\\mathrm x_0) := \\int p_\\theta(\\mathrm x_{0:T})d\\mathrm x_{1:T}$$\n여기서 $p_\\theta(\\mathrm x_{0:T})$를 reverse process라 정의하고, markov chain으로 모델링하면 다음과 같다.\n$$p_\\theta(\\mathrm x_{0:T}) := p(\\mathrm x_T)\\prod^T_{t=1}p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)$$\n$$p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t) := \\mathcal N(\\mathrm x_{t-1}; \\mu_\\theta(\\mathrm x_t; t), \\Sigma_\\theta(\\mathrm x_t; t))$$\ndenoising, diffusion 모델이 다른 latent variable model과 다른 점은, diffusion process를 analytic 하게 정의하여 posterior를 직접 approximate 한다는 것이다. End-to-End로 full transition을 학습하는 것이 아닌, state에 직접적인 constraint를 가한다.\nHo et al., 2020. 에서는 diffusion process를 모델에 noise를 더하는 markov chain으로 정의하고, 더해질 noise의 variance를 scheduler sequence $\\beta_1, \u0026hellip;, \\beta_T$로 두어 다음과 같이 정의한다.\n$$q(\\mathrm x_{1:T}|\\mathrm x_0) := \\prod^T_{t=1}q(\\mathrm x_t|\\mathrm x_{t-1})$$\n$$q(\\mathrm x_t | \\mathrm x_{t-1}) := \\mathcal N(\\mathrm x_t; \\sqrt{1 - \\beta_t}\\mathrm x_{t-1}, \\beta_t \\mathrm I)$$\n이는 autoregressive하게 정의하는 대신, $\\mathrm x_0$에 직접 condition 하는 방식으로 표현할 수 있다.\n$$q(\\mathrm x_t|\\mathrm x_0) = \\mathcal N(\\mathrm x_t; \\sqrt{\\bar \\alpha_t}\\mathrm x_0, (1 - \\bar \\alpha_t)\\mathrm I) \\\\ \\mathrm{where}\\ \\alpha_t = 1 - \\beta_t, \\ \\bar\\alpha_t = \\prod^t_{s=1}\\alpha_t$$\n이렇게 되면 nll에 대한 variational lower bound는 state 사이의 KL-divergence로 rewriting할 수 있다.\n$\\mathbb E[-\\log p_\\theta(\\mathrm x_0)] \\\\ \\le \\mathbb E_q\\left[-\\log \\frac{p_\\theta(\\mathrm x_{0:T})}{q(\\mathrm x_{1:T}|\\mathrm x_0)}\\right] \\\\= \\mathbb E_q\\left[ -\\log p(\\mathrm x_T) - \\sum_{t\\ge 1} \\log\\frac{p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)}{q(\\mathrm x_t|\\mathrm x_{t-1})} \\right] \\\\= \\mathbb E_q\\left[ -\\log p(\\mathrm x_T) - \\sum_{t\\ge 1} \\log\\frac{p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)}{q(\\mathrm x_{t-1}|x_t)} \\cdot \\frac{q(\\mathrm x_{t-1})}{q(\\mathrm x_t)} \\right] \\\\=\\mathbb E_q\\left[ -\\log\\frac{p(\\mathrm x_T)}{q(\\mathrm x_T)} - \\sum_{t\\ge 1} \\log \\frac{p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)}{q(\\mathrm x_{t-1}|\\mathrm x_t)} - \\log q(\\mathrm x_0) \\right] \\\\=D_{\\mathrm{KL}}(q(\\mathrm x_T)||p(\\mathrm x_T)) + \\mathbb \\sum_{t\\ge 1} D_\\mathrm{KL}(q(\\mathrm x_{t-1}|\\mathrm x_t)||p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)) + H(\\mathrm x_0)$\n이 때 $q(\\mathrm x_{t-1}|\\mathrm x_t, \\mathrm x_0)$의 analytic form은 다음과 같다.\n$$q(\\mathrm x_{t-1}|\\mathrm x_t, \\mathrm x_0) = \\frac{q(\\mathrm x_t|\\mathrm x_{t-1})q(\\mathrm x_{t-1}|\\mathrm x_0)}{q(\\mathrm x_t|\\mathrm x_0)} = \\mathcal N(\\mathrm x_{t-1}; \\tilde \\mu_t(\\mathrm x_t, \\mathrm x_0), \\tilde \\beta_t \\mathrm I) \\\\ \\mathrm{where} \\ \\tilde\\mu_t(\\mathrm x_t, \\mathrm x_0) := \\frac{\\sqrt{\\bar a_{t-1}}\\beta_t}{1 - \\bar a_t}\\mathrm x_0 + \\frac{\\sqrt{\\alpha_t}(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}\\mathrm x_t \\ \\ \\mathrm{and} \\ \\ \\tilde\\beta_t := \\frac{1 - \\bar\\alpha_{t-1}}{1 - \\bar\\alpha_t}\\beta_t$$\nReparametrization\n각각의 Dkl term을 순서대로 $L_T, L_{1:T-1}, L_0$로 정의하면, $L_T$는 beta를 learnable 하지 않은 constant로 가정할 때 상수로 고정되기 때문에 연산에서 제외한다.\n$L_{1:T-1}$은 $\\Sigma_\\theta(\\mathrm x_t, t) = \\sigma^2_t\\mathrm I$의 경우 untrained constants로 제외하고, $\\mu_t$에 대해서만 학습을 진행한다. $\\sigma_t$는 $\\sigma_t^2 = \\beta_t$나 $\\sigma^2_t = \\tilde\\beta_t = \\frac{1 - \\bar\\alpha_{t-1}}{1 - \\bar\\alpha_t}\\beta_t$로 실험적으로 설정하였다. 이는 data에 대한 reverse process entropy의 upper, lower bound라고 한다.\n$\\mu_\\theta(x_t, t)$는 KL에서 trainable term을 구축한다.\n$$L_{t-1} = \\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t}||\\tilde\\mu_t(\\mathrm x_t, \\mathrm x_0) - \\mu_\\theta(\\mathrm x_t, t)||^2 \\right] + C$$\n이를 previous term을 통해 다시 써보면 다음과 같다.\n$L_{t-1} - C \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1 - \\bar\\alpha_t}\\mathrm x_0 + \\frac{\\sqrt{\\alpha_t}(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}\\mathrm x_t - \\mu_\\theta(\\mathrm x_t, t) \\right|\\right|^2 \\right] \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1 - \\bar\\alpha_t}\\frac{1}{\\sqrt{\\bar\\alpha_t}}(x_t - \\sqrt{1 - \\bar\\alpha_t}\\epsilon) + \\frac{\\sqrt\\alpha_t(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}x_t - \\mu_\\theta(x_t, t) \\right|\\right|^2 \\right] \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{1}{\\sqrt{\\alpha_t}}\\left( \\frac{\\beta_t + \\alpha_t(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}}\\epsilon \\right) - \\mu_\\theta(x_t, t) \\right|\\right|^2 \\right] \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{1}{\\sqrt{\\alpha_t}}\\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}}\\epsilon \\right) - \\mu_\\theta(x_t, t)\\right|\\right|^2 \\right] \\\\\\mathrm{where} \\ \\ \\mathrm x_t = \\sqrt{\\bar\\alpha_t}\\mathrm x_0 + \\sqrt{1 - \\bar\\alpha_t}\\epsilon$\n위 정리에서 $\\mu_\\theta$는 $\\epsilon_\\theta$를 통해 reparametrizing 할 수 있다.\n$$\\mu_\\theta(\\mathrm x_t, t) = \\frac{1}{\\sqrt\\alpha_t}\\left( \\mathrm x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}}\\epsilon_\\theta(\\mathrm x_t, t) \\right) \\\\\\mathbb E_{\\mathrm x_0, \\epsilon}\\left[ \\frac{\\beta^2_t}{2\\sigma^2_t\\alpha_t(1 - \\bar\\alpha_t)}||\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}\\mathrm x_0 + \\sqrt{1 - \\bar\\alpha_t}\\epsilon, t)||^2 \\right]$$\n최종 objective는 scale term을 생략한 weighted variational bound로 나타낸다.\n$$L_\\mathrm{simple}(\\theta) := \\mathbb E_{t, \\mathrm x_0, \\epsilon}\\left[ || \\epsilon - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}\\mathrm x_0 + \\sqrt{1 - \\bar\\alpha_t}\\epsilon, t)||^2\\right]$$\n원문에서는 실제로 이렇게 formulation 된 objective가 성능이 더 좋았음을 실험으로 보였다.\nTable 2: Unconditional CIFAR10 reverse process parameterization and training objective ablation. (Ho et al., 2020)\n정리하면 $L_\\mathrm{simple}$은 두 process 사이의 Kl-divergence를 재구성한 것이고, 이는 single NN을 통해 현재 input에 존재하는 noise를 noise-level에 따라 직접 예측하여 denoising하는 방식으로 다음 state로의 transition을 진행한다.\nAlgorithms from Ho et al., 2020.\n따라서 state의 수가 늘어나면 더 정교하고, 더 많은 noise를 제거하여 sample quality를 높일 수 있지만 sampling 시간이 길어지고, state 수가 줄어들면 sample에 noise가 낄 수 있지만 이른 시간 안에 결과를 얻을 수 있다.\nWaveGrad: Estimating Gradients for WaveForm Generation, Nanxin Chen et al., 2020.\nWaveGrad는 위 formulation을 통해서 mel-spectrogram에 condition 한 raw signal을 생성하는 방법론을 제시한다.\nFigure 3, 4: WaveGrad network architecture, upsampling block.\nDownsampling block(DBlock)에서 noised signal의 feature를 추출하고, Upsampling block(UBlock)에 feature과 mel-spectrogram을 입력으로 주어 noise를 예측한다.\n원문에서는 24kHz의 raw audio에서 80Hz의 mel을 연산하여, mel-frame 하나당 300개의 audio frame으로 확장하는데, 이는 5개의 UBlock에서 각각 [5, 5, 3, 2, 2] factor에 맞게 upsampling하는 방식으로 구성하고, DBlock에서는 반대로 noised signal을 [2, 2, 3, 5]로 downsampling하여 각각의 intermediate representation의 resolution을 matching 할 수 있도록 두었다.\nFigure 5, 6: Block diagrams of the downsampling, feature-wise linear modulation (FiLM) blocks.\n각각의 convolution은 receptive field를 넓히기 위해서 dilation factor를 가지고, UBlock의 4개 conv는 [1, 2, 1, 2]와 [1, 2, 4, 8], DBlock의 3개 conv는 [1, 2, 4]로 구성된다.\nupsample과 downsample 과정에 정보전달을 위해 wavegrad에서는 Feature-wise linear modulation (FiLM)모델을 통해 noise-level과 positional encoding, DBlock의 feature를 affine parameter로 바꿔 UBlock에서 feature-wise affine transform을 진행한다.\n이외에 batch normalization의 경우 batch에 여러 개의 noise-level을 가진 sample 들이 존재하기 때문에 batch statistics가 정확하지 않아 sample quality에 악영향을 미쳤다고 한다.\nNoise Scheduling\nobjective를 구성하기 위해서는 noise level $\\sqrt{\\bar\\alpha_t}$에 대한 설정이 필요하다. learnable한 parameter로 둘 것이 아니므로 noise distribution에 직접 영향을 줄 수 있어 sample quality와 긴밀한 연관성을 가진다. WaveGrad에서는 noise level에 대한 설정이 음질과 직접적인 연관이 있었음을 실험으로 보였다.\nFigure 7: A plot of different noise schedules\n원문에서는 iteration의 수에 따라 noise level scheduling method를 따로 두었는데, 1000회의 경우 $\\beta_t$를 1e-4에서 0.005를 linear 하게 1000개, 50의 경우 1e-4에서 0.05를 linear 하게 50개 sample 하였다. 25회의 경우에는 $\\beta_0 = 1\\times 10^{-6}, \\ \\beta_1 = 2\\times 10^{-6}$을 시작으로 하는 fibonacci sequence를 구축하였고, 6회의 경우에는 manual 하게 [1e-6, 1e-5, .., 1e-1]로 exponential scale에서 linear 하게 구현하였다.\n이후 이를 통해 partition $l_0 = 1, \\ l_s = \\sqrt{\\prod^s_{i=1}(1 - \\beta_s)}$을 설정하고, $(l_{s-1}, l_s)$에서 uniform 하게 $\\sqrt{\\bar\\alpha}$를 sampling 하여 사용한다. 이렇게 되면 discrete index가 아닌 continuous segment에서 noise level을 sampling 할 수 있고, 6iter과 같이 sparse 한 scheduling 수준에서 괜찮은 성능을 보였다고 한다.\nExperiments, Discussion\nTable 1: Mean opinion scores (MOS) of various models and their confidence intervals.\n원문에서는 이 외에도 iteration 수를 줄이기 위해 여러 가지 noise schedule을 시도했으며, 잘 작동하는 schedule은 $D_\\mathrm{KL}(q(y_N|y_0)||\\mathcal N(0, I))$을 작게 두어 train-inference의 격차가 거의 없게 두었고, $\\beta$를 작은 값으로 시작하여 fine granuality details에 따라 background noise를 줄여야 했다고 한다.\nDiffWave: A Versatile Diffusion Model for Audio Synthesis, Zhifeng Kong et al., 2020\n(2020.09.24. update)\nDiffWave는 WaveGrad와 같은 시기에 나온 또 다른 Diffusion denoising 기반의 mel-inversion vocoder이다.\nFigure 2: The network architecture of DiffWave\nDiffWave는 기본적으로 WaveNet 아키텍쳐를 차용한다. kernel-size=3과 dilation-factor=2의 기본적인 noncausal dilated convolution을 기반으로 [1, 2, \u0026hellip;, 512]의 10개 레이어를 3개 cycle로 구성한다.\nNoise schedule에 대한 embedding을 $\\sqrt{\\bar\\alpha}$에 직접 condition 하던 WaveGrad와 달리 DiffWave에서는 timestep을 기반으로 한 modified positional encoding에 FC-swish layer를 덧붙여 활용한다.\n$$t_\\mathrm{embedding} = \\left[ \\sin(10^{\\frac{0\\times 4}{63}}t), \\cdot\\cdot\\cdot, \\sin(10^{\\frac{63\\times 4}{63}}t), \\cos(10^{\\frac{0\\times 4}{63}}t), \\cdot\\cdot\\cdot, \\cos(10^{\\frac{63\\times 4}{63}}t) \\right]$$\nmel-spectrogram은 channel이 1개인 2D tensor로 가정하여 2D transposed convolution에 의해 22kHz의 signal resolution으로 upsample 되고, WaveNet block에서 dilated convolution 이후에 bias term으로 더해진다.\nnoise scheduling의 경우 [20, 40, 50] iteration에서 $\\beta_t$를 [1e-4, 0.02]를 linear sampling, 200 iteration의 경우 [1e-4, 0.05]를 linear sampling 하였다고 한다.\nDiffWave는 특이하게도 Vocoder purpose 외에 unconditional generation을 시도하였다. 이 경우 보통의 wavenet이라면 single model이 음성의 길이를 모두 커버할 수 있는 receptive field를 구축해야 하지만, DiffWave의 경우 denoising 과정에 발생하는 iteration으로 이에 비례하는 추가 receptive field를 쉽게 얻을 수 있었다.\nExperiments, Discussion\nTable 1: The model hyperparameters, model foot print, and 5-scale MOS with 95% confidence intervals\nVocoder task의 경우 DiffWave는 다른 Flow-based SOTA 모델보다는 조금 느리지만, sample quality는 더 좋았다고 한다. 이는 Flow-based Model이 가지는 architectural constraint에 의한 것으로 추측하였고, inference 속도는 추가 engineering에 의해 일정 부분 빨라질 수 있을 것으로 보인다.\nTable 2: The automatic evaluation metrics and 5-scale MOS with 95% confidence intervals.\nUnconditional generation task의 경우에는 Speech Commands Dataset 에서 spoken digits (0~9) 부분만을 발췌하여 사용했다고 한다. 길이는 16kHz의 1초 미만으로 활용하여 여러 가지 evaluation metric을 측정하였다.\nImplementation\nofficial, Jonathan Ho, tf: diffusion official sample: wavegrad.github.io unofficial, Ivan Vovk, pytorch: WaveGrad official sample: diffwave-demo.github.io unofficial, revsic, tensorflow2: tf-diffwave Reference\nWaveNet: A Generative Model for Raw Audio, Oord et al., 2016. Char2Wav: End-to-End Speech Synthesis, Sotelo et al., 2017. Tacotron: Towards End-to-End Speech Synthesis, Wang et al., 2017. WaveRNN: Efficient Neural Audio Synthesis, Kalchbrenner et al., 2018. ExcitNet Vocoder: A Neural Excitation Model for Parametric Speech Synthesis, Song et al., 2019a. LPCNet: Improving Neural Speech Synthesis through Linear Prediction, Valin \u0026amp; Skoglund, 2019. Parallel WaveNet: Fast High-Fidelity Speech Synthesis, Oord et al., 2018. WaveGlow: A Flow-based Generative Network for Speech Synthesis, Prenger et al., 2019. FloWaveNet: A generative flow for raw audio, Kim et al., 2019. WaveGAN: Adversarial Audio Synthesis, Donahue et al., 2018. MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis, Kumar et al., 2019. Parallel WaveGAN: A Fast Waveform Generation Model based on Generative Adversarial Networks, Yamamoto et al., 2020. HooliGAN: Robust, High Quality Neural Vocoding, McCarthy \u0026amp; Ahmed, 2020. Denoising Diffusion Proabilistic Models, Ho et al., 2020. ","permalink":"https://revsic.github.io/blog/diffusion/","tags":["Machine Learning","Deep Learning","Generative","Vocoder","Mel Inversion","Denoising Diffusion"],"title":"Diffusion, WaveGrad and DiffWave"},{"categories":["Generative"],"contents":" David Bau et al., 2020, arXiv Keyword: Generative, Adversarial learning Problem: How to manipulate specific rules encoded by a deep generative model. Solution: Projected gradient descent for adding rules to convolution of associative memory. Benefits: Enable users to synthesize edited new images by manipulating model only once. Contribution: Providing a new perspective of associative memory, rule manipulating method of projected gradient descent. Weakness or Future work: - Generative model\n생성 모델은 데이터의 분포를 학습하면서 여러 가지 규칙이나 관계를 만들어 나간다. 간단한 예로 ProgressiveGAN[1]이 만든 주방 이미지에서는 창문에서 오는 빛을 테이블에 반사시키는 경향이 있다.\nFig. 6: Inverting a single semantic rule within a model\n저자는 만약 이러한 규칙들을 직접 분석하여 수정할 수 있다면, 생성 모델 자체를 manipulating 하는 것이고, 이는 생성된 이미지를 각각 수정하는 것보다 효율적으로 수정된 이미지를 생성할 수 있다고 이야기 한다.\n이를 위해서 우리는 생성 모델이 어떤 정보를 캡처하고 있고, 어떻게 unseen scenario에 대해 일반화 하고 있는지 알아야 한다.\n현재 생성 모델들은 인간이 직접 라벨링 한 대규모의 데이터셋에 기반을 두고 있는데, 만약 manipulating 과정에서도 이러한 다량의 데이터와 학습이 추가로 필요하다면, 이는 손으로 생성된 이미지를 직접 수정하는 것과 큰 차이가 없을 것이다.\n이에 우리는 단 몇 개의 샘플 데이터와 간단한 optimization을 통해 모델을 manipulation 할 수 있어야 하고, 이 모델은 우리가 원하는 rule을 캡처하여 unseen data에 대한 일반화를 할 수 있어야 한다.\n저자는 이를 위해 sequential 하게 구성된 nonlinear convolutional generator를 associative memory라는 관점으로 해석하고, 전체 레이어가 아닌 단 하나의 레이어에 constrained optimization을 진행하여 기존의 semantic rule을 보존하면서, 우리가 원하는 rule을 추가할 수 있는 방법론을 제시한다.\nPreview\npretrain된 generator $G(\\cdot; \\theta_0)$가 주어질 때, 모델은 각각의 latent $z_i$에 대해 $x_i = G(z_i; \\theta_0)$의 output을 만들어 낸다. 만약 우리가 copy\u0026amp;paste 방식으로 변화를 준 output $x_{*i}$을 통해 새로운 rule을 표현한다면, rule의 표현 중 가장 직관적인 방법일 것이다.\nFig. 3: The Copy-Paste-Context interface for rewriting a model.\n이때 하고자 하는 것은 새로운 rule을 따르는 $\\theta_1$을 만드는 것이고, 이는 $x_{*i} \\approx G(z_i; \\theta_1)$을 만족할 것이다.\n$\\theta_1 = \\arg\\min_\\theta \\mathcal L_{\\mathrm{smooth}}(\\theta) + \\lambda \\mathcal L_\\mathrm{constraint}(\\theta)$\n$\\mathcal L_\\mathrm{smooth}(\\theta) \\overset{\\Delta}{=} \\mathbb E_z[\\mathcal l(G(z; \\theta_0), G(z; \\theta))]$\n$\\mathcal L_\\mathrm{constraint}(\\theta) \\overset{\\Delta}{=} \\sum_i \\mathcal l(x_{*i}, G(z_i; \\theta))$\n고전적인 해결책은 generator의 전체 parameter set $\\theta_0$를 두 가지 constraint에 맞게 gradient 기반의 optimization을 진행하는 것이다. 이때 $\\mathcal l(\\cdot)$은 perceptual distance를 의미한다.\n하지만 이 경우 몇 개 되지 않는 sample에 overfit될 가능성이 농후하며 다른 데이터에 대해 일반화되지 않을 수 있다.\n이에 저자는 두 가지 방법론을 제안한다. 하나는 전체 parameter set이 아닌 특정 한 layer의 weight만을 update하는 것이고, 하나는 optimization을 특정 constraint 내에서 진행하는 것이다.\n특정 layer L과 L-1 layer까지의 feature map k를 가정할 때 L의 output은 $v = f(k; W_0)$가 된다. 원본 이미지의 latent $z_{i}$가 feature $k_{*i}$를 만들 때 $v_i = f(k_{*i}; W_0)$를 가정하고, 직접 수정한 output에 대응하는 feature map $v_{*i}$를 구할 수 있으면 objective는 다음과 같다.\n$W_1 = \\arg\\min_W \\mathcal L_{\\mathrm{smooth}}(W) + \\lambda \\mathcal L_\\mathrm{constraint}(W)$\n$\\mathcal L_\\mathrm{smooth}(W) \\overset{\\Delta}{=} \\mathbb E_z[|| f(k; W_0) - f(k; W)||^2]$\n$\\mathcal L_\\mathrm{constraint}(W) \\overset{\\Delta}{=} \\sum_i ||v_{*i} - f(k_{*i}; W)||^2$\nperceptual distance는 higher semantic을 표현하는 feature map 사이의 l2-distance를 상정한다. 이때 W만으로도 parameter의 양이 충분히 많을 수 있기에, overfit을 제한하면서 더 나은 일반화를 위해 학습 방향을 고정할 필요가 있었고, 특정 direction으로만 optimization 되도록 constraint를 추가한 gradient descent를 사용하였다.\nAssociative Memory\n저자는 preview의 방법론을 associative memory로부터 유도해 낸다.\n어떤 key $k_i \\in \\mathbb R^N$와 value $v_i \\in \\mathbb R^M$의 mapping $\\{ k_i \\to v_i \\}_{i \\in I}$을 가정하자. 이때 $k_i$가 mutually orthonormal 하면 i와 j가 다를 때 $k_i^T k_j = 0$를 만족한다. matrix W를 $W = \\sum_i v_i k_i^T \\in \\mathbb R^{M \\times N}$ 로 정의하면 orthogonality에 의해 $Wk_i = v_i$가 성립한다. 이를 key-value association을 기록한 memory라 하여 associative memory라고 부르며, linear operation으로 구성되므로 linear associative memory라 할 수 있다.\n저자의 이야기는 Convolution 또한 associative memory의 일종으로 볼 수 있다는 것이다. 흔히 생각하는 convolution은 window에 대해 pixel-wise weighted sum을 한 결과를 나열하는 operation이다. 이는 output의 한 pixel을 관점으로 convolution을 해석한 것이다.\n반대로 input feature에 대해 해석하면 single feature $k \\in \\mathbb R^{B\\times N}$에 weight matrix $W \\in \\mathbb R^{N \\times (MHW)}$를 곱하고, BxMxHxW의 2D tensor로 reshape 하여 location-aware summation 한 것으로도 볼 수 있다.\n이렇게 되면 convolution은 kernel을 matrix로 보고 key가 orthogonal 할 때 linear associative memory로 해석될 수 있다.\nNonorthogonal Keys\nkey는 $\\mathbb R^N$의 vector이므로 최대 N개까지 orthogonal 할 수 있고, 더 많은 key-value pair를 기록하기 위해서는 $v_i \\approx Wk_i$를 approximately equal한 조건을 취하여 error를 minimizing 하는 방식으로 구성한다.\n$W_0 \\overset{\\Delta}{=} \\arg \\min_W \\sum_i ||v_i - Wk_i||^2$\n이때 $K \\overset\\Delta= [k_1|\u0026hellip;|k_S] \\in \\mathbb R^{N\\times S}$ 와 $V \\overset\\Delta= [v_1|\u0026hellip;|v_S] \\in \\mathbb R^{M\\times S}$ 로 가정하면 multiple nonorthogonal key, value pair에 대한 associative memory를 구성할 수 있다.\n$W_0 = \\arg\\min_W \\sum_i||V - WK||^2$\n그리고 이는 least square solution $W_0KK^T = VK^T$와 pseudo-inverse $K^+$에 대해 $W_0 = VK^+$로 표현된다.\nWhat we want\n즉 pretrain을 통해 구한 $W_0$는 trainset에서 연산한 L-1까지의 feature map과 그에 대한 response를 key-value로 가정한 associative memory가 된다.\n여기서 우리가 하고 싶은 것은 다음과 같다.\nuser가 copy한 value와 paste한 지점의 key를 가져와 새로운 pair로 memory에 추가\n이렇게 되면 L-1까지의 feature map에서 key가 관측되었을 때 memory에서 새로운 value가 mapping 되어 해당 부분에 copy한 context가 이미지에 발현된다. Model manipulation을 하는 주요한 근거가 되는 것이다.\n이를 표현하면 $W_1 = \\arg\\min_W ||V - WK||^2$와 $v_* = W_1k_*$를 만족 시키는 constrained least-square (CLS) problem으로 구성되고, 이의 해는 다음과 같이 정리된다.\n$W_1KK^T = VK^T + \\Lambda k_*^T$\n$W_1KK^T = W_0KK^T + \\Lambda k_*^T$\n$W_1 = W_0 + \\Lambda(C^{-1}k_*)^T$\n이 때 $C \\overset\\Delta= KK^T$로 구성하면 key가 zero-mean일 때 covariance로 해석될 수 있다. 결국 $\\Lambda \\in \\mathbb R^M$를 구하는 문제로 귀결된다. 여기서 $d \\overset\\Delta= C^{-1}k_*$로 가정하면 $W_1 = W_0 + \\Lambda d^T$로 볼 수 있고, 풀이는 다음과 같다.\n$\\left[ \\begin{array}{c|c} W_1 \u0026amp; \\Lambda \\end{array} \\right] \\left[ \\begin{array}{c|c} I \u0026amp; k_* \\\\ \\hline -d^T \u0026amp; 0 \\end{array} \\right] = \\left[ \\begin{array}{c|c} W_0 \u0026amp; v_* \\end{array}\\right]$\n$\\left[ \\begin{array}{c|c} W_1 \u0026amp; \\Lambda \\end{array} \\right] = \\left[ \\begin{array}{c|c} W_0 \u0026amp; v_* \\end{array} \\right] \\left[ \\begin{array}{c|c} I \u0026amp; k_* \\\\ \\hline -d^T \u0026amp; 0 \\end{array} \\right]^{-1}$\n여기서 주목할 점은 2가지이다.\nuser requested mapping $k_* \\to v_*$의 soft error-minimization objective가 d라는 straight-line을 따라 update해야 하는 hard constraint로 바뀜 direction d가 key에 의해서만 결정되고 value는 오직 user requested $v_*$가 $\\Lambda$에 영향을 주는 방식 정도로만 작용함 결국 구현체에서는 covariance C 정도를 미리 연산하여 caching 해두고, request가 올 때 direction과 $\\Lambda$를 계산하는 방식으로 작동할 것이다.\npreview의 수식을 다시 들고오면, $W_1 = \\arg\\min_W ||V-WK||^2$는 smoothness를 위한 loss, $v_* = W_1k_*$는 constraint를 위한 loss로 볼 수 있다. 그리고 이 둘의 solution이 d라는 direction으로 update된 $W_1$로 나온 것이다.\nGeneralization\n위까지의 정리는 copy\u0026amp;paste로 수정된 이미지에 대한 해당 layer와 그 전 layer의 response를 얻어와 key-value mapping을 구성할 수 있어야 한다. 하지만 SOTA를 이루고 있는 generative model들은 주로 gaussian noise에서 image로의 mapping을 확률적으로 학습하고 있기에, 수정된 이미지의 latent를 z-optimization을 통해 얻을 수 있어야 하고, 이 또한 rule이 크게 바뀐 경우에는 정확하지 않을 수 있다.\n원문에서는 이 부분을 위해 feature independency를 보였는데, 일례로 stylegan과 progressive gan은 특정 레이어의 response를 patch로 나눠 주변 정보 없이 각각을 inference 했을 때도 원본과 유사한 object가 복원되었다는 것이다. 이는 feature map을 low resolution의 image로 보고 각 key가 해당 위치에 존재하는 object를 encoding 하고 있기에 가능하다는 가설을 세울 수 있다.\nFig. 17: Comparison of rendered cropped activations at various layers of Progres- sive GAN generated LSUN church images.\n이렇게 되면 z-known image에서 복사하고자 하는 patch의 위치를 특정할 수 있을 때, low-resolution의 feature map에서 동일한 위치의 value를 가져와 대상에 위치만 맞춰 붙여넣으면 되고, feature map 수준에서 보다 perceptual 한 distance를 측정할 수 있게 된다.\n만약 z와 convolutional response를 얻을 수 없어 image-level에서 distance를 측정해야 하거나, activation을 거친 response를 가정할 때에는 neural net의 nonlinearity에 의해 선형성 가정이 깨지게 된다. 이에 neural generator를 다루는 입장이라면 위 방법론이 nonlinear 환경에서 일반화될 수 있어야 한다.\n원문에서는 nonlinear mapping $f(k; W)$가 있을 떄 update policy가 W의 row-space에 sensitive하고, column-space에 insensitive 하므로 동일한 rank-1 update를 $f(k_*; W) \\approx v_*$의 optimization constraint로 쓸 수 있다고 한다.\nlinear phase에서는 $\\Lambda$를 linear system을 통해 풀었다면, nonlinear phase에서는 gradient 기반의 optimization이 필요하다. 이때 $\\Lambda$는 requested value와 direction에 의존하는 변수이기 때문에 이를 objective로 하는 optimization을 진행한다.\n$\\Lambda_1 = \\arg\\min_{\\Lambda \\in \\mathbb R^M}||v_* - f(k_*; W_0 + \\Lambda d^T)||$\n만약 requested key-value pair가 하나가 아닌 여럿이라면, rank-1 대신 low-rank optimization이 될 것이고, S개 pair에 대해 다음과 같이 표현할 수 있다.\n$d_i = C^{-1}K_{*i}$\n$D_S \\overset\\Delta= [d_1|\u0026hellip;|d_S]$\n$\\Lambda_S = \\arg\\min_{\\Lambda \\in \\mathrm R^{M \\times S}} || V_* - f(K_*; W_0 + \\Lambda D_S^T)||$\n그리고 update는 $W_S = W_0 + \\Lambda_S D_S^T$로 이뤄질 것이다.\n마지막으로 이 조건을 좀 더 relax하면 $\\arg\\min_W ||V_* - f(K_*; W)||$를 optimizing하고, 대신 매 step 마다 W를 $W_0 + \\Lambda_S D_S^T$의 subspace로 projection 하는 projected gradient descent를 취한다.\nDetail\noriginal repository rewriting에서는 L-1까지의 feature map을 BHWxC로 reshape하여 collect_2nd_moment에서 z-dataset을 기반으로 CxC의 covariance를 미리 구해 놓는다.\n이후 edit 요청이 들어오면 covariance_adjusted_query_key에서 direction을 구하는데, C의 pseudoinverse를 구하는 대신 $CD_S = K_S$의 least square solution (torch.lstsq)을 풀어 computational stability를 얻었다고 한다.\n이때 전체 이미지에서 desired key만을 가져오기 위해 multi_key_from_selection에서는 target layer의 resolution에 맞게 image-level의 mask를 bilinear interpolation한 후, key matrix에 직접 곱하여 non-zero key만을 선별한다. feature independency에 따라 가능하다.\n이후 $D_{S}$를 직접 이용하는 것이 아닌 low-rank subspace의 basis를 구해 활용하며, 원문에서는 SVD를 통해 eigen-value가 큰 eigen-vector를 선출하여 동일한 subspace를 구성하는 orthogonal basis로 활용했다.\n이후 insert에서 parameter optimization을 진행한다.\nweight은 subspace에 orthogonal 하게 변환하여 ortho_weight 변수에 저장해 둔다. 이는 projected_conv을 활용하는데, 흔히 gram-schmidt orthogonalization에서 하는 것과 같이 basis에 정사형한 벡터를 원본에서 빼는 방식으로 진행한다.\n$W_\\mathrm{ortho} = W - (WU_{1:R})U_{1:R}^T \\ \\mathrm{where} \\ C^{-1}K_S = U\\Sigma V^T, \\ \\mathrm{lowrank} \\ R$\n이후 feature-level distance를 L1으로 하는 optimization을 진행하고, 특정 스텝마다 weight을 subspace로 projection하여 ortho_weight에 더하는 방식으로 projected gradient descent를 구현한다.\n이렇게 되면 optimization의 여파는 subspace 내에서만 구성되고, subspace에 orthogonal한 weight을 더함으로써 기존의 weight은 유지하고 subspace 내에서의 update만을 취할 수 있게 된다.\nZCA를 활용한 rank reduction은 원문의 Appendix. D.를 참고한다.\nLayer selection\n원문에서는 convolution layer를 neighbor와의 정보 취합으로 edge, texture, shape 등을 구별해 내는 관점보다는, 하나의 feature vector가 local patch가 되면서 주변과 disentangle 되는 관점을 취하였고, 이것이 memory model로 해석되었다.\n원문에서는 실제로 ProgressiveGAN[1]과 StyleGANv2[2]의 일부 레이어에서 이런 feature 간 독립성을 띠고 있음을 보였다.\nfeature map을 MxN의 patch로 잘라 주변 정보 없이 적절한 크기의 output을 만들었을 때, 네트워크는 여전히 동일한 객체와 컨텍스트를 만들어 낼 수 있음을 보인다면, feature 간에 독립적인 정보를 담고 있음을 추론할 수 있다.\n레이어마다 patch를 잘라 output을 만들었을 때 Frechet Inception Distance (FID)가 작다면 해당 patch는 주변 정보로부터 less dependence 한 것이고, FID가 높다면 dependent 한 것임을 나타낼 것이다.\nFig. 13: FID of rendered cropped activations with respect to random crops of StyleGANv2 generated images\n그래프에서 6~11번째 layer가 FID가 가장 낮았고, 이 layer에서 key 값은 주변과 independent 한 정보를 가지고 있을 확률이 높다. 즉, 어느 한 layer의 key를 수정해야 한다면, 해당 layer를 수정하는 것이 object를 render 하는데 좋은 quality의 이미지를 만들 수 있음을 나타낸다.\nFig. 14: Comparison of rendered cropped activations at various layers of Style- GANv2 generated LSUN church images.\nExperiment\n이제 User는 copy\u0026amp;paste를 통해 image에 원하는 부분을 수정하고 (key-value), 몇몇 context image에 수정되었으면 하는 부분(key-context)을 표기하여 rewriter에게 전달한다.\nrewriter은 해당 key-context로부터 direction을 계산하고, pasted image와 original image 사이의 L1-loss를 기반으로 projected-optimization을 진행한다. 이에 따라 일반화된 model을 얻을 수 있고, editing을 마치게 된다.\nFig. 7: Giving horses a hat to wear.\nDiscussion\n저자는 GPT-3, WaveNet과 같이 image 이외의 분야에서도 vastly trained model에 rule을 수정하고자 하는 일이 있을 것이고, model rewriting은 이 경우에 새로운 contents, behavior, interaction을 부여할 충분한 방법론일 것이라 이야기한다.\nImplementation\npytorch, official: David Bau, rewriting pytorch, unofficial: revsic, Rewriting-A-Deep-Generative-Models References\nProgressive Growing of GANs for Improved Quality, Stability, and Variation, Tero Karras et al., 2017, arXiv:1710.10196. Analyzing and Improving the Image Quality of StyleGAN, Tero Karras et al., 2019. arXiv:1912.04958. ","permalink":"https://revsic.github.io/blog/rewriting/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Model editing","Rewriting"],"title":"Rewriting a Deep Generative Model"},{"categories":["Generative"],"contents":" Stanislav Pidhorskyi et al., 2020, arXiv Keyword: Generative, Adversarial learning Problem: AE based approach has poor quality of output distribution. Solution: Adversarial setting and encoder, decoder decomposition. Benefits: Less entangled latent, sharp output distribution. Contribution: Learnable and less entangled latent with adversarial autoencoding structure. Weakness or Future work: - GAN and AE\nGenerative Adversarial Networks (GAN)은 complex distribution을 표현하는 데 좋은 성능을 보여왔다. 특히 sharp 한 generation에 특이점을 가져 많은 현실적인 이미지나 음성을 생성할 수 있었다.\nAutoencoder는 encoder, generator pair로 representation과 generation 모두를 포함하는 구조이다. 본문에서는 AE가 representation은 충분히 잘하고 있지만, generation까지 겸비한 모델은 아직 구현하지 못하였다고 이야기한다.\n이에 소개하고자 하는 것이 Adversarial Latent Autoencoder (ALAE)이고, GAN과 비슷한 generative power를 가지면서도 representation disentangle이 가능한 모델을 목표로 한다.\n대부분의 AE 연구들은 같은 가정을 하는데, latent space를 확률 분포로 모델링 하며, 이것을 고정된 prior에 맞춰야 한다는 것이다. 실제로 ELBO를 정의할 때 posterior q를 가정하고 variational inference를 진행하는데, KL-divergence가 대상으로 삼은 conditional prior가 intractable 하기 때문에 주로 고정된 prior를 사용하게 된다. 하지만 StyleGAN (Karras et al., 2018)에서는 분포상 제약을 받지 않고, 데이터로부터 학습된 latent space가 prior에서 많은 transform을 거칠수록, prior에서 거리가 멀어질수록, disentangle 하기 쉽다는 이야기를 한다.\n여기서 착안하여 저자는 AE가 latent distribution을 data에서 학습할 수 있게 하였고, output distribution은 adversarial strategy를 통해 학습하였다. 이를 통해 GAN만큼의 generative power를 가지면서도 disentanglement를 더 용이하게 하는 것이다. 이는 근래 GAN 관련 분야에서 연구된 여러 기법이나 휴리스틱을 덜 사용하면서도 효과적으로 데이터를 모델링할 수 있게 한다.\nPreliminaries: GAN Objectives\n본문에서 소개하는 GAN objective의 general formulation은 다음과 같다.\n$$V(\\mathtt G, \\mathtt D) = \\mathbb E_{p_D(x)}\\left[ f(\\mathtt D(x)) \\right] + \\mathbb E_{p(z)}\\left[ f(-\\mathtt D(\\mathtt G(z))) \\right]$$\n여기서 f를 softplus $f(t) = -\\log(1 + \\exp(-t))$로 두면 vanilla GAN과 같아지고, f를 identity $f(t) = t$로 두면 wasserstein GAN과 같아진다.\nAdversarial Latent Autoencoders\n기존의 GAN이 generator와 discriminator를 single module로 구성하였다면, ALAE에서는 가장 먼저 G와 D를 $\\mathtt G = G \\circ F$와 $\\mathtt D = D \\circ E$로 분해한다. 그리고 F와 G 사이, E와 D 사이의 represenation을 latent W로 둘 것이다. 이 때 F와 D는 deterministic, G와 E는 stochastic하게 가정한다. G가 additional independent noise $\\eta$를 받는다면 $G(w, \\eta)$의 general stochastic generator가 될 것이다. 이때 G에서 생성된 output x의 확률은 다음과 같다.\n$$q(x) = \\int_w\\int_\\eta q_G(x|w, \\eta) q_F(w) p_\\eta(\\eta) \\mathrm d\\eta \\mathrm dw$$\n마찬가지로 E에서 생성된 latent w의 확률은 다음과 같다.\n$$q_E(w) = \\int_x q_E(w|x)q(x)\\mathrm dx$$\n여기서 q(x)를 실제 데이터 분포 $p_D(x)$로 바꾼다면 데이터에 대한 latent $q_{E, D}(w)$가 될 것이다.\n여기서 앞서 소개한 GAN objective를 토대로 모델을 학습한다면 이는 synthetic distribution q(x)를 실제 데이터 분포 $p_D(x)$로 맞춰가는 작업이 된다. 여기에 더불어 ALAE에서는 하나의 조건을 더 걸게 되며, 이는 $q_F(w) = q_E(w)$로 latent distribution을 matching 하는 작업이다.\nAE는 latent와의 bijection을 위해 reciprocity, 자기복원의 기능을 가지는데, 크게 $x=G(E(x))$로 data space 상에서의 복원이 있을 수 있고, $w=E(G(w))$로 latent space 상에서의 복원이 있을 수 있다. 전자의 경우는 두 분포의 차이를 나타내는 reconstruction error를 가지게 되고, 각 픽셀을 독립된 확률 분포로 가정했을 때 prior에 따라 log-prob으로 l1이나 l2 loss를 띌 수 있다. 대부분의 AE 기반 모델에서 사용하지만 실제로는 blur나 noise 같은 output distribution에 표현되는 perceptual 한 손실을 만들기 때문에 지금까지의 AE 모델들이 쉽게 GAN에 비견되는 품질을 가질 수 없었다.\n반면 ALAE는 후자를 선택하였는데, latent space 상에서 차이를 나타내는 discrepancy measure를 두고, F와 EGF의 출력을 비교하는 것이다. output 상에서의 l2-loss는 human perception을 반영하기보다는 단순 픽셀 상의 차이에 집중하고, 이런 한두 개의 픽셀 차이는 latent 상에 작용하기 어려워야 한다. 이에 latent 상에 직접 discrepancy measure를 걸어 버리는 것이 human perception에 더 직접적으로 작용할 수 있게 학습하는 것이다.\n이는 GAN의 intuition과 비슷한데, GAN은 기존의 AE가 output space 상에서 independent 한 픽셀을 가정하고 discrepancy를 측정한 것에 반해, discriminator라는 human perception을 대체할만한 추가 모델을 두고, receptive field와 인지 능력을 학습받은 adaptive discrepancy를 측정할 수 있게 한 것이다.\nALAE에서는 이 discrepancy measure를 단순 l2로 두었는데, 이는 latent W에 어떠한 제약도 두고 싶지 않았기 때문이라고 한다. latent W에 distribution을 가정하고 KL-divergence와 같은 척도를 이용할 수도 있지만, 이렇게 되면 실상 F가 identity map과 같아지고 그 의미가 무색해진다. 대신 l2를 사용하였기 때문에 실제 데이터에 대한 latent $q_{E, D}(w)$와의 비교는 어려워졌다.\ninference에서는 E로 input data를 encoding 하여 만든 latent w와 G를 통해 이미지를 재생성하는 방식으로 작동한다.\n(StyleALAE에 대한 이야기는 보류한다.)\nDetail\n$L^{E, D}_ {adv} = \\mathrm{softplus}(D\\circ E \\circ G \\circ F(z)) + \\mathrm{softplus}(-D \\circ E(x)) + \\frac{\\gamma}{2}\\mathbb E_{p_D(x)}\\left[ ||\\nabla D \\circ E(x)||^2\\right]$\n$L^{F, G}_ {adv} = \\mathrm{softplus}(-D\\circ E \\circ G \\circ F(z))$\n$L^{E, G}_ {err} = ||F(z) - E \\circ G \\circ F(z)||^2_2$\nGAN objective의 f는 softplus를 사용하였고, 대신에 real data에 대한 gradient regularization term을 두었다. latent prior z는 standard gaussian으로 두었고, 따로 independent noise $\\eta$를 두지 않은 것으로 보인다.\nDiscussion\n실제로 MLP 기반의 MNIST 모델과 StyleALAE 기반의 여러 image synthesizing experiment를 진행하였고, image quality는 물론 latent 상에서의 preceptual path length가 짧아지는 등의 disentanglement 성능 향상도 보였다고 한다.\n다른 연구들과는 달리 adaptive latent를 가정하여 less entangle한 latent를 학습할 수 있었고, adversarial setting으로 output distribution의 sharpness를 유지할 수 있었다. reciprocity에 대한 ablation study 같은 것이 있었으면 좋을거 같다.\nImplementation\npytorch, official: ALAE tensorflow, unofficial, MNIST PoC: tf-alae Reference\nAdversarial Latent Autoencoders, Stanislav Pidhorskyi et al., 2020. StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Tera Karras et al., 2018. ","permalink":"https://revsic.github.io/blog/alae/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Autoencoder","ALAE"],"title":"Adversarial Latent Autoencoders"},{"categories":["Bayesian"],"contents":" Hyunjik kim et al., 2019, arXiv Keyword: Bayesian, Process Problem: Underfitting of Neural Process Solution: NP + Self-Attention, Cross-Attention Benefits: Improvement of prediction accuracy, training speed, model capability. Contribution: Solving underfitting on NP Weakness or Future work: Decoder + Self-Attention Neural Process and Gaussian Process\nNeural Process는 함수 분포를 모델링하기 위한 효과적인 메소드를 소개했다. linear time에 작동하며, 한번 학습되면 임의의 context pair와 query에 대해 target 분포를 예측할 수 있다. 그럼에도 NP와 GP를 직접 비교하기 어려운 이유는 NP는 stochastic process의 여러 realization (process에서 샘플링한 함수 표본) 에 대해서 학습하지만, GP는 하나의 realization에서 sample 된 observation에 대해 학습하기 때문이다.\nNP는 Scalability, Flexibility, Permutation Invariance라는 점에서 여러 장점이 있지만, consistency 문제를 가지고 있다. 이는 context로부터 target을 추론한 후, 다시 context에 덧붙여 target을 추가 추론했을 때와 온전한 context로부터 전체 target을 추론했을 때 분포차가 발생할 수 있음을 의미한다. 그러므로 NP를 그 자체로 consistent 하다고 보기보다는 consistent stochastic process의 근사라고 보는 것이 맞다.\nNP의 또 하나의 약점은 context set에 underfit한다는 것이다. 실제로 1D Curve Fitting 문제를 살펴보면, context point가 존재하는 지점에서도 과한 분산과 부적절한 평균점을 보인다. 본문에서는 이 이유를 NP가 context set을 고정된 크기의 latent로 변환시키는 과정에 permutation invariant function으로 mean-aggregation을 썼는데, 이 과정이 bottleneck으로 작용했기 때문이라고 판단하였다. 이는 모든 컨텍스트에 동일한 가중치를 주었기에, 디코더가 target을 예측할 때 context point로부터 적절한 관련 정보를 제공받지 못하고 있을 것으로 생각한 것이다.\n이러한 점을 해결하기 위해서 GP의 kernel function을 차용하였다. kernel은 입력값의 두 지점에 대해서 유사도를 측정하는 도구로 이용되는데, NP에는 이러한 메커니즘이 존재하지 않는 것이다. 그래서 제안하고자 하는 게 Attentive Neural Process (ANPs)이고, 이는 NP에 differentiable attention을 추가하여 context point에 대한 underfit을 줄인 모델이다.\nAttentive Neural Process\n먼저 입력과 출력 $x_i \\in \\mathbb R^{d_x}, \\ y_i \\in \\mathbb R^{d_y}$, 그리고 observed context $(x_C, y_C) := (x_i, y_i)_ {i \\in C}$ 와 targets $(x_T, y_T) := (x_i, y_i)_{i \\in T}$를 가정한다. context representation aggregator r에 대해 $r_C := r(x_C, y_C) \\in \\mathbb R^d$로 두고, latent encoder s에 대해 $s_C := s(x_C, y_C)$로 두면 NP는 다음을 모델링하는 것과 같다.\n$$p(y_T | x_T, x_C, y_C) := \\int p(y_T | x_T, r_C, z)q(z | s_C)dz$$\n여기서 NP가 가정하는 process F의 randomness는 global latent z에서 오기 때문에 likelihood를 최대화하는 과정은 z의 샘플링을 통해 여러 개로 realization 된 하나의 process를 학습하는 것과 같다.\nz_context = self.z_encoder(context, key=cx, query=cx) z_prob = self.latent_prob(z_context) latent = z_prob.sample() self_attend = self.encoder(context, key=cx, query=cx) ANP는 여기에 두 가지 attention을 덧붙인다. 첫 번째는 self-attention으로 context 사이에서 정보를 공유하고 더 나은 intermediate representation을 만들기 위한 장치이다.\ncross_attend = self.cross_encoder(self_attend, key=cx, query=query) rep = self.decoder(cross_attend, query, latent) dist, mu, sigma = self.normal_dist(rep) context에 self-attention을 취하면 context 개수만큼의 intermediate representation(IR)이 생기고, 이는 target과 context의 유사도를 비교하는 cross attention을 통과하여 query-specific representation $r_* := r^*(x_C, y_C, x_ *)$을 만든다. 이는 모델이 실제로 어떤 컨텍스트 포인트를 조명할지 명시하기 때문에 target prediction에 도움을 줄 수 있다.\nlatent encoder의 경우에는 self-attention 이후 cross-attention 대신에 mean-aggregation을 선택했는데, 본문에서는 이를 global-latent로써 보존하고 싶었다고 한다. latent path에 cross-attention이 들어오면, latent에 locality가 발생하기 때문이다.\n$$\\log p(y_T | x_T, x_C, y_C) \\ge \\mathbb E_{q(z | s_T)} \\left[ \\log p(y_T | x_T, r_C, z) \\right] - D_{KL}(q(z | s_T) || q(z | s_C))$$\ntraining loss는 ELBO를 동일이 가져간다.\n이렇게 하면 computational complexity가 O(n(n + m))이 되는데, 이는 attention 과정에서 모든 컨텍스트를 탐방하기 때문이다. 하지만 dot-product attention 같은 matrix-multiplication 기반의 attention 알고리즘을 이용하면 대부분이 parallel 하게 동작할 수 있으므로 실제로는 training time이 NP와 비교할 만 하다고 한다.\nDiscussion\nANP는 attention mechanism을 통해 underfitting problem을 효과적으로 풀어냈다. 추측의 정확도가 높아졌고, 학습이 빨라졌으며, 모델링 할 수 있는 메소드의 범위도 늘었다. 저자는 ANP의 decoder에 self-attention을 붙여 expressiveness의 향상 정도를 확인하고 싶다고 한다. 하지만 이는 target prediction 사이에 상관성이 생기는 문제이니 ordering이나 grouping을 어떻게 해야 할지가 중요해질 것이라고 한다.\nImplementation\nTensorflow v1: tf-neural-process Reference\nConditional Neural Processes, Garnelo et al., 2018. Neural Processes, Garnelo et al., 2018. Attentive Neural Processes, Kim et al., 2019. ","permalink":"https://revsic.github.io/blog/anp/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process","Attentive Neural Process"],"title":"Attentive Neural Processes"},{"categories":["Bayesian"],"contents":" Marta Garnelo et al., 2018, arXiv Keyword: Bayesian, Process Problem: Data inefficiency, hard to train multiple datasets in one. Solution: Stochastic Process + Latent variable + NN Benefits: Concurrent training, global uncertainty, explicit latent variable. Contribution: CNP + global uncertainty, concurrent dataset, explicit latent Weakness or Future work: Pairwise correlation. Function Approximation\n딥러닝에서는 데이터 간의 상관관계를 찾기 위해 함수를 근사하는 작업을 하는데, 주로 지도 학습에서는 parameterized function의 파라미터 셋을 gradient를 통해 업데이트하는 방식을 차용한다. 이러한 경우 대부분의 workload가 학습 중에 이뤄지며, 추론 과정은 단순 forward pass만으로 가능하다. 하지만 한번 학습된 이후로는 추론 결과의 업데이트가 힘들다는 점에서 메타 러닝 쪽도 관심이 많아지는 편이다.\n그 대체재로 Stochastic Process와 그 에인 Gaussian Process(GP)가 있는데, 이러한 모델들은 training phase를 필요로 하지 않고, test-time에 원하는 쿼리를 직접 렌더링 하게 된다. 하지만 렌더링 과정이 O(N^3)의 연산이 필요하기 때문에 대형 데이터셋을 상대로 적용하기 쉽지 않고, kernel과 같은 prior에 의해 함수 모형이 바뀌는 등 여러 문제점도 존재한다.\n이에 제안하고자 하는 게 Neural Process이다. 함수에 대한 분포를 가정하고, observation을 통해 query와 prediction에 대한 uncertainty를 추정한다. GP와 달리 O(n + m)의 단순 forward pass만으로 추정을 진행할 수 있다는 점에서 장점을 지닌다.\nNeural Process\n먼저 random function $F: \\mathcal X \\to \\mathcal Y$와 finite seq $x_{1:n}=(x_1, \u0026hellip;, x_n)$ with $x_i \\in \\mathcal X$, function values $Y_{1:n} := (F(x_1), \u0026hellip;, F(x_n))$를 가정한다. 이 collection의 joint dist $\\rho_{x_{1:n}}$이 존재할 것이고, GP 라면 multivariate gaussian일 것이다.\n이 joint dist는 exchangeability와 consistentcy라는 조건에서 Kolmogorov Extension Theorem에 의해 stochastic process로 정의될 수 있다. 이 때 exchangeability는 permutation invariance를 의미하고, consistentcy는 marginlize한 범위 외의 sequence에 대해 marginalize했을 때 원본 시퀸스와 동일함을 의미한다.\nStochastic process F와 시퀸스 $x_{1:n}$, 그의 joint dist $\\rho_{x_{1:n}}$에 대해 instantiation of stochastic process f는 다음과 같다\n$$\\rho_{x_{1:n}} = \\int p(f)p(y_{1:n}|f, x_{1:n})df$$\nobservation noise를 고려하여 $Y_i \\sim \\mathcal N(f(x_i), \\sigma^2)$라 가정하면 proability p는 다음과 같다\n$$p(y_{1:n}|f, x_{1:n}) = \\prod^{n}_{i=1} \\mathcal N(y_i | f(x_i), \\sigma^2)$$\n이 때 joint dist $\\lbrace\\rho_{x_{1:n}}\\rbrace$의 exchangeability와 consistentcy에 의해 stochastic process F의 존재성이 증명된다. 여기서 NP가 하고 싶은 것은 high-dimensional random vector z로 F를 parameterize하고, fixed function g에 대해 F(x) = g(x, z)를 NN으로 학습하고 싶은 것이다.\n$$p(z, y_{1:n}|x_{1:n}) = p(z)\\prod^{n}_{i=1} \\mathcal N(y_i|g(x_i, z), \\sigma^2)$$\n이 때 random function과 distribution을 학습하기 위해서는 여러 데이터셋을 동시에 학습해야 한다. 여러 input seq $x_{1:n}$와 output seq $y_{1:n}$를 학습시켜 데이터 간의 variability를 학습할 수 있게 한다.\ng를 non-linear NN으로 두기 때문에 학습에는 variational inference를 이용한다. latent z와 prior p(z)는 standard multivariate gaussian으로 두고, variational posterior $q(z|x_{1:n}, y_{1:n})$를 가정한다.\n$$\\log p(y_{1:n}|x_{1:n}) \\ge \\mathbb E_{q(z|x_{1:n}, y_{1:n})}\\left[\\sum^{n}_{i=1}\\log p(y_i|z, x_i) + \\log \\frac{p(z)}{q(z|x _{1:n}, y _{1:n})}\\right]$$\n이 때 test time에 더욱 well-behave model을 만들기 위해 context-set과 target-set을 나누고, true posterior $p(z|x_{1:n}, y_{1:n})$ 대신 variational posterior로 approximate한다.\n$$\\log p(y_{1:n}|x_{1:n}) \\ge \\mathbb E_{q(z|x_{1:n}, y_{1:n})}\\left[\\sum^{n}_{i=m+1}\\log p(y_i|z, x_i) + \\log \\frac{q(z|x _{1:m}, y _{1:m})}{q(z|x _{1:n}, y _{1:n})}\\right]$$\n이렇게 되면 z가 process F를 capture하는 역할을 하고, 이것이 global uncertainty를 capture 했다고도 볼 수 있다.\n실제 구현체에서는 encoder h가 pair $(x, y)_i$에 대해 repr $r_i = h((x, y)_i)$로 구성하고, exchangeable aggregator $r = a(r_i) = \\frac{1}{n} \\sum^n _{i=1}r_i$를 통해 latent $z \\sim \\mathcal N(\\mu(r), I\\sigma(r))$를 표현한다. 마지막으로 decoder g와 sampled latent z에 대해 $y_T = g(z, x_T)$를 통해 output을 결정하게 된다.\nz_context = self.z_encoder(context) z_dist = self.z_prob(z_context) latent = z_dist.sample() rep = self.decoder(context, query, latent) dist = self.normal_dist(rep) log_prob = dist.log_prob(target) log_prob = tf.reduce_sum(log_prob) prior = self.z_prob(self.z_encoder(context)) posterior = self.z_prob(self.z_encoder([query, target])) kl = tfp.distributions.kl_divergence(prior, posterior) kl = tf.reduce_sum(kl) elbo = -log_prob + kl Conditional Neural Process, Marta Garnelo et al., 2018\n동일 저자는 같은 해에 CNP라는 논문을 냈는데, 차이점은 NP는 latent z를 통해 process F를 캡처하고, global uncertainty를 측정하는데, CNP는 그러한 과정 없이 deterministic 하게 context와 query에 대한 target을 내놓는다. NP는 latent를 명시적으로 설정하였기 때문에, concurrent 한 training process에서도 명확히 latent를 포착하는 것을 볼 수 있다.\nDiscussion\nNP는 역시 stochastic process와 NN을 합친 모델이다. 함수에 대한 분포를 정의하고, context conditioned prediction을 생성한다. regression task에 대해서 실험을 주로 했는데, future work로 high dimensional data에 관한 연구를 남겨두겠다 한다.\nImplementation\nTensorflow v1: tf-neural-process Reference\nConditional Neural Processes, Garnelo et al., 2018. Neural Processes, Garnelo et al., 2018. ","permalink":"https://revsic.github.io/blog/np/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process"],"title":"Neural Processes"},{"categories":["Bayesian"],"contents":" Marta Garnelo et al., 2018, arXiv Keyword: Bayesian, Process Problem: Weakness of knowledge sharing and data inefficiency of classical supervised learning Solution: Stochastic Process + NN Benefits: Data efficient, prior sharing Contribution: Encapsulation of parameterized NN function family. Weakness or Future work: Global uncertainty, pairwise correlation. Function Approximation\n우리는 데이터의 경향성을 파악해 추론을 얻어내기 위해 흔히 데이터셋 $\\lbrace(x_i, y_i)\\rbrace^{n-1}_{i=0}$과 함수 $f: X \\to Y$를 가정한다. 일반적인 지도학습에서는 $f$를 parameterized model로 가정하고, computation을 고정, parameter를 학습하는 방식을 취한다. 그 이후에는 deterministic하게 입력에 대해 출력이 결정된다. 이러한 방식은 prior의 적용이 한정적이고, 그에 따라 learning 사이의 정보 공유가 어려워 매번 대량의 데이터셋에 대한 새로운 학습이 요구되는 등 여러 한계를 보이기도 한다.\nStochastic process는 함수라는 카테고리를 하나의 확률 분포로 가정한다. 함수에 대한 사전 지식은 분포상의 가정으로 표현되고, 학습은 관측된 값들에 대한 조건부 확률과 사후 분포로써 표현된다.\n대표적인 예로 gaussian process는 함수의 smoothness prior를 kernel function으로 나타내었고, 이는 값들 사이의 유사도로 나타나게 된다. 하지만 이러한 메소드들은 prior에 따라서 computationally intractable하기도 하고, $O(N^3)$에 달하는 연산량에 현대에는 많이 쓰이지 않고 있다.\n이러한 문제를 풀기 위해 model family를 제안하고, 이것이 Conditional Neural Process 이다.\nStochastic Process\n먼저 observation $O = \\lbrace(x_i, y_i)\\rbrace \\subset X \\times Y$ 과 target $T=\\lbrace x_i\\rbrace^{n+m-1}_{i=n}$ 를 가정하자. 이 때 $f: X \\to Y$로의 함수와 이 함수의 분포 P가 존재한다면 $f \\sim P$ 이고, 조건부 분포 $P(f(T)|O, T)$로 표현된다.\nGP에서는 P를 Gaussian으로 가정하고, Covariance Matrix 대신 두 지점 사이의 유사도를 측정하는 kernel 함수를 도입한다. 이러한 모델은 data efficient 하지만, prior나 kernel 함수의 설정이 어렵고, 추론 과정이 $O((n+m)^3)$로 computationally expensive 하다.\nConditional Neural Process (CNPs)\nCNP는 함수를 observation에 대한 조건부 분포로 가정한다. CNP는 observation을 고정된 크기의 embedding vector로 표현하고, 이를 토대로 새로운 query에 대한 추론을 만든다. 이 모든 것이 NN을 통한 single forward pass에 이뤄지기 때문에 관측수 n과 쿼리수 m에 대해 O(n + m)의 복잡도만을 요구로 한다.\nobservation O가 주어질 때 CNP는 $Q_\\theta$ 의 conditional process를 가정한다. 기존의 stochastic process처럼 O와 T의 순서에 대해 추론이 변하지 않는 permutation invariance를 보장한다. 또한 factorization $Q_\\theta(f(T)|O, T)=\\Pi_{x \\in T}Q_\\theta(f(x)|O, x)$을 가정한다.\nCNP의 구조는 다음과 같다.\n$r_i = h_\\theta(x_i, y_i) \\quad \\forall (x_i, y_i) \\in O$\n$r = \\oplus^n_i r_i$\n$\\phi_i = g_\\theta(x_i, r) \\quad \\forall x_i \\in T$\n이 때 $h_\\theta: X \\times Y \\to \\mathbb R^d$ 이고, $g_\\theta: X \\times \\mathbb R^d \\to \\mathbb R^e$ 이다. $\\oplus$는 observation embedding을 합치는 operation으로 본문에서는 permutation invariance를 지키기 위해 commutative 하다는 가정을 두었다.\n그 결과 process는 $Q_\\theta(f(x_i) | O, x_i) = Q(f(x_i) | \\phi_i)$ 로 표현되며, 이 과정이 NN forward pass만으로 이뤄지기 때문에 O(n + m)의 복잡도를 가진다.\nregression 에서는 $\\phi_i = (\\mu_i, \\sigma_i^2)$ 와 $\\mathcal N(\\mu_i, \\sigma_i^2)$ 로 두어 최종 $f(x_i)$가 가우시안을 따르게 하고, classification에서는 categorical distribution의 logits로 두었다.\n학습은 nll을 minimize 하는 방식으로 이뤄진다.\n$\\mathcal L(\\theta) = -\\mathbb E_{f \\sim P}\\left[\\mathbb E_N\\left[\\log Q_\\theta(\\lbrace y_i\\rbrace^{n-1}_{i=1}|O_N, \\lbrace x_i\\rbrace^{n-1} _{i=0})\\right]\\right]$\nDiscussion\n본문에서는 CNP가 training 데이터에서 prior을 적절히 학습하였고, 이를 통해 observation 간의 learning share이 가능하다고 이야기한다. 실험에서도 보였듯 data efficient하면서도 NN의 adaptivity를 충분히 잘 활용 하였고, meta-learning이나 few-shot learning 과의 상관성에 대해서도 이야기하였다. 지금은 POC 수준이지만, statistical context에서 function family를 적절히 encapsulate 한 것이 주요 contribution이지 않을까 싶다.\n추후 Neural Process나 Attentive Neural Process에서도 이야기하지만, CNP는 global uncertainty를 측정하는 수단이나, observation과 target 사이의 correlation을 측정하는 수단이 명시적으로 존재하지 않는다는 점도 고려해야 한다.\nImplementation\nTensorflow v1: tf-neural-process Reference\nConditional Neural Processes, Garnelo et al., 2018. ","permalink":"https://revsic.github.io/blog/cnp/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process","Conditional Neural Process"],"title":"Conditional Neural Processes"},{"categories":["Portfolio"],"contents":"Skills\nLanguages : Python : C++ [git+revsic/cpp-obfuscator, git+utilForever/RosettaStone]\nML Framework : Tensorflow [git+revsic/tf-glow-tts, git+revsic/tf-diffwave] : PyTorch [git+revsic/torch-nansypp, git+revsic/torch-flow-models] : Jax/Flax [git+revsic/jax-variational-diffwave]\nWindows Internal [git+revsic/cpp-veh-dbi]\nFuzzing [git+revsic/agent-fuzz]\nOpensource Contributions\nsgl-project/sglang [GIT, PR#411], 2024.05. Cohere Command-R chat template supports.\nlinfeng93/BiTA [GIT, PR#4], 2024.02. Hard-coded path removal.\nSqueezeBits/QUICK [GIT, PR#3], 2024.02. Exclude router projection layers from QUICK quantization.\nmicrosoft/TransformerCompression [GIT, ISSUE#81], 2024.01. Mixtral 8x7B SliceGPT post-train pruning supports.\ncasper-hansen/AutoAWQ [GIT, PR#251], 2023.12. Mixtral 8x7B Activation-aware Quantization supports.\nProjects - Machine Learning\nAgentFuzz: Agentic Fuzz Harness Generation [GIT, blog], 2024. : LLM Agent-based fuzz-driver generation, inspired by PromptFuzz[arXiv:2312.17677]\nAlphaZero Connect6 [GIT], 2018. : AlphaZero training framework for game Connect6 written in Rust with C++, Python interface.\nBehavior based Malware Detection Using Branch Data [GIT], 2017. : Classify malware from benign software using branch data via LSTM based on Tensorflow\nProjects - Windows Internal\ncpp-veh-dbi [GIT], 2019. : C++ implementation of vectored exception handler based simple dynamic binary instrumentation tools.\nBranch Tracer [GIT], 2019. : C++ implementation of dll-based windows debugger for tracking branching instruction via vectored exception handler.\nCode-Injector [GIT], 2018. : C++ implementation of several code injection techniques like dll injection, queue user apc.\nAntiDebugging [GIT], 2017. : C++ implementation for defending windows debugger from attaching the target process.\nProjects\ncpp-concurrency [GIT], 2019. : C++ implementation of golang-style concurrency supports, thread pool, channel, wait-group\ncpp-obfuscator [GIT], 2019. : C++ implementation of compile time string and routine obfuscator.\nRosettaStone [GIT], 2018. : C++ implementation of game \u0026lsquo;Hearthstone\u0026rsquo; as training environment and A.I. for future work.\nPacketInjector [GIT], 2016. : C++ implementation of simple packet detector and injector.\nELF Code Virtualization, 2015. : ELF (Executable Linkable Format) Virtualized Code Protection\nPaper implementations\ntorch-flow-models [GIT], 2025.02. : PyTorch implementations of various generative models, +17\ntorch-nansy++ [GIT], 2022.12. : NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis, openreview, 2022.\ntorch-whisper-guided-vc [GIT], 2022.12. : Torch implementation of Whisper-guided DDPM based Voice Conversion\ntorch-nansy [GIT], 2022.09. : Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations, Choi et al., 2021.\ntorch-retriever-vc [GIT], 2022.04. : Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph, Yin et al., 2022.\ntorch-diffusion-wavegan [GIT], 2022.03. : Parallel waveform generation with DiffusionGAN, Xiao et al., 2021.\ntorch-tacotron [GIT], 2022.02. : PyTorch implementation of Tacotron, Wang et al., 2017.\ntf-mlptts [GIT], 2021.09. : Tensorflow implementation of MLP-Mixer based TTS.\njax-variational-diffwave [GIT], [arXiv:2107.00630], 2021.09. : Variational Diffusion Models\ntf-glow-tts [GIT] [arXiv:2005.11129], 2021.07. : Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search\ntf-survae-flows [GIT], [arXiv:2007.023731], 2021.05. : SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows\ntf-diffwave [GIT] [arXiv:2009.09761], 2020.10. : DiffWave: A Versatile Diffusion Model for Audio Synthesis, Zhifeng Kong et al., 2020.\nRewriting-A-Deep-Generative-Models [GIT] [arXiv:2007.15646], 2020.09. : Rewriting a Deep Generative Model, David Bau et al., 2020.\ntf-alae [GIT] [arXiv:2004.04467], 2020.09. : Adversarial Latent Autoencoders, Stanislav Pidhorskyi et al., 2020.\ntf-neural-process [GIT] [arxiv: NP, CNP, ANP], 2019.05 : Neural process, Conditional Neural Process, Attentive Neural Process\ntf-vanilla-gan [GIT] [arXiv:1406.2661], 2018.01. : Generative Adversarial Nets, Ian J. Goodfellow et al., 2014.\nSchool Works\nHYU-ITE2038 [GIT] : Lab notes on \u0026ldquo;Database Systems and Applications\u0026rdquo; in Hanyang University\nHYU-CSE4007 [GIT] : Lab notes on \u0026ldquo;Artificial Intelligence\u0026rdquo; in Hanyang University\nHYU-ELE3021 [GIT] : Lab notes on \u0026ldquo;Operating System\u0026rdquo; in Hanyang University\nPapers\nBehavior Based Malware Detection Using Branch Data : 2017 KIISE Korea Computer Science Conference, 2017. Presentations\nPrompt Engineering Trends : Theori, OpenTRS, 2025.01.16., 2025.02.18.\nMath for A.I., Generative Models : Mapo High School, 2023.11.28.\nThe 2nd AI \u0026amp; Dining. Virtual Human and Generative Models : Sangmyung University, 2022.09.22.\nDeep learning and A.I. : Danggok High School, 2022.08.30.\n2022 A.I.U. Research generative models in Startup [Google Drive] : A.I.U. 2022 AI Confrerence, 2022.05.\nDeveloping Environment for RL : Nexon Developers Conference 2019 as team RosettaStone, 2019.\nGP to NP: Gaussian process and Neural Process : A.I.U 1st Open AI Conference, 2018.\nHearthstone++: Hearthstone simulator with reinforcement learning Deep Learning Camp Jeju, 2018.\nBehavior based Malware Detection Using Branch Data : CodeGate 2017 Junior, 2017.\nAwards\nKISA, 2016 Software Contest, Application Security Section 2nd Prize (Minister of Interior Award) 2016.09 Educations\nM.S. Department of Computer Science and Engineering Seoul National University, Visual \u0026amp; Geometric Intelligence Lab (2025.03. ~ )\nB.S. Department of Mathematics Hanyang University (2019.03. ~ 2025.02.)\nB.S. Department of Computer Science and Engineering Hanyang University (2018.03. ~ 2025.02.)\nVulnerability Analysis Track : 5th KITRI BoB (2016.05. ~ 2017.03.)\nDepartment of Information and Communication Technology : Sunrin Internet High School (2015.03. ~ 2017.02.)\nWorks\nAI for Offensive Security, Freelance Researcher Theori (2025.02. ~ )\nAI for Offensive Security, Senior Researcher Theori (2024.10. ~ 2025.02.)\nResearch Team Lead Theori (2023.08. ~ 2024.10.)\nVideo Synthesis, AI Researcher LionRocket (2021.10. ~ 2022.10., 2023.03. ~ 2023.08.)\nResearch Team Lead LionRocket (2021.04. ~ 2023.08.)\nSpeech Synthesis, AI Researcher LionRocket (2019.09. ~ 2021.10., 2022.10. ~ 2023.02.)\n","permalink":"https://revsic.github.io/blog/worklist/","tags":["Portfolio"],"title":"Work list"}]