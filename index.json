[{"categories":["Generative"],"contents":" David Bau et al., 2020, arXiv Keyword: Generative, Adversarial learning Problem: How to manipulate specific rules encoded by a deep generative model. Solution: Projected gradient descent for adding rules to convolution of associative memory. Benefits: Enable users to synthesize edited new images by manipulating model only once. Contribution: Providing a new perspective of associative memory, rule manipulating method of projected gradient descent. Weakness or Future work: -  Generative model\n생성 모델은 데이터의 분포를 학습하면서 여러 가지 규칙이나 관계를 만들어 나간다. 간단한 예로 ProgressiveGAN[1]이 만든 주방 이미지에서는 창문에서 오는 빛을 테이블에 반사시키는 경향이 있다.\n  Fig. 6: Inverting a single semantic rule within a model\n  저자는 만약 이러한 규칙들을 직접 분석하여 수정할 수 있다면, 생성 모델 자체를 manipulating 하는 것이고, 이는 생성된 이미지를 각각 수정하는 것보다 효율적으로 수정된 이미지를 생성할 수 있다고 이야기 한다.\n이를 위해서 우리는 생성 모델이 어떤 정보를 캡처하고 있고, 어떻게 unseen scenario에 대해 일반화 하고 있는지 알아야 한다.\n현재 생성 모델들은 인간이 직접 라벨링 한 대규모의 데이터셋에 기반을 두고 있는데, 만약 manipulating 과정에서도 이러한 다량의 데이터와 학습이 추가로 필요하다면, 이는 손으로 생성된 이미지를 직접 수정하는 것과 큰 차이가 없을 것이다.\n이에 우리는 단 몇 개의 샘플 데이터와 간단한 optimization을 통해 모델을 manipulation 할 수 있어야 하고, 이 모델은 우리가 원하는 rule을 캡처하여 unseen data에 대한 일반화를 할 수 있어야 한다.\n저자는 이를 위해 sequential 하게 구성된 nonlinear convolutional generator를 associative memory라는 관점으로 해석하고, 전체 레이어가 아닌 단 하나의 레이어에 constrained optimization을 진행하여 기존의 semantic rule을 보존하면서, 우리가 원하는 rule을 추가할 수 있는 방법론을 제시한다.\nPreview\npretrain된 generator $G(\\cdot; \\theta_0)$가 주어질 때, 모델은 각각의 latent $z_i$에 대해 $x_i = G(z_i; \\theta_0)$의 output을 만들어 낸다. 만약 우리가 copy\u0026amp;paste 방식으로 변화를 준 output $x_{*i}$을 통해 새로운 rule을 표현한다면, rule의 표현 중 가장 직관적인 방법일 것이다.\n  Fig. 3: The Copy-Paste-Context interface for rewriting a model.\n  이때 하고자 하는 것은 새로운 rule을 따르는 $\\theta_1$을 만드는 것이고, 이는 $x_{*i} \\approx G(z_i; \\theta_1)$을 만족할 것이다.\n$\\theta_1 = \\arg\\min_\\theta \\mathcal L_{\\mathrm{smooth}}(\\theta) + \\lambda \\mathcal L_\\mathrm{constraint}(\\theta)$\n$\\mathcal L_\\mathrm{smooth}(\\theta) \\overset{\\Delta}{=} \\mathbb E_z[\\mathcal l(G(z; \\theta_0), G(z; \\theta))]$\n$\\mathcal L_\\mathrm{constraint}(\\theta) \\overset{\\Delta}{=} \\sum_i \\mathcal l(x_{*i}, G(z_i; \\theta))$\n고전적인 해결책은 generator의 전체 parameter set $\\theta_0$를 두 가지 constraint에 맞게 gradient 기반의 optimization을 진행하는 것이다. 이때 $\\mathcal l(\\cdot)$은 perceptual distance를 의미한다.\n하지만 이 경우 몇 개 되지 않는 sample에 overfit될 가능성이 농후하며 다른 데이터에 대해 일반화되지 않을 수 있다.\n이에 저자는 두 가지 방법론을 제안한다. 하나는 전체 parameter set이 아닌 특정 한 layer의 weight만을 update하는 것이고, 하나는 optimization을 특정 constraint 내에서 진행하는 것이다.\n특정 layer L과 L-1 layer까지의 feature map k를 가정할 때 L의 output은 $v = f(k; W_0)$가 된다. 원본 이미지의 latent $z_{i}$가 feature $k_{*i}$를 만들 때 $v_i = f(k_{*i}; W_0)$를 가정하고, 직접 수정한 output에 대응하는 feature map $v_{*i}$를 구할 수 있으면 objective는 다음과 같다.\n$W_1 = \\arg\\min_W \\mathcal L_{\\mathrm{smooth}}(W) + \\lambda \\mathcal L_\\mathrm{constraint}(W)$\n$\\mathcal L_\\mathrm{smooth}(W) \\overset{\\Delta}{=} \\mathbb E_z[|| f(k; W_0) - f(k; W)||^2]$\n$\\mathcal L_\\mathrm{constraint}(W) \\overset{\\Delta}{=} \\sum_i ||v_{*i} - f(k_{*i}; W)||^2$\nperceptual distance는 higher semantic을 표현하는 feature map 사이의 l2-distance를 상정한다. 이때 W만으로도 parameter의 양이 충분히 많을 수 있기에, overfit을 제한하면서 더 나은 일반화를 위해 학습 방향을 고정할 필요가 있었고, 특정 direction으로만 optimization 되도록 constraint를 추가한 gradient descent를 진행하게 된다.\nAssociative Memory\n저자는 preview의 방법론을 associative memory로부터 유도해 낸다.\n어떤 key $k_i \\in \\mathbb R^N$와 value $v_i \\in \\mathbb R^M$의 mapping $\\{ k_i \\to v_i \\}_{i \\in I}$을 가정하자. 이때 $k_i$가 mutually orthonormal 하면 i와 j가 다를 때 $k_i^T k_j = 0$를 만족한다. matrix W를 $W = \\sum_i v_i k_i^T \\in \\mathbb R^{M \\times N}$ 로 정의하면 orthogonality에 의해 $Wk_i = v_i$가 성립한다. 이를 key-value association을 기록한 memory라 하여 associative memory라고 부르며, linear operation으로 구성되므로 linear associative memory라 할 수 있다.\n저자의 이야기는 Convolution 또한 associative memory의 일종으로 볼 수 있다는 것이다. 흔히 생각하는 convolution은 window에 대해 pixel-wise weighted sum을 한 결과를 나열하는 operation이다. 이는 output의 한 pixel을 관점으로 convolution을 해석한 것이다.\n반대로 input feature에 대해 해석하면 single feature $k \\in \\mathbb R^{B\\times N}$에 대해 weight matrix $W \\in \\mathbb R^{N \\times (MHW)}$를 곱하고, BxMxHxW의 2D tensor로 reshape 하여 location-aware summation 한 것으로도 볼 수 있다.\n이렇게 되면 convolution은 kernel을 matrix로 보고 key가 orthogonal 할 때 linear associative memory로 해석될 수 있다.\nNonorthogonal Keys\nkey는 $\\mathbb R^N$의 vector이므로 최대 N개까지 orthogonal 할 수 있고, 더 많은 key-value pair를 기록하기 위해서는 $v_i \\approx Wk_i$를 approximately equal한 조건을 취하여 error를 minimizing 하는 방식으로 구성한다.\n$W_0 \\overset{\\Delta}{=} \\arg \\min_W \\sum_i ||v_i - Wk_i||^2$\n이때 $K \\overset\\Delta= [k_1|\u0026hellip;|k_S] \\in \\mathbb R^{N\\times S}$ 와 $V \\overset\\Delta= [v_1|\u0026hellip;|v_S] \\in \\mathbb R^{M\\times S}$ 로 가정하면 multiple nonorthogonal key, value pair에 대한 associative memory를 구성할 수 있다.\n$W_0 = \\arg\\min_W \\sum_i||V - WK||^2$\n그리고 이는 least square solution $W_0KK^T = VK^T$와 pseudo-inverse $K^+$에 대해 $W_0 = VK^+$로 표현된다.\nWhat we want\n즉 pretrain을 통해 구한 $W_0$는 trainset에서 연산한 L-1까지의 feature map과 그에 대한 response를 key-value로 가정한 associative memory가 된다.\n여기서 우리가 하고 싶은 것은 다음과 같다.\n user가 copy한 value와 paste한 지점의 key를 가져와 새로운 pair로 memory에 추가\n 이렇게 되면 L-1까지의 feature map에서 key가 관측되었을 때 memory에서 새로운 value가 mapping 되어 해당 부분에 copy한 context가 이미지에 발현된다. Model manipulation을 하는 주요한 근거가 되는 것이다.\n이를 표현하면 $W_1 = \\arg\\min_W ||V - WK||^2$와 $v_* = W_1k_*$를 만족 시키는 constrained least-square (CLS) problem으로 구성되고, 이의 해는 다음과 같이 정리된다.\n$W_1KK^T = VK^T + \\Lambda k_*^T$\n$W_1KK^T = W_0KK^T + \\Lambda k_*^T$\n$W_1 = W_0 + \\Lambda(C^{-1}k_*)^T$\n이 때 $C \\overset\\Delta= KK^T$로 구성하면 key가 zero-mean일 때 covariance로 해석될 수 있다. 결국 $\\Lambda \\in \\mathbb R^M$를 구하는 문제로 귀결된다. 여기서 $d \\overset\\Delta= C^{-1}k_*$로 가정하면 $W_1 = W_0 + \\Lambda d^T$로 볼 수 있고, 풀이는 다음과 같다.\n$\\left[ \\begin{array}{c|c} W_1 \u0026amp; \\Lambda \\end{array} \\right] \\left[ \\begin{array}{c|c} I \u0026amp; k_* \\\\ \\hline -d^T \u0026amp; 0 \\end{array} \\right] = \\left[ \\begin{array}{c|c} W_0 \u0026amp; v_* \\end{array}\\right]$\n$\\left[ \\begin{array}{c|c} W_1 \u0026amp; \\Lambda \\end{array} \\right] = \\left[ \\begin{array}{c|c} W_0 \u0026amp; v_* \\end{array} \\right] \\left[ \\begin{array}{c|c} I \u0026amp; k_* \\\\ \\hline -d^T \u0026amp; 0 \\end{array} \\right]^{-1}$\n여기서 주목할 점은 2가지이다.\n user requested mapping $k_* \\to v_*$의 soft error-minimization objective가 d라는 straight-line을 따라 update해야 하는 hard constraint로 바뀜 direction d가 key에 의해서만 결정되고 value는 오직 user requested $v_*$가 $\\Lambda$에 영향을 주는 방식 정도로만 작용함  결국 구현체에서는 covariance C 정도를 미리 연산하여 caching 해두고, request가 올 때 direction과 $\\Lambda$를 계산하는 방식으로 작동할 것이다.\npreview의 수식을 다시 들고오면, $W_1 = \\arg\\min_W ||V-WK||^2$는 smoothness를 위한 loss, $v_* = W_1k_*$는 constraint를 위한 loss로 볼 수 있다. 그리고 이 둘의 solution이 d라는 direction으로 update된 $W_1$로 나온 것이다.\nGeneralization\n위까지의 정리는 copy\u0026amp;paste로 수정된 이미지에 대한 해당 layer와 그 전 layer의 response를 얻어와 key-value mapping을 구성할 수 있어야 한다. 하지만 SOTA를 이루고 있는 generative model들은 주로 gaussian noise에서 image로의 mapping을 확률적으로 학습하고 있기에, 수정된 이미지의 latent를 z-optimization을 통해 얻을 수 있어야 하고, 이 또한 rule이 크게 바뀐 경우에는 정확하지 않을 수 있다.\n결국 paste가 이뤄진 image-level에서 distance를 측정해야 하고, 이 경우 neural net의 nonlinearity에 의해 선형성 가정이 깨지게 된다. 이에 neural generator를 다루는 입장이라면 위 방법론이 nonlinear 환경에서 일반화될 수 있어야 한다.\n원문에서는 nonlinear mapping $f(k; W)$가 있을 떄 update policy가 W의 row-space에 sensitive하고, column-space에 insensitive 하므로 동일한 rank-1 update를 $f(k_*; W) \\approx v_*$의 optimization constraint로 쓸 수 있다고 한다.\nlinear phase에서는 $\\Lambda$를 linear system을 통해 풀었다면, nonlinear phase에서는 gradient 기반의 optimization이 필요하다. 이때 $\\Lambda$는 requested value와 direction에 의존하는 변수이기 때문에 이를 objective로 하는 optimization을 진행한다.\n$\\Lambda_1 = \\arg\\min_{\\Lambda \\in \\mathbb R^M}||v_* - f(k_*; W_0 + \\Lambda d^T)||$\n만약 requested key-value pair가 하나가 아닌 여럿이라면, rank-1 대신 low-rank optimization이 될 것이고, S개 pair에 대해 다음과 같이 표현할 수 있다.\n$d_i = C^{-1}K_{*i}$\n$D_S \\overset\\Delta= [d_1|\u0026hellip;|d_S]$\n$\\Lambda_S = \\arg\\min_{\\Lambda \\in \\mathrm R^{M \\times S}} || V_* - f(K_*; W_0 + \\Lambda D_S^T)||$\n그리고 update는 $W_S = W_0 + \\Lambda_S D_S^T$로 이뤄질 것이다.\n마지막으로 이 조건을 좀 더 relax하면 $\\arg\\min_W ||V_* - f(K_*; W)||$를 optimizing하고, 대신 매 step 마다 W를 $W_0 + \\Lambda_S D_S^T$의 subspace로 projection 하는 projected gradient descent를 취한다.\nDetail\noriginal repository rewriting에서는 L-1까지의 feature map을 BxHWC로 reshape하여 collect_2nd_moment에서 z-dataset을 기반으로 covariance를 미리 구해 놓는다.\n이후 edit 요청이 들어오면 covariance_adjusted_query_key에서 direction을 구하는데, C의 pseudoinverse를 구하는 대신 $CD_S = K_S$의 least square solution (torch.lstsq)을 풀어 computational stability를 얻었다고 한다.\n이후 $D_{S}$를 직접 이용하는 것이 아닌 low-rank subspace의 basis를 구해 활용하며, multi_key_from_selection에서는 ZCA와 SVD를 통해 eigen value가 큰 vector를 선출하고, 동일한 subspace를 구성하는 orthogonal basis로 변형하여 활용한다.\n이후 insert에서 parameter optimization을 진행한다.\nweight은 subspace에 orthogonal 하게 변환하여 ortho_weight 변수에 저장해 둔다. 이는 projected_conv을 활용하는데, 흔히 gram-schmidt orthogonalization에서 하는 것과 같이 basis에 정사형한 벡터를 원본에서 빼는 방식으로 진행한다.\n$W_\\mathrm{ortho} = W - (WU_{1:R})U_{1:R}^T \\ \\mathrm{where} \\ C^{-1}K_S = U\\Sigma V^T, \\ \\mathrm{lowrank} \\ R$\n이후 image-level distance를 L1으로 하는 optimization을 진행하고, 특정 스텝마다 weight을 subspace로 projection하여 ortho_weight에 더하는 방식으로 projected gradient descent를 구현한다.\n이렇게 되면 optimization의 여파는 subspace 내에서만 구성되고, subspace에 orthogonal한 weight을 더함으로써 기존의 weight은 유지하고 subspace 내에서의 update만을 취할 수 있게 된다.\nZCA를 활용한 rank reduction은 원문의 Appendix. D.를 참고한다.\nLayer selection\n원문에서는 convolution layer를 neighbor와의 정보 취합으로 edge, texture, shape 등을 구별해 내는 관점보다는, 하나의 feature vector가 local patch가 되면서 주변과 disentangle 되는 관점을 취하였고, 이것이 memory model로 해석되었다.\n원문에서는 실제로 ProgressiveGAN[1]과 StyleGANv2[2]의 일부 레이어에서 이런 feature 간 독립성을 띠고 있음을 보였다.\nfeature map을 MxN의 patch로 잘라 주변 정보 없이 적절한 크기의 output을 만들었을 때, 네트워크는 여전히 동일한 객체와 컨텍스트를 만들어 낼 수 있음을 보인다면, feature 간에 독립적인 정보를 담고 있음을 추론할 수 있다.\n레이어마다 patch를 잘라 output을 만들었을 때 Frechet Inception Distance (FID)가 작다면 해당 patch는 주변 정보로부터 less dependence 한 것이고, FID가 높다면 dependent 한 것임을 나타낼 것이다.\n  Fig. 13: FID of rendered cropped activations with respect to random crops of StyleGANv2 generated images\n  그래프에서 6~11번째 layer가 FID가 가장 낮았고, 이 layer에서 key 값은 주변과 independent 한 정보를 가지고 있을 확률이 높다. 즉, 어느 한 layer의 key를 수정해야 한다면, 해당 layer를 수정하는 것이 object를 render 하는데 좋은 quality의 이미지를 만들 수 있음을 나타낸다.\n  Fig. 14: Comparison of rendered cropped activations at various layers of Style- GANv2 generated LSUN church images.\n  Experiment\n이제 User는 copy\u0026amp;paste를 통해 image에 원하는 부분을 수정하고 (key-value), 몇몇 context image에 수정되었으면 하는 부분(key-context)을 표기하여 rewriter에게 전달한다.\nrewriter은 해당 key-context로부터 direction을 계산하고, pasted image와 original image 사이의 L1-loss를 기반으로 projected-optimization을 진행한다. 이에 따라 일반화된 model을 얻을 수 있고, editing을 마치게 된다.\n  Fig. 7: Giving horses a hat to wear.\n  Discussion\n저자는 GPT-3, WaveNet과 같이 image 이외의 분야에서도 vastly trained model에 rule을 수정하고자 하는 일이 있을 것이고, model rewriting은 이 경우에 새로운 contents, behavior, interaction을 부여할 충분한 방법론일 것이라 이야기한다.\nImplementation\n pytorch, official: rewriting  References\n Progressive Growing of GANs for Improved Quality, Stability, and Variation, Tero Karras et al., 2017, arXiv:1710.10196. Analyzing and Improving the Image Quality of StyleGAN, Tero Karras et al., 2019. arXiv:1912.04958.  ","permalink":"https://revsic.github.io/blog/rewriting/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Model editing","Rewriting"],"title":"Rewriting a Deep Generative Model"},{"categories":["Generative"],"contents":" Stanislav Pidhorskyi et al., 2020, arXiv Keyword: Generative, Adversarial learning Problem: AE based approach has poor quality of output distribution. Solution: Adversarial setting and encoder, decoder decomposition. Benefits: Less entangled latent, sharp output distribution. Contribution: Learnable and less entangled latent with adversarial autoencoding structure. Weakness or Future work: -  GAN and AE\nGenerative Adversarial Networks (GAN)은 complex distribution을 표현하는 데 좋은 성능을 보여왔다. 특히 sharp 한 generation에 특이점을 가져 많은 현실적인 이미지나 음성을 생성할 수 있었다.\nAutoencoder는 encoder, generator pair로 representation과 generation 모두를 포함하는 구조이다. 본문에서는 AE가 representation은 충분히 잘하고 있지만, generation까지 겸비한 모델은 아직 구현하지 못하였다고 이야기한다.\n이에 소개하고자 하는 것이 Adversarial Latent Autoencoder (ALAE)이고, GAN과 비슷한 generative power를 가지면서도 representation disentangle이 가능한 모델을 목표로 한다.\n대부분의 AE 연구들은 같은 가정을 하는데, latent space를 확률 분포로 모델링 하며, 이것을 고정된 prior에 맞춰야 한다는 것이다. 실제로 ELBO를 정의할 때 posterior q를 가정하고 variational inference를 진행하는데, KL-divergence가 대상으로 삼은 conditional prior가 intractable 하기 때문에 주로 고정된 prior를 사용하게 된다. 하지만 StyleGAN (Karras et al., 2018)에서는 분포상 제약을 받지 않고, 데이터로부터 학습된 latent space가 prior에서 많은 transform을 거칠수록, prior에서 거리가 멀어질수록, disentangle 하기 쉽다는 이야기를 한다.\n여기서 착안하여 저자는 AE가 latent distribution을 data에서 학습할 수 있게 하였고, output distribution은 adversarial strategy를 통해 학습하였다. 이를 통해 GAN만큼의 generative power를 가지면서도 disentanglement를 더 용이하게 하는 것이다. 이는 근래 GAN 관련 분야에서 연구된 여러 기법이나 휴리스틱을 덜 사용하면서도 효과적으로 데이터를 모델링할 수 있게 한다.\nPreliminaries: GAN Objectives\n본문에서 소개하는 GAN objective의 general formulation은 다음과 같다.\n$$V(\\mathtt G, \\mathtt D) = \\mathbb E_{p_D(x)}\\left[ f(\\mathtt D(x)) \\right] + \\mathbb E_{p(z)}\\left[ f(-\\mathtt D(\\mathtt G(z))) \\right]$$\n여기서 f를 softplus $f(t) = -\\log(1 + \\exp(-t))$로 두면 vanilla GAN과 같아지고, f를 identity $f(t) = t$로 두면 wasserstein GAN과 같아진다.\nAdversarial Latent Autoencoders\n기존의 GAN이 generator와 discriminator를 single module로 구성하였다면, ALAE에서는 가장 먼저 G와 D를 $\\mathtt G = G \\circ F$와 $\\mathtt D = D \\circ E$로 분해한다. 그리고 F와 G 사이, E와 D 사이의 represenation을 latent W로 둘 것이다. 이 때 F와 D는 deterministic, G와 E는 stochastic하게 가정한다. G가 additional independent noise $\\eta$를 받는다면 $G(w, \\eta)$의 general stochastic generator가 될 것이다. 이때 G에서 생성된 output x의 확률은 다음과 같다.\n$$q(x) = \\int_w\\int_\\eta q_G(x|w, \\eta) q_F(w) p_\\eta(\\eta) \\mathrm d\\eta \\mathrm dw$$\n마찬가지로 E에서 생성된 latent w의 확률은 다음과 같다.\n$$q_E(w) = \\int_x q_E(w|x)q(x)\\mathrm dx$$\n여기서 q(x)를 실제 데이터 분포 $p_D(x)$로 바꾼다면 데이터에 대한 latent $q_{E, D}(w)$가 될 것이다.\n여기서 앞서 소개한 GAN objective를 토대로 모델을 학습한다면 이는 synthetic distribution q(x)를 실제 데이터 분포 $p_D(x)$로 맞춰가는 작업이 된다. 여기에 더불어 ALAE에서는 하나의 조건을 더 걸게 되며, 이는 $q_F(w) = q_E(w)$로 latent distribution을 matching 하는 작업이다.\nAE는 latent와의 bijection을 위해 reciprocity, 자기복원의 기능을 가지는데, 크게 $x=G(E(x))$로 data space 상에서의 복원이 있을 수 있고, $w=E(G(w))$로 latent space 상에서의 복원이 있을 수 있다. 전자의 경우는 두 분포의 차이를 나타내는 reconstruction error를 가지게 되고, 각 픽셀을 독립된 확률 분포로 가정했을 때 prior에 따라 log-prob으로 l1이나 l2 loss를 띌 수 있다. 대부분의 AE 기반 모델에서 사용하지만 실제로는 blur나 noise 같은 output distribution에 표현되는 perceptual 한 손실을 만들기 때문에 지금까지의 AE 모델들이 쉽게 GAN에 비견되는 품질을 가질 수 없었다.\n반면 ALAE는 후자를 선택하였는데, latent space 상에서 차이를 나타내는 discrepancy measure를 두고, F와 EGF의 출력을 비교하는 것이다. output 상에서의 l2-loss는 human perception을 반영하기보다는 단순 픽셀 상의 차이에 집중하고, 이런 한두 개의 픽셀 차이는 latent 상에 작용하기 어려워야 한다. 이에 latent 상에 직접 discrepancy measure를 걸어 버리는 것이 human perception에 더 직접적으로 작용할 수 있게 학습하는 것이다.\n이는 GAN의 intuition과 비슷한데, GAN은 기존의 AE가 output space 상에서 independent 한 픽셀을 가정하고 discrepancy를 측정한 것에 반해, discriminator라는 human perception을 대체할만한 추가 모델을 두고, receptive field와 인지 능력을 학습받은 adaptive discrepancy를 측정할 수 있게 한 것이다.\nALAE에서는 이 discrepancy measure를 단순 l2로 두었는데, 이는 latent W에 어떠한 제약도 두고 싶지 않았기 때문이라고 한다. latent W에 distribution을 가정하고 KL-divergence와 같은 척도를 이용할 수도 있지만, 이렇게 되면 실상 F가 identity map과 같아지고 그 의미가 무색해진다. 대신 l2를 사용하였기 때문에 실제 데이터에 대한 latent $q_{E, D}(w)$와의 비교는 어려워졌다.\ninference에서는 E로 input data를 encoding 하여 만든 latent w와 G를 통해 이미지를 재생성하는 방식으로 작동한다.\n(StyleALAE에 대한 이야기는 보류한다.)\nDetail\n$L^{E, D}_ {adv} = \\mathrm{softplus}(D\\circ E \\circ G \\circ F(z)) + \\mathrm{softplus}(-D \\circ E(x)) + \\frac{\\gamma}{2}\\mathbb E_{p_D(x)}\\left[ ||\\nabla D \\circ E(x)||^2\\right]$\n$L^{F, G}_ {adv} = \\mathrm{softplus}(-D\\circ E \\circ G \\circ F(z))$\n$L^{E, G}_ {err} = ||F(z) - E \\circ G \\circ F(z)||^2_2$\nGAN objective의 f는 softplus를 사용하였고, 대신에 real data에 대한 gradient regularization term을 두었다. latent prior z는 standard gaussian으로 두었고, 따로 independent noise $\\eta$를 두지 않은 것으로 보인다.\nDiscussion\n실제로 MLP 기반의 MNIST 모델과 StyleALAE 기반의 여러 image synthesizing experiment를 진행하였고, image quality는 물론 latent 상에서의 preceptual path length가 짧아지는 등의 disentanglement 성능 향상도 보였다고 한다.\n다른 연구들과는 달리 adaptive latent를 가정하여 less entangle한 latent를 학습할 수 있었고, adversarial setting으로 output distribution의 sharpness를 유지할 수 있었다. reciprocity에 대한 ablation study 같은 것이 있었으면 좋을거 같다.\nImplementation\n pytorch, official: ALAE tensorflow, unofficial, MNIST PoC: tf-alae  Reference\n Adversarial Latent Autoencoders, Stanislav Pidhorskyi et al., 2020. StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Tera Karras et al., 2018.  ","permalink":"https://revsic.github.io/blog/alae/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Autoencoder","ALAE"],"title":"Adversarial Latent Autoencoders"},{"categories":["Bayesian"],"contents":" Hyunjik kim et al., 2019, arXiv Keyword: Bayesian, Process Problem: Underfitting of Neural Process Solution: NP + Self-Attention, Cross-Attention Benefits: Improvement of prediction accuracy, training speed, model capability. Contribution: Solving underfitting on NP Weakness or Future work: Decoder + Self-Attention  Neural Process and Gaussian Process\nNeural Process는 함수 분포를 모델링하기 위한 효과적인 메소드를 소개했다. linear time에 작동하며, 한번 학습되면 임의의 context pair와 query에 대해 target 분포를 예측할 수 있다. 그럼에도 NP와 GP를 직접 비교하기 어려운 이유는 NP는 stochastic process의 여러 realization (process에서 샘플링한 함수 표본) 에 대해서 학습하지만, GP는 하나의 realization에서 sample 된 observation에 대해 학습하기 때문이다.\nNP는 Scalability, Flexibility, Permutation Invariance라는 점에서 여러 장점이 있지만, consistency 문제를 가지고 있다. 이는 context로부터 target을 추론한 후, 다시 context에 덧붙여 target을 추가 추론했을 때와 온전한 context로부터 전체 target을 추론했을 때 분포차가 발생할 수 있음을 의미한다. 그러므로 NP를 그 자체로 consistent 하다고 보기보다는 consistent stochastic process의 근사라고 보는 것이 맞다.\nNP의 또 하나의 약점은 context set에 underfit한다는 것이다. 실제로 1D Curve Fitting 문제를 살펴보면, context point가 존재하는 지점에서도 과한 분산과 부적절한 평균점을 보인다. 본문에서는 이 이유를 NP가 context set을 고정된 크기의 latent로 변환시키는 과정에 permutation invariant function으로 mean-aggregation을 썼는데, 이 과정이 bottleneck으로 작용했기 때문이라고 판단하였다. 이는 모든 컨텍스트에 동일한 가중치를 주었기에, 디코더가 target을 예측할 때 context point로부터 적절한 관련 정보를 제공받지 못하고 있을 것으로 생각한 것이다.\n이러한 점을 해결하기 위해서 GP의 kernel function을 차용하였다. kernel은 입력값의 두 지점에 대해서 유사도를 측정하는 도구로 이용되는데, NP에는 이러한 메커니즘이 존재하지 않는 것이다. 그래서 제안하고자 하는 게 Attentive Neural Process (ANPs)이고, 이는 NP에 differentiable attention을 추가하여 context point에 대한 underfit을 줄인 모델이다.\nAttentive Neural Process\n먼저 입력과 출력 $x_i \\in \\mathbb R^{d_x}, \\ y_i \\in \\mathbb R^{d_y}$, 그리고 observed context $(x_C, y_C) := (x_i, y_i)_ {i \\in C}$ 와 targets $(x_T, y_T) := (x_i, y_i)_{i \\in T}$를 가정한다. context representation aggregator r에 대해 $r_C := r(x_C, y_C) \\in \\mathbb R^d$로 두고, latent encoder s에 대해 $s_C := s(x_C, y_C)$로 두면 NP는 다음을 모델링하는 것과 같다.\n$$p(y_T | x_T, x_C, y_C) := \\int p(y_T | x_T, r_C, z)q(z | s_C)dz$$\n여기서 NP가 가정하는 process F의 randomness는 global latent z에서 오기 때문에 likelihood를 최대화하는 과정은 z의 샘플링을 통해 여러 개로 realization 된 하나의 process를 학습하는 것과 같다.\nz_context = self.z_encoder(context, key=cx, query=cx)\rz_prob = self.latent_prob(z_context)\rlatent = z_prob.sample()\rself_attend = self.encoder(context, key=cx, query=cx)\rANP는 여기에 두 가지 attention을 덧붙인다. 첫 번째는 self-attention으로 context 사이에서 정보를 공유하고 더 나은 intermediate representation을 만들기 위한 장치이다.\ncross_attend = self.cross_encoder(self_attend, key=cx, query=query)\rrep = self.decoder(cross_attend, query, latent)\rdist, mu, sigma = self.normal_dist(rep)\rcontext에 self-attention을 취하면 context 개수만큼의 intermediate representation(IR)이 생기고, 이는 target과 context의 유사도를 비교하는 cross attention을 통과하여 query-specific representation $r_* := r^*(x_C, y_C, x_*)$을 만든다. 이는 모델이 실제로 어떤 컨텍스트 포인트를 조명할지 명시하기 때문에 target prediction에 도움을 줄 수 있다.\nlatent encoder의 경우에는 self-attention 이후 cross-attention 대신에 mean-aggregation을 선택했는데, 본문에서는 이를 global-latent로써 보존하고 싶었다고 한다. latent path에 cross-attention이 들어오면, latent에 locality가 발생하기 때문이다.\n$$\\log p(y_T | x_T, x_C, y_C) \\ge \\mathbb E_{q(z | s_T)} \\left[ \\log p(y_T | x_T, r_C, z) \\right] - D_{KL}(q(z | s_T) || q(z | s_C))$$\ntraining loss는 ELBO를 동일이 가져간다.\n이렇게 하면 computational complexity가 O(n(n + m))이 되는데, 이는 attention 과정에서 모든 컨텍스트를 탐방하기 때문이다. 하지만 dot-product attention 같은 matrix-multiplication 기반의 attention 알고리즘을 이용하면 대부분이 parallel 하게 동작할 수 있으므로 실제로는 training time이 NP와 비교할 만 하다고 한다.\nDiscussion\nANP는 attention mechanism을 통해 underfitting problem을 효과적으로 풀어냈다. 추측의 정확도가 높아졌고, 학습이 빨라졌으며, 모델링 할 수 있는 메소드의 범위도 늘었다. 저자는 ANP의 decoder에 self-attention을 붙여 expressiveness의 향상 정도를 확인하고 싶다고 한다. 하지만 이는 target prediction 사이에 상관성이 생기는 문제이니 ordering이나 grouping을 어떻게 해야 할지가 중요해질 것이라고 한다.\nImplementation\n Tensorflow v1: tf-neural-process  Reference\n Conditional Neural Processes, Garnelo et al., 2018. Neural Processes, Garnelo et al., 2018. Attentive Neural Processes, Kim et al., 2019.  ","permalink":"https://revsic.github.io/blog/anp/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process","Attentive Neural Process"],"title":"Attentive Neural Processes"},{"categories":["Bayesian"],"contents":" Marta Garnelo et al., 2018, arXiv Keyword: Bayesian, Process Problem: Data inefficiency, hard to train multiple datasets in one. Solution: Stochastic Process + Latent variable + NN Benefits: Concurrent training, global uncertainty, explicit latent variable. Contribution: CNP + global uncertainty, concurrent dataset, explicit latent Weakness or Future work: Pairwise correlation.  Function Approximation\n딥러닝에서는 데이터 간의 상관관계를 찾기 위해 함수를 근사하는 작업을 하는데, 주로 지도 학습에서는 parameterized function의 파라미터 셋을 gradient를 통해 업데이트하는 방식을 차용한다. 이러한 경우 대부분의 workload가 학습 중에 이뤄지며, 추론 과정은 단순 forward pass만으로 가능하다. 하지만 한번 학습된 이후로는 추론 결과의 업데이트가 힘들다는 점에서 메타 러닝 쪽도 관심이 많아지는 편이다.\n그 대체재로 Stochastic Process와 그 에인 Gaussian Process(GP)가 있는데, 이러한 모델들은 training phase를 필요로 하지 않고, test-time에 원하는 쿼리를 직접 렌더링 하게 된다. 하지만 렌더링 과정이 O(N^3)의 연산이 필요하기 때문에 대형 데이터셋을 상대로 적용하기 쉽지 않고, kernel과 같은 prior에 의해 함수 모형이 바뀌는 등 여러 문제점도 존재한다.\n이에 제안하고자 하는 게 Neural Process이다. 함수에 대한 분포를 가정하고, observation을 통해 query와 prediction에 대한 uncertainty를 추정한다. GP와 달리 O(n + m)의 단순 forward pass만으로 추정을 진행할 수 있다는 점에서 장점을 지닌다.\nNeural Process\n먼저 random function $F: \\mathcal X \\to \\mathcal Y$와 finite seq $x_{1:n}=(x_1, \u0026hellip;, x_n)$ with $x_i \\in \\mathcal X$, function values $Y_{1:n} := (F(x_1), \u0026hellip;, F(x_n))$를 가정한다. 이 collection의 joint dist $\\rho_{x_{1:n}}$이 존재할 것이고, GP 라면 multivariate gaussian일 것이다.\n이 joint dist는 exchangeability와 consistentcy라는 조건에서 Kolmogorov Extension Theorem에 의해 stochastic process로 정의될 수 있다. 이 때 exchangeability는 permutation invariance를 의미하고, consistentcy는 marginlize한 범위 외의 sequence에 대해 marginalize했을 때 원본 시퀸스와 동일함을 의미한다.\nStochastic process F와 시퀸스 $x_{1:n}$, 그의 joint dist $\\rho_{x_{1:n}}$에 대해 instantiation of stochastic process f는 다음과 같다\n$$\\rho_{x_{1:n}} = \\int p(f)p(y_{1:n}|f, x_{1:n})df$$\nobservation noise를 고려하여 $Y_i \\sim \\mathcal N(f(x_i), \\sigma^2)$라 가정하면 proability p는 다음과 같다\n$$p(y_{1:n}|f, x_{1:n}) = \\prod^{n}_{i=1} \\mathcal N(y_i | f(x_i), \\sigma^2)$$\n이 때 joint dist $\\lbrace\\rho_{x_{1:n}}\\rbrace$의 exchangeability와 consistentcy에 의해 stochastic process F의 존재성이 증명된다. 여기서 NP가 하고 싶은 것은 high-dimensional random vector z로 F를 parameterize하고, fixed function g에 대해 F(x) = g(x, z)를 NN으로 학습하고 싶은 것이다.\n$$p(z, y_{1:n}|x_{1:n}) = p(z)\\prod^{n}_{i=1} \\mathcal N(y_i|g(x_i, z), \\sigma^2)$$\n이 때 random function과 distribution을 학습하기 위해서는 여러 데이터셋을 동시에 학습해야 한다. 여러 input seq $x_{1:n}$와 output seq $y_{1:n}$를 학습시켜 데이터 간의 variability를 학습할 수 있게 한다.\ng를 non-linear NN으로 두기 때문에 학습에는 variational inference를 이용한다. latent z와 prior p(z)는 standard multivariate gaussian으로 두고, variational posterior $q(z|x_{1:n}, y_{1:n})$를 가정한다.\n$$\\log p(y_{1:n}|x_{1:n}) \\ge \\mathbb E_{q(z|x_{1:n}, y_{1:n})}\\left[\\sum^{n}_{i=1}\\log p(y_i|z, x_i) + \\log \\frac{p(z)}{q(z|x_{1:n}, y_{1:n})}\\right]$$\n이 때 test time에 더욱 well-behave model을 만들기 위해 context-set과 target-set을 나누고, true posterior $p(z|x_{1:n}, y_{1:n})$ 대신 variational posterior로 approximate한다.\n$$\\log p(y_{1:n}|x_{1:n}) \\ge \\mathbb E_{q(z|x_{1:n}, y_{1:n})}\\left[\\sum^{n}_{i=m+1}\\log p(y_i|z, x_i) + \\log \\frac{q(z|x_{1:m}, y_{1:m})}{q(z|x_{1:n}, y_{1:n})}\\right]$$\n이렇게 되면 z가 process F를 capture하는 역할을 하고, 이것이 global uncertainty를 capture 했다고도 볼 수 있다.\n실제 구현체에서는 encoder h가 pair $(x, y)_i$에 대해 repr $r_i = h((x, y)_i)$로 구성하고, exchangeable aggregator $r = a(r_i) = \\frac{1}{n} \\sum^n _{i=1}r_i$를 통해 latent $z \\sim \\mathcal N(\\mu(r), I\\sigma(r))$를 표현한다. 마지막으로 decoder g와 sampled latent z에 대해 $y_T = g(z, x_T)$를 통해 output을 결정하게 된다.\nz_context = self.z_encoder(context) z_dist = self.z_prob(z_context) latent = z_dist.sample() rep = self.decoder(context, query, latent) dist = self.normal_dist(rep) log_prob = dist.log_prob(target) log_prob = tf.reduce_sum(log_prob) prior = self.z_prob(self.z_encoder(context)) posterior = self.z_prob(self.z_encoder([query, target])) kl = tfp.distributions.kl_divergence(prior, posterior) kl = tf.reduce_sum(kl) elbo = -log_prob + kl Conditional Neural Process, Marta Garnelo et al., 2018\n동일 저자는 같은 해에 CNP라는 논문을 냈는데, 차이점은 NP는 latent z를 통해 process F를 캡처하고, global uncertainty를 측정하는데, CNP는 그러한 과정 없이 deterministic 하게 context와 query에 대한 target을 내놓는다. NP는 latent를 명시적으로 설정하였기 때문에, concurrent 한 training process에서도 명확히 latent를 포착하는 것을 볼 수 있다.\nDiscussion\nNP는 역시 stochastic process와 NN을 합친 모델이다. 함수에 대한 분포를 정의하고, context conditioned prediction을 생성한다. regression task에 대해서 실험을 주로 했는데, future work로 high dimensional data에 관한 연구를 남겨두겠다 한다.\nImplementation\n Tensorflow v1: tf-neural-process  Reference\n Conditional Neural Processes, Garnelo et al., 2018. Neural Processes, Garnelo et al., 2018.  ","permalink":"https://revsic.github.io/blog/np/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process"],"title":"Neural Processes"},{"categories":["Bayesian"],"contents":" Marta Garnelo et al., 2018, arXiv Keyword: Bayesian, Process Problem: Weakness of knowledge sharing and data inefficiency of classical supervised learning Solution: Stochastic Process + NN Benefits: Data efficient, prior sharing Contribution: Encapsulation of parameterized NN function family. Weakness or Future work: Global uncertainty, pairwise correlation.  Function Approximation\n우리는 데이터의 경향성을 파악해 추론을 얻어내기 위해 흔히 데이터셋 $\\lbrace(x_i, y_i)\\rbrace^{n-1}_{i=0}$과 함수 $f: X \\to Y$를 가정한다. 일반적인 지도학습에서는 $f$를 parameterized model로 가정하고, computation을 고정, parameter를 학습하는 방식을 취한다. 그 이후에는 deterministic하게 입력에 대해 출력이 결정된다. 이러한 방식은 prior의 적용이 한정적이고, 그에 따라 learning 사이의 정보 공유가 어려워 매번 대량의 데이터셋에 대한 새로운 학습이 요구되는 등 여러 한계를 보이기도 한다.\nStochastic process는 함수라는 카테고리를 하나의 확률 분포로 가정한다. 함수에 대한 사전 지식은 분포상의 가정으로 표현되고, 학습은 관측된 값들에 대한 조건부 확률과 사후 분포로써 표현된다.\n대표적인 예로 gaussian process는 함수의 smoothness prior를 kernel function으로 나타내었고, 이는 값들 사이의 유사도로 나타나게 된다. 하지만 이러한 메소드들은 prior에 따라서 computationally intractable하기도 하고, $O(N^3)$에 달하는 연산량에 현대에는 많이 쓰이지 않고 있다.\n이러한 문제를 풀기 위해 model family를 제안하고, 이것이 Conditional Neural Process 이다.\nStochastic Process\n먼저 observation $O = \\lbrace(x_i, y_i)\\rbrace \\subset X \\times Y$ 과 target $T=\\lbrace x_i\\rbrace^{n+m-1}_{i=n}$ 를 가정하자. 이 때 $f: X \\to Y$로의 함수와 이 함수의 분포 P가 존재한다면 $f \\sim P$ 이고, 조건부 분포 $P(f(T)|O, T)$로 표현된다.\nGP에서는 P를 Gaussian으로 가정하고, Covariance Matrix 대신 두 지점 사이의 유사도를 측정하는 kernel 함수를 도입한다. 이러한 모델은 data efficient 하지만, prior나 kernel 함수의 설정이 어렵고, 추론 과정이 $O((n+m)^3)$로 computationally expensive 하다.\nConditional Neural Process (CNPs)\nCNP는 함수를 observation에 대한 조건부 분포로 가정한다. CNP는 observation을 고정된 크기의 embedding vector로 표현하고, 이를 토대로 새로운 query에 대한 추론을 만든다. 이 모든 것이 NN을 통한 single forward pass에 이뤄지기 때문에 관측수 n과 쿼리수 m에 대해 O(n + m)의 복잡도만을 요구로 한다.\nobservation O가 주어질 때 CNP는 $Q_\\theta$ 의 conditional process를 가정한다. 기존의 stochastic process처럼 O와 T의 순서에 대해 추론이 변하지 않는 permutation invariance를 보장한다. 또한 factorization $Q_\\theta(f(T)|O, T)=\\Pi_{x \\in T}Q_\\theta(f(x)|O, x)$을 가정한다.\nCNP의 구조는 다음과 같다.\n$r_i = h_\\theta(x_i, y_i) \\quad \\forall (x_i, y_i) \\in O$\n$r = \\oplus^n_i r_i$\n$\\phi_i = g_\\theta(x_i, r) \\quad \\forall x_i \\in T$\n이 때 $h_\\theta: X \\times Y \\to \\mathbb R^d$ 이고, $g_\\theta: X \\times \\mathbb R^d \\to \\mathbb R^e$ 이다. $\\oplus$는 observation embedding을 합치는 operation으로 본문에서는 permutation invariance를 지키기 위해 commutative 하다는 가정을 두었다.\n그 결과 process는 $Q_\\theta(f(x_i) | O, x_i) = Q(f(x_i) | \\phi_i)$ 로 표현되며, 이 과정이 NN forward pass만으로 이뤄지기 때문에 O(n + m)의 복잡도를 가진다.\nregression 에서는 $\\phi_i = (\\mu_i, \\sigma_i^2)$ 와 $\\mathcal N(\\mu_i, \\sigma_i^2)$ 로 두어 최종 $f(x_i)$가 가우시안을 따르게 하고, classification에서는 categorical distribution의 logits로 두었다.\n학습은 nll을 minimize 하는 방식으로 이뤄진다.\n$\\mathcal L(\\theta) = -\\mathbb E_{f \\sim P}\\left[\\mathbb E_N\\left[\\log Q_\\theta(\\lbrace y_i\\rbrace^{n-1}_{i=1}|O_N, \\lbrace x_i\\rbrace^{n-1}_{i=0})\\right]\\right]$\nDiscussion\n본문에서는 CNP가 training 데이터에서 prior을 적절히 학습하였고, 이를 통해 observation 간의 learning share이 가능하다고 이야기한다. 실험에서도 보였듯 data efficient하면서도 NN의 adaptivity를 충분히 잘 활용 하였고, meta-learning이나 few-shot learning 과의 상관성에 대해서도 이야기하였다. 지금은 POC 수준이지만, statistical context에서 function family를 적절히 encapsulate 한 것이 주요 contribution이지 않을까 싶다.\n추후 Neural Process나 Attentive Neural Process에서도 이야기하지만, CNP는 global uncertainty를 측정하는 수단이나, observation과 target 사이의 correlation을 측정하는 수단이 명시적으로 존재하지 않는다는 점도 고려해야 한다.\nImplementation\n Tensorflow v1: tf-neural-process  Reference\n Conditional Neural Processes, Garnelo et al., 2018.  ","permalink":"https://revsic.github.io/blog/cnp/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process","Conditional Neural Process"],"title":"Conditional Neural Processes"},{"categories":["Portfolio"],"contents":"Skills\n Languages: Python, C++ ML Framework: Tensorflow v1, PyTorch Windows Internal  Projects - Machine Learning\n  Behavior based Malware Detection Using Branch Data [GIT]\n: Classify malware from benign software using branch data via LSTM based on Tensorflow\n  AlphaZero Connect6 [GIT]\n: AlphaZero training framework for game Connect6 written in Rust with C++, Python interface.\n  Fine Dust Prediction [GIT]\n: Predict amount of fine dust for next 7 days via Convolutional LSTM based on Tensorflow.\n  numpy-rnn [GIT]\n: Numpy implementation of vanilla-rnn and lstm for solving binary addition and mnist classification problem.\n  np-gaussian-process [GIT]\n: Numpy implementation of Gaussian Process Regression.\n  Chess A.I. [GIT]\n: Java implementation of board game \u0026lsquo;Chess\u0026rsquo; and A.I. based on min-max and alpha-beta pruning.\n  Projects - Windows Internal\n  Anti-Attacher [GIT]\n: C++ implementation for defending windows debugger from attaching the target process.\n  Code-Injector [GIT]\n: C++ implementation of several code injection techniques like dll injection, queue user apc.\n  Branch Tracer [GIT]\n: C++ implementation of dll-based windows debugger for tracking branching instruction via vectored exception handler.\n  cpp-veh-dbi [GIT]\n: C++ implementation of vectored exception handler based simple dynamic binary instrumentation tools.\n  Projects\n  cpp-concurrency [GIT]\n: C++ implementation of golang-style concurrency supports, thread pool, channel, wait-group\n  cpp-obfuscator [GIT]\n: C++ implementation of compile time string and routine obfuscator.\n  RosettaStone [GIT]\n: C++ implementation of game \u0026lsquo;Hearthstone\u0026rsquo; as training environment and A.I. for future work.\n  Haskell Calculator [GIST]\n: Haskell implementation of calculator with generic binary operators.\n  ThreeByteVM [GIST]\n: C implementation of simple virtual machine that word size is 3 bytes.\n  TopMost [GIT]\n: C++ implementation of topmost library for windows and javascript support.\n  PacketInjector [GIT]\n: C++ implementation of simple packet detector and injector.\n  ELF Code Virtualization\n: ELF (Executable Linkable Format) Virtualized Code Protection\n  ML Paper implementation\n  tf-neural-process [GIT] [arxiv: NP, CNP, ANP]\n: Tensorflow implementation of neural process family.\n  tf-vanilla-gan [GIT] [arXiv]\n: Generative Adversarial Networks\n  tf-alae [GIT] [arXiv]\n: Adversarial Latent Autoencoders\n  School Works\n  HYU-ITE2038 [GIT]\n: Database Systems and Applications in Hanyang University\n  HYU-CSE4006 [GIT]\n: Artificial Intelligence\n  HYU-ELE3021 [GIT]\n: Operating System\n  Study\n  Modern C++ Challenge [GIT]\n: Challenge real-world problems with C++17 features\n  Stanford-CS166: Data Structure [GIT]\n: Data structure for undergraduate\n  Paper\n Behavior Based Malware Detection Using Branch Data at 2017 KIISE Korea Computer Science Conference  Presentation\n  Behavior based Malware Detection Using Branch Data at CodeGate 2017 Junior\n  Hearthstone++: Hearthstone simulator with reinforcement learning at Deep Learning Camp Jeju\n  Developing Environment for RL at Nexon Developers Conference 2019 as team RosettaStone\n  GP to NP: Gaussian process and Neural Process at A.I.U 1st Open AI Conference\n  Awards\n KISA, 2016 Software Contest,\nApplication Security Section 2nd Prize (Minister of Interior Award) 2016.09  Education\n  Department of Information and Communication Technology at Sunrin Internet High School\n(2015.03 ~ 2017.02)\n  Vulnerability Analysis Track at KITRI BoB\n(2016.05 ~ 2017.03)\n  Department of Computer Software Engineering at Hanyang University\n(2018.03 ~)\n  Works\n TTS Researcher at LionRocket\n(2019.09 ~)  ","permalink":"https://revsic.github.io/blog/worklist/","tags":["Portfolio"],"title":"Work list"}]