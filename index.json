[{"categories":["Bayesian"],"contents":" Glow: Generative Flow with Invertible 1x1 Convolutions, Kingma and Dhariwal, 2018, arXiv Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design, Jonathan Ho et al., 2019, arXiv Keyword: Bayesian, Normalizing Flow, Glow, Flow++ Problem: Inexpressiveness of engineered bijectives Solution: Invertible 1x1 convolution, variational dequantization, mixture of logistics Benefits: Lower bits/dim, better sample quality Weakness or Future work: -  Series: Normalizing flow\n Normalizing flow, Real NVP [link] Glow, Flow++ [this] i-ResNet, ResFlow [future works] AFlow, VFlow, CIF [future works] SurVAE Flows [future works]  Normalizing flow\nlatent variable model은 high-dimensional data로부터 내재된 패턴들을 축약한, 유의미한 latent space를 구성하고자 한다. 이는 주로 확률 모델로 구현되며, 크게 VAE, Flow와 같은 likelihood 기반의 모델과 GAN 부류의 모델로 구분할 수 있다.\nFlow의 경우 데이터 $x \\sim p_X^*(x)$에 대해 bijective sequence $\\{f_k\\}^L_{k=1}$를 통한 change of variables를 근간으로 한다. 자세한 정의는 이전 글을 따른다.\n$$z = f_L \\circ \\ \u0026hellip; \\ \\circ f_1(x) \\\\\n\\log p_X(x) = \\log p_Z(z) + \\sum^L_{k=1}\\log\\left|\\det\\frac{\\partial f_k}{\\partial f_{k-1}}\\right| \\ \\ \\mathrm{where} \\ \\ f_0 = x$$\ntransform에 bijective라는 constraint가 붙은 만큼 몇 가지 이점을 갖는다.\nVAE의 경우 intractable posterior로 인해, variational infernce를 통한 log-likelihood의 lower-bound 추정을 objective로 하지만, normalizing flow의 경우에는 change of variables를 통한 exact log-likelihood estimation과 inference가 가능하다.\n또한 그 과정에서 encoder, decoder가 별개의 네트워크가 아닌, 파라미터를 공유하는 하나의 네트워크로 구성되므로 memory efficient 한 모델링이 가능하다.\n이전 글에서 다룬 Rezende \u0026amp; Mohamed(2015)[1], RealNVP[2]로 물살을 탄 normalizing flow를 이번 글에서는 engineered bijective 관점에서 어떠한 발전이 있었는지 알아본다.\nGlow\nGlow[3]는 RealNVP[2]의 multi-scale architecture를 기반으로 더욱 풍부하고 다양한 engineered bijective를 하나의 flow block으로 구성한 모델이다.\n기존의 RealNVP[2]가 Affine coupling, Batchnorm의 두 개 layer를 하나의 flow block으로 구성했다면, Glow는 ActNorm, Invertible 1x1 convolution, Affine coupling 3개 layer를 하나의 flow block으로 구성한다.\n ActNorm  RealNVP[2]에서는 deep models가 학습 중 겪게 되는 여러 문제를 해결하고자 batch normalization을 도입하였다. 하지만 batch norm의 경우 batch size에 영향을 받고, 그 크기가 작아짐에 따라 성능이 절감된다. 특히나 image의 경우 tensor size가 커 memory에 많은 양의 batch를 구성하지 못할 때에 치명적일 수 있다.\n이에 Glow[3]에서는 activation normalization, 이하 actnorm을 제안한다. actnorm은 첫 번째 minibatch의 mean과 variance로 초기화한 parameter로 normalization을 진행한다. 이는 DDI(data-dependent initialization)을 따르고, 초기화된 이후에는 데이터와 독립된 일반적인 trainable parameter로 취급한다.\nBatchnorm이 data에서 연산한 running statistics를 통해 normalization을 진행했다면, actnorm은 첫 번째 batch에서 연산한 statistics로 초기화한 파라미터를, 이후에는 데이터에 독립적인 trainable parameter로 상정하고 normalization을 진행한다는 점에서 차이가 존재한다.\n물론 이렇게 학습된 parameter가 실제로 hidden state의 statistics를 따르지는 않는다.\n$[h\\times w \\times c]$의 image tensor가 주어진다면, actnorm은 channel dimension에서 작동한다.\n$$y \\leftarrow \\frac{x - \\hat\\mu}{\\sqrt{\\hat\\sigma^2 + \\epsilon}}, \\ \\ \\log\\left|\\det\\frac{\\partial y}{\\partial x}\\right| = -h \\cdot w \\cdot\\sum\\log\\sqrt{\\sigma^2 + \\epsilon}$$\nInvertible 1x1 convlution  RealNVP[2]와 같은 기성 모델은 coupling layer의 활용으로 인해 일부 channel에 identity map이 적용되었고, 모든 channel에 transform을 적용히기 위해 고정된 permutation operation을 활용하였다.\nGlow[3]에서는 이 대체재로 invertible 1x1 convolution을 제안한다. invertible matrix를 근간으로 하는 linear projection은 어떤 basis로의 permutation으로 일반화되며, 1x1 conv는 이 과정에서 channel axis에 대한 일반화된 learnable permutation을 진행한다.\ninvertible 1x1 convolution의 log-determinant는 determinant of weight matrix로 귀결되며 다음과 같이 정리된다.\n$$\\log\\left|\\det\\frac{d \\mathrm{conv2D}(h; W)}{dh}\\right| = h \\cdot w \\cdot \\log\\left|\\det W\\right|$$\n문제는 weight matrix $W$의 determinant 연산은 $\\mathcal O(c^3)$의 cubic 연산이기 때문에 channel의 크기가 커짐에 따라 intractable 하다는 특성을 가진다.\nGlow[3]는 이를 위해 LU Decomposition을 제안한다. invertible matrix W를 두고, LDU factorized $L, D, U$를 trainable parameter로 가정한다. 그럼 non-zero diagonal matrix $D = \\mathrm{diag}(s)$에 대해 다음과 같이 weight matrix W를 재구성할 수 있다. (이 때 permutation P는 고정이다.)\n$$W = PL(U + \\mathrm{diag}(s))$$\n그럼 log-determinant를 $\\mathcal O(c)$의 linear time에 연산해낼 수 있게 된다.\n$$\\log\\left|\\det W\\right| = \\sum \\log |s|$$\nAffine coupling  기존의 RealNVP[2]에서의 affine coupling에 몇 가지 trick을 제안한다.\n우선 zero initialization이다. coupling layer는 affine transform에 활용할 파라미터를 NN을 통해 연산해내는데, 이때 NN 이후 추가 convolution을 하나 더 두고, 이의 weight을 0으로 두어 학습 초기에 identity function이 되도록 강제한다. 그리고 이것이 very dep networks의 학습에 도움을 주었다고 한다.\n두 번째는 permutation에 관해서이다. Glow[3]는 invertible 1x1 convolution을 통해 permutation을 일반화하였으므로, RealNVP[2]와 같은 checkerboard pattern 형식의 mask가 큰 의미가 있지 않다. 따라서 Glow[3]에서는 단순히 절반의 channel을 split하고 concat하는 방식을 차용하였다고 한다.\nFlow++\nFlow++[4]의 저자는 Rezende \u0026amp; Mohamed, 2015[1], RealNVP[2], Glow[3]를 넘어선 여러 가지 normalizing flow에 관한 연구가 있었지만, 여전히 다른 generative model보다 표현력이 부족하다는 것을 느꼈다.\n그는 그 문제점으로 3가지를 들었다.\n1. uniform dequantization이 loss와 generalization의 suboptimal choice라는 것\n2. affine coupling layer가 충분히 expressive 하지 않다는 것\n3. coupling layer의 conditional network로 convolution은 충분히 powerful 하지 않다는 것\n그리고 다음에서 그 대체재를 소개하고자 한다.\n Variational dequantization  이미지나 음성 데이터의 경우에는 continuous signal을 discrete representation으로 바꿔 저장하고, 이를 모델링하게 되는데, 단순히 continuous density model을 fitting 할 때 대부분의 probability mass가 discrete point에 치중되며 품질이 떨어지는 현상이 발생한다.\n이를 해결하기 위해 RNADE[5]에서는 dequantization을 제안했으며, 이는 uniform noise를 통해 data를 continous distribution으로 만들고, 이를 continuous density model로 표현하는 것이다.\n$$P_\\mathrm{model}(x) := \\int_{[0, 1)^D}p_\\mathrm{model}(x + u)du$$\n그리고 이는 다음 전개에 의해서 dequantized data의 log-likelihood가 lower-bound를 maximize 한 것으로 볼 수 있다.\n$$\\mathbb E_{y \\sim p_\\mathrm{data}}[\\log p_\\mathrm{model}(y)] \\\\\n= \\sum_x P_\\mathrm{data}(x) \\int _{[0, 1)^D}\\log p_\\mathrm{model}(x+u)du \\\\ \\le \\sum_x P_\\mathrm{data}(x)\\log\\int_{[0, 1)^D}p_\\mathrm{model}(x+u)du \\\\\n= \\mathbb E_{x\\sim P_\\mathrm{data}}[\\log P_\\mathrm{model}(x)]$$\n이를 통해 probability mass가 discrete point에 치중되고, degenerate mixture로 collapse 하는 현상을 막을 수 있었지만, 단순 unit hypercube $x + [0, 1)^D$로 모델링하기엔 uninformative 하고 unnatural 하다.\n따라서 variational dequantization에서는 dequantization noise distribution을 variational $q(u|x)$로 상정하고 lower bound를 objective로 학습시킨다.\n$$\\mathbb E_{x\\sim P_\\mathrm{data}}[\\log P_\\mathrm{model}(x)] \\\\\n= \\mathbb E_{x\\sim P_\\mathrm{data}}\\left[\\log\\int_{[0, 1)^D}q(u|x)\\frac{p_\\mathrm{model}(x+u)}{q(u|x)}du\\right] \\\\\n\\le \\mathbb E_{x\\sim P_\\mathrm{data}}\\left[\\int_{[0, 1)^D}q(u|x)\\log\\frac{p_\\mathrm{model}(x+u)}{q(u|x)}du\\right] \\\\\n= \\mathbb E_{x\\sim P_\\mathrm{data}, \\ u \\sim q(\\cdot|x)}\\left[\\log\\frac{p_\\mathrm{model}(x+u)}{q(u|x)}\\right]$$\n이때 variational distribution $q$는 flow-based model로 상정하여 $u = q_x(\\epsilon), \\ \\mathrm{where} \\ \\epsilon \\sim p(\\epsilon) = \\mathcal N(\\epsilon; 0, I)$로 둔다. 이후 likelihood는 change of variables로 estimation이 가능하고 $q(u|x) = p(q_x^{-1}(u))\\cdot|\\partial q_x^{-1}/\\partial u|$, lower bound objective는 다음과 같이 쓸 수 있다.\n$$\\mathbb E_{x \\sim P_\\mathrm{data}}[\\log P_\\mathrm{model}(x)] \\le \\mathbb E_{x \\sim P_\\mathrm{data}, \\ \\epsilon \\sim p}\\left[\\log \\frac{p_\\mathrm{model}(x + q_x(\\epsilon))}{p(\\epsilon)\\left|\\partial q_x/\\partial \\epsilon\\right|^{-1}}\\right]$$\n이에 발생하는 true likelihood와의 gap은 $\\mathbb E_{x\\sim p_\\mathrm{data}}[D_{KL}(q(u|x)||p_\\mathrm{model}(u|x))]$이다. 이는 $q$를 uniform과 같은 inexpressive distribution을 상정했을 때 lower bound가 loose 해질 수 있음을 의미한다. 따라서 flow 기반의 $q$를 사용함으로써 더움 flexible 한 modeling이 가능하게 하였고, 실제로 train loss나 generalization에서 더 나은 성능을 보였다.\nImproved coupling layers  근래의 flow-based model은 대부분 affine coupling과 permutation layer을 활용했다. coupling layer의 경우 conditioning network $a_\\theta, b_\\theta$를 상정하여 입력 일부로부터 parameter를 설정, 이를 토대로 나머지 입력을 transform 한다.\n$$y_1 = x_1, \\ \\ y_2 = x_2 \\cdot \\exp(a_\\theta(x_1)) + b_\\theta(x_1)$$\nFlow++[4]의 저자들은 실험을 통해 더욱 expressive 한 coupling layer를 제안한다. 이는 mixture of logistics를 활용하여 invertible nonlinear transform을 가능케 한다.\n$$x \\mapsto \\sigma^{-1}(\\mathrm{MixLogCDF}(x;\\pi, \\mu, s)) \\cdot \\exp(a) + b \\\\\n\\mathrm{where} \\ \\ \\mathrm{MixLogCDF}(x; \\pi, \\mu, s) := \\sum^K_{k=1}\\pi_i\\sigma((x - \\mu_i)\\cdot\\exp(-s_i))$$\n이 때 $\\{\\pi_i, \\mu_i, s_i\\}_{i=1}^K, a, b$는 모두 neural network로 parameterizing한다.\nExpressive conditioning architectures with self-attention  기존까지는 coupling layer에서 conditioning network로 convolutional layer를 주로 상정했다면, 이번에는 multihead self-attention 기반의 network(Vaswani et al., 2017[6])를 활용해본다.\nnetwork는 stack of blocks로 구성되고, 각 block은 아래와 같이 구성된 뒤 residual connection과 layer normalization을 통해 연결된다.\n$$\\mathrm{Attn = Input \\to Conv_{1x1} \\to MultiHeadSelfAttention \\to Gate}$$\n이때 $\\mathrm{Gate}$는 gated activation unit을 의미한다. network는 input tensor를 여러 개의 block에 forward하고, 마지막에 convolutional layer를 통해 coupling에 필요한 파라미터 수 만큼 channel을 늘리게 된다.\nExperiments\n  Table 1: Unconditional image modeling results in bits/dim. (Ho et al., 2019)\n  RealNVP[2], Glow[3], FlowW++[4]로 넘어오는 과정이 정량적으로 잘 나타났다.\n  Table 2: CIFIAR10 ablation results after 400 epochs of training. (Ho et al., 2019)\n  또한 실제로 ablation study를 통해 component별 향상치도 확인할 수 있다.\n  Figure 6: Manipulation of attributes of a face. (Kingma \u0026amp; Dhariwal, 2018)\n  Discusion\n(사견)\nFlow는 bijective라는 constraint로 인해 기존의 nonlinearity를 근간으로 하는 expressiveness를 충분히 누리지 못했다. 그렇기 때문에 Flow 발전 초기에는 더욱 bijective block을 충분히 engineering 하여 표현력을 높이고자 하는 연구가 많았던 것 같다.\n그 과정에서 actnorm, invertible 1x1 convolution, logistic coupler, variational dequantization 등 다양한 블럭이 나왔고, 이번 기회에 이를 소개하고자 했다.\n이후에는 i-ResNet, ResFlow 등에서 residual network를 inversion 하는 시도 등을 통해 최대한 많은 feature에 nonlinearity를 활용하고자 하였고, 본격적으로 vae와의 통합을 위한 발판을 마련하기도 한다.\nReference\n[1] Rezende, D. J. and Mohamed, S. Variational inference with normalizing flows. In ICML 2015.\n[2] Dinh, L., Sohl-Dickstein, J. and Bengio, S. Density estimation using Real NVP. In ICLR 2017.\n[3] Kingma, D. P. and Dhariwal, P. Glow: Generative Flow with Invertible 1x1 Convolutions. In NIPS 2018.\n[4] Ho, J. et al. Flow++: Improving flow-based generative models with variational dequantization and architecture design. In ICML 2019.\n[5] Uria, B., Murray, I. and Larochelle, Hugo. RNADE: The real-valued neural autoregressive density-estimator. In NeurIPS 2013. [6] Vaswani, A. et al. Attention is all you need. In NeurIPS 2017.\n","permalink":"https://revsic.github.io/blog/glowflowpp/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","Glow","Flow++"],"title":"Glow, Flow++"},{"categories":["Bayesian"],"contents":" Variational Inference with Normalizing Flows, Rezende and Mohamed, 2015, arXiv Density Estimation using Real NVP, Dinh et al., 2017, arXiv Keyword: Bayesian, Normalizing Flow, Real NVP Problem: inflexibility of variational posterior Solution: probabilistic modeling with bijective and change of variables Benefits: simple sampling, exact log-likelihood estimation Weakness or Future work: determinant, inverse and architecutral constraint  Series: Normalizing flow\n Normalizing flow, Real NVP [this] Glow, Flow++ [link] i-ResNet, ResFlow [future works] AFlow, VFlow, CIF [future works] SurVAE Flows [future works]  Variational Inference\n우리는 데이터에 대한 insight를 얻고자 할 때 probabilistic modeling을 통해 데이터가 어떤 분포를 가지는지 추정한다. 그 과정에서 latent variable을 도입하기도 하고, marginalize 과정에서 발생하는 적분의 intractability로 인해 variational inference를 활용해 posterior를 known distribution으로 근사하기도 한다.\n$$\\log p_\\theta(x^{(i)}) = D_{KL}(q_\\phi(z|x^{(i)})||p_\\theta(z|x^{(i)})) + \\mathbb E_{q_\\phi}\\left[ \\log \\frac{p_\\theta(x, z)}{q_\\phi(z|x)} \\right]$$\n이 중 연산이 가능한 두번째 RHS term만을 발췌해 variational lower bound라 부른다.\n$$\\log p_\\theta(x^{(i)}) \\ge \\mathbb E_{q_\\phi}\\left[\\log\\frac{p_\\theta(x, z)}{q_\\phi(z|x)}\\right] = \\mathbb E_{q_\\phi(z|x^{(i)})}\\left[ \\log p_\\theta(x^{(i)}|z) \\right] - D_{KL}(q_\\phi(z|x^{(i)})||p_\\theta(z))$$\nRezende \u0026amp; Mohamed(2015)[1]에서는 성공적인 variational inference를 위해 1) derivatives of log-likelihood $\\nabla_\\phi\\mathbb E_{q_\\phi(z)}\\left[\\log p_\\theta(x|z)\\right]$ 연산의 효율성과 2) approximate posterior $q(\\cdot)$의 유연함이 필요하다 이야기한다.\n전자의 경우에는 VAE[2]에서와 같이 Monte carlo approximation과 reparametrization을 통해 gradient를 연산하는 방식을 취할 수 있다.\n$$z \\sim \\mathcal N(z|\\mu, \\sigma^2) \\Leftrightarrow z = \\mu + \\sigma \\epsilon, \\ \\ \\epsilon \\sim \\mathcal N(0, 1) $$\n하지만 이렇게 되면 variational posterior가 gaussian과 같은 분포로 한정되고, 이 경우 true posterior로의 근사가 어려울 수 있다.\n따라서 이상적인 variational distribution $q_\\phi(z|x)$는 true posterior의 근사를 위해 highly flexible해야 하고, 저자는 그 solution으로 normalizing flow를 제안한다.\nNormalizing Flow\nNormalizing flow는 invertible map을 통해 probability density를 순차적으로 변형시켜 나가는 모델이다. 각각의 invertible map은 change of variables를 통해 initial density를 변형시켜 나가고, density의 변환 흐름, \u0026lsquo;flow'를 표현하게 된다.\nChange of variables\n확률변수 $X \\in \\mathbb R^d$의 CDF $F_X$와 어떤 단조함수 $g: \\mathbb R^d \\to \\mathbb R^d$에 대해 $Y=g(X)$이면, 다음이 성립한다.\n$$F_Y(y) = P(Y \\le y) = P(g(X) \\le y) = P(X \\le g^{-1}(y)) = F_X(g^{-1}(y))$$\n이때 양변을 미분하면 $Y$에 대한 density를 구할 수 있게 되고, sample에 대한 exact log-likliehood의 연산이 가능해진다.\n$$f_Y(y) = f_X(g^{-1}(y))\\left|\\det\\frac{\\partial g^{-1}}{\\partial y}\\right| \\\\\n\\log f_Y(y) = \\log f_X(g^{-1}(y)) + \\log\\left|\\det\\frac{\\partial g^{-1}}{\\partial y}\\right|$$\nFinite Flows\nNormalizing flow는 simple invertible map을 순차적으로 합성해 나가며 initial density를 임의의 complex distribution으로 만들어나간다.\ninitial random variable $z_0$와 distribution $q_0$에 대해 sequence of invertible map $f_1, \u0026hellip;, f_K$을 chain으로 구성하면 $x=z_k$의 sampling과 exact log-likelihood의 연산이 가능하다.\n$$z_K = f_K \\circ \\ \u0026hellip; \\ \\circ f_2 \\circ f_1(z_0) \\\\\n\\ln q_K(z_K) = \\ln q_0(z_0) - \\sum^K_{k=1}\\ln\\left|\\det\\frac{\\partial f_k}{\\partial z_{k-1}}\\right|$$\n이때 initial distribution $q_0(z_0)$부터 $z_k = f_k(z_{k-1})$로 구성된 path를 flow라 한다.\n이는 LOTUS(law of unconscious statistician)으로도 불리며, 이 경우 $q_K$로 구성된 expectation을 분포에 대한 정보가 없이 연산 할 수 있게 된다. 이를 활용해 posterior를 모델링 하면 최종 분포상 제약이 없어 보다 유연한 근사가 가능하다.\n또한 기존의 확률 모델이 complexity를 높이기 위해 nonlinear transform을 활용하면서 invertibility를 포기하고, ELBO를 통해 log-likelihood의 lower bound를 추정했다면,\nnomarlizing flow는 NN을 활용한 engineered linear transform을 순차적으로 적용해 나가며 exact log-likelihood의 연산과 single forward-pass의 sampling이 가능하다는 것에 의의가 있다.\nReal NVP: Modeling bijectivity\nNormalizing flow는 여러가지 이점을 가지는 대신에 determinant와 inverse map이 tractable 해야 한다는 architecture의 constraint를 가진다.\nRealNVP[3]는 이러한 constraint에 대해 well-engineered transform을 제안한다.\n Coupling layers  determinant와 jacobian을 고차원 데이터와 함수에 대해 연산한다는 것은 일반적으로 굉장히 computationally expensive하다. 이를 위해서 RealNVP[3]가 한 선택은 bijective에 제약을 가하여 jacobian을 triangular matrix로 구성하는 것이다.\nAffine coupling layer은 D-dimensional input $x \\in \\mathbb R^D$에서 $d \\lt D$의 일부 $x_{1:d}$를 활용하여 나머지 $x_{d+1:D}$를 affine transform한다.\n$$y_{1:d} = x_{1:d} \\\\\ny_{d+1:D} = x_{d+1:D} \\cdot \\exp(s(x_{1:d})) + t(x_{1:d})$$\n이때 $s$와 $t$는 NN으로 구성한 scale과 translation function $\\mathbb R^d \\mapsto \\mathbb R^{D-d}$이다.\n이 경우 jacobian matrix는 lower-triangular matrix로 구성되고, log-determinant는 scale의 합으로 연산된다.\n$$\\frac{\\partial y}{\\partial x} = \\left[ \\begin{matrix} \\mathbb I_d \u0026amp; 0 \\\\ \\frac{\\partial y_{d+1:D}}{\\partial x_{1:d}} \u0026amp; \\mathrm{diag}(\\exp(s(x_{1:d}))) \\end{matrix} \\right] \\\\\n\\log\\left|\\det\\frac{\\partial y}{\\partial x}\\right| = \\sum s(x_{1:d})$$\n이뿐만 아니라 coupling 기반의 layer는 inverse도 쉽게 연산해낼 수 있다.\n$$x_{1:d} = y_{1:d} \\\\\nx_{d+1:D} = (y_{d+1:D} - t(y_{1:d})) \\cdot \\exp(-s(y_{1:d}))$$\n1.1. Masked Convolution\nRealNVP[3]에서는 partitioning을 binary mask를 통해 일반화 한다.\n$$y = b \\odot x + (1 - b) \\odot \\left( x \\odot \\exp(s(b \\odot x)) + t(b \\odot x) \\right)$$\ncoupling layer 특성상 input의 일부에는 transform이 이뤄지지 않기 때문에, 연속된 coupling layer를 구성할 때는 binary mask를 alternating 하면서 모든 feature가 transform 될 수 있도록 구성한다.\n  Figure 3: Masking schemes for affine coupling layers. (Dinh et al., 2017)\n  RealNVP[3]에서는 checkerboard pattern의 mask를 상정했으며 even index와 odd index를 번갈아 가며 trigging하는 방식으로 binary mask를 구성한다.\nMulti-scale architecture  RealNVP[3]는 input의 spatial size와 channel size 사이의 tradeoff를 위해 squeezing을 활용한다. 2x2xC의 subsquare를 1x1x4C로 squeezing 한다면 channel을 4배가량 늘릴 수 있게 된다.\nRealNVP[3]는 multiple squeezing operation과 inter-coupling layer를 통해 여러 scale에서의 latent를 뽑고자 했다. 이때 전체 dimension이 유지되는 normalizing flow의 특성상 computational, memory cost는 고수준에서 유지되고, 부담을 줄이기 위해 각 scale에서 절반의 feature를 factorizing 한다.\n$$h^{(0)} = x \\\\\n(z^{i+1}, h^{i+1}) = f^{(i+1)}(h^{(i)}) \\\\\nz^{(L)} = f^{(L)}(h^{(L-1)}) \\\\\nz = (z^{(1)}, \\ \u0026hellip; , z^{(L)})$$\n이 경우 latent z는 명시적으로 coarser scale의 정보와 finer scale의 정보를 분리하여 다룰 수 있게 된다. 이는 RealNVP[3]의 Appendix D.에서 확인 가능하다.\n  Figure 4: Composition schemes for affine coupling layers. (Dinh et al., 2017)\n  또한 intermediate representation을 직접 활용하기 때문에 gradient의 전달과 학습이 용이하다는 장점을 가진다.\nBatch normalization  training signal의 효율적인 전파를 위해 여러 모델은 batch normalization을 활용한다. RealNVP[3]에서는 running statistics를 활용하여 normalization을 구성한다.\n$$x \\mapsto \\frac{x - \\tilde \\mu}{\\sqrt{\\tilde\\sigma^2 + \\epsilon}}$$\n이 경우 linear rescaling과 동일하므로 jacobian은 $\\sigma$의 곱으로 구성된다.\n$$J = \\left(\\prod_i(\\tilde\\sigma^2 + \\epsilon)\\right)$$\nTraining, Sampling\n이렇게 bijective를 활용한 invertible map $g: X \\to Z$을 구성했다면, $x \\in X$의 입력에 대해 forward pass로 latent $z = g(x) \\in Z$를 구하고, 해당 latent를 통해 log-likelihood를 추정한다.\n$$\\log p_X(x) = \\log p_Z(z) + \\log\\left|\\frac{\\partial g}{\\partial x}\\right|$$\n원문에서는 prior $p(z)$를 gaussian으로 상정하였고, 추정된 log-likelihood를 maximize 하는 방식으로 네트워크를 학습시킨다.\nsampling의 경우 prior에서 sampling한 noise $z \\in Z$를 inverse pass하여 $x = g^{-1}(z) \\in X$ 바로 사용할 수도 있고, 데이터로부터 latent를 구하여 interpolation 등 후처리 후 사용할 수도 있다.\n$$z \\sim p(z) \\mapsto g^{-1}(z) \\in X$$\nResults\n  Table 1: Bits/dim results. (Dinh et al., 2017)\n    Figure 6: Manifold generated from four examples in the dataset. (Dinh et al., 2017)\n  Discusion\n(사견)\nNormalizing flow의 시작이 Rezende \u0026amp; Mohamed (2015)[1]는 아니었다. density estimation을 위해 Tabak \u0026amp; Vanden-Eijnden (2010)[4], Tabak \u0026amp; Turner (2013)[5]에서 제안이 되었고, 딥러닝을 활용한 probabilistic modeling으로 Rezende \u0026amp; Mohamed (2015)[1]에서 크게 유명해졌다.\n비록 determinant와 inverse의 tractability로 인한 architectural constraint를 가지고 있지만, sampling이 single-forward pass로 가능하고, exact log-likelihood의 연산이 가능하다는 점에서 충분한 매력을 가진 모델이다.\n추후 bijective에 대한 연구, VAE와의 상관성, 통합 가능성이 연구됨에 따라 더 많은 이야기가 남은 모델이므로 관심 가지고 봐도 좋을 것 같다.\nReference\n[1] Rezende, D. J. and Mohamed, S. Variational inference with normalizing flows. In ICML 2015.\n[2] Kingma, D. P. and Welling, M. Auto-encoding variational bayes. In ICLR 2014.\n[3] Dinh, L., Sohl-Dickstein, J. and Bengio, S. Density estimation using Real NVP. In ICLR 2017.\n[4] Tabak, E. G. and Vanden-Eijnden, E. Density estimation by dual ascent of the log-likelihood. Communications in Mathematical Sciences, 2010.\n[5] Tabak, E. G. and Turner, C. V. A family of nonparametric density estimation algorithms. Communications on Pure and Applied Mathmatics, 2013.\n","permalink":"https://revsic.github.io/blog/realnvp/","tags":["Machine Learning","Deep Learning","Bayesian","Normalizing Flow","Real NVP"],"title":"Normalizing Flow, Real NVP"},{"categories":["Writing"],"contents":"올해로 1년 좀 넘게 음성 합성 리서치 업무를 보고 있다.\n이번 글에선 19년 9월, 입사부터 20년 말까지 한 활동을 조심히 정리해보려 한다.\n[대학교 3학년의 2020] On 2020 as student\n[딥러닝 리서처의 2020] 현재 글\n 입사 당시 입사 당시 우리 회사는 설립된 지 반년 정도 된 학부생 스타트업이었다.\n처음에는 대표님의 요청으로 비전 프로젝트 외주를 진행했었고,\n9월에 입사하여 본격적으로 음성 업무를 보기 시작했다.\n당시 회사 인원은 나 포함 5명이었고, 각자 역할이 부여된 상황이었다.\n그중 나는 TTS 리서처로 들어왔다.\n당연히 사수는 없었다.\nTTS 연구 개발 프레임워크는 리팩토링이 시급해 보였고,\n그를 기반으로 딥러닝 리서치를 진행하는 과정이 확립되어 있지 않았다.\n모든 것을 처음부터 시작해야 하는 상황이었다.\n하지만 이제 막 2학년이 끝난 학부생은 모든 게 패기로웠다.\n 딥러닝 리서처 업무 음성 합성 리서치의 목표는\n합성된 음성의 발음이 또렷해야 하고, 자연스러우면서, 음질이 좋아야 한다.\n이후에는 다국어, 다화자, 감정 등 추가 기능 지원이 들어간다.\n논문 리뷰\n회사 들어와서 가장 먼저 한 리서치 업무는\n음성 합성 논문 리스트를 만들고 쭉 리뷰 한 것이었다.\n처음 입사했을 때에는 푸리에 변환이 뭔지도 모르고 시작했다.\n그냥 이렇게 저렇게 만든 스펙트로그램이란 피쳐가 있고,\n딥러닝 모델이 텍스트에서 스펙트로그램으로의 매핑을 학습한다는 정도만 나이브하게 알고 있었다.\n신호처리 공부도 해야 했고, 딥러닝 모델 논문도 봐야 했다.\n그렇게 1년 동안 대략 60편 정도의 논문을 보고 20개 가까이 구현해본 것 같다.\n입사 전에도 그랬지만, 시작부터 다독을 목표로 했다.\n리뷰가 진행된 논문이던, 안 된 논문이던,\n메이저 학회에 통과한 논문이던, 그저 arXiv에 올라온 글이던 가리지 않았다.\n논문 볼 때 정리했던 내용\n논문을 보면 항상 5가지 항목에 대해서 정리했다.\n 어느 분야에서 이전 논문들에서 어떤 문제점을 발견했고 어떤 해결방법을 제시했으며 이때 생기는 이점과 발견되었거나 예상되는 약점은 무엇인지  그렇게 해서 학계의 흐름을 쫓고 있고,\n올해 말부터는 이제 본인만의 실험을 기획하기 시작했다.\n딥러닝에 관심을 가지고 있던 적당한 학부생이었고,\n어디서 연구하는 방법이란 것을 배워본 적이 없었기 때문에 모든 게 서툴렀다.\n논문을 볼 때 어느 것이 중요하고,\n어떻게 쫓아야 하고, 무엇을 이야기하고 싶은건지,\n저 5가지 질문을 확립하는데에도 꽤 시간이 걸렸던 것 같다.\n신호처리 관련 공부\n문제는 어느 시점부터, 음성 분야 논문이 단순 스펙트로그램을 넘어서\n여러 가지 피쳐나 기성 신호처리 알고리즘들을 차용하여 성능을 높이는 시도가 등장했다는 것이다.\n따로 물리나 신호처리학을 공부해본 적이 없었기 때문에,\n어디서부터 무엇을 공부해야 할지도 몰랐고,\n처음부터 공부해서 이른 시일 안에 현업에 사용할 자신도 없었다.\n그래서 모르는 단어가 나오면,\n탑다운 방식으로 구글에 단어를 검색하고,\n대학 강의에 쓰인 pdf 파일을 보면서 공부했다.\n  (생각보다 검색하면 잘 나옴)\n  그러다 보니 틀리게 이해한 내용도 많았고,\n이곳저곳 빈 곳도 많았다.\n하지만 탑다운도 결국 수렴한다고,\n결국에는 틀린 이해를 정정하고, 꽤 많은 빈 곳을 채웠다는 생각이 든다.\n모델 구현\n기존에는 tensorflow를 많이 활용했었다.\n하지만 회사에서는 pytorch를 사용하고 있었고,\n이에 맞추기 위해 하루에서 이틀 정도는 파이토치에 적응을 좀 했던 거 같다.\n모델을 구현하기에 앞서 원저자가 구현한 오픈소스 코드가 있는지 확인했다.\n처음에는 하루 정도면 모델 하나 구현할 수 있다고,\n오픈소스 찾아볼 게 있냐고 처음부터 짜는 객기를 부렸지만,\n딥러닝 코드는 버그를 잡기 어렵고,\n이미 구현된 코드가 있으면 I/O 정도만 수정해서 바로 실험해볼 수 있으므로\n오픈소스를 참고해서 회사 스타일에 맞게 정리하는 게 빠르다.\n물론 라이센스 확인은 필수다.\n또한, 논문에 기재되지 않은 디자인 초이스나 휴리스틱이 존재할 수 있으므로\n원작자의 코드 존재 여부를 우선 파악하는 것이 맞는 것 같다.\n만약 이해되지 않는 디자인이나,\n기재되지 않은 하이퍼 파라미터 정보가 있다면 레딧에 물어보는 것도 괜찮은거 같다.\n  (생각보다 관심을 많이 받아서 신기했음)\n  실험, 문제점, 해결책\n이렇게 구현이 끝난 모델은 사전에 선정한 데이터셋으로 학습해 보고,\n여러 지표를 통해 모델을 평가했다.\n문제는 생성된 음성은 원본과 1대1로 비교하는 것이 무의미하다.\n음의 높낮이가 다르더라도 충분히 자연스러울 수 있고,\n파형이 다르더라도 같은 발음 성분을 가지고 있을 수 있다.\n이러다 보니 1대1로 비교하는 것은 무의미하고,\n길이가 다른 시퀀스의 유사도나, ASR 모델을 활용하여\n의미 있는 평가를 자동화하기 위한 여러 추가 연구도 진행했었다.\n그렇게 모델을 평가하고 나면 문제점이 나타난다.\n이 모델은 발음을 못 한다, 이 모델은 음질이 안 좋다. 등등\n그럼 기존까지 관찰된 여러 모델의 현상을 통해 단점을 커버하기 위한 추가 실험을 진행한다.\n아직은 딥러닝이라는 분야가\n특정된 데이터셋과 컴퍼넌트의 상호작용을 연역적으로 분석하기 어려우므로\n현상과 실험적인 접근이 최선인 것 같다는 생각이 든다.\n그래서 조금 답답하기도 하다.\n연구하는 방법을 배운 기분\n위에 엄청 대단한 거 마냥 글을 썼지만,\n사실 당연한 연구 루틴이었을지도 모른다.\n앞서 이야기했듯, 나는 그냥 딥러닝에 관심이 있던 학부생이었고,\n연구라는 것을 해보거나 배워본 적이 없기 때문에\n1년 동안은 정말 벽에 부딪치며 연구하는 방법을 배운 거 같다.\n실제로 처음에는 그냥 성능을 높이는 게 목적이니\n닥치는 대로 논문을 읽고, 시간 되는 대로 구현하고,\n뭐가 안되면 모델 잘못이네, 수정은 하이퍼 파라미터 튜닝하는 정도였다.\n그러다 이제 타임라인이 현재에 도달해서,\n과거 논문을 구현하는 것이 아니면 추가로 볼 논문이나 모델이 없는 시점에 왔다.\n이제는 모델 탓만 할 것이 아닌,\n어떤 문제가 있고, 어떻게 해결해야 할지에 대한 고민을 해야 하는 상황이다.\n올해 말이 되어서야 나는 가설이라는 걸 세워보고,\n실험을 통해 증명하고, 개선하는 일련의 프로세스를 확립해서 업무에 적용해 보고 있다.\n그 과정에서 평가 지표도 자동화했고,\n컴퍼넌트랑 지표의 상관성, 현상과의 연관성도 하나씩 알아보고 있다.\n결과를 보는 그 과정이 재미로 다가왔다.\n이제야 길이 환해진 느낌이 든다.\n 엔지니어링 업무 입사해서 연구 관련 업무만을 볼 수는 없었다.\n딥러닝 프레임워크\n딥러닝 모델 개발은 생각보다 여러 가지 코드를 수반한다.\n단순 텍스트 파일과 wav 파일로 이뤄진 데이터를\n전처리하여 저장하기 위한 코드도 필요하고,\n저장된 데이터를 불러와 모델에 전달,\nloss를 계산하여 업데이트하는 학습 과정,\n학습이 얼마나 잘 되어 가고 있는지,\n모델이 어느 정도 수준을 성취했는지 기록하는 과정,\n마지막으로 모델을 통해 서비스를 작동시킬 수 있도록\n캡슐화시키고 배포하는 과정 등이 있다.\n나는 개발, 학습, 기록, 캡슐화 정도의 과정을 맡았고,\n전처리, 후처리, 서비스 개발 및 배포 과정은 다른 분이 맡았다.\n이 중에서 배포 과정을 뺀 모델 개발 전 과정을\n하나의 구조로 엮은 프레임워크가 있었는데,\n코딩 컨벤션이나 문서화도 따로 되어 있지 않았고,\n깃은 단순 코드 보관용, 모델 캡슐화는\n코드 전체와 체크포인트를 복붙하여 압축파일(?)로 저장하는 구조로 되어 있었다.\n9월에 입사한 나는 회사 규모가 커졌을 때,\n이 모든 코드가 레거시로 남을게 뻔히 보여 더 커지기 전에 갈아엎을 것을 제안했고,\n팀장님도 이에 수긍하셔 11월까지 3개월간의 대규모 리팩토링에 들어간다.\n협업 약속\n가장 먼저 제안한 것은 브랜치, PR, 코드 리뷰의 3가지 과정이다.\n기존까지 모든 코드는 마스터로 들어가고 있었고,\n혼자 개발하고 계셨기 때문에 브랜치나 PR의 개념이 없었다.\n이젠 둘이 개발해야 하는 상황이고,\n마스터는 항상 stable한 상태로 두어야 한다는 전제를 깔았다.\n그러고 나니 브랜치, PR, 코드 리뷰는 당연히 쫓아오는 과정이었다.\n또 하나는 문서화를 제안했다.\n당장 리팩토링을 하려고 보니, 음성 합성 지식이 전무했던 나에겐\n주석 하나 없는 코드가 어떤 역할을 하는지 몰랐다.\n당시에는 회사에 오래 있을지 모르는 상황이었기에,\n다음 사람이 오면 똑같은 일이 일어날 것이고,\n이제는 코딩 컨벤션과 주석을 의무적으로 달아야 한다고 전달했다.\n의견은 모두 받아들여졌고,\n가장 근간이 되는 토대를 확립하고 나서야 리팩토링을 진행할 수 있었다.\n리팩토링\n가장 먼저 한 것은 각 과정에 맞게 레이어를 분리한 것이다.\n모델 클래스를 추상화하고,\n이를 토대로 학습, 기록, 추론 과정을 어플리케이션 레이어로 분리했다.\n모델을 개발하면 더 이상 복사 붙여넣기 없이,\nhyper-parameter와 체크포인트만 가지고 모델을 작동시킬 수 있게 되었다.\n딥러닝 컴퍼넌트 중 중복된 코드는 분리하고,\n어텐션 모듈같이 추상화가 요구되는 것들은 레이어를 하나 더 두었다.\n문제는 전처리 코드였는데,\n이 부분은 음성 합성 지식이 전무한 나에겐 함부로 건드릴 수 없는 부분이었다.\n결국 전처리 레이어를 두고, 어플리케이션에서 사용 가능하게 두되,\n내용물은 레거시 코드에서 가져온 것을 래핑 해둔 정도로 놔둬야 했다.\n쓰다 보니 정말 당연한 리팩토링 수순을 밟았지만,\n그렇게 만들어진 당시의 프레임워크는 정말 간결했고, 개발자 친화적이었다.\n돌고 돌아\n하지만 리팩토링된 프레임워크는 1년이 된 시점에서 망가지기 시작했다.\n회사는 바빴고,\n코드 퀄리티가 떨어지더라도 당장에 작동하는 듯 보이는 코드가 필요했다.\n처음과 달리 코드 리뷰는 약식화 되어 갔고,\n코드에 구멍이 나기 시작했다.\n점점 핫픽스 브랜치가 늘어났고,\n원인과 여파의 분석 없이 당장 필요한 부분만 작동하면 머지를 해야 했다.\n한 1년 즈음 까지는 나라도 붙잡고,\n나라도 리뷰 열심히 해야지 하고 이런저런 리뷰를 남겼지만,\n어느 순간부터 나도 포기했다.\n회사는 결국은 돈을 벌어와야 했고,\n회사가 요구하는 연구 방향이나 개발 방향이 설정된다.\n급하다는 이유로 언제 터질지 모르는 구멍을 보고도 모른 척 하게 된 것이다.\n이제는 프레임워크가 거의 제구실을 하지 못한다.\n작동하는 모델은 상용화된 것 몇 개 뿐이고,\n연구용으로 남긴 모델은 작동하지도 않는다.\n중간에 experimental feature라고 분리도 해봤지만,\n이젠 마스터 브랜치의 모델도 돌아가는 것은 몇 개 없다.\n그 외에 학계의 움직임에도 영향을 받았다.\n이젠 기성 신호처리 기법들이 딥러닝과 연계되어 들어왔고,\n프레임워크는 그에 필요한 새로운 피쳐나 출력물들까지 모두 처리할 수 없었다.\n입출력 파이프라인은 난잡해졌고,\n결국 안 좋은 의미의 레거시로의 길을 걷고 있는 것 같았다.\n앞으로\n올 11월 즈음, 나는 더 이상 가면 되돌릴 수 없다는 걸 깨달았다.\n하지만 새로운 서비스를 준비하고 있던 팀에는 그걸 모두 뜯어고칠 시간이 없었다.\n매일 새로운 실험을 통해 모델을 개선해야 했고,\n모델 변형, 실험, 정리, 새 실험 기획만 하다가도 날이 저물었다.\n결국 이번 모델 개발이 끝나면,\n기간을 잡고 리팩토링을 하거나 새로운 프레임워크를 구성하자는 이야기를 꺼냈다.\n이다음에 프레임워크를 재구성하게 된다면,\n그때는 지금과 다를 수 있을지 의문이 들기는 한다.\n CUDA까지 내려갔다 오면 음성은 보통 초당 16k, 22k, 44k 정도의 프레임을 샘플링 하는데,\n19년 말, 20년 초까지만 해도 이 프레임 수에 합성 시간이 비례했다.\n음성 길이가 길어지면 합성 시간도 길어졌고,\n1초의 음성을 만드는데 대략 10초 정도 걸렸던 거 같다.\n당연히 실시간 서비스에 사용하기는 어려웠고,\n프레임 수에 합성 시간이 비례하지 않는 모델을 찾아봤지만,\n음질이 좋지 않아 결국 돌아오게 되었다.\n모델 가속화\n올해 초 모델을 가속화 하라는 특명이 떨어졌다.\n대략 1초 합성에 1초 언저리 즈음 걸리도록\n여러 가지 찾아봤다.\nTensorRT, TorchScript JIT, ONNX 등등\n하지만 공통적인 문제가 있었다.\n기본적으로 당시 음성 합성 기술은 대부분이\n하나의 프레임을 만들고, 해당 프레임을 토대로 새로운 프레임을 만드는\n자기 회귀(autoregressive) 방식으로 작동하고 있었고,\n언제 회귀를 끝낼지는 동적으로 판단하기 때문에\n iteration 수가 정해져 있어야 하고, 자기 회귀 없이 forwarding만을 지원하는  가속화 도구 대부분을 사용할 수 없었다.\n모델을 분리하여, 병목이라도 가속화 해보려 했지만,\n극적인 성능 향상 없이 대부분 1.7배, 2배 정도만 빨라졌다.\n목표는 10배이고, 상용 프레임워크는 불가능했기에,\n결국 눈을 질끈 감고 CUDA 프레임워크를 개발하기로 했다.\n결국 CUDA\n팀 내에서 CUDA를 다룰 줄 아는 사람은 없었기에,\n급하게 CUDA 서적을 구매해 예시 코드 몇개 적어보고 가속화 작업에 착수했다.\n결론부터 이야기하면, 대략 2주 만에 7배 빠른\n추론 가속화용 CUDA C++ 프레임워크를 개발해냈다.\n내 손으로 텐서플로를 만들어 본다는 기분으로 시작했다.\nCUDA 메모리를 추상화하고,\nshape과 blob으로 구성된 텐서 구조체를 설정하고,\n텐서에서 작동하는 여러 연산을 CUDA 커널로 구현했다.\n이후 문제의 모델을 C++에서 재구현하고,\n파이토치 체크포인트에서 weight을 불러올 수 있는 기능을 추가했다.\n그렇게 만든 CUDA 프레임워크는 처음에 PyTorch보다 느렸다.\n당시 야근을 하고 있었는데, 팀장님이랑 같이 한숨부터 쉰 기억이 있다.\n이제 하나씩 최적화를 시작했다.\n그 중 몇 가지만을 소개하려 한다.\n가장 먼저 한 것은 TensorView를 만든 것이었다.\nreshape, transpose나 slice의 경우에는 값의 수정 없이 tensor를 보는 관점만 바뀐 것인데,\n연산 과정에 매번 값을 복사하여 새로운 Tensor를 만드는 것은 비효율적이다.\n따라서 같은 메모리를 공유하되,\n값은 수정하지 못하고, stride나 shape만을 수정 가능한 view를 두는 것이 좋다.\n두 번째는 메모리 매니저를 따로 둔 것이다.\n자기 회귀(AR) 모델처럼 연산이 가볍지만, 반복이 많은 경우에는,\n프로파일링을 해보면 연산보단 메모리의 할당과 해제에 병목이 걸리는 경우가 많았다.\n당시에 힙 메모리와 malloc 관련 공부를 하고 있었고, 메모리 관리 기법에서 영감을 얻었다.\nCUDA 에서 할당받은 메모리는 사용 직후 바로 반환하기보다는, 크기별로 분류해 두었다가,\n메모리 요청이 왔을 때 적절한 메모리가 있으면 CUDA를 안 거치고 반환,\n아니면 CUDA 에서 추가 할당받는 식으로 매니저를 구성해서 시간을 많이 줄일 수 있었다.\n그렇게 해서 총 7배 정도가 빨라졌고, 대략 1.5초에 1초 음성 정도를 만들었다.\n이후에 pybind11 활용해서 파이썬으로도 매핑하고,\nC++ 개발자 아니어도 쓸 수 있게 구성을 해놨지만\n여러 이유로 프로젝트는 폐기되고,\n죽은 기술이 되었다.\n회사에 묶여서 공개하지 못하는 게 아쉽기도 하다.\nCUDA 개발 정리하면서\nCUDA 개발하면서 그래도 느낀 점이 좀 있었다.\n왜 torch에는 view와 reshape이 따로 있을지, contiguous가 필요한 이유가 뭘지,\n왜 채널 크기는 32의 배수로 설정되는 것인지 등등\n실상은 많은 디자인이 GPU와 CUDA 에 의해 결정되고 있었다.\n딥러닝 하는 분들한테 추천해볼 법한 프로젝트였던 것 같고,\n죽은 기술로만 두는 것이 아쉬워\n이번 겨울에 개인적으로 러스트와 rustacuda를 통해 재구현해 볼 생각이다.\n 정리 다사다난한 한 해였다.\nTTS, 보코더 연구부터 프레임워크, CUDA 개발까지 여러 가지 해본 것도 많았다.\n회사 인원도 거진 20명에 가까워지고 있고,\n팀과 역할도 더욱 세분되어 동아리처럼 시작했던 것이 더욱 회사 같아졌다.\n내년에 목표가 있다면, 지금 정리 중인 모델을 마무리 짓고\n개인적으로 논문도 한 편 써 보고 싶다.\n한 해를 잘 정리한 거 같아 후회는 없다.\n내년에도 딱 이만큼만 했으면 좋겠다.\n","permalink":"https://revsic.github.io/blog/on2020dev/","tags":["Writing","2020","Researcher","TTS"],"title":"On 2020 as researcher"},{"categories":["Writing"],"contents":"첫 회고 사실 작년 이맘때부터 회고를 써야겠다 고민을 했는데,\n미루고 미루다 결국 올해 끝이 되어서야 회고를 쓰게 되었다.\n어떤 이야기를 써야 할까 고민을 하다가\n올해를 정리하는 의미에서\n큰 부담 없이 2020년에 한 일을 돌아보려 한다.\n첫 글에는 대학교 3학년으로의 2020년,\n두 번째 글은 2년 차 딥러닝 리서처로의 2020년에 관해 쓸 것이다.\n[대학교 3학년의 2020] 현재 글\n[딥러닝 리서처의 2020] On 2020 as researcher\n 신종코로나 COVID-19 2020년 하면 당연히 코로나를 빼놓을 수 없는 거 같다.\n19년 12월 말, 중국 우한에서 원인 불명의 바이러스성 집단 폐렴이 발생했다.\n이후 이는 신종코로나 바이러스, COVID-19라고 명명되었고 전 세계를 팬데믹에 몰아넣는다.\n당장 백신은 없고, 사망하는 사람은 생기고, 전염성마저 강하니\n거리 두기와 마스크는 생활화되어 갔다.\n문제는 당장 내일 출근할 때 쓸 마스크를 구하기 어려울 정도로\n마스크의 공급이 수요를 따르지 못했고, 사재기도 있었을 테지만,\n직장 동료분이 막 급하게 \u0026ldquo;지금 ! 쿠팡 열렸어요 !\u0026rdquo; 하면 대기하다 알트탭 쳐서 마스크 사는 일도 있었다.\n마스크를 구하는 것만이 문제는 아니었다.\n평소 황사 철 아니면 쓰지도 않던 마스크를 근무 내내 끼고 있으니\n피부가 버티질 못해 트러블이 생기고,\n마스크 쓰고 출퇴근을 하면 숨이 가빠 평소보다 더 힘든 기분이었다.\n  (그래도 마스크 열심히 쓰고 다녔음)\n  사회적 거리 두기는 그래도 할만했다.\n어차피 책상에서 멀리 가는 성격도 아니고,\n원래도 집에서 잘 안 나갔는데 합법적으로 집에 있는 기분이었다.\n이런 생활이 1년간 이어지다 보니,\n이젠 지각할 거 같으면 마스크 쓰고도 역에서 회사까지 뛰어가고 그런다.\n오히려 밖에서 담배를 피우거나 이런 사람도 많이 줄어든 거 같고,\n중국발 황사도 줄어 봄철 피부염도 거의 없었다.\n자택 근무도 너무 적응해버린 거 아닌가 싶을 때가 있다.\n이제 백신도 나왔고, 슬슬 줄어들 때가 된 거 같아 다행이다.\n빨리 줄어들어서 맘 놓고 놀러 다니고 싶다.\n 3학년 학교 생활 올해 한 가장 큰 실수는 역시 학교랑 회사랑 같이 다닌 거 같다.\n코로나라 자택 근무까지 하니까, 퇴근 시간 아끼는 만큼이라도 공부할 거 같았는데,\n막상 시험 기간 아니면 잘 안 하게 되더라.\n뭔가 한 가지에 집중한 것도 아니고, 이것저것 얕게 보는 느낌이었다.\n그래도 시험 기간이나, 회사 스퍼트 기간에는 한쪽에 집중하려 노력한 거 같다.\n시험 기간에는 9시-6시 칼퇴근하고 남는 시간에 시험공부 하고,\n스퍼트 때는 자기 전에 실험 결과 확인하고 추가 실험 기획해 놓기도 했다.\n뭔가 나이 대비 빠르게 경력이나 졸업을 당기는 데는 도움이 될 수 있어도,\n내가 어떤 것에 숙련할 수 있는가를 보면 썩 좋은 선택은 아닌 거 같다.\n  (500페이지 정도 분량 써가면서 공부함 그래도 ㅠ)\n  컴공 3대장 - 컴퓨터구조론, 운영체제, 컴파일러\n개인적으로 컴공 3대장이 있다면 컴구, 운체, 컴파일러 3개이지 않을까 싶다.\n이 중 운영체제와 컴파일러 과목을 각각 3-1, 3-2에 듣게 되었다.\n2학년 2학기에 C로 DB를 만드는 수업이 있었고,\n이때 워낙 고생을 많이 했던 터라\n같은 교수님이 운영체제를 맡으셨을 때는 고민을 좀 했던 것 같다.\n교수님은 정말 좋은 분이셨기에,\n적당히 수업 들으면서 과목별 투자 시간에 대한 가성비 싸움을 할지,\n아님 운체에 올인을 하고 다른 과목의 시간을 나눌지,\n아니면 다른 교수님 강의를 들을지 고민했다.\n결국 수업을 포기할 수는 없었기에 전자를 골랐고,\n그거랑 별개로 그냥 기한이 있는 줄 몰랐던 과제 OT 7개를 놓쳐서 성적은 반 토막 났다..ㅎ\n과제는 xv6에 MLFQ 기반의 CPU Scheduler, Thread 기능 추가, Filesystem 최대 크기 확장 등이 있었다.\n이 중 MLFQ, Thread 정도를 선택과 집중했고, 성적과 별개로 만족스러운 수업이었다.\n컴파일러 역시 정말 좋은 교수님이 수업을 여셨고,\n운체와 달리 과제가 많은 교수님은 아니셨기에,\n과제 공지가 올라오면 하루 날 잡고 완성했던 것 같다.\n실제로 loucomp tiny C를 시작으로 컴파일러를 재구성하는 수업이었고,\n언어 스펙에 따라 파싱을 위한 state machine을 구성하고, 타입을 체크하는 루틴을 추가하였다.\n[OS]: github HYU-ELE3021\n[Compiler]: github HYU-ELE4029\n수학과 부전\n드디어 꿈꿔오던 수학과 수업을 정식으로 듣게 되었다.\n고등학교 때부터 수틀리면 컴퓨터 전공 때려치우고 수학과 가겠다고 담임 선생님한테 투정을 부렸었는데,\n결국 돌고 돌아 컴퓨터 전공에 부전공을 수학으로 잡게 되었다.\n문제는 학교 정책상 부전공으로 이수해야 하는 과목 수가 정해져 있는데,\n수학과는 학년당 3과목 정도가 책 한 권을 1년 동안 배우다 보니 (선대1, 선대2 등)\n졸업을 위해서 무조건 들어야 하는 과목들이 몇 개 있다.\n그중 하나가 선형대수였는데,\n나는 심지어 공대에서도 선형대수를 들어 총 3학기의 선형대수를 듣게 되었다.\n(1학년 2학기, 3학년 1,2학기)\n물론 조금 다르긴 하지만,\n수강한 교수님 특성상 응용 파트가 많다 보니 실상은 크게 다르지 않았다.\n오히려 대수를 많이 못 다뤄 아쉬웠다.\n그리고 또 하나는 해석학이었다.\n일전에 해석학 공부하겠다고 혼자 책을 사 와서 폈는데,\n첫 장부터 문제를 못 풀어 접었던 기억이 있다.\n실은 이것 때문에 더욱 수학과 부전에 대한 기대가 있었지만,\n교수님이 증명 팁을 알려주시는 그런 건 없었고\n그냥 연습 문제 풀다 보니 되더라 ! 가 정답인 거 같다.\n주변의 권유로 4학년 과목인 확률론도 들었다.\n선이수 과목인 실해석학을 안 듣고 온 사람이 나 말고도 더 있어서,\n수업 초반부는 그 설명으로 시간을 좀 쓴 것 같다.\n아무래도 딥러닝, 머신러닝 하면서 확률을 다루는 사람이다 보니,\n그 기저에는 어떤 정의와 연역으로 구성되었을지에 대한 기대가 좀 있었다.\n나는 딥러닝에서도 음성 응용을 다루다 보니, 직접적으로 도움이 되었다 ! 보다는,\n학술적으로 이러한 의미와 가치가 있었구나에 대해 새로 알게 된게 컸다.\n그렇게 해서 3학년에 선형대수, 해석학, 확률론 3개 과목을 들었고,\n2학기 해석학 확률론 성적이 1학기에 비해 반토막 난 걸 보니 눈물이 찔끔 났다.\n나름 올인했었는데..\n그래서 난 대수가 더 좋다.\n 여행 올해 코로나로 여행도 잘 못 다녔다.\n그러다 보니 무슨 일이 있지 않고서야 멀리 갈 엄두도 못 냈던 거 같다.\n부산 친구 군대 보내기\n3학년쯤 되니 친구들이 다 군대에 갔다.\n남아 있는 친구들이 손에 꼽을 정도이다.\n나는 이유는 모르겠지만 경남 출신 친구들이 많았고,\n군대 간다고 휴학한 친구 만나러 부산에 당일치기로 놀러 갔었다.\n부산에 도착했을 때는 정말 충격이었던 게\n4월 당시 부산 확진자 수는 굉장히 적었고,\n마스크를 쓰는 사람도 거의 없었다.\n마스크를 쓰고 있으면 여행객인가 ? 싶을 정도였다.\n가서 텐동도 먹고, 장어덮밥도 먹고, 바닷가도 걸으며 이런저런 얘기를 했었다.\n  (텐동 맛있엉)\n  호캉스 - 시그니엘 서울\n여름이 되었고, 연차는 썼고, 뭐라도 하고 싶다는 생각이 강하게 들었다.\n코로나라 돌아다니거나 멀리 가는 건 힘들 거 같아서,\n간단히 호캉스나 1박 2일 다녀와야겠단 생각이 들었다.\n이곳저곳 알아보다가 자본주의를 좀 느껴보잔 생각에\n롯데 시그니엘을 가기로 마음먹었다.\n100층 가볼 일이 얼마나 있겠어~ 라는 생각으로 객실을 예약했다.\n  (사진이 몇장 없음 ㅠ)\n  호텔에 도착해서 100층까지 가는 엘리베이터를 처음 타봤다.\n중간에 멈추는 구간은 몇 개 없었고,\n부우우웅 하고 올라가더니 귀가 먹먹했다.\n도착해서는 라운지에서 샴페인도 마시며 즐거운 시간을 보내고 왔다.\n중간에 수영장도 갔는데, 초등학생 이후 수영을 해본 적이 없었기에\n이게 되려나 ? 싶다가도\n몸은 기억한다고 그새 또 막 돌아다니고 있는 게 신기했다.\n저녁은 룸서비스를 시켜 먹었고, 조식은 뷔페를 가서 먹었다.\n  (진짜 후회 안할만큼 맛있었음)\n  함께 사 온 와인이랑 룸서비스로 시킨 스테이크, 파스타 모두 잘 어울렸다.\n조식 뷔페는 샐러드, 빵, 육류 3가지 정도로 구성된 파트가 있었고,\n뭐 하나 빠짐없이 깔끔했다.\n잘 먹고, 잘 놀다 집에 돌아오니\n이래서 호캉스, 호캉스 하는구나 싶었다.\n 운전면허 드디어 운전면허를 땄다.\n작년 말부터 딸거다 딸거다, 말만 하다가,\n이번 11월에 드디어 운전 연습 학원을 등록했다.\n10시간 강습, 거의 80만원 가까운 등록금에, 시험은 때마다 5만원씩 내야 하니\n한 번에 합격해도 거진 100만 원 가까이 쓰게 된다.\n정말 한 번에 붙어야겠다는 일념으로 연습 열심히 했다.\n기능 때는 노란선 한 번 밟고 컷트라인에 걸쳐서 한 번에 붙고,\n주행 때는 합격 했는데 점수를 안 알려줘서 뭘 실수했을지는 잘 모르겠다.\n면허가 발급되고,\n가족이랑 같이 연습 삼아 운전을 좀 하고 돌아다녔는데,\n확실히 10시간 교육받고 면허까지 따니 큰 문제 없이 잘 돌아 다녔다.\n 정리 회사랑 학교랑 같이 다니다 보니,\n일하다 공부하다 1년이 지나갔다.\n코로나 때문에 금방 간 건가 싶기도 하다.\n그래도 사람 종종 만나고,\n확진자 적을 때는 여행 아닌 여행도 다녀와서\n만족스럽게 한 해를 보낸 거 같다.\n내년부터는 아마 휴학계를 내고,\n회사 일에 전념할 것 같다.\n당분간은 얕고 넓게 보다는,\n회사에서는 음성 딥러닝 쪽을, 개인적으로는 관심 있던 논문 리뷰, 구현하며\n한 토픽에 대해 깊이 있는 공부를 해볼 예정이다.\n그 외의 부분에 대해서는 딱 올해만큼만 살았으면 좋겠다.\n다음 글\n[딥러닝 리서처의 2020] On 2020 as researcher\n","permalink":"https://revsic.github.io/blog/on2020stud/","tags":["Writing","2020","Student","Undergraduate"],"title":"On 2020 as student"},{"categories":["Vocoder"],"contents":" Diffusion: Ho et al., 2020, arXiv:2006.11239 WaveGrad: Nanxin Chen et al., 2020, arXiv:2009.00713 DiffWave: Zhifeng Kong et al., 2020, arXiv:2009.09761 Keyword: Denoising, Diffusion, Vocoder Problem: Quality and generation speed trade off on mel-inversion procedure. Solution: Denoising and diffusion based raw audio sampling. Benefits: Explicit trade off between speed and quality in single framework. Contribution: First use of denoising \u0026amp; diffusion model on vocoder, high fidelity audio generation, explicit trade off, etc. Weakness or Future work: -  Mel-inversion\nNeural Text-to-Speech (TTS) 분야는 WaveNet(Oord et al., 2016), Char2Wav(Sotelo et al., 2017), Tacotron(Wang et al., 2017)을 거쳐 발전해 왔다. 그 중 Tacotron의 경우 text에서 mel-spectrogram을 예측하여 vocoder를 통해 raw-audio signal로 mel-inversion 하는 방식을 취한다.\n현재는 많은 mel-inversion 모델들이 개발되었고, autoregressive 구조로 raw-audio와의 likelihood를 maximizing 하는 WaveNet(Oord et al., 2016), WaveRNN(Kalchbrenner et al., 2018), ExcitNet(Song et al., 2019a), LPCNet(Valin \u0026amp; Skoglund, 2019) 등의 모델이 있다.\n하지만 이 경우 high sample rate를 가진 음성을 생성할 때 방대한 양의 frame 수에 비례하는 샘플링 시간을 가진다는 점에서 autoregressive의 근본적인 한계를 가지고 있었다.\n이를 해결하고자 non-autoregressive vocoder의 연구가 활발해졌고, IAF를 기반으로 한 PWN(Oord et al., 2018), Glow를 기반으로 한 WaveGlow(Prenger et al., 2019), FloWaveNet(Kim et al., 2019), GAN을 기반으로 한 WaveGAN(Donahue et al., 2018), MelGAN(Kumar et al., 2019), PWG(Yamamoto et al., 2020), HooliGAN(McCarthy \u0026amp; Ahmed, 2020) 등이 발표되었다.\nWaveGrad는 non-autoregressive vocoder 연구의 연속으로 raw signal의 log-density에서 gradient를 estimation 하는 방식으로 작동한다. 이를 통해 모델은 refinement step의 수를 조절함으로써 inference speed와 sample quality 사이의 trade off를 직접적으로 조절할 수 있게 되었고, autoregressive와 non-autoregressive 사이의 격차를 잇는 역할을 한다.\nDenoising Diffusion Proabilistic Models, Jonathan Ho et al., 2020\nWaveGrad와 DiffWave의 모델링은 기본적으로 Denoising Diffusion Model(Ho et al., 2020)을 따른다.\n  Figure 2: The directed graphical model considered in this work. (Ho et al., 2020)\n  Diffusion 모델은 finite step의 markov chain을 가정하여, 매 transition마다 sample에 noise를 더해간다. 이후 denoising을 위한 NN 모델을 두고 Diffusion의 reverse process를 학습하여 gaussian noise로부터 sample을 순차적으로 denoising하는 방식이다. 학습은 analytic 하게 구한 diffusion의 posterior와 denoising process 사이의 KL-divergence를 줄이는 방식으로 작동한다.\nFormulation\nDenoising model은 gaussian $p(\\mathrm x_T) = \\mathcal N(\\mathrm x_T; 0, I)$을 시작으로, 동일한 dimension을 가지는 latent $\\mathrm x_{T-1}, \u0026hellip;, \\mathrm x_{1}$을 거쳐 sample $\\mathrm x_0 \\sim q(\\mathrm x_0)$로 향하는 latent variable model로 표현한다.\n$$p_\\theta(\\mathrm x_0) := \\int p_\\theta(\\mathrm x_{0:T})d\\mathrm x_{1:T}$$\n여기서 $p_\\theta(\\mathrm x_{0:T})$를 reverse process라 정의하고, markov chain으로 모델링하면 다음과 같다.\n$$p_\\theta(\\mathrm x_{0:T}) := p(\\mathrm x_T)\\prod^T_{t=1}p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)$$\n$$p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t) := \\mathcal N(\\mathrm x_{t-1}; \\mu_\\theta(\\mathrm x_t; t), \\Sigma_\\theta(\\mathrm x_t; t))$$\ndenoising, diffusion 모델이 다른 latent variable model과 다른 점은, diffusion process를 analytic 하게 정의하여 posterior를 직접 approximate 한다는 것이다. End-to-End로 full transition을 학습하는 것이 아닌, state에 직접적인 constraint를 가한다.\nHo et al., 2020. 에서는 diffusion process를 모델에 noise를 더하는 markov chain으로 정의하고, 더해질 noise의 variance를 scheduler sequence $\\beta_1, \u0026hellip;, \\beta_T$로 두어 다음과 같이 정의한다.\n$$q(\\mathrm x_{1:T}|\\mathrm x_0) := \\prod^T_{t=1}q(\\mathrm x_t|\\mathrm x_{t-1})$$\n$$q(\\mathrm x_t | \\mathrm x_{t-1}) := \\mathcal N(\\mathrm x_t; \\sqrt{1 - \\beta_t}\\mathrm x_{t-1}, \\beta_t \\mathrm I)$$\n이는 autoregressive하게 정의하는 대신, $\\mathrm x_0$에 직접 condition 하는 방식으로 표현할 수 있다.\n$$q(\\mathrm x_t|\\mathrm x_0) = \\mathcal N(\\mathrm x_t; \\sqrt{\\bar \\alpha_t}\\mathrm x_0, (1 - \\bar \\alpha_t)\\mathrm I) \\\\\n\\mathrm{where}\\ \\alpha_t = 1 - \\beta_t, \\ \\bar\\alpha_t = \\prod^t_{s=1}\\alpha_t$$\n이렇게 되면 nll에 대한 variational lower bound는 state 사이의 KL-divergence로 rewriting할 수 있다.\n\r$\\mathbb E[-\\log p_\\theta(\\mathrm x_0)] \\\\ \\le \\mathbb E_q\\left[-\\log \\frac{p_\\theta(\\mathrm x_{0:T})}{q(\\mathrm x_{1:T}|\\mathrm x_0)}\\right] \\\\= \\mathbb E_q\\left[ -\\log p(\\mathrm x_T) - \\sum_{t\\ge 1} \\log\\frac{p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)}{q(\\mathrm x_t|\\mathrm x_{t-1})} \\right] \\\\= \\mathbb E_q\\left[ -\\log p(\\mathrm x_T) - \\sum_{t\\ge 1} \\log\\frac{p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)}{q(\\mathrm x_{t-1}|x_t)} \\cdot \\frac{q(\\mathrm x_{t-1})}{q(\\mathrm x_t)} \\right] \\\\=\\mathbb E_q\\left[ -\\log\\frac{p(\\mathrm x_T)}{q(\\mathrm x_T)} - \\sum_{t\\ge 1} \\log \\frac{p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)}{q(\\mathrm x_{t-1}|\\mathrm x_t)} - \\log q(\\mathrm x_0) \\right] \\\\=D_{\\mathrm{KL}}(q(\\mathrm x_T)||p(\\mathrm x_T)) + \\mathbb \\sum_{t\\ge 1} D_\\mathrm{KL}(q(\\mathrm x_{t-1}|\\mathrm x_t)||p_\\theta(\\mathrm x_{t-1}|\\mathrm x_t)) + H(\\mathrm x_0)$  이 때 $q(\\mathrm x_{t-1}|\\mathrm x_t, \\mathrm x_0)$의 analytic form은 다음과 같다.\n$$q(\\mathrm x_{t-1}|\\mathrm x_t, \\mathrm x_0) = \\frac{q(\\mathrm x_t|\\mathrm x_{t-1})q(\\mathrm x_{t-1}|\\mathrm x_0)}{q(\\mathrm x_t|\\mathrm x_0)} = \\mathcal N(\\mathrm x_{t-1}; \\tilde \\mu_t(\\mathrm x_t, \\mathrm x_0), \\tilde \\beta_t \\mathrm I) \\\\ \\mathrm{where} \\ \\tilde\\mu_t(\\mathrm x_t, \\mathrm x_0) := \\frac{\\sqrt{\\bar a_{t-1}}\\beta_t}{1 - \\bar a_t}\\mathrm x_0 + \\frac{\\sqrt{\\alpha_t}(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}\\mathrm x_t \\ \\ \\mathrm{and} \\ \\ \\tilde\\beta_t := \\frac{1 - \\bar\\alpha_{t-1}}{1 - \\bar\\alpha_t}\\beta_t$$\nReparametrization\n각각의 Dkl term을 순서대로 $L_T, L_{1:T-1}, L_0$로 정의하면, $L_T$는 beta를 learnable 하지 않은 constant로 가정할 때 상수로 고정되기 때문에 연산에서 제외한다.\n$L_{1:T-1}$은 $\\Sigma_\\theta(\\mathrm x_t, t) = \\sigma^2_t\\mathrm I$의 경우 untrained constants로 제외하고, $\\mu_t$에 대해서만 학습을 진행한다. $\\sigma_t$는 $\\sigma_t^2 = \\beta_t$나 $\\sigma^2_t = \\tilde\\beta_t = \\frac{1 - \\bar\\alpha_{t-1}}{1 - \\bar\\alpha_t}\\beta_t$로 실험적으로 설정하였다. 이는 data에 대한 reverse process entropy의 upper, lower bound라고 한다.\n$\\mu_\\theta(x_t, t)$는 KL에서 trainable term을 구축한다.\n$$L_{t-1} = \\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t}||\\tilde\\mu_t(\\mathrm x_t, \\mathrm x_0) - \\mu_\\theta(\\mathrm x_t, t)||^2 \\right] + C$$\n이를 previous term을 통해 다시 써보면 다음과 같다.\n\r$L_{t-1} - C \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1 - \\bar\\alpha_t}\\mathrm x_0 + \\frac{\\sqrt{\\alpha_t}(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}\\mathrm x_t - \\mu_\\theta(\\mathrm x_t, t) \\right|\\right|^2 \\right] \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1 - \\bar\\alpha_t}\\frac{1}{\\sqrt{\\bar\\alpha_t}}(x_t - \\sqrt{1 - \\bar\\alpha_t}\\epsilon) + \\frac{\\sqrt\\alpha_t(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}x_t - \\mu_\\theta(x_t, t) \\right|\\right|^2 \\right] \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{1}{\\sqrt{\\alpha_t}}\\left( \\frac{\\beta_t + \\alpha_t(1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t}x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}}\\epsilon \\right) - \\mu_\\theta(x_t, t) \\right|\\right|^2 \\right] \\\\=\\mathbb E_q\\left[ \\frac{1}{2\\sigma^2_t} \\left|\\left| \\frac{1}{\\sqrt{\\alpha_t}}\\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}}\\epsilon \\right) - \\mu_\\theta(x_t, t)\\right|\\right|^2 \\right] \\\\\\mathrm{where} \\ \\ \\mathrm x_t = \\sqrt{\\bar\\alpha_t}\\mathrm x_0 + \\sqrt{1 - \\bar\\alpha_t}\\epsilon$  위 정리에서 $\\mu_\\theta$는 $\\epsilon_\\theta$를 통해 reparametrizing 할 수 있다.\n$$\\mu_\\theta(\\mathrm x_t, t) = \\frac{1}{\\sqrt\\alpha_t}\\left( \\mathrm x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}}\\epsilon_\\theta(\\mathrm x_t, t) \\right) \\\\\\mathbb E_{\\mathrm x_0, \\epsilon}\\left[ \\frac{\\beta^2_t}{2\\sigma^2_t\\alpha_t(1 - \\bar\\alpha_t)}||\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}\\mathrm x_0 + \\sqrt{1 - \\bar\\alpha_t}\\epsilon, t)||^2 \\right]$$\n최종 objective는 scale term을 생략한 weighted variational bound로 나타낸다.\n$$L_\\mathrm{simple}(\\theta) := \\mathbb E_{t, \\mathrm x_0, \\epsilon}\\left[ || \\epsilon - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}\\mathrm x_0 + \\sqrt{1 - \\bar\\alpha_t}\\epsilon, t)||^2\\right]$$\n원문에서는 실제로 이렇게 formulation 된 objective가 성능이 더 좋았음을 실험으로 보였다.\n  Table 2: Unconditional CIFAR10 reverse process parameterization and training objective ablation. (Ho et al., 2020)\n  정리하면 $L_\\mathrm{simple}$은 두 process 사이의 Kl-divergence를 재구성한 것이고, 이는 single NN을 통해 현재 input에 존재하는 noise를 noise-level에 따라 직접 예측하여 denoising하는 방식으로 다음 state로의 transition을 진행한다.\n  Algorithms from Ho et al., 2020.\n  따라서 state의 수가 늘어나면 더 정교하고, 더 많은 noise를 제거하여 sample quality를 높일 수 있지만 sampling 시간이 길어지고, state 수가 줄어들면 sample에 noise가 낄 수 있지만 이른 시간 안에 결과를 얻을 수 있다.\nWaveGrad: Estimating Gradients for WaveForm Generation, Nanxin Chen et al., 2020.\nWaveGrad는 위 formulation을 통해서 mel-spectrogram에 condition 한 raw signal을 생성하는 방법론을 제시한다.\n  Figure 3, 4: WaveGrad network architecture, upsampling block.\n  Downsampling block(DBlock)에서 noised signal의 feature를 추출하고, Upsampling block(UBlock)에 feature과 mel-spectrogram을 입력으로 주어 noise를 예측한다.\n원문에서는 24kHz의 raw audio에서 80Hz의 mel을 연산하여, mel-frame 하나당 300개의 audio frame으로 확장하는데, 이는 5개의 UBlock에서 각각 [5, 5, 3, 2, 2] factor에 맞게 upsampling하는 방식으로 구성하고, DBlock에서는 반대로 noised signal을 [2, 2, 3, 5]로 downsampling하여 각각의 intermediate representation의 resolution을 matching 할 수 있도록 두었다.\n  Figure 5, 6: Block diagrams of the downsampling, feature-wise linear modulation (FiLM) blocks.\n  각각의 convolution은 receptive field를 넓히기 위해서 dilation factor를 가지고, UBlock의 4개 conv는 [1, 2, 1, 2]와 [1, 2, 4, 8], DBlock의 3개 conv는 [1, 2, 4]로 구성된다.\nupsample과 downsample 과정에 정보전달을 위해 wavegrad에서는 Feature-wise linear modulation (FiLM)모델을 통해 noise-level과 positional encoding, DBlock의 feature를 affine parameter로 바꿔 UBlock에서 feature-wise affine transform을 진행한다.\n이외에 batch normalization의 경우 batch에 여러 개의 noise-level을 가진 sample 들이 존재하기 때문에 batch statistics가 정확하지 않아 sample quality에 악영향을 미쳤다고 한다.\nNoise Scheduling\n  objective를 구성하기 위해서는 noise level $\\sqrt{\\bar\\alpha_t}$에 대한 설정이 필요하다. learnable한 parameter로 둘 것이 아니므로 noise distribution에 직접 영향을 줄 수 있어 sample quality와 긴밀한 연관성을 가진다. WaveGrad에서는 noise level에 대한 설정이 음질과 직접적인 연관이 있었음을 실험으로 보였다.\n  Figure 7: A plot of different noise schedules\n  원문에서는 iteration의 수에 따라 noise level scheduling method를 따로 두었는데, 1000회의 경우 $\\beta_t$를 1e-4에서 0.005를 linear 하게 1000개, 50의 경우 1e-4에서 0.05를 linear 하게 50개 sample 하였다. 25회의 경우에는 $\\beta_0 = 1\\times 10^{-6}, \\ \\beta_1 = 2\\times 10^{-6}$을 시작으로 하는 fibonacci sequence를 구축하였고, 6회의 경우에는 manual 하게 [1e-6, 1e-5, .., 1e-1]로 exponential scale에서 linear 하게 구현하였다.\n이후 이를 통해 partition $l_0 = 1, \\ l_s = \\sqrt{\\prod^s_{i=1}(1 - \\beta_s)}$을 설정하고, $(l_{s-1}, l_s)$에서 uniform 하게 $\\sqrt{\\bar\\alpha}$를 sampling 하여 사용한다. 이렇게 되면 discrete index가 아닌 continuous segment에서 noise level을 sampling 할 수 있고, 6iter과 같이 sparse 한 scheduling 수준에서 괜찮은 성능을 보였다고 한다.\nExperiments, Discussion\n  Table 1: Mean opinion scores (MOS) of various models and their confidence intervals.\n  원문에서는 이 외에도 iteration 수를 줄이기 위해 여러 가지 noise schedule을 시도했으며, 잘 작동하는 schedule은 $D_\\mathrm{KL}(q(y_N|y_0)||\\mathcal N(0, I))$을 작게 두어 train-inference의 격차가 거의 없게 두었고, $\\beta$를 작은 값으로 시작하여 fine granuality details에 따라 background noise를 줄여야 했다고 한다.\nDiffWave: A Versatile Diffusion Model for Audio Synthesis, Zhifeng Kong et al., 2020\n(2020.09.24. update)\nDiffWave는 WaveGrad와 같은 시기에 나온 또 다른 Diffusion denoising 기반의 mel-inversion vocoder이다.\n  Figure 2: The network architecture of DiffWave\n  DiffWave는 기본적으로 WaveNet 아키텍쳐를 차용한다. kernel-size=3과 dilation-factor=2의 기본적인 noncausal dilated convolution을 기반으로 [1, 2, \u0026hellip;, 512]의 10개 레이어를 3개 cycle로 구성한다.\nNoise schedule에 대한 embedding을 $\\sqrt{\\bar\\alpha}$에 직접 condition 하던 WaveGrad와 달리 DiffWave에서는 timestep을 기반으로 한 modified positional encoding에 FC-swish layer를 덧붙여 활용한다.\n$$t_\\mathrm{embedding} = \\left[ \\sin(10^{\\frac{0\\times 4}{63}}t), \\cdot\\cdot\\cdot, \\sin(10^{\\frac{63\\times 4}{63}}t), \\cos(10^{\\frac{0\\times 4}{63}}t), \\cdot\\cdot\\cdot, \\cos(10^{\\frac{63\\times 4}{63}}t) \\right]$$\nmel-spectrogram은 channel이 1개인 2D tensor로 가정하여 2D transposed convolution에 의해 22kHz의 signal resolution으로 upsample 되고, WaveNet block에서 dilated convolution 이후에 bias term으로 더해진다.\nnoise scheduling의 경우 [20, 40, 50] iteration에서 $\\beta_t$를 [1e-4, 0.02]를 linear sampling, 200 iteration의 경우 [1e-4, 0.05]를 linear sampling 하였다고 한다.\nDiffWave는 특이하게도 Vocoder purpose 외에 unconditional generation을 시도하였다. 이 경우 보통의 wavenet이라면 single model이 음성의 길이를 모두 커버할 수 있는 receptive field를 구축해야 하지만, DiffWave의 경우 denoising 과정에 발생하는 iteration으로 이에 비례하는 추가 receptive field를 쉽게 얻을 수 있었다.\nExperiments, Discussion\n  Table 1: The model hyperparameters, model foot print, and 5-scale MOS with 95% confidence intervals\n  Vocoder task의 경우 DiffWave는 다른 Flow-based SOTA 모델보다는 조금 느리지만, sample quality는 더 좋았다고 한다. 이는 Flow-based Model이 가지는 architectural constraint에 의한 것으로 추측하였고, inference 속도는 추가 engineering에 의해 일정 부분 빨라질 수 있을 것으로 보인다.\n  Table 2: The automatic evaluation metrics and 5-scale MOS with 95% confidence intervals.\n  Unconditional generation task의 경우에는 Speech Commands Dataset 에서 spoken digits (0~9) 부분만을 발췌하여 사용했다고 한다. 길이는 16kHz의 1초 미만으로 활용하여 여러 가지 evaluation metric을 측정하였다.\nImplementation\n official, Jonathan Ho, tf: diffusion official sample: wavegrad.github.io unofficial, Ivan Vovk, pytorch: WaveGrad official sample: diffwave-demo.github.io unofficial, revsic, tensorflow2: tf-diffwave  Reference\n WaveNet: A Generative Model for Raw Audio, Oord et al., 2016. Char2Wav: End-to-End Speech Synthesis, Sotelo et al., 2017. Tacotron: Towards End-to-End Speech Synthesis, Wang et al., 2017. WaveRNN: Efficient Neural Audio Synthesis, Kalchbrenner et al., 2018. ExcitNet Vocoder: A Neural Excitation Model for Parametric Speech Synthesis, Song et al., 2019a. LPCNet: Improving Neural Speech Synthesis through Linear Prediction, Valin \u0026amp; Skoglund, 2019. Parallel WaveNet: Fast High-Fidelity Speech Synthesis, Oord et al., 2018. WaveGlow: A Flow-based Generative Network for Speech Synthesis, Prenger et al., 2019. FloWaveNet: A generative flow for raw audio, Kim et al., 2019. WaveGAN: Adversarial Audio Synthesis, Donahue et al., 2018. MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis, Kumar et al., 2019. Parallel WaveGAN: A Fast Waveform Generation Model based on Generative Adversarial Networks, Yamamoto et al., 2020. HooliGAN: Robust, High Quality Neural Vocoding, McCarthy \u0026amp; Ahmed, 2020. Denoising Diffusion Proabilistic Models, Ho et al., 2020.  ","permalink":"https://revsic.github.io/blog/diffusion/","tags":["Machine Learning","Deep Learning","Generative","Vocoder","Mel Inversion","Denoising Diffusion"],"title":"Diffusion, WaveGrad and DiffWave"},{"categories":["Generative"],"contents":" David Bau et al., 2020, arXiv Keyword: Generative, Adversarial learning Problem: How to manipulate specific rules encoded by a deep generative model. Solution: Projected gradient descent for adding rules to convolution of associative memory. Benefits: Enable users to synthesize edited new images by manipulating model only once. Contribution: Providing a new perspective of associative memory, rule manipulating method of projected gradient descent. Weakness or Future work: -  Generative model\n생성 모델은 데이터의 분포를 학습하면서 여러 가지 규칙이나 관계를 만들어 나간다. 간단한 예로 ProgressiveGAN[1]이 만든 주방 이미지에서는 창문에서 오는 빛을 테이블에 반사시키는 경향이 있다.\n  Fig. 6: Inverting a single semantic rule within a model\n  저자는 만약 이러한 규칙들을 직접 분석하여 수정할 수 있다면, 생성 모델 자체를 manipulating 하는 것이고, 이는 생성된 이미지를 각각 수정하는 것보다 효율적으로 수정된 이미지를 생성할 수 있다고 이야기 한다.\n이를 위해서 우리는 생성 모델이 어떤 정보를 캡처하고 있고, 어떻게 unseen scenario에 대해 일반화 하고 있는지 알아야 한다.\n현재 생성 모델들은 인간이 직접 라벨링 한 대규모의 데이터셋에 기반을 두고 있는데, 만약 manipulating 과정에서도 이러한 다량의 데이터와 학습이 추가로 필요하다면, 이는 손으로 생성된 이미지를 직접 수정하는 것과 큰 차이가 없을 것이다.\n이에 우리는 단 몇 개의 샘플 데이터와 간단한 optimization을 통해 모델을 manipulation 할 수 있어야 하고, 이 모델은 우리가 원하는 rule을 캡처하여 unseen data에 대한 일반화를 할 수 있어야 한다.\n저자는 이를 위해 sequential 하게 구성된 nonlinear convolutional generator를 associative memory라는 관점으로 해석하고, 전체 레이어가 아닌 단 하나의 레이어에 constrained optimization을 진행하여 기존의 semantic rule을 보존하면서, 우리가 원하는 rule을 추가할 수 있는 방법론을 제시한다.\nPreview\npretrain된 generator $G(\\cdot; \\theta_0)$가 주어질 때, 모델은 각각의 latent $z_i$에 대해 $x_i = G(z_i; \\theta_0)$의 output을 만들어 낸다. 만약 우리가 copy\u0026amp;paste 방식으로 변화를 준 output $x_{*i}$을 통해 새로운 rule을 표현한다면, rule의 표현 중 가장 직관적인 방법일 것이다.\n  Fig. 3: The Copy-Paste-Context interface for rewriting a model.\n  이때 하고자 하는 것은 새로운 rule을 따르는 $\\theta_1$을 만드는 것이고, 이는 $x_{*i} \\approx G(z_i; \\theta_1)$을 만족할 것이다.\n$\\theta_1 = \\arg\\min_\\theta \\mathcal L_{\\mathrm{smooth}}(\\theta) + \\lambda \\mathcal L_\\mathrm{constraint}(\\theta)$\n$\\mathcal L_\\mathrm{smooth}(\\theta) \\overset{\\Delta}{=} \\mathbb E_z[\\mathcal l(G(z; \\theta_0), G(z; \\theta))]$\n$\\mathcal L_\\mathrm{constraint}(\\theta) \\overset{\\Delta}{=} \\sum_i \\mathcal l(x_{*i}, G(z_i; \\theta))$\n고전적인 해결책은 generator의 전체 parameter set $\\theta_0$를 두 가지 constraint에 맞게 gradient 기반의 optimization을 진행하는 것이다. 이때 $\\mathcal l(\\cdot)$은 perceptual distance를 의미한다.\n하지만 이 경우 몇 개 되지 않는 sample에 overfit될 가능성이 농후하며 다른 데이터에 대해 일반화되지 않을 수 있다.\n이에 저자는 두 가지 방법론을 제안한다. 하나는 전체 parameter set이 아닌 특정 한 layer의 weight만을 update하는 것이고, 하나는 optimization을 특정 constraint 내에서 진행하는 것이다.\n특정 layer L과 L-1 layer까지의 feature map k를 가정할 때 L의 output은 $v = f(k; W_0)$가 된다. 원본 이미지의 latent $z_{i}$가 feature $k_{*i}$를 만들 때 $v_i = f(k_{*i}; W_0)$를 가정하고, 직접 수정한 output에 대응하는 feature map $v_{*i}$를 구할 수 있으면 objective는 다음과 같다.\n$W_1 = \\arg\\min_W \\mathcal L_{\\mathrm{smooth}}(W) + \\lambda \\mathcal L_\\mathrm{constraint}(W)$\n$\\mathcal L_\\mathrm{smooth}(W) \\overset{\\Delta}{=} \\mathbb E_z[|| f(k; W_0) - f(k; W)||^2]$\n$\\mathcal L_\\mathrm{constraint}(W) \\overset{\\Delta}{=} \\sum_i ||v_{*i} - f(k_{*i}; W)||^2$\nperceptual distance는 higher semantic을 표현하는 feature map 사이의 l2-distance를 상정한다. 이때 W만으로도 parameter의 양이 충분히 많을 수 있기에, overfit을 제한하면서 더 나은 일반화를 위해 학습 방향을 고정할 필요가 있었고, 특정 direction으로만 optimization 되도록 constraint를 추가한 gradient descent를 사용하였다.\nAssociative Memory\n저자는 preview의 방법론을 associative memory로부터 유도해 낸다.\n어떤 key $k_i \\in \\mathbb R^N$와 value $v_i \\in \\mathbb R^M$의 mapping $\\{ k_i \\to v_i \\}_{i \\in I}$을 가정하자. 이때 $k_i$가 mutually orthonormal 하면 i와 j가 다를 때 $k_i^T k_j = 0$를 만족한다. matrix W를 $W = \\sum_i v_i k_i^T \\in \\mathbb R^{M \\times N}$ 로 정의하면 orthogonality에 의해 $Wk_i = v_i$가 성립한다. 이를 key-value association을 기록한 memory라 하여 associative memory라고 부르며, linear operation으로 구성되므로 linear associative memory라 할 수 있다.\n저자의 이야기는 Convolution 또한 associative memory의 일종으로 볼 수 있다는 것이다. 흔히 생각하는 convolution은 window에 대해 pixel-wise weighted sum을 한 결과를 나열하는 operation이다. 이는 output의 한 pixel을 관점으로 convolution을 해석한 것이다.\n반대로 input feature에 대해 해석하면 single feature $k \\in \\mathbb R^{B\\times N}$에 weight matrix $W \\in \\mathbb R^{N \\times (MHW)}$를 곱하고, BxMxHxW의 2D tensor로 reshape 하여 location-aware summation 한 것으로도 볼 수 있다.\n이렇게 되면 convolution은 kernel을 matrix로 보고 key가 orthogonal 할 때 linear associative memory로 해석될 수 있다.\nNonorthogonal Keys\nkey는 $\\mathbb R^N$의 vector이므로 최대 N개까지 orthogonal 할 수 있고, 더 많은 key-value pair를 기록하기 위해서는 $v_i \\approx Wk_i$를 approximately equal한 조건을 취하여 error를 minimizing 하는 방식으로 구성한다.\n$W_0 \\overset{\\Delta}{=} \\arg \\min_W \\sum_i ||v_i - Wk_i||^2$\n이때 $K \\overset\\Delta= [k_1|\u0026hellip;|k_S] \\in \\mathbb R^{N\\times S}$ 와 $V \\overset\\Delta= [v_1|\u0026hellip;|v_S] \\in \\mathbb R^{M\\times S}$ 로 가정하면 multiple nonorthogonal key, value pair에 대한 associative memory를 구성할 수 있다.\n$W_0 = \\arg\\min_W \\sum_i||V - WK||^2$\n그리고 이는 least square solution $W_0KK^T = VK^T$와 pseudo-inverse $K^+$에 대해 $W_0 = VK^+$로 표현된다.\nWhat we want\n즉 pretrain을 통해 구한 $W_0$는 trainset에서 연산한 L-1까지의 feature map과 그에 대한 response를 key-value로 가정한 associative memory가 된다.\n여기서 우리가 하고 싶은 것은 다음과 같다.\n user가 copy한 value와 paste한 지점의 key를 가져와 새로운 pair로 memory에 추가\n 이렇게 되면 L-1까지의 feature map에서 key가 관측되었을 때 memory에서 새로운 value가 mapping 되어 해당 부분에 copy한 context가 이미지에 발현된다. Model manipulation을 하는 주요한 근거가 되는 것이다.\n이를 표현하면 $W_1 = \\arg\\min_W ||V - WK||^2$와 $v_* = W_1k_*$를 만족 시키는 constrained least-square (CLS) problem으로 구성되고, 이의 해는 다음과 같이 정리된다.\n$W_1KK^T = VK^T + \\Lambda k_*^T$\n$W_1KK^T = W_0KK^T + \\Lambda k_*^T$\n$W_1 = W_0 + \\Lambda(C^{-1}k_*)^T$\n이 때 $C \\overset\\Delta= KK^T$로 구성하면 key가 zero-mean일 때 covariance로 해석될 수 있다. 결국 $\\Lambda \\in \\mathbb R^M$를 구하는 문제로 귀결된다. 여기서 $d \\overset\\Delta= C^{-1}k_*$로 가정하면 $W_1 = W_0 + \\Lambda d^T$로 볼 수 있고, 풀이는 다음과 같다.\n$\\left[ \\begin{array}{c|c} W_1 \u0026amp; \\Lambda \\end{array} \\right] \\left[ \\begin{array}{c|c} I \u0026amp; k_* \\\\ \\hline -d^T \u0026amp; 0 \\end{array} \\right] = \\left[ \\begin{array}{c|c} W_0 \u0026amp; v_* \\end{array}\\right]$\n$\\left[ \\begin{array}{c|c} W_1 \u0026amp; \\Lambda \\end{array} \\right] = \\left[ \\begin{array}{c|c} W_0 \u0026amp; v_* \\end{array} \\right] \\left[ \\begin{array}{c|c} I \u0026amp; k_* \\\\ \\hline -d^T \u0026amp; 0 \\end{array} \\right]^{-1}$\n여기서 주목할 점은 2가지이다.\n user requested mapping $k_* \\to v_*$의 soft error-minimization objective가 d라는 straight-line을 따라 update해야 하는 hard constraint로 바뀜 direction d가 key에 의해서만 결정되고 value는 오직 user requested $v_*$가 $\\Lambda$에 영향을 주는 방식 정도로만 작용함  결국 구현체에서는 covariance C 정도를 미리 연산하여 caching 해두고, request가 올 때 direction과 $\\Lambda$를 계산하는 방식으로 작동할 것이다.\npreview의 수식을 다시 들고오면, $W_1 = \\arg\\min_W ||V-WK||^2$는 smoothness를 위한 loss, $v_* = W_1k_*$는 constraint를 위한 loss로 볼 수 있다. 그리고 이 둘의 solution이 d라는 direction으로 update된 $W_1$로 나온 것이다.\nGeneralization\n위까지의 정리는 copy\u0026amp;paste로 수정된 이미지에 대한 해당 layer와 그 전 layer의 response를 얻어와 key-value mapping을 구성할 수 있어야 한다. 하지만 SOTA를 이루고 있는 generative model들은 주로 gaussian noise에서 image로의 mapping을 확률적으로 학습하고 있기에, 수정된 이미지의 latent를 z-optimization을 통해 얻을 수 있어야 하고, 이 또한 rule이 크게 바뀐 경우에는 정확하지 않을 수 있다.\n원문에서는 이 부분을 위해 feature independency를 보였는데, 일례로 stylegan과 progressive gan은 특정 레이어의 response를 patch로 나눠 주변 정보 없이 각각을 inference 했을 때도 원본과 유사한 object가 복원되었다는 것이다. 이는 feature map을 low resolution의 image로 보고 각 key가 해당 위치에 존재하는 object를 encoding 하고 있기에 가능하다는 가설을 세울 수 있다.\n  Fig. 17: Comparison of rendered cropped activations at various layers of Progres- sive GAN generated LSUN church images.\n  이렇게 되면 z-known image에서 복사하고자 하는 patch의 위치를 특정할 수 있을 때, low-resolution의 feature map에서 동일한 위치의 value를 가져와 대상에 위치만 맞춰 붙여넣으면 되고, feature map 수준에서 보다 perceptual 한 distance를 측정할 수 있게 된다.\n만약 z와 convolutional response를 얻을 수 없어 image-level에서 distance를 측정해야 하거나, activation을 거친 response를 가정할 때에는 neural net의 nonlinearity에 의해 선형성 가정이 깨지게 된다. 이에 neural generator를 다루는 입장이라면 위 방법론이 nonlinear 환경에서 일반화될 수 있어야 한다.\n원문에서는 nonlinear mapping $f(k; W)$가 있을 떄 update policy가 W의 row-space에 sensitive하고, column-space에 insensitive 하므로 동일한 rank-1 update를 $f(k_*; W) \\approx v_*$의 optimization constraint로 쓸 수 있다고 한다.\nlinear phase에서는 $\\Lambda$를 linear system을 통해 풀었다면, nonlinear phase에서는 gradient 기반의 optimization이 필요하다. 이때 $\\Lambda$는 requested value와 direction에 의존하는 변수이기 때문에 이를 objective로 하는 optimization을 진행한다.\n$\\Lambda_1 = \\arg\\min_{\\Lambda \\in \\mathbb R^M}||v_* - f(k_*; W_0 + \\Lambda d^T)||$\n만약 requested key-value pair가 하나가 아닌 여럿이라면, rank-1 대신 low-rank optimization이 될 것이고, S개 pair에 대해 다음과 같이 표현할 수 있다.\n$d_i = C^{-1}K_{*i}$\n$D_S \\overset\\Delta= [d_1|\u0026hellip;|d_S]$\n$\\Lambda_S = \\arg\\min_{\\Lambda \\in \\mathrm R^{M \\times S}} || V_* - f(K_*; W_0 + \\Lambda D_S^T)||$\n그리고 update는 $W_S = W_0 + \\Lambda_S D_S^T$로 이뤄질 것이다.\n마지막으로 이 조건을 좀 더 relax하면 $\\arg\\min_W ||V_* - f(K_*; W)||$를 optimizing하고, 대신 매 step 마다 W를 $W_0 + \\Lambda_S D_S^T$의 subspace로 projection 하는 projected gradient descent를 취한다.\nDetail\noriginal repository rewriting에서는 L-1까지의 feature map을 BHWxC로 reshape하여 collect_2nd_moment에서 z-dataset을 기반으로 CxC의 covariance를 미리 구해 놓는다.\n이후 edit 요청이 들어오면 covariance_adjusted_query_key에서 direction을 구하는데, C의 pseudoinverse를 구하는 대신 $CD_S = K_S$의 least square solution (torch.lstsq)을 풀어 computational stability를 얻었다고 한다.\n이때 전체 이미지에서 desired key만을 가져오기 위해 multi_key_from_selection에서는 target layer의 resolution에 맞게 image-level의 mask를 bilinear interpolation한 후, key matrix에 직접 곱하여 non-zero key만을 선별한다. feature independency에 따라 가능하다.\n이후 $D_{S}$를 직접 이용하는 것이 아닌 low-rank subspace의 basis를 구해 활용하며, 원문에서는 SVD를 통해 eigen-value가 큰 eigen-vector를 선출하여 동일한 subspace를 구성하는 orthogonal basis로 활용했다.\n이후 insert에서 parameter optimization을 진행한다.\nweight은 subspace에 orthogonal 하게 변환하여 ortho_weight 변수에 저장해 둔다. 이는 projected_conv을 활용하는데, 흔히 gram-schmidt orthogonalization에서 하는 것과 같이 basis에 정사형한 벡터를 원본에서 빼는 방식으로 진행한다.\n$W_\\mathrm{ortho} = W - (WU_{1:R})U_{1:R}^T \\ \\mathrm{where} \\ C^{-1}K_S = U\\Sigma V^T, \\ \\mathrm{lowrank} \\ R$\n이후 feature-level distance를 L1으로 하는 optimization을 진행하고, 특정 스텝마다 weight을 subspace로 projection하여 ortho_weight에 더하는 방식으로 projected gradient descent를 구현한다.\n이렇게 되면 optimization의 여파는 subspace 내에서만 구성되고, subspace에 orthogonal한 weight을 더함으로써 기존의 weight은 유지하고 subspace 내에서의 update만을 취할 수 있게 된다.\nZCA를 활용한 rank reduction은 원문의 Appendix. D.를 참고한다.\nLayer selection\n원문에서는 convolution layer를 neighbor와의 정보 취합으로 edge, texture, shape 등을 구별해 내는 관점보다는, 하나의 feature vector가 local patch가 되면서 주변과 disentangle 되는 관점을 취하였고, 이것이 memory model로 해석되었다.\n원문에서는 실제로 ProgressiveGAN[1]과 StyleGANv2[2]의 일부 레이어에서 이런 feature 간 독립성을 띠고 있음을 보였다.\nfeature map을 MxN의 patch로 잘라 주변 정보 없이 적절한 크기의 output을 만들었을 때, 네트워크는 여전히 동일한 객체와 컨텍스트를 만들어 낼 수 있음을 보인다면, feature 간에 독립적인 정보를 담고 있음을 추론할 수 있다.\n레이어마다 patch를 잘라 output을 만들었을 때 Frechet Inception Distance (FID)가 작다면 해당 patch는 주변 정보로부터 less dependence 한 것이고, FID가 높다면 dependent 한 것임을 나타낼 것이다.\n  Fig. 13: FID of rendered cropped activations with respect to random crops of StyleGANv2 generated images\n  그래프에서 6~11번째 layer가 FID가 가장 낮았고, 이 layer에서 key 값은 주변과 independent 한 정보를 가지고 있을 확률이 높다. 즉, 어느 한 layer의 key를 수정해야 한다면, 해당 layer를 수정하는 것이 object를 render 하는데 좋은 quality의 이미지를 만들 수 있음을 나타낸다.\n  Fig. 14: Comparison of rendered cropped activations at various layers of Style- GANv2 generated LSUN church images.\n  Experiment\n이제 User는 copy\u0026amp;paste를 통해 image에 원하는 부분을 수정하고 (key-value), 몇몇 context image에 수정되었으면 하는 부분(key-context)을 표기하여 rewriter에게 전달한다.\nrewriter은 해당 key-context로부터 direction을 계산하고, pasted image와 original image 사이의 L1-loss를 기반으로 projected-optimization을 진행한다. 이에 따라 일반화된 model을 얻을 수 있고, editing을 마치게 된다.\n  Fig. 7: Giving horses a hat to wear.\n  Discussion\n저자는 GPT-3, WaveNet과 같이 image 이외의 분야에서도 vastly trained model에 rule을 수정하고자 하는 일이 있을 것이고, model rewriting은 이 경우에 새로운 contents, behavior, interaction을 부여할 충분한 방법론일 것이라 이야기한다.\nImplementation\n pytorch, official: David Bau, rewriting pytorch, unofficial: revsic, Rewriting-A-Deep-Generative-Models  References\n Progressive Growing of GANs for Improved Quality, Stability, and Variation, Tero Karras et al., 2017, arXiv:1710.10196. Analyzing and Improving the Image Quality of StyleGAN, Tero Karras et al., 2019. arXiv:1912.04958.  ","permalink":"https://revsic.github.io/blog/rewriting/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Model editing","Rewriting"],"title":"Rewriting a Deep Generative Model"},{"categories":["Generative"],"contents":" Stanislav Pidhorskyi et al., 2020, arXiv Keyword: Generative, Adversarial learning Problem: AE based approach has poor quality of output distribution. Solution: Adversarial setting and encoder, decoder decomposition. Benefits: Less entangled latent, sharp output distribution. Contribution: Learnable and less entangled latent with adversarial autoencoding structure. Weakness or Future work: -  GAN and AE\nGenerative Adversarial Networks (GAN)은 complex distribution을 표현하는 데 좋은 성능을 보여왔다. 특히 sharp 한 generation에 특이점을 가져 많은 현실적인 이미지나 음성을 생성할 수 있었다.\nAutoencoder는 encoder, generator pair로 representation과 generation 모두를 포함하는 구조이다. 본문에서는 AE가 representation은 충분히 잘하고 있지만, generation까지 겸비한 모델은 아직 구현하지 못하였다고 이야기한다.\n이에 소개하고자 하는 것이 Adversarial Latent Autoencoder (ALAE)이고, GAN과 비슷한 generative power를 가지면서도 representation disentangle이 가능한 모델을 목표로 한다.\n대부분의 AE 연구들은 같은 가정을 하는데, latent space를 확률 분포로 모델링 하며, 이것을 고정된 prior에 맞춰야 한다는 것이다. 실제로 ELBO를 정의할 때 posterior q를 가정하고 variational inference를 진행하는데, KL-divergence가 대상으로 삼은 conditional prior가 intractable 하기 때문에 주로 고정된 prior를 사용하게 된다. 하지만 StyleGAN (Karras et al., 2018)에서는 분포상 제약을 받지 않고, 데이터로부터 학습된 latent space가 prior에서 많은 transform을 거칠수록, prior에서 거리가 멀어질수록, disentangle 하기 쉽다는 이야기를 한다.\n여기서 착안하여 저자는 AE가 latent distribution을 data에서 학습할 수 있게 하였고, output distribution은 adversarial strategy를 통해 학습하였다. 이를 통해 GAN만큼의 generative power를 가지면서도 disentanglement를 더 용이하게 하는 것이다. 이는 근래 GAN 관련 분야에서 연구된 여러 기법이나 휴리스틱을 덜 사용하면서도 효과적으로 데이터를 모델링할 수 있게 한다.\nPreliminaries: GAN Objectives\n본문에서 소개하는 GAN objective의 general formulation은 다음과 같다.\n$$V(\\mathtt G, \\mathtt D) = \\mathbb E_{p_D(x)}\\left[ f(\\mathtt D(x)) \\right] + \\mathbb E_{p(z)}\\left[ f(-\\mathtt D(\\mathtt G(z))) \\right]$$\n여기서 f를 softplus $f(t) = -\\log(1 + \\exp(-t))$로 두면 vanilla GAN과 같아지고, f를 identity $f(t) = t$로 두면 wasserstein GAN과 같아진다.\nAdversarial Latent Autoencoders\n기존의 GAN이 generator와 discriminator를 single module로 구성하였다면, ALAE에서는 가장 먼저 G와 D를 $\\mathtt G = G \\circ F$와 $\\mathtt D = D \\circ E$로 분해한다. 그리고 F와 G 사이, E와 D 사이의 represenation을 latent W로 둘 것이다. 이 때 F와 D는 deterministic, G와 E는 stochastic하게 가정한다. G가 additional independent noise $\\eta$를 받는다면 $G(w, \\eta)$의 general stochastic generator가 될 것이다. 이때 G에서 생성된 output x의 확률은 다음과 같다.\n$$q(x) = \\int_w\\int_\\eta q_G(x|w, \\eta) q_F(w) p_\\eta(\\eta) \\mathrm d\\eta \\mathrm dw$$\n마찬가지로 E에서 생성된 latent w의 확률은 다음과 같다.\n$$q_E(w) = \\int_x q_E(w|x)q(x)\\mathrm dx$$\n여기서 q(x)를 실제 데이터 분포 $p_D(x)$로 바꾼다면 데이터에 대한 latent $q_{E, D}(w)$가 될 것이다.\n여기서 앞서 소개한 GAN objective를 토대로 모델을 학습한다면 이는 synthetic distribution q(x)를 실제 데이터 분포 $p_D(x)$로 맞춰가는 작업이 된다. 여기에 더불어 ALAE에서는 하나의 조건을 더 걸게 되며, 이는 $q_F(w) = q_E(w)$로 latent distribution을 matching 하는 작업이다.\nAE는 latent와의 bijection을 위해 reciprocity, 자기복원의 기능을 가지는데, 크게 $x=G(E(x))$로 data space 상에서의 복원이 있을 수 있고, $w=E(G(w))$로 latent space 상에서의 복원이 있을 수 있다. 전자의 경우는 두 분포의 차이를 나타내는 reconstruction error를 가지게 되고, 각 픽셀을 독립된 확률 분포로 가정했을 때 prior에 따라 log-prob으로 l1이나 l2 loss를 띌 수 있다. 대부분의 AE 기반 모델에서 사용하지만 실제로는 blur나 noise 같은 output distribution에 표현되는 perceptual 한 손실을 만들기 때문에 지금까지의 AE 모델들이 쉽게 GAN에 비견되는 품질을 가질 수 없었다.\n반면 ALAE는 후자를 선택하였는데, latent space 상에서 차이를 나타내는 discrepancy measure를 두고, F와 EGF의 출력을 비교하는 것이다. output 상에서의 l2-loss는 human perception을 반영하기보다는 단순 픽셀 상의 차이에 집중하고, 이런 한두 개의 픽셀 차이는 latent 상에 작용하기 어려워야 한다. 이에 latent 상에 직접 discrepancy measure를 걸어 버리는 것이 human perception에 더 직접적으로 작용할 수 있게 학습하는 것이다.\n이는 GAN의 intuition과 비슷한데, GAN은 기존의 AE가 output space 상에서 independent 한 픽셀을 가정하고 discrepancy를 측정한 것에 반해, discriminator라는 human perception을 대체할만한 추가 모델을 두고, receptive field와 인지 능력을 학습받은 adaptive discrepancy를 측정할 수 있게 한 것이다.\nALAE에서는 이 discrepancy measure를 단순 l2로 두었는데, 이는 latent W에 어떠한 제약도 두고 싶지 않았기 때문이라고 한다. latent W에 distribution을 가정하고 KL-divergence와 같은 척도를 이용할 수도 있지만, 이렇게 되면 실상 F가 identity map과 같아지고 그 의미가 무색해진다. 대신 l2를 사용하였기 때문에 실제 데이터에 대한 latent $q_{E, D}(w)$와의 비교는 어려워졌다.\ninference에서는 E로 input data를 encoding 하여 만든 latent w와 G를 통해 이미지를 재생성하는 방식으로 작동한다.\n(StyleALAE에 대한 이야기는 보류한다.)\nDetail\n$L^{E, D}_ {adv} = \\mathrm{softplus}(D\\circ E \\circ G \\circ F(z)) + \\mathrm{softplus}(-D \\circ E(x)) + \\frac{\\gamma}{2}\\mathbb E_{p_D(x)}\\left[ ||\\nabla D \\circ E(x)||^2\\right]$\n$L^{F, G}_ {adv} = \\mathrm{softplus}(-D\\circ E \\circ G \\circ F(z))$\n$L^{E, G}_ {err} = ||F(z) - E \\circ G \\circ F(z)||^2_2$\nGAN objective의 f는 softplus를 사용하였고, 대신에 real data에 대한 gradient regularization term을 두었다. latent prior z는 standard gaussian으로 두었고, 따로 independent noise $\\eta$를 두지 않은 것으로 보인다.\nDiscussion\n실제로 MLP 기반의 MNIST 모델과 StyleALAE 기반의 여러 image synthesizing experiment를 진행하였고, image quality는 물론 latent 상에서의 preceptual path length가 짧아지는 등의 disentanglement 성능 향상도 보였다고 한다.\n다른 연구들과는 달리 adaptive latent를 가정하여 less entangle한 latent를 학습할 수 있었고, adversarial setting으로 output distribution의 sharpness를 유지할 수 있었다. reciprocity에 대한 ablation study 같은 것이 있었으면 좋을거 같다.\nImplementation\n pytorch, official: ALAE tensorflow, unofficial, MNIST PoC: tf-alae  Reference\n Adversarial Latent Autoencoders, Stanislav Pidhorskyi et al., 2020. StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Tera Karras et al., 2018.  ","permalink":"https://revsic.github.io/blog/alae/","tags":["Machine Learning","Deep Learning","Generative","Adversarial Learning","Autoencoder","ALAE"],"title":"Adversarial Latent Autoencoders"},{"categories":["Bayesian"],"contents":" Hyunjik kim et al., 2019, arXiv Keyword: Bayesian, Process Problem: Underfitting of Neural Process Solution: NP + Self-Attention, Cross-Attention Benefits: Improvement of prediction accuracy, training speed, model capability. Contribution: Solving underfitting on NP Weakness or Future work: Decoder + Self-Attention  Neural Process and Gaussian Process\nNeural Process는 함수 분포를 모델링하기 위한 효과적인 메소드를 소개했다. linear time에 작동하며, 한번 학습되면 임의의 context pair와 query에 대해 target 분포를 예측할 수 있다. 그럼에도 NP와 GP를 직접 비교하기 어려운 이유는 NP는 stochastic process의 여러 realization (process에서 샘플링한 함수 표본) 에 대해서 학습하지만, GP는 하나의 realization에서 sample 된 observation에 대해 학습하기 때문이다.\nNP는 Scalability, Flexibility, Permutation Invariance라는 점에서 여러 장점이 있지만, consistency 문제를 가지고 있다. 이는 context로부터 target을 추론한 후, 다시 context에 덧붙여 target을 추가 추론했을 때와 온전한 context로부터 전체 target을 추론했을 때 분포차가 발생할 수 있음을 의미한다. 그러므로 NP를 그 자체로 consistent 하다고 보기보다는 consistent stochastic process의 근사라고 보는 것이 맞다.\nNP의 또 하나의 약점은 context set에 underfit한다는 것이다. 실제로 1D Curve Fitting 문제를 살펴보면, context point가 존재하는 지점에서도 과한 분산과 부적절한 평균점을 보인다. 본문에서는 이 이유를 NP가 context set을 고정된 크기의 latent로 변환시키는 과정에 permutation invariant function으로 mean-aggregation을 썼는데, 이 과정이 bottleneck으로 작용했기 때문이라고 판단하였다. 이는 모든 컨텍스트에 동일한 가중치를 주었기에, 디코더가 target을 예측할 때 context point로부터 적절한 관련 정보를 제공받지 못하고 있을 것으로 생각한 것이다.\n이러한 점을 해결하기 위해서 GP의 kernel function을 차용하였다. kernel은 입력값의 두 지점에 대해서 유사도를 측정하는 도구로 이용되는데, NP에는 이러한 메커니즘이 존재하지 않는 것이다. 그래서 제안하고자 하는 게 Attentive Neural Process (ANPs)이고, 이는 NP에 differentiable attention을 추가하여 context point에 대한 underfit을 줄인 모델이다.\nAttentive Neural Process\n먼저 입력과 출력 $x_i \\in \\mathbb R^{d_x}, \\ y_i \\in \\mathbb R^{d_y}$, 그리고 observed context $(x_C, y_C) := (x_i, y_i)_ {i \\in C}$ 와 targets $(x_T, y_T) := (x_i, y_i)_{i \\in T}$를 가정한다. context representation aggregator r에 대해 $r_C := r(x_C, y_C) \\in \\mathbb R^d$로 두고, latent encoder s에 대해 $s_C := s(x_C, y_C)$로 두면 NP는 다음을 모델링하는 것과 같다.\n$$p(y_T | x_T, x_C, y_C) := \\int p(y_T | x_T, r_C, z)q(z | s_C)dz$$\n여기서 NP가 가정하는 process F의 randomness는 global latent z에서 오기 때문에 likelihood를 최대화하는 과정은 z의 샘플링을 통해 여러 개로 realization 된 하나의 process를 학습하는 것과 같다.\nz_context = self.z_encoder(context, key=cx, query=cx)\rz_prob = self.latent_prob(z_context)\rlatent = z_prob.sample()\rself_attend = self.encoder(context, key=cx, query=cx)\rANP는 여기에 두 가지 attention을 덧붙인다. 첫 번째는 self-attention으로 context 사이에서 정보를 공유하고 더 나은 intermediate representation을 만들기 위한 장치이다.\ncross_attend = self.cross_encoder(self_attend, key=cx, query=query)\rrep = self.decoder(cross_attend, query, latent)\rdist, mu, sigma = self.normal_dist(rep)\rcontext에 self-attention을 취하면 context 개수만큼의 intermediate representation(IR)이 생기고, 이는 target과 context의 유사도를 비교하는 cross attention을 통과하여 query-specific representation $r_* := r^*(x_C, y_C, x_*)$을 만든다. 이는 모델이 실제로 어떤 컨텍스트 포인트를 조명할지 명시하기 때문에 target prediction에 도움을 줄 수 있다.\nlatent encoder의 경우에는 self-attention 이후 cross-attention 대신에 mean-aggregation을 선택했는데, 본문에서는 이를 global-latent로써 보존하고 싶었다고 한다. latent path에 cross-attention이 들어오면, latent에 locality가 발생하기 때문이다.\n$$\\log p(y_T | x_T, x_C, y_C) \\ge \\mathbb E_{q(z | s_T)} \\left[ \\log p(y_T | x_T, r_C, z) \\right] - D_{KL}(q(z | s_T) || q(z | s_C))$$\ntraining loss는 ELBO를 동일이 가져간다.\n이렇게 하면 computational complexity가 O(n(n + m))이 되는데, 이는 attention 과정에서 모든 컨텍스트를 탐방하기 때문이다. 하지만 dot-product attention 같은 matrix-multiplication 기반의 attention 알고리즘을 이용하면 대부분이 parallel 하게 동작할 수 있으므로 실제로는 training time이 NP와 비교할 만 하다고 한다.\nDiscussion\nANP는 attention mechanism을 통해 underfitting problem을 효과적으로 풀어냈다. 추측의 정확도가 높아졌고, 학습이 빨라졌으며, 모델링 할 수 있는 메소드의 범위도 늘었다. 저자는 ANP의 decoder에 self-attention을 붙여 expressiveness의 향상 정도를 확인하고 싶다고 한다. 하지만 이는 target prediction 사이에 상관성이 생기는 문제이니 ordering이나 grouping을 어떻게 해야 할지가 중요해질 것이라고 한다.\nImplementation\n Tensorflow v1: tf-neural-process  Reference\n Conditional Neural Processes, Garnelo et al., 2018. Neural Processes, Garnelo et al., 2018. Attentive Neural Processes, Kim et al., 2019.  ","permalink":"https://revsic.github.io/blog/anp/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process","Attentive Neural Process"],"title":"Attentive Neural Processes"},{"categories":["Bayesian"],"contents":" Marta Garnelo et al., 2018, arXiv Keyword: Bayesian, Process Problem: Data inefficiency, hard to train multiple datasets in one. Solution: Stochastic Process + Latent variable + NN Benefits: Concurrent training, global uncertainty, explicit latent variable. Contribution: CNP + global uncertainty, concurrent dataset, explicit latent Weakness or Future work: Pairwise correlation.  Function Approximation\n딥러닝에서는 데이터 간의 상관관계를 찾기 위해 함수를 근사하는 작업을 하는데, 주로 지도 학습에서는 parameterized function의 파라미터 셋을 gradient를 통해 업데이트하는 방식을 차용한다. 이러한 경우 대부분의 workload가 학습 중에 이뤄지며, 추론 과정은 단순 forward pass만으로 가능하다. 하지만 한번 학습된 이후로는 추론 결과의 업데이트가 힘들다는 점에서 메타 러닝 쪽도 관심이 많아지는 편이다.\n그 대체재로 Stochastic Process와 그 에인 Gaussian Process(GP)가 있는데, 이러한 모델들은 training phase를 필요로 하지 않고, test-time에 원하는 쿼리를 직접 렌더링 하게 된다. 하지만 렌더링 과정이 O(N^3)의 연산이 필요하기 때문에 대형 데이터셋을 상대로 적용하기 쉽지 않고, kernel과 같은 prior에 의해 함수 모형이 바뀌는 등 여러 문제점도 존재한다.\n이에 제안하고자 하는 게 Neural Process이다. 함수에 대한 분포를 가정하고, observation을 통해 query와 prediction에 대한 uncertainty를 추정한다. GP와 달리 O(n + m)의 단순 forward pass만으로 추정을 진행할 수 있다는 점에서 장점을 지닌다.\nNeural Process\n먼저 random function $F: \\mathcal X \\to \\mathcal Y$와 finite seq $x_{1:n}=(x_1, \u0026hellip;, x_n)$ with $x_i \\in \\mathcal X$, function values $Y_{1:n} := (F(x_1), \u0026hellip;, F(x_n))$를 가정한다. 이 collection의 joint dist $\\rho_{x_{1:n}}$이 존재할 것이고, GP 라면 multivariate gaussian일 것이다.\n이 joint dist는 exchangeability와 consistentcy라는 조건에서 Kolmogorov Extension Theorem에 의해 stochastic process로 정의될 수 있다. 이 때 exchangeability는 permutation invariance를 의미하고, consistentcy는 marginlize한 범위 외의 sequence에 대해 marginalize했을 때 원본 시퀸스와 동일함을 의미한다.\nStochastic process F와 시퀸스 $x_{1:n}$, 그의 joint dist $\\rho_{x_{1:n}}$에 대해 instantiation of stochastic process f는 다음과 같다\n$$\\rho_{x_{1:n}} = \\int p(f)p(y_{1:n}|f, x_{1:n})df$$\nobservation noise를 고려하여 $Y_i \\sim \\mathcal N(f(x_i), \\sigma^2)$라 가정하면 proability p는 다음과 같다\n$$p(y_{1:n}|f, x_{1:n}) = \\prod^{n}_{i=1} \\mathcal N(y_i | f(x_i), \\sigma^2)$$\n이 때 joint dist $\\lbrace\\rho_{x_{1:n}}\\rbrace$의 exchangeability와 consistentcy에 의해 stochastic process F의 존재성이 증명된다. 여기서 NP가 하고 싶은 것은 high-dimensional random vector z로 F를 parameterize하고, fixed function g에 대해 F(x) = g(x, z)를 NN으로 학습하고 싶은 것이다.\n$$p(z, y_{1:n}|x_{1:n}) = p(z)\\prod^{n}_{i=1} \\mathcal N(y_i|g(x_i, z), \\sigma^2)$$\n이 때 random function과 distribution을 학습하기 위해서는 여러 데이터셋을 동시에 학습해야 한다. 여러 input seq $x_{1:n}$와 output seq $y_{1:n}$를 학습시켜 데이터 간의 variability를 학습할 수 있게 한다.\ng를 non-linear NN으로 두기 때문에 학습에는 variational inference를 이용한다. latent z와 prior p(z)는 standard multivariate gaussian으로 두고, variational posterior $q(z|x_{1:n}, y_{1:n})$를 가정한다.\n$$\\log p(y_{1:n}|x_{1:n}) \\ge \\mathbb E_{q(z|x_{1:n}, y_{1:n})}\\left[\\sum^{n}_{i=1}\\log p(y_i|z, x_i) + \\log \\frac{p(z)}{q(z|x_{1:n}, y_{1:n})}\\right]$$\n이 때 test time에 더욱 well-behave model을 만들기 위해 context-set과 target-set을 나누고, true posterior $p(z|x_{1:n}, y_{1:n})$ 대신 variational posterior로 approximate한다.\n$$\\log p(y_{1:n}|x_{1:n}) \\ge \\mathbb E_{q(z|x_{1:n}, y_{1:n})}\\left[\\sum^{n}_{i=m+1}\\log p(y_i|z, x_i) + \\log \\frac{q(z|x_{1:m}, y_{1:m})}{q(z|x_{1:n}, y_{1:n})}\\right]$$\n이렇게 되면 z가 process F를 capture하는 역할을 하고, 이것이 global uncertainty를 capture 했다고도 볼 수 있다.\n실제 구현체에서는 encoder h가 pair $(x, y)_i$에 대해 repr $r_i = h((x, y)_i)$로 구성하고, exchangeable aggregator $r = a(r_i) = \\frac{1}{n} \\sum^n _{i=1}r_i$를 통해 latent $z \\sim \\mathcal N(\\mu(r), I\\sigma(r))$를 표현한다. 마지막으로 decoder g와 sampled latent z에 대해 $y_T = g(z, x_T)$를 통해 output을 결정하게 된다.\nz_context = self.z_encoder(context) z_dist = self.z_prob(z_context) latent = z_dist.sample() rep = self.decoder(context, query, latent) dist = self.normal_dist(rep) log_prob = dist.log_prob(target) log_prob = tf.reduce_sum(log_prob) prior = self.z_prob(self.z_encoder(context)) posterior = self.z_prob(self.z_encoder([query, target])) kl = tfp.distributions.kl_divergence(prior, posterior) kl = tf.reduce_sum(kl) elbo = -log_prob + kl Conditional Neural Process, Marta Garnelo et al., 2018\n동일 저자는 같은 해에 CNP라는 논문을 냈는데, 차이점은 NP는 latent z를 통해 process F를 캡처하고, global uncertainty를 측정하는데, CNP는 그러한 과정 없이 deterministic 하게 context와 query에 대한 target을 내놓는다. NP는 latent를 명시적으로 설정하였기 때문에, concurrent 한 training process에서도 명확히 latent를 포착하는 것을 볼 수 있다.\nDiscussion\nNP는 역시 stochastic process와 NN을 합친 모델이다. 함수에 대한 분포를 정의하고, context conditioned prediction을 생성한다. regression task에 대해서 실험을 주로 했는데, future work로 high dimensional data에 관한 연구를 남겨두겠다 한다.\nImplementation\n Tensorflow v1: tf-neural-process  Reference\n Conditional Neural Processes, Garnelo et al., 2018. Neural Processes, Garnelo et al., 2018.  ","permalink":"https://revsic.github.io/blog/np/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process"],"title":"Neural Processes"},{"categories":["Bayesian"],"contents":" Marta Garnelo et al., 2018, arXiv Keyword: Bayesian, Process Problem: Weakness of knowledge sharing and data inefficiency of classical supervised learning Solution: Stochastic Process + NN Benefits: Data efficient, prior sharing Contribution: Encapsulation of parameterized NN function family. Weakness or Future work: Global uncertainty, pairwise correlation.  Function Approximation\n우리는 데이터의 경향성을 파악해 추론을 얻어내기 위해 흔히 데이터셋 $\\lbrace(x_i, y_i)\\rbrace^{n-1}_{i=0}$과 함수 $f: X \\to Y$를 가정한다. 일반적인 지도학습에서는 $f$를 parameterized model로 가정하고, computation을 고정, parameter를 학습하는 방식을 취한다. 그 이후에는 deterministic하게 입력에 대해 출력이 결정된다. 이러한 방식은 prior의 적용이 한정적이고, 그에 따라 learning 사이의 정보 공유가 어려워 매번 대량의 데이터셋에 대한 새로운 학습이 요구되는 등 여러 한계를 보이기도 한다.\nStochastic process는 함수라는 카테고리를 하나의 확률 분포로 가정한다. 함수에 대한 사전 지식은 분포상의 가정으로 표현되고, 학습은 관측된 값들에 대한 조건부 확률과 사후 분포로써 표현된다.\n대표적인 예로 gaussian process는 함수의 smoothness prior를 kernel function으로 나타내었고, 이는 값들 사이의 유사도로 나타나게 된다. 하지만 이러한 메소드들은 prior에 따라서 computationally intractable하기도 하고, $O(N^3)$에 달하는 연산량에 현대에는 많이 쓰이지 않고 있다.\n이러한 문제를 풀기 위해 model family를 제안하고, 이것이 Conditional Neural Process 이다.\nStochastic Process\n먼저 observation $O = \\lbrace(x_i, y_i)\\rbrace \\subset X \\times Y$ 과 target $T=\\lbrace x_i\\rbrace^{n+m-1}_{i=n}$ 를 가정하자. 이 때 $f: X \\to Y$로의 함수와 이 함수의 분포 P가 존재한다면 $f \\sim P$ 이고, 조건부 분포 $P(f(T)|O, T)$로 표현된다.\nGP에서는 P를 Gaussian으로 가정하고, Covariance Matrix 대신 두 지점 사이의 유사도를 측정하는 kernel 함수를 도입한다. 이러한 모델은 data efficient 하지만, prior나 kernel 함수의 설정이 어렵고, 추론 과정이 $O((n+m)^3)$로 computationally expensive 하다.\nConditional Neural Process (CNPs)\nCNP는 함수를 observation에 대한 조건부 분포로 가정한다. CNP는 observation을 고정된 크기의 embedding vector로 표현하고, 이를 토대로 새로운 query에 대한 추론을 만든다. 이 모든 것이 NN을 통한 single forward pass에 이뤄지기 때문에 관측수 n과 쿼리수 m에 대해 O(n + m)의 복잡도만을 요구로 한다.\nobservation O가 주어질 때 CNP는 $Q_\\theta$ 의 conditional process를 가정한다. 기존의 stochastic process처럼 O와 T의 순서에 대해 추론이 변하지 않는 permutation invariance를 보장한다. 또한 factorization $Q_\\theta(f(T)|O, T)=\\Pi_{x \\in T}Q_\\theta(f(x)|O, x)$을 가정한다.\nCNP의 구조는 다음과 같다.\n$r_i = h_\\theta(x_i, y_i) \\quad \\forall (x_i, y_i) \\in O$\n$r = \\oplus^n_i r_i$\n$\\phi_i = g_\\theta(x_i, r) \\quad \\forall x_i \\in T$\n이 때 $h_\\theta: X \\times Y \\to \\mathbb R^d$ 이고, $g_\\theta: X \\times \\mathbb R^d \\to \\mathbb R^e$ 이다. $\\oplus$는 observation embedding을 합치는 operation으로 본문에서는 permutation invariance를 지키기 위해 commutative 하다는 가정을 두었다.\n그 결과 process는 $Q_\\theta(f(x_i) | O, x_i) = Q(f(x_i) | \\phi_i)$ 로 표현되며, 이 과정이 NN forward pass만으로 이뤄지기 때문에 O(n + m)의 복잡도를 가진다.\nregression 에서는 $\\phi_i = (\\mu_i, \\sigma_i^2)$ 와 $\\mathcal N(\\mu_i, \\sigma_i^2)$ 로 두어 최종 $f(x_i)$가 가우시안을 따르게 하고, classification에서는 categorical distribution의 logits로 두었다.\n학습은 nll을 minimize 하는 방식으로 이뤄진다.\n$\\mathcal L(\\theta) = -\\mathbb E_{f \\sim P}\\left[\\mathbb E_N\\left[\\log Q_\\theta(\\lbrace y_i\\rbrace^{n-1}_{i=1}|O_N, \\lbrace x_i\\rbrace^{n-1}_{i=0})\\right]\\right]$\nDiscussion\n본문에서는 CNP가 training 데이터에서 prior을 적절히 학습하였고, 이를 통해 observation 간의 learning share이 가능하다고 이야기한다. 실험에서도 보였듯 data efficient하면서도 NN의 adaptivity를 충분히 잘 활용 하였고, meta-learning이나 few-shot learning 과의 상관성에 대해서도 이야기하였다. 지금은 POC 수준이지만, statistical context에서 function family를 적절히 encapsulate 한 것이 주요 contribution이지 않을까 싶다.\n추후 Neural Process나 Attentive Neural Process에서도 이야기하지만, CNP는 global uncertainty를 측정하는 수단이나, observation과 target 사이의 correlation을 측정하는 수단이 명시적으로 존재하지 않는다는 점도 고려해야 한다.\nImplementation\n Tensorflow v1: tf-neural-process  Reference\n Conditional Neural Processes, Garnelo et al., 2018.  ","permalink":"https://revsic.github.io/blog/cnp/","tags":["Machine Learning","Deep Learning","Bayesian","Stochastic Process","Neural Process","Conditional Neural Process"],"title":"Conditional Neural Processes"},{"categories":["Portfolio"],"contents":"Skills\n Languages: Python, C++ ML Framework: Tensorflow v1, PyTorch Windows Internal  Projects - Machine Learning\n  Behavior based Malware Detection Using Branch Data [GIT]\n: Classify malware from benign software using branch data via LSTM based on Tensorflow\n  AlphaZero Connect6 [GIT]\n: AlphaZero training framework for game Connect6 written in Rust with C++, Python interface.\n  Fine Dust Prediction [GIT]\n: Predict amount of fine dust for next 7 days via Convolutional LSTM based on Tensorflow.\n  numpy-rnn [GIT]\n: Numpy implementation of vanilla-rnn and lstm for solving binary addition and mnist classification problem.\n  np-gaussian-process [GIT]\n: Numpy implementation of Gaussian Process Regression.\n  Chess A.I. [GIT]\n: Java implementation of board game \u0026lsquo;Chess\u0026rsquo; and A.I. based on min-max and alpha-beta pruning.\n  Projects - Windows Internal\n  Anti-Attacher [GIT]\n: C++ implementation for defending windows debugger from attaching the target process.\n  Code-Injector [GIT]\n: C++ implementation of several code injection techniques like dll injection, queue user apc.\n  Branch Tracer [GIT]\n: C++ implementation of dll-based windows debugger for tracking branching instruction via vectored exception handler.\n  cpp-veh-dbi [GIT]\n: C++ implementation of vectored exception handler based simple dynamic binary instrumentation tools.\n  Projects\n  cpp-concurrency [GIT]\n: C++ implementation of golang-style concurrency supports, thread pool, channel, wait-group\n  cpp-obfuscator [GIT]\n: C++ implementation of compile time string and routine obfuscator.\n  RosettaStone [GIT]\n: C++ implementation of game \u0026lsquo;Hearthstone\u0026rsquo; as training environment and A.I. for future work.\n  Haskell Calculator [GIST]\n: Haskell implementation of calculator with generic binary operators.\n  ThreeByteVM [GIST]\n: C implementation of simple virtual machine that word size is 3 bytes.\n  TopMost [GIT]\n: C++ implementation of topmost library for windows and javascript support.\n  PacketInjector [GIT]\n: C++ implementation of simple packet detector and injector.\n  ELF Code Virtualization\n: ELF (Executable Linkable Format) Virtualized Code Protection\n  ML Paper implementation\n  tf-neural-process [GIT] [arxiv: NP, CNP, ANP]\n: Neural process, Conditional Neural Process, Attentive Neural Process\n  tf-vanilla-gan [GIT] [arXiv:1406.2661]\n: Generative Adversarial Nets, Ian J. Goodfellow et al., 2014.\n  tf-alae [GIT] [arXiv:2004.04467]\n: Adversarial Latent Autoencoders, Stanislav Pidhorskyi et al., 2020.\n  Rewriting-A-Deep-Generative-Models [GIT] [arXiv:2007.15646]\n: Rewriting a Deep Generative Model, David Bau et al., 2020.\n  tf-diffwave [GIT] [arXiv:2009.09761]\n: DiffWave: A Versatile Diffusion Model for Audio Synthesis, Zhifeng Kong et al., 2020.\n  School Works\n  HYU-ITE2038 [GIT]\n: Database Systems and Applications in Hanyang University\n  HYU-CSE4006 [GIT]\n: Artificial Intelligence\n  HYU-ELE3021 [GIT]\n: Operating System\n  Study\n  Modern C++ Challenge [GIT]\n: Challenge real-world problems with C++17 features\n  Stanford-CS166: Data Structure [GIT]\n: Data structure for undergraduate\n  Paper\n Behavior Based Malware Detection Using Branch Data at 2017 KIISE Korea Computer Science Conference  Presentation\n  Behavior based Malware Detection Using Branch Data at CodeGate 2017 Junior\n  Hearthstone++: Hearthstone simulator with reinforcement learning at Deep Learning Camp Jeju\n  Developing Environment for RL at Nexon Developers Conference 2019 as team RosettaStone\n  GP to NP: Gaussian process and Neural Process at A.I.U 1st Open AI Conference\n  Awards\n KISA, 2016 Software Contest,\nApplication Security Section 2nd Prize (Minister of Interior Award) 2016.09  Education\n  Department of Information and Communication Technology at Sunrin Internet High School\n(2015.03 ~ 2017.02)\n  Vulnerability Analysis Track at KITRI BoB\n(2016.05 ~ 2017.03)\n  Department of Computer Software Engineering at Hanyang University\n(2018.03 ~)\n  Works\n TTS Researcher at LionRocket\n(2019.09 ~)  ","permalink":"https://revsic.github.io/blog/worklist/","tags":["Portfolio"],"title":"Work list"}]