---
title: "On 2020 as researcher"
date: 2020-12-29T15:58:56+09:00
draft: false

# post thumb
image: "images/post/on2020dev/head.jpg"

# meta description
description: ""

# taxonomies
categories:
    - "Writing"
tags:
    - "Writing"
    - "2020"
    - "Researcher"
    - "TTS"

# post type
type: "post"
---

올해로 1년 좀 넘게 음성 합성 리서치 업무를 보고 있다. \
이번 글에선 19년 9월, 입사부터 20년 말까지 한 활동을 조심히 정리해보려 한다.

&nbsp;

##### 입사 당시

입사 당시 우리 회사는 설립된 지 반년 정도 된 학부생 스타트업이었다.

처음에는 대표님의 요청으로 비전 프로젝트 외주를 진행했었고, \
9월에 입사하여 본격적으로 음성 업무를 보기 시작했다.

당시 회사 인원은 나 포함 5명이었고, 각자 역할이 부여된 상황이었다. \
그중 나는 TTS 리서처로 들어왔다.

당연히 사수는 없었다. \
TTS 연구 개발 프레임워크는 리팩토링이 시급해 보였고, \
그를 기반으로 딥러닝 리서치를 진행하는 과정이 확립되어 있지 않았다.

모든 것을 처음부터 시작해야 하는 상황이었다. \
하지만 이제 막 2학년이 끝난 학부생은 모든 게 패기로웠다.

&nbsp;

##### 딥러닝 리서처 업무

음성 합성 리서치의 목표는 \
합성된 음성의 발음이 또렷해야 하고, 자연스러우면서, 음질이 좋아야 한다. \
이후에는 다국어, 다화자, 감정 등 추가 기능 지원이 들어간다.

**논문 리뷰**

회사 들어와서 가장 먼저 한 리서치 업무는 \
음성 합성 논문 리스트를 만들고 쭉 리뷰 한 것이었다.

처음 입사했을 때에는 푸리에 변환이 뭔지도 모르고 시작했다. \
그냥 이렇게 저렇게 만든 스펙트로그램이란 피쳐가 있고, \
딥러닝 모델이 텍스트에서 스펙트로그램으로의 매핑을 학습한다는 정도만 나이브하게 알고 있었다.

신호처리 공부도 해야 했고, 딥러닝 모델 논문도 봐야 했다. \
그렇게 1년 동안 대략 60편 정도의 논문을 보고 20개 가까이 구현해본 것 같다.

입사 전에도 그랬지만, 시작부터 다독을 목표로 했다. \
리뷰가 진행된 논문이던, 안 된 논문이던, \
메이저 학회에 통과한 논문이던, 그저 arXiv에 올라온 글이던 가리지 않았다.

하루에 한 번은 레딧이나 arXiv에 음성 관련 논문이 올라왔나 확인하는거 같다.

**논문 볼 때 정리했던 내용**

논문을 보면 항상 5가지 항목에 대해서 정리했다.

1. 어느 분야에서
2. 이전 논문들에서 어떤 문제점을 발견했고
3. 어떤 해결방법을 제시했으며
4. 이때 생기는 이점과
5. 발견되었거나 예상되는 약점은 무엇인지

그렇게 해서 학계의 흐름을 쫓고 있고, \
올해 말부터는 이제 본인만의 실험을 기획하기 시작했다.

딥러닝에 관심을 가지고 있던 적당한 학부생이었고, \
어디서 연구하는 방법이란 것을 배워본 적이 없었기 때문에 모든 게 서툴렀다.

논문을 볼 때 어느 것이 중요하고, \
어떻게 쫓아야 하고, 무엇을 이야기하고 싶은건지, \
저 5가지 질문을 확립하는데에도 꽤 시간이 걸렸던 것 같다.

**신호처리 관련 공부**

문제는 어느 시점부터, 음성 분야 논문이 단순 스펙트로그램을 넘어서 \
여러 가지 피쳐나 기성 신호처리 알고리즘들을 차용하여 성능을 높이는 시도가 등장했다는 것이다.

따로 물리나 신호처리학을 공부해본 적이 없었기 때문에, \
어디서부터 무엇을 공부해야 할지도 몰랐고, \
처음부터 공부해서 이른 시일 안에 현업에 사용할 자신도 없었다.

그래서 모르는 단어가 나오면, \
탑다운 방식으로 구글에 단어를 검색하고, \
대학 강의에 쓰인 pdf 파일을 보면서 공부했다. 

{{< figure src="/images/post/on2020dev/searchresult.jpg" width="80%" caption="(생각보다 검색하면 잘 나옴)" >}}

그러다 보니 틀리게 이해한 내용도 많았고, \
이곳저곳 빈 곳도 많았다.

하지만 탑다운도 결국 수렴한다고, \
결국에는 틀린 이해를 정정하고, 꽤 많은 빈 곳을 채웠다는 생각이 든다.

**모델 구현**

기존에는 tensorflow를 많이 활용했었다. \
하지만 회사에서는 pytorch를 사용하고 있었고, \
이에 맞추기 위해 하루에서 이틀 정도는 파이토치에 적응을 좀 했던 거 같다.

모델을 구현하기에 앞서 원저자가 구현한 오픈소스 코드가 있는지 확인했다.

처음에는 하루 정도면 모델 하나 구현할 수 있다고, \
오픈소스 찾아볼 게 있냐고 처음부터 짜는 객기를 부렸지만,

딥러닝 코드는 버그를 잡기 어렵고, \
이미 구현된 코드가 있으면 I/O 정도만 수정해서 바로 실험해볼 수 있으므로 \
오픈소스를 참고해서 회사 스타일에 맞게 정리하는 게 빠르다. \
물론 라이센스 확인은 필수다.

또한, 논문에 기재되지 않은 디자인 초이스나 휴리스틱이 존재할 수 있으므로 \
원작자의 코드 존재 여부를 우선 파악하는 것이 맞는 것 같다. 

만약 이해되지 않는 디자인이나, \
기재되지 않은 하이퍼 파라미터 정보가 있다면 레딧에 물어보는 것도 괜찮은거 같다.

{{< figure src="/images/post/on2020dev/reddit.jpg" width="80%" caption="(생각보다 관심을 많이 받아서 신기했음)" >}}

**실험, 문제점, 해결책**

이렇게 구현이 끝난 모델은 사전에 선정한 데이터셋으로 학습해 보고, \
여러 지표를 통해 모델을 평가했다.

문제는 생성된 음성은 원본과 1대1로 비교하는 것이 무의미하다. \
음의 높낮이가 다르더라도 충분히 자연스러울 수 있고, \
파형이 다르더라도 같은 발음 성분을 가지고 있을 수 있다.

이러다 보니 1대1로 비교하는 것은 무의미하고, \
길이가 다른 시퀀스의 유사도나, ASR 모델을 활용하여 \
의미 있는 평가를 자동화하기 위한 여러 추가 연구도 진행했었다.

그렇게 모델을 평가하고 나면 문제점이 나타난다. \
이 모델은 발음을 못 한다, 이 모델은 음질이 안 좋다. 등등 \
그럼 기존까지 관찰된 여러 모델의 현상을 통해 단점을 커버하기 위한 추가 실험을 진행한다.

아직은 딥러닝이라는 분야가 \
특정된 데이터셋과 컴퍼넌트의 상호작용을 연역적으로 분석하기 어려우므로 \
현상과 실험적인 접근이 최선인 것 같다는 생각이 든다.

그래서 조금 답답하기도 하다.

**연구하는 방법을 배운 기분**

위에 엄청 대단한 거 마냥 글을 썼지만, \
사실 당연한 연구 루틴이었을지도 모른다.

앞서 이야기했듯, 나는 그냥 딥러닝에 관심이 있던 학부생이었고, \
연구라는 것을 해보거나 배워본 적이 없기 때문에 \
1년 동안은 정말 벽에 부딪치며 연구하는 방법을 배운 거 같다.

실제로 처음에는 그냥 성능을 높이는 게 목적이니 \
닥치는 대로 논문을 읽고, 시간 되는 대로 구현하고, \
뭐가 안되면 모델 잘못이네, 수정은 하이퍼 파라미터 튜닝하는 정도였다.

그러다 이제 타임라인이 현재에 도달해서, \
과거 논문을 구현하는 것이 아니면 추가로 볼 논문이나 모델이 없는 시점에 왔다. \
이제는 모델 탓만 할 것이 아닌, \
어떤 문제가 있고, 어떻게 해결해야 할지에 대한 고민을 해야 하는 상황이다.

올해 말이 되어서야 나는 가설이라는 걸 세워보고, \
실험을 통해 보이고, 개선하는 일련의 프로세스를 확립해서 업무에 적용해 보고 있다.

그 과정에서 평가 지표도 자동화했고, \
컴퍼넌트랑 지표의 상관성, 현상과의 연관성도 하나씩 알아보고 있다.

결과를 보는 그 과정이 재미로 다가왔다. \
이제야 길이 환해진 느낌이 든다.

&nbsp;

##### 엔지니어링 업무



##### CUDA까지 내려갔다 오면

##### 프레임워크 유지보수
