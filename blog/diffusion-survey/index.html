<!DOCTYPE html>
<html lang="ko-kr"><head>
  <meta charset="utf-8">
  <title>revsic | ML Developer</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Diffusion, Flow Survey">
  <meta name="author" content="YoungJoong Kim">
  <meta name="generator" content="Hugo 0.125.7">

  <!-- plugins -->
  
  <link rel="stylesheet" href="/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="/plugins/venobox/venobox.css ">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="/scss/style.min.css" media="screen">

</head><body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom">
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.facebook.com/profile.php?id=100009484787654"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://github.com/revsic"><i class="ti-github"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.linkedin.com/in/young-joong-kim-878630154/"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://revsic.github.io/"> Home </a>
          </li>
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/blog">Post</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search px-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://revsic.github.io//search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/generative"
          class="text-primary">Generative</a>
        
        <h2>[WIP] Diffusion, Flow Survey</h2>
        <div class="mb-3 post-meta">
          <span>By YoungJoong Kim</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>09 February 2025</span>
          
        </div>
        
        <img src="/images/post/diffusion-survey/head.png" class="img-fluid w-100 mb-4" alt="[WIP] Diffusion, Flow Survey">
        
        <div class="content mb-5">
          <ul>
<li>Survey of Diffusion, Flow Models</li>
<li>Keyword: Bayesian, VAE, Diffusion Models, Score Models, Schrodinger Bridge, Normalizing Flows, Rectified Flows, Neural ODE, Consistency Models</li>
</ul>
<p><strong>Abstract</strong></p>
<p>2013년 VAE[<a href="https://arxiv.org/abs/1312.6114">Kingma &amp; Welling, 2013.</a>], 2014년 GAN[<a href="https://arxiv.org/abs/1406.2661">Goodfellow et al., 2014.</a>]을 지나 2020년의 DDPM[<a href="https://arxiv.org/abs/2006.11239">Ho et al., 2020.</a>]과 2022년의 Flow Matching[<a href="https://arxiv.org/abs/2210.02747">Lipman et al., 2022.</a>]까지, 생성 모델은 다양한 형태로 발전해 왔다. 기존까지의 생성 모델을 짚어보고, 앞으로의 방향성에 관하여 고민해 보고자 한다.</p>
<p><strong>Introduction</strong></p>
<p>Supervised Learning에서는 흔히 입력 데이터 $x\in X$와 출력 데이터 $y\in Y$를 가정한다. 이때 데이터셋 $D = \{(x, y)\}$의 분포 $\Pi(X, Y)$를 X와 Y의 Coupling이라 정의하자(i.e. $(x, y)\sim\Pi(X, Y)$). 단순히는 dirac delta $\delta$에 대해 $\Pi(X, Y)$의 pdf를 $p_{X, Y}(x, y) = \delta_{(x, y)\in D}; (x, y)\in (X, Y)$로 가정해볼 수 있다.</p>
<p>많은 경우에 Supervised Learning은 parametrized function $f_\theta: X \to Y$를 통해 $x\mapsto y$의 대응을 학습하고, 조건부 분포의 likelihood를 maximizing 하는 방식으로 이뤄진다.</p>
<p>$$\hat\theta = \arg\max_\theta \sum_{(x, y)\sim\Pi(X, Y)} \log p_{Y|X}(f_\theta(x)|x)$$</p>
<p>만약 조건부 분포를 정규 분포로 가정한다면, 이는 흔히 알려진 Mean Squared Error의 형태로 정리된다.</p>
<p>$$\log p_{Y|X}(f_\theta(x)|x) \propto -||f_\theta(x) - y||^2 + C \implies \hat\theta = \arg\min_\theta \sum_{(x, y)\sim\Pi(X, Y)}||f_\theta(x) - y||^2$$</p>
<p>생성 모델(Generative Model)은 주어진 데이터의 확률 분포 학습을 목표로 한다. 이는 데이터로부터 probability density function을 추정하거나(혹은 probability mass function), Generator의 학습을 통해 데이터 분포의 표본을 생성하고자 한다.</p>
<p>i.e. 데이터 $X$의 분포를 $\pi_X$라 할 때, $\pi_X$의 pdf $p_X(x)$를 construct 하거나, known distribution(e.g. $\mathcal N(0, I)$)의 표본 $z\sim Z$를 데이터 분포의 한 점 $x&rsquo;\sim\pi_X$으로 대응하는 Generator $G: Z \to X$를 학습한다.</p>
<p>이 경우 대부분 사전 분포와 데이터 분포의 Coupling은 독립으로 가정하며(i.e. $\Pi(Z, X) = \pi_Z\times \pi_X$), parameterized generator $G_\theta$에 대해 log-likelihood(i.e. $\log p_X(x)$)를 maximizing 하거나, 분포 간 거리를 측정할 수 있는 differentiable objective $D$를 최적화하기도 한다(i.e. $\min_\theta \sum_{(x, z)\sim\Pi(Z, X)} D(G_\theta(z), x)$).</p>
<p>Generator가 $z\sim Z$의 조건부 분포를 표현하는 것은 자명하다(i.e. $G_\theta(z)\sim p_{\theta, X|Z}(\cdot|z)$). 전자의 상황에서 우리는 $p_X$의 형태를 모를 때(혹은 가정하지 않을 때), 조건부 분포를 $Z$에 대해 marginalize 하여(i.e. $p_{\theta, X}$) 데이터셋 $X$에 대해 maximize 하는 선택을 할 수 있다. $\max_\theta \sum_{x\sim\pi_X}\log p_{\theta, X}(x)$</p>
<p>(후자는 GAN에 관한 논의로 이어지므로, 현재의 글에서는 다루지 않는다.)</p>
<p>조건부 분포를 marginalize 하기 위해서는 $p_{\theta,X}(x) = \int_Z p_Z(z)p_{\theta,X|Z}(x|z)dz$의 적분 과정이 필요한데, neural network로 표현된 $G_\theta$의 조건부 분포 $p_{\theta,X}$를 적분하는 것은 사실상 불가능하다(intractable).</p>
<p>만약 이를 $\Pi(X, Y)$에 대해 충분히 Random sampling 하여 Emperical average를 취하는 방식으로 근사한다면(i.e. Monte Carlo Estimation), 대형 데이터셋을 취급하는 현대의 문제 상황에서는 Resource Exhaustive 할 것이다. 특히나 Independent Coupling을 가정하고 있기에, Emperical Estimation의 분산이 커 학습에 어려움을 겪을 가능성이 높다. 분산을 줄이기 위해 표본을 늘린다면 컴퓨팅 리소스는 더욱더 많이 필요할 것이다.</p>
<p>현대의 생성 모델은 이러한 문제점을 다양한 관점에서 풀어 나간다. Invertible Generator를 두어 변수 치환(change-of-variables)의 형태로 적분 문제를 우회하기도 하고, 적분 없이 likelihood의 하한을 구해 maximizing lower bound의 형태로 근사하는 경우도 있다.</p>
<p>아래의 글에서는 2013년 VAE[<a href="https://arxiv.org/abs/1312.6114">Kingma &amp; Welling, 2013.</a>]부터 차례대로 각각의 생성 모델이 어떤 문제를 해결하고자 하였는지, 어떤 방식으로 해결하고자 하였는지 살펴보고자 한다. VAE[<a href="https://arxiv.org/abs/1312.6114">Kingma &amp; Welling, 2013.</a>, <a href="https://arxiv.org/abs/2007.03898">NVAE; Vahdat &amp; Kautz, 2020.</a>]를 시작으로, Normalizing Flows[<a href="https://arxiv.org/abs/1605.08803">RealNVP; Dinh et al., 2016.</a>, <a href="https://arxiv.org/abs/1807.03039">Glow; Kingma &amp; Dhariwal, 2018.</a>], Neural ODE[<a href="https://arxiv.org/abs/1806.07366">NODE; Chen et al., 2018</a>], Score Models[<a href="https://arxiv.org/abs/1907.05600">NCSN; Song &amp; Ermon, 2019.</a>, <a href="https://arxiv.org/abs/2011.13456">Song et al., 2020.</a>], Diffusion Models[<a href="https://arxiv.org/abs/2006.11239">DDPM; Ho et al., 2020.</a>, <a href="https://arxiv.org/abs/2010.02502">DDIM; Song et al., 2020.</a>], Flow Matching[<a href="https://arxiv.org/abs/2209.03003">Liu et al., 2022.</a>, <a href="https://arxiv.org/abs/2210.02747">Lipman et al., 2022.</a>], Consistency Models[<a href="https://arxiv.org/abs/2303.01469,">Song et al., 2023.</a>, <a href="https://arxiv.org/abs/2410.11081">Lu &amp; Song, 2024.</a>], Schrodinger Bridge[<a href="https://arxiv.org/abs/2303.16852">DSBM; Shi et al., 2023.</a>]에 관해 이야기 나눠본다.</p>
<hr>
<p><strong>VAE: Variational Autoencoder</strong></p>
<ul>
<li>VAE: Auto-Encoding Variational Bayes, Kingma &amp; Welling, 2013. [<a href="https://arxiv.org/abs/1312.6114">arXiv:1312.6114</a>]</li>
</ul>
<p>2013년 Kingma와 Welling은 VAE를 발표한다. VAE의 시작점은 위의 Introduction과 같다. Marginalize 과정은 intractable하고, Monte Carlo Estimation을 하기에는 컴퓨팅 자원이 과요구된다.</p>
<p>이에 VAE는 $z$의 intractable posterior $p_{Z|X}(z|x) = p_{Z, X}(z, x)/p_X(x)$를 approximate posterior $E_\phi(x)\sim p_{\phi,Z|X}(\cdot|x)$ 로 대치하는 방식을 택한다. (아래는 편의를 위해 $q_\phi(z|x) = p_{\phi,Z|X}(z|x)$로 표기한다.)</p>
<p>$$\begin{align*}
\log p_{\theta, X}(x) &amp;= \mathbb E_{z\sim q_\phi(\cdot|x)} \log p_{\theta, X}(x) \\
&amp;= \mathbb E_{z\sim q_\phi(\cdot|x)}\left[\log p_{\theta, X}(x) + \log\frac{p_{\theta,Z,X}(z, x)q_\phi(z|x)}{p_{\theta,Z,X}(z, x)q_\phi(z|x)}\right] \\
&amp;= \mathbb E_{z\sim q_\phi(\cdot|x)}\left[\log\frac{p_Z(z)p_{\theta,X|Z}(x|z)\cdot q_\phi(z|x)}{p_{\theta,Z|X}(z|x)\cdot q_\phi(z|x)} \right] \\
&amp;= \mathbb E_{z\sim q_\phi(\cdot|x)}\left[\log\frac{q_\phi(z|x)}{p_{\theta,Z|X}(z|x)} - \log\frac{q_\phi(z|x)}{p_Z(z)} + \log p_{\theta,X|Z}(x|z)\right] \\
&amp;= D_{KL}(q_\phi(z|x)||p_{\theta,Z|X}(z|x)) - D_{KL}(q_\phi(z|x)||p_Z(z)) + \mathbb E_{z\sim q_\phi(\cdot|x)}\log p_{\theta,X|Z}(x|z)
\end{align*}$$</p>
<p>$q_\phi(z|x)$의 도입과 함께 $\log p_{\theta, X}(x)$는 위와 같이 정리된다. 순서대로 $D_{KL}(q_\phi(z|x)||p_{\theta,Z|X}(z|x))$은 approximate posterior와 true posterior의 KL-Divergence, $D_{KL}(q_\phi(z|x)||p_{Z}(z))$는 사전 분포 $p_Z(z)$와의 divergence, $\mathbb E_{z\sim q_\phi(\cdot|x)}\log p_{\theta, X|Z}(x|z)$는 reconstruction을 다루게 된다.</p>
<p>여기서 계산이 불가능한 true posterior $p_{\theta, Z|X}(z|x)$를 포함한 항을 제외하면, 다음의 하한을 얻을 수 있으며 이를 Evidence Lower Bound라 한다(이하 ELBO). VAE는 ELBO $\mathcal L_{\theta, \phi}$를 Maximize 하는 방식으로 확률 분포를 학습한다.</p>
<p>$$\log p_{\theta, X}(x)\ge \mathbb E_{z\sim q_\phi(\cdot|x)}\log p_{\theta, X|Z}(x|z)- D_{KL}(q_\phi(z|x)||p_Z(z)) = \mathcal L_{\theta, \phi}(x)\ \ (\because D_{KL} \ge 0)$$</p>
<p>ELBO를 maximize하는 과정은 approximate posterior가 사전 분포와의 관계성을 유지하면서도, 데이터를 충분히 결정지을 수 있길 바라는 것이다.</p>
<p>이 과정은 Expectation 내에 $z\sim q_\phi(\cdot|x)$의 Sampling을 상정하고 있지만, Sampling 자체는 미분을 지원하지 않아 Gradient 기반의 업데이트를 수행할 수 없다. VAE는 이를 우회하고자, approximate posterior의 분포를 $z\sim \mathcal N(\mu_\phi(x), \sigma_\phi^2(x)I)$의 Gaussian으로 가정하고, $z = \mu_\phi(x) + \sigma_\phi(x)\zeta;\ \zeta\sim \mathcal N(0, I)$로 표본 추출을 대치하여 $E_\phi = (\mu_\phi, \sigma_\phi)$ 역시 학습할 수 있도록 두었다(i.e. reparametrization trick).</p>
<p>이때 $z_i\sim\mathcal N(\mu_\phi(x), \sigma^2_\phi(x)I)$를 몇 번 샘플링하여 평균을 구할 것인지 실험하였을 때(i.e. $1/N\cdot \sum_i^N\log p(x|z_i)$), 학습의 Batch size가 커지면(논문에서는 100개) 각 1개 표본만을 활용해도(N=1) 성능상 큰 차이가 없었다고 한다.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>mu, sigma <span style="color:#000;font-weight:bold">=</span> E_phi(x)
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># reparametrization</span>
</span></span><span style="display:flex;"><span>z <span style="color:#000;font-weight:bold">=</span> mu <span style="color:#000;font-weight:bold">+</span> sigma <span style="color:#000;font-weight:bold">*</span> torch<span style="color:#000;font-weight:bold">.</span>randn(<span style="color:#000;font-weight:bold">...</span>)
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># ELBO</span>
</span></span><span style="display:flex;"><span>loss <span style="color:#000;font-weight:bold">=</span> (
</span></span><span style="display:flex;"><span>  <span style="color:#998;font-style:italic"># log p(x|z)</span>
</span></span><span style="display:flex;"><span>  (x <span style="color:#000;font-weight:bold">-</span> G_theta(z))<span style="color:#000;font-weight:bold">.</span>square()<span style="color:#000;font-weight:bold">.</span>mean()
</span></span><span style="display:flex;"><span>  <span style="color:#998;font-style:italic"># log p(z)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#000;font-weight:bold">+</span> z<span style="color:#000;font-weight:bold">.</span>square()<span style="color:#000;font-weight:bold">.</span>mean()
</span></span><span style="display:flex;"><span>  <span style="color:#998;font-style:italic"># - log q(z|x)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#000;font-weight:bold">-</span> ((z <span style="color:#000;font-weight:bold">-</span> mu) <span style="color:#000;font-weight:bold">/</span> sigma)<span style="color:#000;font-weight:bold">.</span>square()<span style="color:#000;font-weight:bold">.</span>mean()
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>VAE는 Approximate posterior를 도입하여 Intractable likelihood를  근사하는 방향으로 접근하였고, Posterior 기반 Coupling을 통해 분산을 줄여 Monte Carlo Estimation의 시행 수를 줄일 수 있었다.</p>
<p>하지만 VAE 역시 여러 한계를 보였다.</p>
<p>$D_{KL}(q_\phi(z|x)||p_Z(z))$의 수렴 속도가 다른 항에 비해 상대적으로 빨라 posterior가 reconstruction에 필요한 정보를 충분히 담지 못하였고, 이는 Generator의 성능에 영향을 미쳤다. 이에 KL-Annealing/Warmup 등의 다양한 엔지니어링 기법이 소개되기도 한다.</p>
<p>또한, 뒤에 소개될 Normalizing Flows, Diffusion Models, GAN에 비해 Sample이 다소 Blurry 하는 등 품질이 높지 않았다. 이에는 Reconstruction loss가 MSE의 형태이기에 Blurry 해진다는 이야기, Latent variable의 dimension이 작아 그렇다는 이야기, 구조적으로 Diffusion에 비해 NLL이 높을 수밖에 없다는 논의 등 다양한 이야기가 뒤따랐다.</p>
<p>이에 VAE의 성능 개선을 위해 노력했던 연구 중, NVIDIA의 NVAE 연구를 소개하고자 한다.</p>
<hr>
<ul>
<li>NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat &amp; Kautz, NeurIPS 2020. [<a href="https://arxiv.org/abs/2007.03898">arXiv:2007.03898</a>]</li>
</ul>
<p>NVAE(Nouveau VAE)는 프랑스어 <code>Nouveau: 새로운</code>의 뜻을 담아 <em>make VAEs great again</em>을 목표로 한다.</p>
<p>당시 VAE는 네트워크를 더 깊게 가져가고, Latent variable $z$를 단일 벡터가 아닌 여럿 두는 등(e.g. $z = \{z_1, &hellip;, z_N\}$) Architectural Scaling에 초점을 맞추고 있었다(e.g. <a href="https://arxiv.org/abs/2011.10650">VDVAE; Child, 2020.</a>). 특히나 StyleGAN[<a href="https://arxiv.org/abs/1812.04948">Karras et al., 2018.</a>, <a href="https://arxiv.org/abs/1912.04958">Karras et al., 2019.</a>], DDPM[<a href="https://arxiv.org/abs/2006.11239">Ho et al., 2020.</a>] 등의 생성 모델이 Latent variable의 크기를 키우며 성능을 확보해 나가는 당대 분위기상 VAE에서도 유사한 시도가 여럿 보였다[blog:<a href="/blog/1-step-diffusion">Essay: VAE as a 1-step Diffusion Model</a>].</p>
<figure><img src="/images/post/diffusion-survey/nvae.png"
    alt="Figure 2: The neural networks implementing an encoder and generative model. (Vahdat &amp;amp; Kautz, 2020)" width="60%"><figcaption>
      <p>Figure 2: The neural networks implementing an encoder and generative model. (Vahdat &amp; Kautz, 2020)</p>
    </figcaption>
</figure>

<p>NVAE는 latent groups $z = \{z_1, z_2, &hellip; z_L\}$에 대해 $q(z|x) = \Pi_l q(z_l|z_{&lt;1}, x)$의 hierarchical approximate posterior를 활용한다. ELBO는 다음과 같다.</p>
<p>$$\mathcal L_{VAE}(x) = \mathbb E_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z_1|x)||p(z_1)) - \sum^L_{l=2}\mathbb E_{q(z_{&lt;l}|x)}[D_{KL}(q(z_l|x, z_{&lt;l})||p(z_l))]$$</p>
<p>Encoder가 이미지로부터 feature map <code>r</code>를 생성(i.e. hierarchical approximate posterior, $q(z_l|x, z_{&lt;l})$), Decoder가 trainable basis <code>h</code>로부터 Encoder feature map을 역순으로 더해가며 이미지를 생성하는 U-Net 구조를 상상하자. Generation 단계에서는 Encoder feature map <code>r</code>이 주어지지 않기에, feature map의 prior distribution $p(z_l)$의 샘플로 대체한다. 이는 어찌 보면 Spatial noise를 더해가는 StyleGAN[<a href="https://arxiv.org/abs/1812.04948">Karras et al., 2018.</a>]과도 형태가 유사하다.</p>
<p>다만 이 경우, $D_{KL}$의 조기 수렴에 따라 posterior collapse가 발생할 가능성이 높기에, 여러 engineering trick이 함께 제안되었다. Decoder에는 Depthwise-seperable convolution을 활용하지만 Encoder에서는 사용하지 않고, SE Block[<a href="https://arxiv.org/abs/1709.01507">Hu et al., 2017.</a>]과 Spectral regularization, KL Warmup 도입, Batch normalization의 momentum parameter 조정 등이 있다.</p>
<p>이를 통해 실제로 당시 Normalizing Flows와 VAE 계열 모델 중에서는 좋은 성능을 보였다. 하지만 논문에서는 NLL(bit/dim)에 관한 지표만 보일 뿐, FID나 Precision/Recall 등 지표는 보이지 않아 다른 모델과의 비교는 쉽지 않았다.</p>
<p>정성적으로 보았을 때는 NVAE는 여전히 다소 Blurry 한 이미지를 보이거나, 인체의 형태가 종종 왜곡되는 등의 Degenerate Mode가 관찰되며 아쉬운 모습을 보이기도 했다.</p>
<hr>
<p><strong>Normalizing Flows</strong></p>
<ul>
<li>RealNVP: Density estimation using Real NVP, Dinh et al., 2016. [<a href="https://arxiv.org/abs/1605.08803">arXiv:1605.08803</a>]</li>
</ul>
<p>VAE가 연구되는 동시에 approximate posterior 도입 없이 marginal $\log p_{\theta,X}(x)$를 구하려는 시도가 있었다.</p>
<p>만약 parametrized generator $G_\theta: Z \to X$가 가역함수(혹은 전단사함수, Bijective)이면 marginal pdf는 변수 치환 법칙에 따라 $p_{\theta,X}(x) = p_Z(f^{-1}(x))\left|\frac{\partial f^{-1}(x)}{\partial x}\right|$를 만족한다.</p>
<p>적분 없이도 determinant of jacobian을 구함으로 marginal을 구할 수 있게 되었고, 이 과정이 differentiable 하다면 gradient 기반의 학습도 가능하다. 문제는 뉴럴 네트워크 가정에서 jacobian을 구한 후, 이미지 pixel-dimension에서 $O(n^3)$의 determinant 연산을 수행해야 한다는 것이다(e.g. 256x256 이미지의 경우 281조, 281 Trillion).</p>
<p>RealNVP는 현실적인 시간 내에 이를 수행하기 위해 Coupling layer를 제안한다.</p>
<p>$$\begin{align*}
y_{1:d} &amp;= x_{1:d} \\
y_{d+1:D} &amp;= x_{d+1:D} \odot \exp(s_\theta(x_{1:d})) + t_\theta(x_{1:d})
\end{align*}$$</p>
<p>Affine coupling layer는 hidden state를 반으로 나눠 한 쪽을 유지한 채, 나머지 반에 다른 반을 기반으로 affine transform을 가한다. 이는 가역 연산으로, 절반의 원본을 통해 다른 절반의 역연산이 가능하며, 연산 복잡도 역시 순연산과 동일하다.</p>
<p>$$\begin{align*}
x&rsquo;_{1:d} &amp;= y _{1:d} \\
x&rsquo; _{d+1:D} &amp;= (y _{d+1:D} - t _\theta(y _{1:d})) \odot \exp(-s _\theta(y _{1:d}))
\end{align*}$$</p>
<p>Affine coupling layer의 Jacobian matrix는 $y_{1:d}$와 $x_{1:d}$가 identity mapping이기에 identity matrix를 형성, $y_{1:d}$는 $x_{d+1:D}$에 dependent 하지 않기 때문에 zeroing out 되고, $y_{d+1:D}$와 $x_{d+1:D}$는 element-wise linear 관계로 diagonal matrix가 되어, 최종 low triangular block matrix의 형태로 구성된다. 이 경우 determinant는 별도의 matrix transform을 거치지 않고 대각 원소의 곱으로 곧장 연산해 낼 수 있다.</p>
<p>$$\begin{align*}
\frac{\partial y}{\partial x} &amp;= \left[\begin{matrix}
\mathbb I_d &amp; 0 \\
\frac{\partial y_{d+1:D}}{\partial x_{1:d}} &amp; \mathrm{diag}[\exp(s(x_{1:d}))]
\end{matrix}\right] \\
\det\frac{\partial y}{\partial x} &amp;= \prod_{i=d+1}^D \exp(s_i(x_{1:d})) = \exp\left(\sum^D_{i=d+1}s_i(x_{1:d})\right)
\end{align*}
$$</p>
<p>Affine coupling layer를 여러 개 쌓아 $f_2(f_1(z))$의 형태로 표현한다면, 역함수는 $f_1^{-1}(f_2^{-1}(x))$로 네트워크를 출력부부터 역순으로 연산해 나가면 되고, determinant 역시 각각 계산하여 곱하여 구할 수 있다.</p>
<p>$$\det\frac{\partial f_2}{\partial z} = \det\frac{\partial f_2}{\partial f_1}\frac{\partial f_1}{\partial z} = \left(\det \frac{\partial f_2}{\partial f_1}\right)\left(\det\frac{\partial f_1}{\partial z}\right)$$</p>
<p>다만 이 경우 한쪽에만 연산이 가해지는 형태이기에, Coupling layer 이후 shuffling $[y_{1:d}, y_{d+1:D}] = [x_{d+1:D}, x_{1:d}]$를 수행하여 각각의 청크가 모두 transform 될 수 있도록 구성한다.</p>
<p>$$\begin{align*}
\max_\theta \log p_{\theta, X}(x) &amp;= \max_\theta \left[\log p_Z(f_\theta^{-1}(x)) + \log\left|\det\frac{\partial f_\theta^{-1}(x)}{\partial x}\right|\right] \\
&amp;= \max_\theta \left[\log p_Z(f_\theta^{-1}(z)) - \exp\left(\sum^L_{l=1}\sum^D_{i=d+1}s^l_{\theta,i}(x^l_{1:d})\right)\right]
\end{align*}$$</p>
<p>L개 affine coupling layer w/shuffling으로 구성된 네트워크 $f_\theta$의 최종 objective는 위와 같다.</p>
<p>Normalzing Flow는 Network의 형태를 제약함으로 Generation과 함께 exact likelihood를 구할 수 있게 되었고, 별도의 Encoder 없이 posterior를 구할 수 있다는 장점이 있다.</p>
<p>하지만 반대로, 네트워크의 형태에 제약을 가하기에 발생하는 approximation의 한계가 발생할 수 있다. 자세한 내용은 뒤에서 논의한다.</p>
<hr>
<ul>
<li>Glow: Generative Flow and Invertible 1x1 Convolutions, Kingma &amp; Dhariwal, 2018. [<a href="https://arxiv.org/abs/1807.03039">arXiv:1807.03039</a>]</li>
</ul>
<p>Glow는 이에서 더 나아가, 256x256 크기의 이미지까지 연구를 확장하여 그 실용성을 보였다.</p>
<p>기본적으로 가역 함수와 치환 법칙을 기저로 하며, RealNVP에서 몇 가지 네트워크 구조를 수정하였다.</p>
<p>가장 먼저 Batch Normalization을 Activation Normalization으로 교체한다. 당시 GPU VRAM은 10GB (1080TI, 2080TI) 정도로, 이미지의 크기가 조금만 커져도 배치의 크기를 1~2까지로 줄여나가야 했다. 이러한 상황에서 BN의 Moving statistics는 noisy 했고, 성능 하락을 감안해야 했다.</p>
<p>이에 Glow는 최초 Forward pass에서 normalization 직전 레이어의 평균과 표준편차를 연산하여 저장해두고, 이를 토대로 normalization을 수행한다. 한 번 초기화된 파라미터는 이후 별도의 이동 평균 처리나 통계치 재연산을 수행하지 않고, 일반적인 trainable constant로 여긴다. 이를 data-dependent initalization이라 하고, 위 정규화 레이어를 activation normalization이라 한다.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#998;font-style:italic"># PSEUDO CODE OF DATA-DEPENDENT INITIALIZATION</span>
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0086b3">super</span>()<span style="color:#000;font-weight:bold">.</span>__init__()
</span></span><span style="display:flex;"><span>    <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>mean, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>logstd <span style="color:#000;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">None</span>, <span style="color:#000;font-weight:bold">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">forward</span>(<span style="color:#999">self</span>, x: Tensor) <span style="color:#000;font-weight:bold">-&gt;</span> <span style="color:#0086b3">tuple</span>[Tensor, Tensor]:
</span></span><span style="display:flex;"><span>    <span style="color:#998;font-style:italic"># x: [B, C, H, W]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">if</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>mean <span style="color:#000;font-weight:bold">is</span> <span style="color:#000;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#000;font-weight:bold">with</span> no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>register_parameter(
</span></span><span style="display:flex;"><span>                <span style="color:#d14">&#34;mean&#34;</span>,
</span></span><span style="display:flex;"><span>                nn<span style="color:#000;font-weight:bold">.</span>Parameter(x<span style="color:#000;font-weight:bold">.</span>mean(dim<span style="color:#000;font-weight:bold">=</span>[<span style="color:#099">0</span>, <span style="color:#099">2</span>, <span style="color:#099">3</span>], keepdim<span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">True</span>)),
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>            <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>register_parameter(
</span></span><span style="display:flex;"><span>                <span style="color:#d14">&#34;logstd&#34;</span>,
</span></span><span style="display:flex;"><span>                nn<span style="color:#000;font-weight:bold">.</span>Parameter(x<span style="color:#000;font-weight:bold">.</span>std(dim<span style="color:#000;font-weight:bold">=</span>[<span style="color:#099">0</span>, <span style="color:#099">2</span>, <span style="color:#099">3</span>], keepdim<span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">True</span>)<span style="color:#000;font-weight:bold">.</span>log()),
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>    norm <span style="color:#000;font-weight:bold">=</span> (x <span style="color:#000;font-weight:bold">-</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>mean) <span style="color:#000;font-weight:bold">*</span> (<span style="color:#000;font-weight:bold">-</span><span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>logstd)<span style="color:#000;font-weight:bold">.</span>exp()
</span></span><span style="display:flex;"><span>    logdet <span style="color:#000;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">-</span><span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>logstd
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">return</span> norm, logdet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">inverse</span>(<span style="color:#999">self</span>, y: Tensor) <span style="color:#000;font-weight:bold">-&gt;</span> Tensor:
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">assert</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>mean <span style="color:#000;font-weight:bold">is</span> <span style="color:#000;font-weight:bold">not</span> <span style="color:#000;font-weight:bold">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">return</span> y <span style="color:#000;font-weight:bold">*</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>logstd<span style="color:#000;font-weight:bold">.</span>exp() <span style="color:#000;font-weight:bold">+</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>mean
</span></span></code></pre></div><p>ActNorm은 첫 배치에서 zero-mean, unit-variance의 feature map을 반환하여 학습을 안정화하고, 이후는 학습에 따라 자연스레 값을 바꿔나간다. 배치 크기에 영향을 상대적으로 덜 받고, 이러한 형태의 DDI는 Weight normalization[<a href="https://arxiv.org/abs/1602.07868">Salimans &amp; Kingma, 2016.</a>]에서 효과가 확인된 바 있다.</p>
<p>다음은 Invertible 1x1 convolution이다. RealNVP는 Shuffling을 통해 절반의 feature map에 연산이 가해지지 않던 문제를 해결했다면, Glow는 가역 행렬을 channel-axis에 곱함으로(1x1 conv), 채널 축의 정보 공유를 학습 가능하도록 두었다(generalized permutation).</p>
<p>우선 초기화 단계에서 QR 분해를 통해 1x1 Convolution의 Random weight matrix W가 invertible 하게 두었고, 이후에는 $\log|\det W|$를 직접 연산하여 objective에 활용(<code>torch.linalg.slogdet</code>), inference에는 weight의 역행렬을 구하여 활용한다(<code>torch.linalg.inv</code>).</p>
<p>다만 이 경우 channel-axis의 크기가 커질 경우 연산량에 부담이 생길 수 있으므로, 다음과 같이 LU Decomposition을 활용하여 연산량을 줄여볼 수도 있다.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>, channels: <span style="color:#0086b3">int</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0086b3">super</span>()<span style="color:#000;font-weight:bold">.</span>__init__()
</span></span><span style="display:flex;"><span>    weight, _ <span style="color:#000;font-weight:bold">=</span> torch<span style="color:#000;font-weight:bold">.</span>linalg<span style="color:#000;font-weight:bold">.</span>qr(torch<span style="color:#000;font-weight:bold">.</span>randn(channels, channels))
</span></span><span style="display:flex;"><span>    p, l, u <span style="color:#000;font-weight:bold">=</span> torch<span style="color:#000;font-weight:bold">.</span>linalg<span style="color:#000;font-weight:bold">.</span>lu(weight)
</span></span><span style="display:flex;"><span>    <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>p <span style="color:#000;font-weight:bold">=</span> nn<span style="color:#000;font-weight:bold">.</span>Parameter(p)
</span></span><span style="display:flex;"><span>    <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>l <span style="color:#000;font-weight:bold">=</span> nn<span style="color:#000;font-weight:bold">.</span>Parameter(l)
</span></span><span style="display:flex;"><span>    <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>u <span style="color:#000;font-weight:bold">=</span> nn<span style="color:#000;font-weight:bold">.</span>Parameter(u)
</span></span><span style="display:flex;"><span>    <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>s <span style="color:#000;font-weight:bold">=</span> nn<span style="color:#000;font-weight:bold">.</span>Parameter(torch<span style="color:#000;font-weight:bold">.</span>diagonal(u))
</span></span><span style="display:flex;"><span>    <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>register_buffer(<span style="color:#d14">&#34;i&#34;</span>, torch<span style="color:#000;font-weight:bold">.</span>eye(channels), persistent<span style="color:#000;font-weight:bold">=</span><span style="color:#000;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#3c5d5d;font-weight:bold">@property</span>
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">weight</span>(<span style="color:#999">self</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">return</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>p <span style="color:#000;font-weight:bold">@</span> (<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>l<span style="color:#000;font-weight:bold">.</span>tril(<span style="color:#000;font-weight:bold">-</span><span style="color:#099">1</span>) <span style="color:#000;font-weight:bold">+</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>i) <span style="color:#000;font-weight:bold">@</span> (<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>u<span style="color:#000;font-weight:bold">.</span>triu(<span style="color:#099">1</span>) <span style="color:#000;font-weight:bold">+</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>s)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">forward</span>(<span style="color:#999">self</span>, x: torch<span style="color:#000;font-weight:bold">.</span>Tensor) <span style="color:#000;font-weight:bold">-&gt;</span> <span style="color:#0086b3">tuple</span>[torch<span style="color:#000;font-weight:bold">.</span>Tensor, torch<span style="color:#000;font-weight:bold">.</span>Tensor]:
</span></span><span style="display:flex;"><span>    b, c, h, w <span style="color:#000;font-weight:bold">=</span> x<span style="color:#000;font-weight:bold">.</span>shape
</span></span><span style="display:flex;"><span>    shuffled <span style="color:#000;font-weight:bold">=</span> F<span style="color:#000;font-weight:bold">.</span>conv2d(x, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>weight[<span style="color:#000;font-weight:bold">...</span>, <span style="color:#000;font-weight:bold">None</span>, <span style="color:#000;font-weight:bold">None</span>])
</span></span><span style="display:flex;"><span>    logdet <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>s<span style="color:#000;font-weight:bold">.</span>abs()<span style="color:#000;font-weight:bold">.</span>log()<span style="color:#000;font-weight:bold">.</span>sum() <span style="color:#000;font-weight:bold">*</span> h <span style="color:#000;font-weight:bold">*</span> w
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">return</span> shuffled, logdet
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">inverse</span>(<span style="color:#999">self</span>, y: torch<span style="color:#000;font-weight:bold">.</span>Tensor) <span style="color:#000;font-weight:bold">-&gt;</span> torch<span style="color:#000;font-weight:bold">.</span>Tensor:
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">return</span> F<span style="color:#000;font-weight:bold">.</span>conv2d(x, torch<span style="color:#000;font-weight:bold">.</span>linalg<span style="color:#000;font-weight:bold">.</span>inv(<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>weight)[<span style="color:#000;font-weight:bold">...</span>, <span style="color:#000;font-weight:bold">None</span>, <span style="color:#000;font-weight:bold">None</span>])
</span></span></code></pre></div><p>마지막으로 affine coupling layer의 두 개 네트워크 $t_\theta, s_\theta$의 마지막 convolution 레이어를 zero-initialize하여 학습의 첫 forward pass에서는 identity mapping이 되도록 구성하였다. 이는 LayerScale[<a href="https://arxiv.org/abs/2103.17239">Touvron et al., 2021.</a>]처럼 레이어가 많은 네트워크를 운용할 때 학습을 안정화한다고 알려져 있다.</p>
<p>이러한 트릭을 활용하여 Glow는 256x256 이미지에서도 좋은 합성 결과를 보였고, 아직도 likelihood 기반의 새로운 학습 방법론이 소개될 때마다 베이스라인으로 인용되고 있다.</p>
<hr>
<ul>
<li>CIF: Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows, Cornish et al., 2019. [<a href="https://arxiv.org/pdf/1909.13833">arXiv:1909.13833</a>]</li>
</ul>
<p>앞서 이야기한 Bijective의 제약에 의해 발생하는 Approximation의 한계에 관하여 이야기해 보고자 한다.</p>
<p>Normalizing flows는 대표적인 pushforward measure이다.</p>
<p>i.e. measurable space $(Z, \Sigma_Z, \mu_Z)$, $(X, \Sigma_X)$와 measurable mapping $f: Z \to X$에 대해 $f_\# p_Z = p_Z(f^{-1}(B)); B \in \Sigma_X$를 Pushforward measure라 한다. (w/sigma algebra $\Sigma_Z, \Sigma_X$ of $Z, X$)</p>
<p>Normalizing flows는 특히 generator $f$를 전단사함수로 가정하기 때문에, $\mathrm{supp}\ p_X$와 $\overline{f(\mathrm{supp}\ p_Z)}$가 같아야 한다. i.e. support of $p_X$, $\mathrm{supp}\ p_X = \{x \in X : \forall \mathrm{open}\ U \ni x,\ p_X(U) \ge 0 \}$</p>
<p>FYI. 직관적으로 support는 사건의 발생 확률이 0보다 큰 원소의 집합이다. 확률이 존재하는 공간을 전단사 함수로 대응하였을 때, 대응된 원소 역시 발생 가능성이 0보다 커야 함을 의미한다.</p>
<p>RealNVP, Glow 등의 Normlizing flows는 대부분 연속 함수이다(tanh, relu, sigmoid 등의 연속 활성함수를 사용하는 네트워크 기반의 affine coupling을 가정). 동시에 전단사 함수이기 때문에 역함수 역시 연속 함수이고, 이 경우 $f$는 topological property를 보존하는 homeomorphism이다(위상 동형 사상).</p>
<p>$Z$와 $X$의 hole의 수, connected component의 수 등이 같아야 한다는 것이다. 흔히 가정하는 정규 분포의 support는 hole을 가지지 않고, 1개의 connected components를 가진다. 만약 데이터의 분포가 두 Truncate Normal 분포의 mixture로 표현되어, 그의 support가 2개의 connected components를 가진다면 연속 함수 형태의 normalizing flows를 construction 하는 것에는 한계가 발생한다.</p>
<p>원소 단위의 Exact support matching을 보장하지는 못하더라도, Normalizing flows는 대개 좋은 분포 근사를 보이기도 한다.</p>
<p>경우에 따라 Invertible ResNet[<a href="https://arxiv.org/abs/1811.00995">Behrmann et al., 2018.</a>], Residual Flow[<a href="https://arxiv.org/abs/1906.02735">Chen et al., 2019.</a>]는 invertibility를 위해 network에 lipschitz constant를 제약하는데, 이 과정에서 또 다른 문제가 발생한다.</p>
<p>Injective $f$에 대해 bi-Lipschitz constant $\mathrm{BiLip}\ f = \max\left(\sup_{z\in Z}|J_{f(z)}|, \sup_{x\in f(Z)}|J_{f^{-1}(x)}|\right)$를 정의하자. homeomorphic하지 않은 두 topological space $Z$와 $X$는 $\lim_{n\to\infty}\mathrm{BiLip}\ f_n = \infty$일 때에만 $f_{n}\#p_Z \stackrel{D}{\to}p_X$의 weak convergence under statistical divergence $D$를 만족한다.</p>
<p>결국 Lipschitz Constant가 제약된 네트워크는 weak convergence를 보장받지 못할 수도 있는 것이다.</p>
<p>Normalizing flows는 네트워크의 제약상 고질적으로 Exact support matching 문제와 Lipschitz-constrained network의 수렴성 문제를 겪게 된다. Continuously Indexed Flow, CIF는 이를 해결하고자 augmented normalizing flows를 제안한다.</p>
<p>TBD</p>
<hr>
<ul>
<li>FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models, Grathwohl et al., 2018.  [<a href="https://arxiv.org/abs/1810.01367">arXiv:1810.01367</a>]</li>
</ul>
<p>TBD</p>
<p><strong>References</strong></p>
<ul>
<li>VAE: Auto-Encoding Variational Bayes, Kingma &amp; Welling, 2013. [<a href="https://arxiv.org/abs/1312.6114">arXiv:1312.6114</a>]</li>
<li>GAN: Generative Adversarial Networks, Goodfellow et al., 2014. [<a href="https://arxiv.org/abs/1406.2661">arXiv:1406.2661</a>]</li>
<li>DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [<a href="https://arxiv.org/abs/2006.11239">arXiv:2006.11239</a>]</li>
<li>Flow Matching for Generative Modeling, Lipman et al., 2022. [<a href="https://arxiv.org/abs/2210.02747">arXiv:2210.02747</a>]</li>
<li>NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat &amp; Kautz, 2020. [<a href="https://arxiv.org/abs/2007.03898">arXiv:2007.03898</a>]</li>
<li>RealNVP: Density estimation using Real NVP, Dinh et al., 2016. [<a href="https://arxiv.org/abs/1605.08803">arXiv:1605.08803</a>]</li>
<li>Glow: Generative Flow and Invertible 1x1 Convolutions, Kingma &amp; Dhariwal, 2018. [<a href="https://arxiv.org/abs/1807.03039">arXiv:1807.03039</a>]</li>
<li>NODE: Neural Ordinary Differential Equations, Chen et al., 2018. [<a href="https://arxiv.org/abs/1806.07366">arXiv:1806.07366</a>]</li>
<li>NCSN: Generative Modeling by Estimating Gradients of the Data Distribution, Song &amp; Ermon, 2019. [<a href="https://arxiv.org/abs/1907.05600">arXiv:1907.05600</a>]</li>
<li>Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., 2020. [<a href="https://arxiv.org/abs/2011.13456">arXiv:2011.13456</a>]</li>
<li>DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [<a href="https://arxiv.org/abs/2006.11239">arXiv:2006.11239</a>]</li>
<li>DDIM: Denoising Diffusion Implicit Models, Song et al., 2020. [<a href="https://arxiv.org/abs/2010.02502">arXiv:2010.02502</a>]</li>
<li>Rectified Flow: Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow, Liu et al., 2022. [<a href="https://arxiv.org/abs/2209.03003">arXiv:2209.03003</a>]</li>
<li>Flow Matching for Generative Modeling, Lipman et al., 2022. [<a href="https://arxiv.org/abs/2210.02747">arXiv:2210.02747</a>]</li>
<li>Consistency Models, Song et al., 2023. [<a href="https://arxiv.org/abs/2303.01469">arXiv:2303.01469</a>]</li>
<li>Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models, Lu &amp; Song, 2024. [<a href="https://arxiv.org/abs/2410.11081">arXiv:2410.11081</a>]</li>
<li>DSBM: Diffusion Schrodinger Bridge Matching, Shi et al., 2023. [<a href="https://arxiv.org/abs/2303.16852">arXiv:2303.16852</a>]</li>
<li>VDVAE: Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images, Child, 2020. [<a href="https://arxiv.org/abs/2011.10650">arXiv:2011.10650</a>]</li>
<li>StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Karras et al., 2018. [<a href="https://arxiv.org/abs/1812.04948">arXiv:1812.04948</a>]</li>
<li>StyleGAN2: Analyzing and Improving the Image Quality of StyleGAN, Karras et al., 2019. [<a href="https://arxiv.org/abs/1912.04958">arXiv:1912.04958</a>]</li>
<li>Squeeze-and-Excitation Networks, Hu et al., 2017. [<a href="https://arxiv.org/abs/1709.01507">arXiv:1709.01507</a>]</li>
<li>CIF: Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows, Cornish et al., 2019. [<a href="https://arxiv.org/pdf/1909.13833">arXiv:1909.13833</a>]</li>
<li>FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models, Grathwohl et al., 2018. [<a href="https://arxiv.org/abs/1810.01367">arXiv:1810.01367</a>]</li>
<li>Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks, Salimans &amp; Kingma, 2016. [<a href="https://arxiv.org/abs/1602.07868">arXiv:1602.07868</a>]</li>
<li>LayerScale: Going deeper with Image Transformers, Touvron et al., 2021. [<a href="https://arxiv.org/abs/2103.17239">arXiv:2103.17239</a>]</li>
<li>Invertible Residual Networks, Behrmann et al., 2018. [<a href="https://arxiv.org/abs/1811.00995">arXiv:1811.00995</a>]</li>
<li>Residual Flows for Invertible Generative Modeling, Chen et al., 2019. [<a href="https://arxiv.org/abs/1906.02735">arXiv:1906.02735</a>]</li>
</ul>
<hr>
<details>
    <summary>TODO</summary>
    <ol start="0">
<li>Preliminaries</li>
</ol>
<p>Oksendal SDE</p>
<ul>
<li>Brownian Motion Model</li>
<li>Ito process</li>
<li>Ito Diffusion, Markovian Property</li>
</ul>
<p>Neural ODE</p>
<ul>
<li>Neural Ordinary Differential Equations, Chen et al., 2018. <a href="https://arxiv.org/abs/1806.07366">https://arxiv.org/abs/1806.07366</a></li>
</ul>
<ol>
<li>Score model</li>
</ol>
<ul>
<li>Generative Modeling by Estimating Gradients of the Data Distribution, Song &amp; Ermon, <a href="https://arxiv.org/abs/1907.05600">https://arxiv.org/abs/1907.05600</a></li>
<li>Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., <a href="https://arxiv.org/abs/2011.13456">https://arxiv.org/abs/2011.13456</a></li>
</ul>
<ol start="2">
<li>DDPM</li>
</ol>
<ul>
<li>Denoising Diffusion Probabilistic Models, Ho et al., 2020. <a href="https://arxiv.org/abs/2006.11239">https://arxiv.org/abs/2006.11239</a>, <a href="https://revsic.github.io/blog/diffusion/">https://revsic.github.io/blog/diffusion/</a></li>
<li>Diffusion Models Beat GANs on Image Synthesis, Dhariwal &amp; Nichol, 2021. <a href="https://arxiv.org/abs/2105.05233">https://arxiv.org/abs/2105.05233</a></li>
<li>Variational Diffusion Models, Kingma et al., 2021. <a href="https://arxiv.org/abs/2107.00630">https://arxiv.org/abs/2107.00630</a>, <a href="https://revsic.github.io/blog/vdm/">https://revsic.github.io/blog/vdm/</a></li>
<li>Denoising Diffusion Implicit Models, Song et al., 2020. <a href="https://arxiv.org/abs/2010.02502">https://arxiv.org/abs/2010.02502</a></li>
<li>Classifier-Free Diffusion Guidance, Ho &amp; Salimans, 2022. <a href="https://arxiv.org/abs/2207.12598">https://arxiv.org/abs/2207.12598</a></li>
<li>[Blog] Essay: VAE as a 1-step Diffusion Model
, <a href="https://revsic.github.io/blog/1-step-diffusion/">https://revsic.github.io/blog/1-step-diffusion/</a></li>
</ul>
<ol start="3">
<li>SDE &amp; PF ODE</li>
</ol>
<ul>
<li>Score-Based Generative Modeling through Stochastic Differential Equations, Song et al., 2020. <a href="https://arxiv.org/abs/2011.13456">https://arxiv.org/abs/2011.13456</a></li>
</ul>
<ol start="4">
<li>Rectified Flow &amp; Flow Matching</li>
</ol>
<ul>
<li>Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow, Liu et al., 2022. <a href="https://arxiv.org/abs/2209.03003">https://arxiv.org/abs/2209.03003</a></li>
<li>Flow Matching for Generative Modeling, Lipman et al., 2022. <a href="https://arxiv.org/abs/2210.02747">https://arxiv.org/abs/2210.02747</a></li>
<li>Simple ReFlow: Improved Techniques for Fast Flow Models, Kim et al., 2024. <a href="https://arxiv.org/abs/2410.07815s">https://arxiv.org/abs/2410.07815s</a></li>
<li>Improving the Training of Rectified Flows, Lee et al., 2024. <a href="https://arxiv.org/abs/2405.20320">https://arxiv.org/abs/2405.20320</a></li>
</ul>
<ol start="5">
<li>Consistency Models</li>
</ol>
<ul>
<li>Consistency Models, Song et al., 2023. <a href="https://arxiv.org/abs/2303.01469">https://arxiv.org/abs/2303.01469</a>, <a href="https://revsic.github.io/blog/cm/">https://revsic.github.io/blog/cm/</a></li>
<li>Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples, Vouitsis et al., 2024. <a href="https://arxiv.org/abs/2411.08954">https://arxiv.org/abs/2411.08954</a></li>
<li>Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models, Lu &amp; Song, 2024. <a href="https://arxiv.org/abs/2410.11081">https://arxiv.org/abs/2410.11081</a></li>
</ul>
<ol start="6">
<li>Bridge</li>
</ol>
<ul>
<li>Diffusion Schrodinger Bridge Matching, Shi et al., 2023. <a href="https://arxiv.org/abs/2303.16852">https://arxiv.org/abs/2303.16852</a></li>
</ul>
<ol start="7">
<li>Furthers
Unified view</li>
</ol>
<ul>
<li>SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows, Nielsen et al., 2020. <a href="https://arxiv.org/abs/2007.02731">https://arxiv.org/abs/2007.02731</a>, <a href="https://revsic.github.io/blog/survaeflow/">https://revsic.github.io/blog/survaeflow/</a></li>
<li>Simulation-Free Training of Neural ODEs on Paired Data, Kim et al., 2024. <a href="https://arxiv.org/abs/2410.22918">https://arxiv.org/abs/2410.22918</a></li>
<li>Simulation-Free Differential Dynamics through Neural Conservation Laws, Hua et al., ICLR 2025. <a href="https://openreview.net/forum?id=jIOBhZO1ax">https://openreview.net/forum?id=jIOBhZO1ax</a></li>
</ul>
<p>Fewer-step approaches</p>
<ul>
<li>Progressive Distillation for Fast Sampling of Diffusion Models, Salimans &amp; Ho, 2022. <a href="https://arxiv.org/abs/2202.00512">https://arxiv.org/abs/2202.00512</a></li>
<li>Tackling the Generative Learning Trilemma with Denoising Diffusion GANs, Xiao et al., 2021.</li>
<li>InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation, Liu et al., 2023. <a href="https://arxiv.org/abs/2309.06380">https://arxiv.org/abs/2309.06380</a></li>
<li>One Step Diffusion via Shortcut Models, Frans et al,. 2024. <a href="https://arxiv.org/abs/2410.12557">https://arxiv.org/abs/2410.12557</a></li>
</ul>
<p>Velocity consistency</p>
<ul>
<li>
<p>Rectified Diffusion: Straightness Is Not Your Need in Rectified Flow, Want et al., 2024. <a href="https://arxiv.org/abs/2410.07303">https://arxiv.org/abs/2410.07303</a></p>
</li>
<li>
<p>Consistency Flow Matching: Defining Straight Flows with Velocity Consistency, Yang et al., 2024. <a href="https://arxiv.org/abs/2407.02398">https://arxiv.org/abs/2407.02398</a></p>
</li>
<li>
<p>[Blog] Essay: Generative models, Mode coverage, <a href="https://revsic.github.io/blog/coverage/">https://revsic.github.io/blog/coverage/</a></p>
</li>
</ul>

</details>

        </div>

        
        
      </div>
    </div>
  </div>
</section>

<footer>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center mb-5">
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark" href="tel:"><i
                class="ti-mobile mr-3 text-primary"></i></a></li>
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>Seoul, Korea</li>
          <li class="mb-3"><a class="text-dark" href="mailto:revsic99@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>revsic99@gmail.com</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://www.facebook.com/profile.php?id=100009484787654">facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://github.com/revsic">github</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.linkedin.com/in/young-joong-kim-878630154/">linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/attention">Attention</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/bayesian">Bayesian</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/generative">Generative</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/portfolio">Portfolio</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/software-testing">Software testing</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/vocoder">Vocoder</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/writing">Writing</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="/about">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="/blog">Post</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2020 <a href="https://revsic.github.io">YoungJoong Kim</a> All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "/index.json"
</script>

<!-- JS Plugins -->

<script src="/plugins/jQuery/jquery.min.js"></script>

<script src="/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/plugins/slick/slick.min.js"></script>

<script src="/plugins/venobox/venobox.min.js"></script>

<script src="/plugins/search/fuse.min.js"></script>

<script src="/plugins/search/mark.js"></script>

<script src="/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="/js/script.min.js"></script>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$']],
    }
  }
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.4/tex-mml-chtml.js"></script>
</body>
</html>