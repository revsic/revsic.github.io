<!DOCTYPE html>
<html lang="ko-kr"><head>
  <meta charset="utf-8">
  <title>revsic | ML Developer</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Rewriting a Deep Generative Model, David Bau et al., 2020.">
  <meta name="author" content="YoungJoong Kim">
  <meta name="generator" content="Hugo 0.67.0" />

  <!-- plugins -->
  
  <link rel="stylesheet" href="/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="/plugins/venobox/venobox.css ">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="/scss/style.min.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="/images/favicon.png " type="image/x-icon">
  <link rel="icon" href="/images/favicon.png " type="image/x-icon">

</head><body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom">
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.facebook.com/profile.php?id=100009484787654"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://github.com/revsic"><i class="ti-github"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.linkedin.com/in/young-joong-kim-878630154/"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://revsic.github.io"> Home </a>
          </li>
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/blog">Post</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search px-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://revsic.github.io/search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/generative"
          class="text-primary">Generative</a>
        
        <h2>Rewriting a Deep Generative Model</h2>
        <div class="mb-3 post-meta">
          <span>By YoungJoong Kim</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>01 September 2020</span>
          
        </div>
        
        <img src="/images/post/rewriting/1.jpg" class="img-fluid w-100 mb-4" alt="Rewriting a Deep Generative Model">
        
        <div class="content mb-5">
          <ul>
<li>David Bau et al., 2020, <a href="https://arxiv.org/abs/2007.15646">arXiv</a></li>
<li>Keyword: Generative, Adversarial learning</li>
<li>Problem: How to manipulate specific rules encoded by a deep generative model.</li>
<li>Solution: Projected gradient descent for adding rules to convolution of associative memory.</li>
<li>Benefits: Enable users to synthesize edited new images by manipulating model only once.</li>
<li>Contribution: Providing a new perspective of associative memory, rule manipulating method of projected gradient descent.</li>
<li>Weakness or Future work: -</li>
</ul>
<p><strong>Generative model</strong></p>
<p>생성 모델은 데이터의 분포를 학습하면서 여러 가지 규칙이나 관계를 만들어 나간다. 간단한 예로 ProgressiveGAN[1]이 만든 주방 이미지에서는 창문에서 오는 빛을 테이블에 반사시키는 경향이 있다.</p>
<figure>
    <img src="/images/post/rewriting/2.jpg"
         alt="Fig. 6: Inverting a single semantic rule within a model" width="100%"/> <figcaption>
            <p>Fig. 6: Inverting a single semantic rule within a model</p>
        </figcaption>
</figure>

<p>저자는 만약 이러한 규칙들을 직접 분석하여 수정할 수 있다면, 생성 모델 자체를 manipulating 하는 것이고, 이는 생성된 이미지를 각각 수정하는 것보다 효율적으로 수정된 이미지를 생성할 수 있다고 이야기 한다.</p>
<p>이를 위해서 우리는 생성 모델이 어떤 정보를 캡처하고 있고, 어떻게 unseen scenario에 대해 일반화 하고 있는지 알아야 한다.</p>
<p>현재 생성 모델들은 인간이 직접 라벨링 한 대규모의 데이터셋에 기반을 두고 있는데, 만약 manipulating 과정에서도 이러한 다량의 데이터와 학습이 추가로 필요하다면, 이는 손으로 생성된 이미지를 직접 수정하는 것과 큰 차이가 없을 것이다.</p>
<p>이에 우리는 단 몇 개의 샘플 데이터와 간단한 optimization을 통해 모델을 manipulation 할 수 있어야 하고, 이 모델은 우리가 원하는 rule을 캡처하여 unseen data에 대한 일반화를 할 수 있어야 한다.</p>
<p>저자는 이를 위해 sequential 하게 구성된 nonlinear convolutional generator를 associative memory라는 관점으로 해석하고, 전체 레이어가 아닌 단 하나의 레이어에 constrained optimization을 진행하여 기존의 semantic rule을 보존하면서, 우리가 원하는 rule을 추가할 수 있는 방법론을 제시한다.</p>
<p><strong>Preview</strong></p>
<p>pretrain된 generator $G(\cdot; \theta_0)$가 주어질 때, 모델은 각각의 latent $z_i$에 대해 $x_i = G(z_i; \theta_0)$의 output을 만들어 낸다. 만약 우리가 copy&amp;paste 방식으로 변화를 준 output $x_{*i}$을 통해 새로운 rule을 표현한다면, rule의 표현 중 가장 직관적인 방법일 것이다.</p>
<figure>
    <img src="/images/post/rewriting/3.jpg"
         alt="Fig. 3: The Copy-Paste-Context interface for rewriting a model." width="100%"/> <figcaption>
            <p>Fig. 3: The Copy-Paste-Context interface for rewriting a model.</p>
        </figcaption>
</figure>

<p>이때 하고자 하는 것은 새로운 rule을 따르는 $\theta_1$을 만드는 것이고, 이는 $x_{*i} \approx G(z_i; \theta_1)$을 만족할 것이다.</p>
<p>$\theta_1 = \arg\min_\theta \mathcal L_{\mathrm{smooth}}(\theta) + \lambda \mathcal L_\mathrm{constraint}(\theta)$</p>
<p>$\mathcal L_\mathrm{smooth}(\theta) \overset{\Delta}{=} \mathbb E_z[\mathcal l(G(z; \theta_0), G(z; \theta))]$</p>
<p>$\mathcal L_\mathrm{constraint}(\theta) \overset{\Delta}{=} \sum_i \mathcal l(x_{*i}, G(z_i; \theta))$</p>
<p>고전적인 해결책은 generator의 전체 parameter set $\theta_0$를 두 가지 constraint에 맞게 gradient 기반의 optimization을 진행하는 것이다. 이때 $\mathcal l(\cdot)$은 perceptual distance를 의미한다.</p>
<p>하지만 이 경우 몇 개 되지 않는 sample에 overfit될 가능성이 농후하며 다른 데이터에 대해 일반화되지 않을 수 있다.</p>
<p>이에 저자는 두 가지 방법론을 제안한다. 하나는 전체 parameter set이 아닌 특정 한 layer의 weight만을 update하는 것이고, 하나는 optimization을 특정 constraint 내에서 진행하는 것이다.</p>
<p>특정 layer L과 L-1 layer까지의 feature map k를 가정할 때 L의 output은 $v = f(k; W_0)$가 된다. 원본 이미지의 latent $z_{i}$가 feature $k_{*i}$를 만들 때 $v_i = f(k_{*i}; W_0)$를 가정하고, 직접 수정한 output에 대응하는 feature map $v_{*i}$를 구할 수 있으면 objective는 다음과 같다.</p>
<p>$W_1 = \arg\min_W \mathcal L_{\mathrm{smooth}}(W) + \lambda \mathcal L_\mathrm{constraint}(W)$</p>
<p>$\mathcal L_\mathrm{smooth}(W) \overset{\Delta}{=} \mathbb E_z[|| f(k; W_0) - f(k; W)||^2]$</p>
<p>$\mathcal L_\mathrm{constraint}(W) \overset{\Delta}{=} \sum_i ||v_{*i} - f(k_{*i}; W)||^2$</p>
<p>perceptual distance는 higher semantic을 표현하는 feature map 사이의 l2-distance를 상정한다. 이때 W만으로도 parameter의 양이 충분히 많을 수 있기에, overfit을 제한하면서 더 나은 일반화를 위해 학습 방향을 고정할 필요가 있었고, 특정 direction으로만 optimization 되도록 constraint를 추가한 gradient descent를 사용하였다.</p>
<p><strong>Associative Memory</strong></p>
<p>저자는 preview의 방법론을 associative memory로부터 유도해 낸다.</p>
<p>어떤 key $k_i \in \mathbb R^N$와 value $v_i \in \mathbb R^M$의 mapping $\{ k_i \to v_i \}_{i \in I}$을 가정하자. 이때 $k_i$가 mutually orthonormal 하면 i와 j가 다를 때 $k_i^T k_j = 0$를 만족한다. matrix W를 $W = \sum_i v_i k_i^T \in \mathbb R^{M \times N}$ 로 정의하면 orthogonality에 의해 $Wk_i = v_i$가 성립한다. 이를 key-value association을 기록한 memory라 하여 associative memory라고 부르며, linear operation으로 구성되므로 linear associative memory라 할 수 있다.</p>
<p>저자의 이야기는 Convolution 또한 associative memory의 일종으로 볼 수 있다는 것이다. 흔히 생각하는 convolution은 window에 대해 pixel-wise weighted sum을 한 결과를 나열하는 operation이다. 이는 output의 한 pixel을 관점으로 convolution을 해석한 것이다.</p>
<p>반대로 input feature에 대해 해석하면 single feature $k \in \mathbb R^{B\times N}$에 weight matrix $W \in \mathbb R^{N \times (MHW)}$를 곱하고, BxMxHxW의 2D tensor로 reshape 하여 location-aware summation 한 것으로도 볼 수 있다.</p>
<p>이렇게 되면 convolution은 kernel을 matrix로 보고 key가 orthogonal 할 때 linear associative memory로 해석될 수 있다.</p>
<p><strong>Nonorthogonal Keys</strong></p>
<p>key는 $\mathbb R^N$의 vector이므로 최대 N개까지 orthogonal 할 수 있고, 더 많은 key-value pair를 기록하기 위해서는 $v_i \approx Wk_i$를 approximately equal한 조건을 취하여 error를 minimizing 하는 방식으로 구성한다.</p>
<p>$W_0 \overset{\Delta}{=} \arg \min_W \sum_i ||v_i - Wk_i||^2$</p>
<p>이때 $K \overset\Delta= [k_1|&hellip;|k_S] \in \mathbb R^{N\times S}$ 와 $V \overset\Delta= [v_1|&hellip;|v_S] \in \mathbb R^{M\times S}$ 로 가정하면 multiple nonorthogonal key, value pair에 대한 associative memory를 구성할 수 있다.</p>
<p>$W_0 = \arg\min_W \sum_i||V - WK||^2$</p>
<p>그리고 이는 least square solution $W_0KK^T = VK^T$와 pseudo-inverse $K^+$에 대해 $W_0 = VK^+$로 표현된다.</p>
<p><strong>What we want</strong></p>
<p>즉 pretrain을 통해 구한 $W_0$는 trainset에서 연산한 L-1까지의 feature map과 그에 대한 response를 key-value로 가정한 associative memory가 된다.</p>
<p>여기서 우리가 하고 싶은 것은 다음과 같다.</p>
<blockquote>
<p>user가 copy한 value와 paste한 지점의 key를 가져와 새로운 pair로 memory에 추가</p>
</blockquote>
<p>이렇게 되면 L-1까지의 feature map에서 key가 관측되었을 때 memory에서 새로운 value가 mapping 되어 해당 부분에 copy한 context가 이미지에 발현된다. Model manipulation을 하는 주요한 근거가 되는 것이다.</p>
<p>이를 표현하면 $W_1 = \arg\min_W ||V - WK||^2$와 $v_* = W_1k_*$를 만족 시키는 constrained least-square (CLS) problem으로 구성되고, 이의 해는 다음과 같이 정리된다.</p>
<p>$W_1KK^T = VK^T + \Lambda k_*^T$</p>
<p>$W_1KK^T = W_0KK^T + \Lambda k_*^T$</p>
<p>$W_1 = W_0 + \Lambda(C^{-1}k_*)^T$</p>
<p>이 때 $C \overset\Delta= KK^T$로 구성하면 key가 zero-mean일 때 covariance로 해석될 수 있다. 결국 $\Lambda \in \mathbb R^M$를 구하는 문제로 귀결된다. 여기서 $d \overset\Delta= C^{-1}k_*$로 가정하면 $W_1 = W_0 + \Lambda d^T$로 볼 수 있고, 풀이는 다음과 같다.</p>
<p>$\left[ \begin{array}{c|c} W_1 &amp; \Lambda \end{array} \right] \left[ \begin{array}{c|c} I &amp; k_* \\ \hline -d^T &amp; 0 \end{array} \right] = \left[ \begin{array}{c|c} W_0 &amp; v_* \end{array}\right]$</p>
<p>$\left[ \begin{array}{c|c} W_1 &amp; \Lambda \end{array} \right] = \left[ \begin{array}{c|c} W_0 &amp; v_* \end{array} \right] \left[ \begin{array}{c|c} I &amp; k_* \\ \hline -d^T &amp; 0 \end{array} \right]^{-1}$</p>
<p>여기서 주목할 점은 2가지이다.</p>
<ol>
<li>user requested mapping $k_* \to v_*$의 soft error-minimization objective가 d라는 straight-line을 따라 update해야 하는 hard constraint로 바뀜</li>
<li>direction d가 key에 의해서만 결정되고 value는 오직 user requested $v_*$가 $\Lambda$에 영향을 주는 방식 정도로만 작용함</li>
</ol>
<p>결국 구현체에서는 covariance C 정도를 미리 연산하여 caching 해두고, request가 올 때 direction과 $\Lambda$를 계산하는 방식으로 작동할 것이다.</p>
<p>preview의 수식을 다시 들고오면, $W_1 = \arg\min_W ||V-WK||^2$는 smoothness를 위한 loss, $v_* = W_1k_*$는 constraint를 위한 loss로 볼 수 있다. 그리고 이 둘의 solution이 d라는 direction으로 update된 $W_1$로 나온 것이다.</p>
<p><strong>Generalization</strong></p>
<p>위까지의 정리는 copy&amp;paste로 수정된 이미지에 대한 해당 layer와 그 전 layer의 response를 얻어와 key-value mapping을 구성할 수 있어야 한다. 하지만 SOTA를 이루고 있는 generative model들은 주로 gaussian noise에서 image로의 mapping을 확률적으로 학습하고 있기에, 수정된 이미지의 latent를 z-optimization을 통해 얻을 수 있어야 하고, 이 또한 rule이 크게 바뀐 경우에는 정확하지 않을 수 있다.</p>
<p>결국 paste가 이뤄진 image-level에서 distance를 측정해야 하고, 이 경우 neural net의 nonlinearity에 의해 선형성 가정이 깨지게 된다. 이에 neural generator를 다루는 입장이라면 위 방법론이 nonlinear 환경에서 일반화될 수 있어야 한다.</p>
<p>원문에서는 nonlinear mapping $f(k; W)$가 있을 떄 update policy가 W의 row-space에 sensitive하고, column-space에 insensitive 하므로 동일한 rank-1 update를 $f(k_*; W) \approx v_*$의 optimization constraint로 쓸 수 있다고 한다.</p>
<p>linear phase에서는 $\Lambda$를 linear system을 통해 풀었다면, nonlinear phase에서는 gradient 기반의 optimization이 필요하다. 이때 $\Lambda$는 requested value와 direction에 의존하는 변수이기 때문에 이를 objective로 하는 optimization을 진행한다.</p>
<p>$\Lambda_1 = \arg\min_{\Lambda \in \mathbb R^M}||v_* - f(k_*; W_0 + \Lambda d^T)||$</p>
<p>만약 requested key-value pair가 하나가 아닌 여럿이라면, rank-1 대신 low-rank optimization이 될 것이고, S개 pair에 대해 다음과 같이 표현할 수 있다.</p>
<p>$d_i = C^{-1}K_{*i}$</p>
<p>$D_S \overset\Delta= [d_1|&hellip;|d_S]$</p>
<p>$\Lambda_S = \arg\min_{\Lambda \in \mathrm R^{M \times S}} || V_* - f(K_*; W_0 + \Lambda D_S^T)||$</p>
<p>그리고 update는 $W_S = W_0 + \Lambda_S D_S^T$로 이뤄질 것이다.</p>
<p>마지막으로 이 조건을 좀 더 relax하면 $\arg\min_W ||V_* - f(K_*; W)||$를 optimizing하고, 대신 매 step 마다 W를 $W_0 + \Lambda_S D_S^T$의 subspace로 projection 하는 projected gradient descent를 취한다.</p>
<p><strong>Detail</strong></p>
<p>original repository <a href="https://github.com/davidbau/rewriting">rewriting</a>에서는 L-1까지의 feature map을 BxHWC로 reshape하여 <a href="https://github.com/davidbau/rewriting/blob/master/rewrite/ganrewrite.py#L83">collect_2nd_moment</a>에서 z-dataset을 기반으로 covariance를 미리 구해 놓는다.</p>
<p>이후 edit 요청이 들어오면 <a href="https://github.com/davidbau/rewriting/blob/master/rewrite/ganrewrite.py#L101">covariance_adjusted_query_key</a>에서 direction을 구하는데, C의 pseudoinverse를 구하는 대신 $CD_S = K_S$의 least square solution (torch.lstsq)을 풀어 computational stability를 얻었다고 한다.</p>
<p>이후 $D_{S}$를 직접 이용하는 것이 아닌 low-rank subspace의 basis를 구해 활용하며, <a href="https://github.com/davidbau/rewriting/blob/master/rewrite/ganrewrite.py#L333">multi_key_from_selection</a>에서는 ZCA와 SVD를 통해 eigen value가 큰 vector를 선출하고, 동일한 subspace를 구성하는 orthogonal basis로 변형하여 활용한다.</p>
<p>이후 <a href="https://github.com/davidbau/rewriting/blob/master/rewrite/ganrewrite.py#L254">insert</a>에서 parameter optimization을 진행한다.</p>
<p>weight은 subspace에 orthogonal 하게 변환하여 ortho_weight 변수에 저장해 둔다. 이는 <a href="https://github.com/davidbau/rewriting/blob/master/rewrite/ganrewrite.py#L806">projected_conv</a>을 활용하는데, 흔히 gram-schmidt orthogonalization에서 하는 것과 같이 basis에 정사형한 벡터를 원본에서 빼는 방식으로 진행한다.</p>
<p>$W_\mathrm{ortho} = W - (WU_{1:R})U_{1:R}^T \ \mathrm{where} \ C^{-1}K_S = U\Sigma V^T, \ \mathrm{lowrank} \ R$</p>
<p>이후 image-level distance를 L1으로 하는 optimization을 진행하고, 특정 스텝마다 weight을 subspace로 projection하여 ortho_weight에 더하는 방식으로 projected gradient descent를 구현한다.</p>
<p>이렇게 되면 optimization의 여파는 subspace 내에서만 구성되고, subspace에 orthogonal한 weight을 더함으로써 기존의 weight은 유지하고 subspace 내에서의 update만을 취할 수 있게 된다.</p>
<p>ZCA를 활용한 rank reduction은 원문의 Appendix. D.를 참고한다.</p>
<p><strong>Layer selection</strong></p>
<p>원문에서는 convolution layer를 neighbor와의 정보 취합으로 edge, texture, shape 등을 구별해 내는 관점보다는, 하나의 feature vector가 local patch가 되면서 주변과 disentangle 되는 관점을 취하였고, 이것이 memory model로 해석되었다.</p>
<p>원문에서는 실제로 ProgressiveGAN[1]과 StyleGANv2[2]의 일부 레이어에서 이런 feature 간 독립성을 띠고 있음을 보였다.</p>
<p>feature map을 MxN의 patch로 잘라 주변 정보 없이 적절한 크기의 output을 만들었을 때, 네트워크는 여전히 동일한 객체와 컨텍스트를 만들어 낼 수 있음을 보인다면, feature 간에 독립적인 정보를 담고 있음을 추론할 수 있다.</p>
<p>레이어마다 patch를 잘라 output을 만들었을 때 Frechet Inception Distance (FID)가 작다면 해당 patch는 주변 정보로부터 less dependence 한 것이고, FID가 높다면 dependent 한 것임을 나타낼 것이다.</p>
<figure>
    <img src="/images/post/rewriting/4.jpg"
         alt="Fig. 13: FID of rendered cropped activations with respect to random crops of StyleGANv2 generated images" width="100%"/> <figcaption>
            <p>Fig. 13: FID of rendered cropped activations with respect to random crops of StyleGANv2 generated images</p>
        </figcaption>
</figure>

<p>그래프에서 6~11번째 layer가 FID가 가장 낮았고, 이 layer에서 key 값은 주변과 independent 한 정보를 가지고 있을 확률이 높다. 즉, 어느 한 layer의 key를 수정해야 한다면, 해당 layer를 수정하는 것이 object를 render 하는데 좋은 quality의 이미지를 만들 수 있음을 나타낸다.</p>
<figure>
    <img src="/images/post/rewriting/5.jpg"
         alt="Fig. 14: Comparison of rendered cropped activations at various layers of Style- GANv2 generated LSUN church images." width="100%"/> <figcaption>
            <p>Fig. 14: Comparison of rendered cropped activations at various layers of Style- GANv2 generated LSUN church images.</p>
        </figcaption>
</figure>

<p><strong>Experiment</strong></p>
<p>이제 User는 copy&amp;paste를 통해 image에 원하는 부분을 수정하고 (key-value), 몇몇 context image에 수정되었으면 하는 부분(key-context)을 표기하여 rewriter에게 전달한다.</p>
<p>rewriter은 해당 key-context로부터 direction을 계산하고, pasted image와 original image 사이의 L1-loss를 기반으로 projected-optimization을 진행한다. 이에 따라 일반화된 model을 얻을 수 있고, editing을 마치게 된다.</p>
<figure>
    <img src="/images/post/rewriting/6.jpg"
         alt="Fig. 7: Giving horses a hat to wear." width="100%"/> <figcaption>
            <p>Fig. 7: Giving horses a hat to wear.</p>
        </figcaption>
</figure>

<p><strong>Discussion</strong></p>
<p>저자는 GPT-3, WaveNet과 같이 image 이외의 분야에서도 vastly trained model에 rule을 수정하고자 하는 일이 있을 것이고, model rewriting은 이 경우에 새로운 contents, behavior, interaction을 부여할 충분한 방법론일 것이라 이야기한다.</p>
<p><strong>Implementation</strong></p>
<ul>
<li>pytorch, official: <a href="https://github.com/davidbau/rewriting">rewriting</a></li>
</ul>
<p><strong>References</strong></p>
<ol>
<li>Progressive Growing of GANs for Improved Quality, Stability, and Variation, Tero Karras et al., 2017, <a href="https://arxiv.org/abs/1710.10196">arXiv:1710.10196</a>.</li>
<li>Analyzing and Improving the Image Quality of StyleGAN, Tero Karras et al., 2019. <a href="https://arxiv.org/abs/1912.04958">arXiv:1912.04958</a>.</li>
</ol>

        </div>

        
        
      </div>
    </div>
  </div>
</section>

<footer>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center mb-5">
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark" href="tel:"><i
                class="ti-mobile mr-3 text-primary"></i></a></li>
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>Seoul, Korea</li>
          <li class="mb-3"><a class="text-dark" href="mailto:revsic99@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>revsic99@gmail.com</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://www.facebook.com/profile.php?id=100009484787654">facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://github.com/revsic">github</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.linkedin.com/in/young-joong-kim-878630154/">linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/bayesian">Bayesian</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/generative">Generative</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/portfolio">Portfolio</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="/about">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="/blog">Post</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2020 <a href="https://revsic.github.io">YoungJoong Kim</a> All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "/index.json"
</script>

<!-- JS Plugins -->

<script src="/plugins/jQuery/jquery.min.js"></script>

<script src="/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/plugins/slick/slick.min.js"></script>

<script src="/plugins/venobox/venobox.min.js"></script>

<script src="/plugins/search/fuse.min.js"></script>

<script src="/plugins/search/mark.js"></script>

<script src="/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="/js/script.min.js"></script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</body>
</html>