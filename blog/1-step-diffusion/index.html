<!DOCTYPE html>
<html lang="ko-kr"><head>
  <meta charset="utf-8">
  <title>revsic | ML Developer</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Essay: VAE as a 1-step Diffusion Model">
  <meta name="author" content="YoungJoong Kim">
  <meta name="generator" content="Hugo 0.125.7">

  <!-- plugins -->
  
  <link rel="stylesheet" href="/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="/plugins/slick/slick.css ">
  
  <link rel="stylesheet" href="/plugins/themify-icons/themify-icons.css ">
  
  <link rel="stylesheet" href="/plugins/venobox/venobox.css ">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="/scss/style.min.css" media="screen">

</head><body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom">
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <div class="desktop-view">
          <ul class="navbar-nav mr-auto">
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.facebook.com/profile.php?id=100009484787654"><i class="ti-facebook"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://github.com/revsic"><i class="ti-github"></i></a>
            </li>
            
            <li class="nav-item">
              <a class="nav-link" href="https://www.linkedin.com/in/young-joong-kim-878630154/"><i class="ti-linkedin"></i></a>
            </li>
            
          </ul>
        </div>

        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://revsic.github.io/"> Home </a>
          </li>
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about">About</a>
          </li>
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/blog">Post</a>
          </li>
          
          
        </ul>

        
        <!-- search -->
        <div class="search px-4">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://revsic.github.io//search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        

        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation -->

<section class="section-sm">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        
        <a href="/categories/bayesian"
          class="text-primary">Bayesian</a>
        
        <h2>Essay: VAE as a 1-step Diffusion Model</h2>
        <div class="mb-3 post-meta">
          <span>By YoungJoong Kim</span>
          
          <span class="border-bottom border-primary px-2 mx-1"></span>
          <span>13 October 2024</span>
          
        </div>
        
        <img src="/images/post/1-step-diffusion/vae.png" class="img-fluid w-100 mb-4" alt="Essay: VAE as a 1-step Diffusion Model">
        
        <div class="content mb-5">
          <p>아래 글은 비공식적인 개인의 사견임을 밝힌다.</p>
<ul>
<li>Essay on VAE and its relationship to diffusion model</li>
<li>Keyword: VAE, Diffusion Model, VDM, VLB</li>
</ul>
<p><strong>Introduction</strong></p>
<p>DDPM[<a href="https://arxiv.org/abs/2006.11239">arXiv:2006.11239</a>] 이후 Diffusion Model은 그 합성 품질에 힘입어 빠른 속도로 발전해 왔다.</p>
<p>DDPM과 VAE[<a href="https://arxiv.org/abs/1312.6114">arXiv:1312.6114</a>]는 동일하게 Variational Lowerbounds(이하 VLB)를 통해 학습되지만, DDPM에서 더 High-fidelity의 이미지를 생성한다.</p>
<p>DDPM은 어떻게 VAE 보다 더 실제같은 이미지를 생성할 수 있었는가, 그에 대해 논의한다.</p>
<table>
<thead>
<tr>
<th></th>
<th>VAE</th>
<th>DDPM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Objective</td>
<td>VLB</td>
<td>VLB</td>
</tr>
<tr>
<td>Size of latent variable</td>
<td>Smaller than data dimension</td>
<td>Same with data dimension</td>
</tr>
<tr>
<td>Generation</td>
<td>Single forward pass</td>
<td>Multiple forward passe (T-steps)</td>
</tr>
<tr>
<td>Architecture</td>
<td>Autoencoder w/Bottleneck</td>
<td>U-Net w/Time-embedding</td>
</tr>
</tbody>
</table>
<p><strong>Revisit: Variational Lowerbounds</strong></p>
<p>VAE는 몇 가지 문제 상황을 가정한다.</p>
<p>어떤 데이터셋 $X = \{x_i\}^N_{i=1}$는 Random variable $x$에서 i.i.d.로 샘플링되었다. 우리는 이 데이터가 관측되지 않은 random variable $z$에 어떤 random process를 취해 생성되었다 가정할 것이다.</p>
<p>$z$는 prior distribution $p(z)$에서 샘플링되고, $x$는 조건부 분포 $p(x|z;\theta)$에 의해 생성된다. (그리고 각 분포는 $z$와 $\theta$에 대해 미분가능하다 가정한다)</p>
<p>우리는 $p(z)$가 어떻게 생긴 분포인지 모르기 때문에, $p(x; \theta) = \int p(z)p(x|z; \theta)dz$의 marginalize가 불가능하다. (그렇기에 true posterior $p(z|x) = p(x|z)p(z)/(x)$ 역시 연산 불가능하다)</p>
<p>이에 대응하고자 VAE에서는 approximate posterior $q(z|x; \phi)$를 도입하여 $\phi$와 $\theta$를 동시에 업데이트할 수 있는 objective function $\mathcal L$을 제안하였다.</p>
<p>$$\log p(x;\theta) = \mathcal L(x; \theta, \phi) + D_{KL}(q(z|x;\phi) || p(z|x;\theta))$$
$$\mathcal L(x; \theta, \phi) = \mathbb E_{q(z|x; \phi)}\left[\log p(x|z; \theta)\right] - D_{KL}(q(z|x; \phi)||p(z))$$</p>
<p>$D_{KL}$은 0 이상 값을 가지므로 $\mathcal L(\theta, \phi; x)$는 log-likelihood의 하한이 되고, 이를 optimizing 하면 log-likelihood를 ascent 하는 것과 같은 효과를 볼 수 있다는 것이다.</p>
<p>DDPM 역시 Markov chain에 대한 variational lowerbound를 ascent 하는 방식으로 학습을 수행한다.</p>
<p>$x = x_0,\ z = x_T \sim \mathcal N(0, I)$의 T-step Diffusion Model을 가정할 때, variance schedule $\beta_1, &hellip;\beta_T$에 대해 forward process(noising) $q(x_t|x_{t-1})$와 reverse process(denoising) $p(x_{t-1}|x_t; \theta)$를 가정한다.</p>
<p>$$q(x_t|x_{t-1}) = \mathcal N(\sqrt{1 - \beta_t}x_{t-1}, \beta_t I), \ p(x_{t-1}|x_t; \theta) = \mathcal N(\mu_\theta(x_t; t), \Sigma_\theta(x_t, t))$$</p>
<p>이때 VLB는 동일하게 적용된다.</p>
<p>$$\log p(x; \theta) \ge \mathbb E_{q(x_0|x)}[\log p(x|x_0)] + \mathcal L_{T}(x; \theta) - D_{KL}(q(x_T|x)||p(z))$$
$$\mathcal L_{T}(x; \theta) = -\sum^T_{i=1}\mathbb E_{q(x_i|x)} D_{KL}\left[q(x_{i-1}|x_i, x)||p(x_{i-1}|x_i; \theta)\right]$$</p>
<p>학습 목적 함수는 사실상 같다고 봐야 한다.</p>
<p><strong>Size of latent variables</strong></p>
<p>VAE와 Diffusion Model의 차이로 떠오르는 것은 Bottleneck Architecture이다.</p>
<p>VAE는 latent variable의 dimension은 대개 데이터보다 작다. Diffusion은 markov chain 내의 state를 모두 latent variable로 바라보고, 각각의 latent variable은 데이터의 dimension과 크기가 같다.</p>
<p>작은 latent variable은 초기 GAN[<a href="https://arxiv.org/abs/1406.2661">arXiv:1406.2661</a>] 기반의 모델에서도 공통으로 나타나는 특징이다.</p>
<p>이후 VAE와 GAN 모두, 데이터 차원과 같은 크기의 잠재 변수를 도입하여 성능 향상을 본 모델이 나온다. StyleGAN[<a href="https://arxiv.org/abs/1812.04948">arXiv:1812.04948</a>]은 이미지의 stochastic detail을 생성하기 위해 $\mathbb R^{\mathrm{H\times W\times 1}}$의 single-channel noise를 더하였고, NVAE[<a href="https://arxiv.org/abs/2007.03898">arXiv:2007.03898</a>]는 U-Net-like architecture를 도입하면서 residual signal을 latent variable로 모델링한다.</p>
<figure><img src="/images/post/1-step-diffusion/1.png"
    alt="Left: Figure 1, Karras et al.(StyleGAN), 2018 / Right: Figure 2, Vahdat &amp;amp; Kautz(NVAE), 2020." width="100%"><figcaption>
      <p>Left: Figure 1, Karras et al.(StyleGAN), 2018 / Right: Figure 2, Vahdat &amp; Kautz(NVAE), 2020.</p>
    </figcaption>
</figure>

<p>다만 둘 모두 이론적 근거를 제시하기보단 Ablation study를 통해 정량적, 정성적 개선 정도를 보인다.</p>
<p>이미지의 대략적인 형상과 배치 등 lower frequency의 정보는 작은 잠재 변수 공간에서 capture 할 수 있지만, Higher frequency의 정보를 capture 하기 위해서는 spatial information에 correlate 된 latent variable이 있어야 하지 않을까 싶은 정도이다.</p>
<p>VAE와 Diffusion의 합성 품질 차이는 latent variable의 크기에서 일부 기인했을 것으로 보인다.</p>
<p><strong>VAE as a 1-step Diffusion Model</strong></p>
<p>VAE가 이미지와 같은 크기의 잠재 변수를 취급하고, $z \mapsto x$의 매핑을 U-Net으로 모델링한다 가정하자. 동일하게 VLB를 통해 학습되고, 잠재 변수의 크기도 이미지의 차원과 같으며, U-Net을 디코더 백본으로 사용한다.</p>
<p>주어진 가정 아래 VAE는 $\beta_1 = 1$의 variance schedule을 가지는 T=1의 Single-step diffusion model로 볼 수 있다. T=1 이므로 timestep embedding을 배제하고 학습하여도 무방하며, timestep embdding을 포함하여 DDPM과 완전히 동일한 백본을 가정할 수도 있다.</p>
<p>$$q(x_1|x_0) = \mathcal N(\sqrt{1 - \beta_1}x_0, \beta_1 I) = \mathcal N(0, I) \Leftrightarrow p(z)$$
$$p(x_0|x_1) = \mathcal N(\mu_\theta(x_1), \Sigma_\theta(x_1)) \Leftrightarrow p(x|z; \theta)$$</p>
<p>1-step Diffusion model은 $x_0 = x, z = x_1 \sim \mathcal N(0, I)$을 상정하므로, 단순 이름 바꾸기를 통해 $p(x|z; \theta) = p(x_0|x_1; \theta)$를 얻을 수 있고, 이는 VAE의 generation process와 같다.</p>
<p>이 경우 Encoder의 위치에 관하여 고민해 볼 필요가 있다. VAE는 Encoder를 통해 posterior를 근사하지만, DDPM은 variance schedule을 통해 chain의 끝이 prior distribution에 충분히 가깝도록 설계한다.</p>
<p>$$\bar\alpha_t = \prod^t_{i=1}(1 - \beta_i) \Rightarrow q(x_t|x_0) = \mathcal N(\sqrt{\bar\alpha_t}x_0, (1 - \bar\alpha_t)I)$$</p>
<p>일반화를 위해 기존의 $q(x_t|x)$를 $q(x_t|x; \psi)$로 parametrize하고, $D_{KL}(q(x_T|x; \psi)||p(z))$ 역시 학습의 대상으로 삼자. 이 경우 $x_t = \sqrt{\bar\alpha_t}x + \sqrt{1 - \bar\alpha_t}\epsilon_\psi\ \mathrm{where}\ \epsilon_\psi \sim \mathcal N(\mu_\psi(x), \sigma^2_\psi(x))$로 모델링하여 VAE와 같이 $D_{KL}(\mathcal N(\mu_\psi(x), \Sigma_\psi(x))||p(z))$가 학습되도록 한다. ($\because x_T = 0\cdot x + 1\cdot\epsilon_\psi = \epsilon_\psi$)</p>
<p>$\mathcal L_T$의 $D_{KL}(q(x_{i-1}|x_i, x; \psi)||p(x_{i-1}|x_i; \theta))$는 $||x - x_\theta(\sqrt{\bar\alpha_t}x + \sqrt{1 - \bar\alpha_t}\epsilon_\psi; t)||^2_2$의 noise estimation loss 형태로 표현해 볼 수 있다. (w/reparametrization $\epsilon_\psi = \mu_\psi(x) + \sigma_\psi(x)\epsilon,\ \epsilon \sim \mathcal N(0, I)$)</p>
<p>이제 둘의 마지막 차이는 step의 수뿐이다.</p>
<p><strong>More step is better</strong></p>
<p>VDM[<a href="https://arxiv.org/abs/2107.00630">arXiv:2107.00630</a>]에서는 step의 수가 많을수록 더 tight 한 VLB의 하한을 얻을 수 있다고 이야기한다.</p>
<p>variance preserving diffusion model에서의 SNR(signal-to-noise ratio)을 $\gamma^2_t = \frac{\bar\alpha_t}{1 - \bar\alpha_t}$로 표현하면, variance schedule $\beta_1, &hellip;\beta_{2T}$에 대해 목적함수 $\mathcal L_{2T}$는 다음으로 정리할 수 있다.</p>
<p>$$\mathcal L_{2T}(x; \theta) = -\frac{1}{2}\mathbb E_{\epsilon \sim \mathcal N(0, I)}\left[\sum^{2T}_ {t=1}(\gamma^2_{t-1} - \gamma^2_t)||x - x_\theta(x_t; t)||^2_2\right]$$</p>
<p>variance schedule을 유지한 채 step을 절반으로 줄이면 다음과 같이 표현할 수 있다.</p>
<p>$$\mathcal L_T(x; \theta) = -\frac{1}{2}\mathbb E_{\epsilon \sim\mathcal N(0, I)}\left[\sum^T_{t=1}(\gamma^2_{2(t-1)} - \gamma^2_{2t})||x - x_\theta(x_{2t}; 2t)||^2_2\right]$$</p>
<p>우리가 보이고 싶은 것은 $\mathcal L_{2T} - \mathcal L_T &gt; 0$가 성립하여 $\mathcal L_{2T}$가 $\log p(x; \theta)$에 더 가까운 하한이라는 것이다.</p>
<p>$$\mathcal L_T(x; \theta) = -\frac{1}{2}\mathbb E_{\epsilon\sim\mathcal N(0, I)}\left[\sum^T_{t=1}(\gamma^2_{2(t-1)} - \gamma^2_{2t - 1} + \gamma^2_{2t - 1} - \gamma^2_{2t})||x - x_\theta(x_{2t}; 2t)||^2_2\right]$$
$$\begin{align*}\mathcal L_{2T}(x; \theta) = -\frac{1}{2}\mathbb E_{\epsilon\sim\mathcal N(0, I)}&amp;\left[\sum^T_{t=1}(\gamma^2_{2t - 1} - \gamma^2_{2t})||x - x_\theta(x_{2t}; 2t)||^2_2\right. \\&amp;+ \left.\sum^T_{t=1}(\gamma^2_{2(t-1)} - \gamma^2_{2t-1})||x - x_\theta(x_{2t-1}; 2t-1)||^2_2 \right]\end{align*}$$
$$\mathcal L_{2T}(x; \theta) - \mathcal L_{T}(x; \theta) = -\frac{1}{2}\mathbb E_{\epsilon\sim\mathcal N(0, I)}\left[\sum^T_{t=1} (\gamma^2_{2(t-1)} - \gamma^2_{2t-1})(||x - x_\theta(x_{2t-1}; 2t-1)||^2_2 - ||x - x_\theta(x_{2t}; 2t)||^2_2) \right]$$</p>
<p>variance schedule에서 $\gamma_t$는 대개 감소함수로 설정되므로, $\gamma^2_{2(t-1)} - \gamma^2_{2t-1}$은 양수이다.</p>
<p>$||x - x_\theta(x_{2t-1}; 2t-1)||^2_2 - ||x - x_\theta(x_{2t}; 2t)||^2_2$는 2t-1번째 스텝에서 추정한 데이터와 2t번째 스텝에서 추정한 데이터 각각의 MSE를 다룬다. 잘 학습된 네트워크 입장에서는 상대적으로 SNR이 높은 2t-1번째 스텝에서 데이터를 추정하기 더 쉬울 것이고, 그렇기에 MSE 값은 상대적으로 낮게 측정될 것이다. 결국 MSE의 차는 음수로 떨어진다.</p>
<p>가장 앞단의 부호를 포함하면 $\mathcal L_{2T} - \mathcal L_T$는 양수가 되고, $\mathcal L_{2T}$가 tighter lower bound가 된다.</p>
<p>VAE를 1-step Diffusion model로 볼 경우, 1천 스텝 정도를 다루는 Diffusion model에 대비하여 NLL(Negative log-likelihood)이 높게 측정될 가능성이 높다. 물론 NLL이 낮다고 visual quality가 좋은 것은 아니나, 그 가능성 측면에서는 유의미하게 해석할 수 있는 지표일 것이다.</p>
<p><strong>How about a 1,000-step VAE ?</strong></p>
<p>반대로 VAE를 Diffusion model처럼 1천번 forward pass 하여 성능 개선이 가능할지도 고민해 볼 법하다. 네트워크로부터 데이터 포인트를 생성하고, forward process(noising)을 거쳐 다시 네트워크에 통과시키는 것을 가정하자.</p>
<p>$$\tilde x_t = \mathrm{Decoder}(x_t; \theta),\ x_{t-1} = \sqrt{\bar\alpha_{t-1}}\tilde x_t + \sqrt{1 - \bar\alpha_{t-1}}\epsilon\ \mathrm{where}\ \epsilon \sim \mathcal N(0, I),\ t=1000,&hellip;,0$$</p>
<p>Diffusion model은 $D_{KL}(q(x_{i-1}|x_i, x)||p(x_{i-1}|x_i; \theta))$을 통해 하나의 데이터를 두고, noised sample에서 noise를 줄여가는 방향으로 학습한다. 충분히 작은 noise를 데이터에 더하여 t=1의 네트워크에 통과시킬 경우, 네트워크의 출력물로 원본 데이터가 나올 것이라 기대할 수 있다.</p>
<figure><img src="/images/post/1-step-diffusion/2.png"
    alt="Generation trajectory (Figure 1, Song et al., 2023)" width="100%"><figcaption>
      <p>Generation trajectory (Figure 1, Song et al., 2023)</p>
    </figcaption>
</figure>

<p>반면 VAE는 $0.99999\times x + 0.00001\times\epsilon$을 입력으로 하여도 $x$가 나올 것이라 기대할 수 없다. VAE는 학습 중에 posterior를 prior에 가까워지게 할 뿐이다. 보수적으로는 noised sample 역시 prior에서 샘플링하였다 가정해야 하고, 1천번의 수행 과정에서 1천개의 서로 다른 이미지가 나올 수도 있다.</p>
<p>이를 대응하기 위해서는 noised sample에 대해 원본 샘플이 나오도록 학습해야 하고, Consistency model[<a href="https://arxiv.org/abs/2303.01469">arXiv:2303.01469</a>]과도 관련이 있어 보인다.</p>
<p>$$\mathcal L(\theta, \theta^-) \leftarrow \lambda(t_n)d(f_\theta(x + t_{n+1}z, t_{n+1}), f_{\theta^-}(x + t_nz, t_n))$$</p>
<p><strong>Wrap up</strong></p>
<p>Diffusion의 합성 품질은 latent variable의 크기와 sampling step의 수에 기인했을 것으로 보인다. 또한 VAE를 1-step Diffusion으로 해석할 수도 있으나, 1000-step VAE로는 성능 향상을 기대할 수 없다는 것도 확인하였다.</p>
<p>근래에는 datum point를 prior distribution으로 transport 하는 trajectory에 관하여도 연구가 많은 듯 보인다. 이에 관하여도 연관하여 고민하면 좋을 듯하다.</p>
<p><strong>References</strong></p>
<ul>
<li>Consistency Models, Song et al., 2023. [<a href="https://arxiv.org/abs/2303.01469">arXiv:2303.01469</a>]</li>
<li>VDM: Variational Diffusion Models, Kingma et al., 2021. [<a href="https://arxiv.org/abs/2107.00630">arXiv:2107.00630</a>]</li>
<li>NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat &amp; Kautz, 2020. [<a href="https://arxiv.org/abs/2007.03898">arXiv:2007.03898</a>]</li>
<li>DDPM: Denoising Diffusion Probabilistic Models, Ho et al., 2020. [<a href="https://arxiv.org/abs/2006.11239">arXiv:2006.11239</a>]</li>
<li>StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks, Karras et al., 2018. [<a href="https://arxiv.org/abs/1812.04948">arXiv:1812.04948</a>]</li>
<li>GAN: Generative Adversarial Networks, Goodfellow et al., 2014. [<a href="https://arxiv.org/abs/1406.2661">arXiv:1406.2661</a>]</li>
<li>VAE: Autoencoding Variational Bayes, Kingma &amp; Welling, 2013. [<a href="https://arxiv.org/abs/1312.6114">arXiv:1312.6114</a>]</li>
</ul>

        </div>

        
        
      </div>
    </div>
  </div>
</section>

<footer>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center mb-5">
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Contact Me</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark" href="tel:"><i
                class="ti-mobile mr-3 text-primary"></i></a></li>
          <li class="mb-3"><i class="ti-location-pin mr-3 text-primary"></i>Seoul, Korea</li>
          <li class="mb-3"><a class="text-dark" href="mailto:revsic99@gmail.com"><i
                class="ti-email mr-3 text-primary"></i>revsic99@gmail.com</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Social Contacts</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="https://www.facebook.com/profile.php?id=100009484787654">facebook</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://github.com/revsic">github</a></li>
          
          <li class="mb-3"><a class="text-dark" href="https://www.linkedin.com/in/young-joong-kim-878630154/">linkedin</a></li>
          
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Categories</h6>
        <ul class="list-unstyled">
          <li class="mb-3"><a class="text-dark"
              href="/categories/attention">Attention</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/bayesian">Bayesian</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/generative">Generative</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/portfolio">Portfolio</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/software-testing">Software testing</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/vocoder">Vocoder</a>
          </li>
          <li class="mb-3"><a class="text-dark"
              href="/categories/writing">Writing</a>
          </li>
        </ul>
      </div>
      <div class="col-lg-3 col-sm-6 mb-5">
        <h6 class="mb-4">Quick Links</h6>
        <ul class="list-unstyled">
          
          <li class="mb-3"><a class="text-dark" href="/about">About</a></li>
          
          <li class="mb-3"><a class="text-dark" href="/blog">Post</a></li>
          
        </ul>
      </div>
      <div class="col-12 border-top py-4 text-center">
        | copyright © 2020 <a href="https://revsic.github.io">YoungJoong Kim</a> All Rights Reserved |
      </div>
    </div>
  </div>
</footer>

<script>
  var indexURL = "/index.json"
</script>

<!-- JS Plugins -->

<script src="/plugins/jQuery/jquery.min.js"></script>

<script src="/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/plugins/slick/slick.min.js"></script>

<script src="/plugins/venobox/venobox.min.js"></script>

<script src="/plugins/search/fuse.min.js"></script>

<script src="/plugins/search/mark.js"></script>

<script src="/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="/js/script.min.js"></script>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$']],
    }
  }
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.4/tex-mml-chtml.js"></script>
</body>
</html>